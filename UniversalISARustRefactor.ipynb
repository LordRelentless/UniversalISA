{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPecTqGCkohBesq/Vnm0SlP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LordRelentless/UniversalISA/blob/main/UniversalISARustRefactor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjKsNvkeYURG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cb16482",
        "outputId": "6c41cba0-0ed9-4aad-c2a5-328842ac493c"
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| + n_|y, η| = n_|x+y, ξ+η|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| · n_|y, η| = n_|x·y, ξ·η|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ξ| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ξ_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register.\n",
        "    A triplet block collapses if 'both high AND low values coexist' in the real\n",
        "    component within that block, or similarly for the unreal component.\n",
        "    If a triplet collapses, all 3 indices corresponding to that triplet are marked.\n",
        "    COLL(x, χ) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for real component (should be negative).\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    def _mark_block_phase_dual(block_real, block_unreal):\n",
        "        \"\"\"\n",
        "        Helper to mark collapse within a specific block for phase-dual components.\n",
        "        block_real and block_unreal shapes: [Q, block_size]\n",
        "        \"\"\"\n",
        "        # Collapse detection for REAL component: high AND low coexistence\n",
        "        high_real = tf.cast(block_real >= tau_hi, tf.int32)\n",
        "        low_real  = tf.cast(block_real <= tau_low, tf.int32)\n",
        "        any_h_real = tf.reduce_max(high_real, axis=1, keepdims=True) # [Q,1] (1 if any element is >= tau_hi)\n",
        "        any_l_real = tf.reduce_max(low_real,  axis=1, keepdims=True)  # [Q,1] (1 if any element is <= tau_low)\n",
        "        collapse_condition_real = tf.logical_and(any_h_real > 0, any_l_real > 0) # [Q,1]\n",
        "\n",
        "        # Collapse detection for UNREAL component: high AND low coexistence\n",
        "        high_unreal = tf.cast(block_unreal >= tau_hi, tf.int32)\n",
        "        low_unreal  = tf.cast(block_unreal <= tau_low, tf.int32)\n",
        "        any_h_unreal = tf.reduce_max(high_unreal, axis=1, keepdims=True) # [Q,1]\n",
        "        any_l_unreal = tf.reduce_max(low_unreal,  axis=1, keepdims=True)  # [Q,1]\n",
        "        collapse_condition_unreal = tf.logical_and(any_h_unreal > 0, any_l_unreal > 0) # [Q,1]\n",
        "\n",
        "        # A unit collapses if collapse is detected in EITHER real OR unreal components' blocks\n",
        "        unit_collapse_flag = tf.logical_or(collapse_condition_real, collapse_condition_unreal) # [Q,1]\n",
        "        unit_collapse_flag_int = tf.cast(unit_collapse_flag, tf.int32) # [Q,1]\n",
        "\n",
        "        # Mark all elements within the block if the block-level collapse flag is true\n",
        "        # for that qubit. This marks individual selectors within the block as collapsed.\n",
        "        mark = tf.broadcast_to(unit_collapse_flag_int, tf.shape(block_real)) # [Q, block_size]\n",
        "        return mark\n",
        "\n",
        "    # Initialize a collapse mask filled with zeros\n",
        "    collapse_mask = tf.zeros(tf.shape(real_parts), dtype=tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Iterate over each triplet block and apply collapse detection\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # Extract real and unreal parts for the current triplet across all Q qubits\n",
        "        # shape [Q, 3]\n",
        "        triplet_real_block = tf.gather(real_parts, current_triplet_indices, axis=1)\n",
        "        triplet_unreal_block = tf.gather(unreal_parts, current_triplet_indices, axis=1)\n",
        "\n",
        "        # Apply collapse detection for this triplet block\n",
        "        # Returns [Q, 3] where each element is marked if the *triplet block* collapsed\n",
        "        marked_triplet_block = _mark_block_phase_dual(triplet_real_block, triplet_unreal_block) # [Q, 3]\n",
        "\n",
        "        # Construct indices for scatter_nd_max to update the global collapse_mask\n",
        "        # indices_to_update will be [Q*3, 2]\n",
        "        # First column is qubit index, second is original 30-index\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1)\n",
        "\n",
        "        # Flatten marked_triplet_block to [Q*3] for updates\n",
        "        updates = tf.reshape(marked_triplet_block, [-1])\n",
        "\n",
        "        # Use tf.tensor_scatter_nd_max to update the collapse_mask.\n",
        "        # This ensures that if any triplet marks an index as collapsed, it remains marked.\n",
        "        collapse_mask = tf.tensor_scatter_nd_max(collapse_mask, indices_to_update, updates)\n",
        "\n",
        "    return collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components. Implements ASSOC(A, B, α) logic.\n",
        "\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`).\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode('utf-8')).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    for b_idx in range(10):\n",
        "        s = signs[b_idx*3:(b_idx+1)*3] # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        trip_mix.extend([has_mix]*3) # Apply this mix flag to all 3 indices of the triplet\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook: Derives corrected bits from tuplet order if current bits are inconsistent.\n",
        "    Updates Bits[q] and ResonanceKey[q] if correction occurs.\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs)\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primaries In:\n",
            " [[[ 0.2541511   0.8986068 ]\n",
            "  [-0.2541511  -0.8986068 ]\n",
            "  [-0.09633875  0.35258794]\n",
            "  [ 0.09633875 -0.35258794]\n",
            "  [-0.3163607  -0.04357171]\n",
            "  [ 0.3163607   0.04357171]]\n",
            "\n",
            " [[-0.6968477  -0.17868495]\n",
            "  [ 0.6968477   0.17868495]\n",
            "  [-0.20259881  0.7930813 ]\n",
            "  [ 0.20259881 -0.7930813 ]\n",
            "  [-0.38047624 -0.13316798]\n",
            "  [ 0.38047624  0.13316798]]\n",
            "\n",
            " [[-0.34390664 -0.58339953]\n",
            "  [ 0.34390664  0.58339953]\n",
            "  [ 0.5035124  -0.86647725]\n",
            "  [-0.5035124   0.86647725]\n",
            "  [-0.8744559  -0.61148405]\n",
            "  [ 0.8744559   0.61148405]]\n",
            "\n",
            " [[-0.17083311  0.20602894]\n",
            "  [ 0.17083311 -0.20602894]\n",
            "  [ 0.5869796   0.47984862]\n",
            "  [-0.5869796  -0.47984862]\n",
            "  [ 0.32479215  0.8408687 ]\n",
            "  [-0.32479215 -0.8408687 ]]\n",
            "\n",
            " [[ 0.9069524  -0.5122864 ]\n",
            "  [-0.9069524   0.5122864 ]\n",
            "  [ 0.68847966 -0.11749649]\n",
            "  [-0.68847966  0.11749649]\n",
            "  [ 0.4480846  -0.01048684]\n",
            "  [-0.4480846   0.01048684]]\n",
            "\n",
            " [[ 0.20893955 -0.87714624]\n",
            "  [-0.20893955  0.87714624]\n",
            "  [-0.4830606   0.38656855]\n",
            "  [ 0.4830606  -0.38656855]\n",
            "  [ 0.9871509   0.9589827 ]\n",
            "  [-0.9871509  -0.9589827 ]]\n",
            "\n",
            " [[-0.34618258  0.28782773]\n",
            "  [ 0.34618258 -0.28782773]\n",
            "  [-0.8187847   0.20081687]\n",
            "  [ 0.8187847  -0.20081687]\n",
            "  [-0.29898405 -0.74265623]\n",
            "  [ 0.29898405  0.74265623]]\n",
            "\n",
            " [[ 0.4076438   0.5755899 ]\n",
            "  [-0.4076438  -0.5755899 ]\n",
            "  [-0.7495625   0.7552254 ]\n",
            "  [ 0.7495625  -0.7552254 ]\n",
            "  [-0.52618074 -0.983804  ]\n",
            "  [ 0.52618074  0.983804  ]]\n",
            "\n",
            " [[-0.25623488 -0.43343544]\n",
            "  [ 0.25623488  0.43343544]\n",
            "  [ 0.16891336  0.0972681 ]\n",
            "  [-0.16891336 -0.0972681 ]\n",
            "  [ 0.10404992 -0.06385565]\n",
            "  [-0.10404992  0.06385565]]\n",
            "\n",
            " [[-0.23034692  0.09536624]\n",
            "  [ 0.23034692 -0.09536624]\n",
            "  [-0.41157293  0.63549614]\n",
            "  [ 0.41157293 -0.63549614]\n",
            "  [ 0.3296647   0.85622907]\n",
            "  [-0.3296647  -0.85622907]]\n",
            "\n",
            " [[ 0.6063554   0.4688058 ]\n",
            "  [-0.6063554  -0.4688058 ]\n",
            "  [ 0.4971156   0.21038151]\n",
            "  [-0.4971156  -0.21038151]\n",
            "  [ 0.57845044  0.22871423]\n",
            "  [-0.57845044 -0.22871423]]\n",
            "\n",
            " [[-0.63472676  0.65557146]\n",
            "  [ 0.63472676 -0.65557146]\n",
            "  [ 0.08368301 -0.8355355 ]\n",
            "  [-0.08368301  0.8355355 ]\n",
            "  [ 0.06763959  0.8346045 ]\n",
            "  [-0.06763959 -0.8346045 ]]\n",
            "\n",
            " [[ 0.45410585 -0.14694834]\n",
            "  [-0.45410585  0.14694834]\n",
            "  [ 0.6284754   0.17448306]\n",
            "  [-0.6284754  -0.17448306]\n",
            "  [ 0.32329297 -0.60235953]\n",
            "  [-0.32329297  0.60235953]]\n",
            "\n",
            " [[ 0.15164804 -0.8104987 ]\n",
            "  [-0.15164804  0.8104987 ]\n",
            "  [ 0.7668028  -0.3891728 ]\n",
            "  [-0.7668028   0.3891728 ]\n",
            "  [ 0.3754933  -0.11771894]\n",
            "  [-0.3754933   0.11771894]]\n",
            "\n",
            " [[-0.04900622  0.37060118]\n",
            "  [ 0.04900622 -0.37060118]\n",
            "  [ 0.37204862 -0.09909964]\n",
            "  [-0.37204862  0.09909964]\n",
            "  [-0.4053688  -0.9312525 ]\n",
            "  [ 0.4053688   0.9312525 ]]\n",
            "\n",
            " [[-0.8216121  -0.6204829 ]\n",
            "  [ 0.8216121   0.6204829 ]\n",
            "  [ 0.23405337  0.87406254]\n",
            "  [-0.23405337 -0.87406254]\n",
            "  [-0.53863597  0.9185085 ]\n",
            "  [ 0.53863597 -0.9185085 ]]\n",
            "\n",
            " [[-0.53731036 -0.96753645]\n",
            "  [ 0.53731036  0.96753645]\n",
            "  [-0.5809164   0.28987598]\n",
            "  [ 0.5809164  -0.28987598]\n",
            "  [-0.40555954 -0.08609557]\n",
            "  [ 0.40555954  0.08609557]]\n",
            "\n",
            " [[ 0.69717836  0.32225895]\n",
            "  [-0.69717836 -0.32225895]\n",
            "  [-0.7273061  -0.3669803 ]\n",
            "  [ 0.7273061   0.3669803 ]\n",
            "  [-0.07356882  0.00898242]\n",
            "  [ 0.07356882 -0.00898242]]\n",
            "\n",
            " [[-0.9728322   0.61183596]\n",
            "  [ 0.9728322  -0.61183596]\n",
            "  [-0.0969491   0.20843053]\n",
            "  [ 0.0969491  -0.20843053]\n",
            "  [-0.03753281  0.9186809 ]\n",
            "  [ 0.03753281 -0.9186809 ]]\n",
            "\n",
            " [[-0.53587556 -0.39849162]\n",
            "  [ 0.53587556  0.39849162]\n",
            "  [-0.45581174 -0.22983289]\n",
            "  [ 0.45581174  0.22983289]\n",
            "  [-0.4319775  -0.20031118]\n",
            "  [ 0.4319775   0.20031118]]\n",
            "\n",
            " [[ 0.8389969   0.67459965]\n",
            "  [-0.8389969  -0.67459965]\n",
            "  [-0.93471956  0.91805935]\n",
            "  [ 0.93471956 -0.91805935]\n",
            "  [ 0.00751734  0.10414004]\n",
            "  [-0.00751734 -0.10414004]]\n",
            "\n",
            " [[ 0.8558607   0.14544487]\n",
            "  [-0.8558607  -0.14544487]\n",
            "  [ 0.9503741   0.90879536]\n",
            "  [-0.9503741  -0.90879536]\n",
            "  [-0.8693168   0.62765527]\n",
            "  [ 0.8693168  -0.62765527]]\n",
            "\n",
            " [[-0.3380654  -0.53420377]\n",
            "  [ 0.3380654   0.53420377]\n",
            "  [ 0.16968441  0.32112026]\n",
            "  [-0.16968441 -0.32112026]\n",
            "  [ 0.16826177  0.6919327 ]\n",
            "  [-0.16826177 -0.6919327 ]]\n",
            "\n",
            " [[-0.829653   -0.1349082 ]\n",
            "  [ 0.829653    0.1349082 ]\n",
            "  [ 0.3239243  -0.49692702]\n",
            "  [-0.3239243   0.49692702]\n",
            "  [-0.6005266  -0.88000464]\n",
            "  [ 0.6005266   0.88000464]]\n",
            "\n",
            " [[-0.7790966  -0.03417945]\n",
            "  [ 0.7790966   0.03417945]\n",
            "  [-0.46971345 -0.636204  ]\n",
            "  [ 0.46971345  0.636204  ]\n",
            "  [-0.64201784 -0.20165157]\n",
            "  [ 0.64201784  0.20165157]]\n",
            "\n",
            " [[ 0.7546921  -0.5017452 ]\n",
            "  [-0.7546921   0.5017452 ]\n",
            "  [ 0.10471773  0.08233452]\n",
            "  [-0.10471773 -0.08233452]\n",
            "  [-0.7484584   0.9942467 ]\n",
            "  [ 0.7484584  -0.9942467 ]]\n",
            "\n",
            " [[ 0.74654484 -0.8335397 ]\n",
            "  [-0.74654484  0.8335397 ]\n",
            "  [-0.14167833 -0.41392326]\n",
            "  [ 0.14167833  0.41392326]\n",
            "  [ 0.9678364   0.4088223 ]\n",
            "  [-0.9678364  -0.4088223 ]]\n",
            "\n",
            " [[-0.3854661   0.32396817]\n",
            "  [ 0.3854661  -0.32396817]\n",
            "  [-0.73682785  0.8718631 ]\n",
            "  [ 0.73682785 -0.8718631 ]\n",
            "  [ 0.67480016 -0.94335794]\n",
            "  [-0.67480016  0.94335794]]\n",
            "\n",
            " [[-0.21993256 -0.9545984 ]\n",
            "  [ 0.21993256  0.9545984 ]\n",
            "  [-0.8151555   0.8103342 ]\n",
            "  [ 0.8151555  -0.8103342 ]\n",
            "  [-0.34187412 -0.07466102]\n",
            "  [ 0.34187412  0.07466102]]\n",
            "\n",
            " [[-0.12183189 -0.9280822 ]\n",
            "  [ 0.12183189  0.9280822 ]\n",
            "  [ 0.0859158  -0.7694745 ]\n",
            "  [-0.0859158   0.7694745 ]\n",
            "  [ 0.56319284 -0.5742674 ]\n",
            "  [-0.56319284  0.5742674 ]]\n",
            "\n",
            " [[-0.6976881  -0.9084077 ]\n",
            "  [ 0.6976881   0.9084077 ]\n",
            "  [-0.66100025  0.7751336 ]\n",
            "  [ 0.66100025 -0.7751336 ]\n",
            "  [ 0.16002774 -0.21837187]\n",
            "  [-0.16002774  0.21837187]]\n",
            "\n",
            " [[-0.0762372   0.33780074]\n",
            "  [ 0.0762372  -0.33780074]\n",
            "  [ 0.7129147  -0.04924059]\n",
            "  [-0.7129147   0.04924059]\n",
            "  [ 0.14065003 -0.6598184 ]\n",
            "  [-0.14065003  0.6598184 ]]\n",
            "\n",
            " [[-0.28247452 -0.3647473 ]\n",
            "  [ 0.28247452  0.3647473 ]\n",
            "  [ 0.62151265 -0.79587245]\n",
            "  [-0.62151265  0.79587245]\n",
            "  [-0.29155278 -0.89939404]\n",
            "  [ 0.29155278  0.89939404]]\n",
            "\n",
            " [[-0.9912634  -0.8659167 ]\n",
            "  [ 0.9912634   0.8659167 ]\n",
            "  [ 0.91509485  0.99379253]\n",
            "  [-0.91509485 -0.99379253]\n",
            "  [ 0.65527177 -0.27965045]\n",
            "  [-0.65527177  0.27965045]]\n",
            "\n",
            " [[-0.34394336 -0.7642858 ]\n",
            "  [ 0.34394336  0.7642858 ]\n",
            "  [ 0.8708377   0.55744934]\n",
            "  [-0.8708377  -0.55744934]\n",
            "  [ 0.55195475 -0.16073895]\n",
            "  [-0.55195475  0.16073895]]\n",
            "\n",
            " [[-0.8361368   0.25015736]\n",
            "  [ 0.8361368  -0.25015736]\n",
            "  [ 0.03969097 -0.08964205]\n",
            "  [-0.03969097  0.08964205]\n",
            "  [ 0.8623097   0.01198578]\n",
            "  [-0.8623097  -0.01198578]]\n",
            "\n",
            " [[-0.24489808  0.86725163]\n",
            "  [ 0.24489808 -0.86725163]\n",
            "  [-0.6545758  -0.5856123 ]\n",
            "  [ 0.6545758   0.5856123 ]\n",
            "  [ 0.55155563 -0.5623071 ]\n",
            "  [-0.55155563  0.5623071 ]]\n",
            "\n",
            " [[-0.2372446   0.4080732 ]\n",
            "  [ 0.2372446  -0.4080732 ]\n",
            "  [ 0.03021049  0.7945528 ]\n",
            "  [-0.03021049 -0.7945528 ]\n",
            "  [ 0.21626186  0.7885394 ]\n",
            "  [-0.21626186 -0.7885394 ]]\n",
            "\n",
            " [[ 0.4881301  -0.3393178 ]\n",
            "  [-0.4881301   0.3393178 ]\n",
            "  [ 0.95537233  0.23382378]\n",
            "  [-0.95537233 -0.23382378]\n",
            "  [ 0.37726307 -0.71787286]\n",
            "  [-0.37726307  0.71787286]]\n",
            "\n",
            " [[ 0.8888395   0.36924148]\n",
            "  [-0.8888395  -0.36924148]\n",
            "  [ 0.6271651  -0.4506867 ]\n",
            "  [-0.6271651   0.4506867 ]\n",
            "  [ 0.8585453  -0.82508683]\n",
            "  [-0.8585453   0.82508683]]\n",
            "\n",
            " [[-0.05425143 -0.9982929 ]\n",
            "  [ 0.05425143  0.9982929 ]\n",
            "  [-0.41296816  0.38862514]\n",
            "  [ 0.41296816 -0.38862514]\n",
            "  [-0.94748235  0.50962305]\n",
            "  [ 0.94748235 -0.50962305]]\n",
            "\n",
            " [[-0.3414235  -0.26264906]\n",
            "  [ 0.3414235   0.26264906]\n",
            "  [-0.8510535  -0.8238685 ]\n",
            "  [ 0.8510535   0.8238685 ]\n",
            "  [ 0.94921637  0.55063224]\n",
            "  [-0.94921637 -0.55063224]]\n",
            "\n",
            " [[ 0.2685666  -0.9434333 ]\n",
            "  [-0.2685666   0.9434333 ]\n",
            "  [-0.04028201 -0.18207788]\n",
            "  [ 0.04028201  0.18207788]\n",
            "  [-0.7902868   0.6483624 ]\n",
            "  [ 0.7902868  -0.6483624 ]]\n",
            "\n",
            " [[-0.67359614  0.23244596]\n",
            "  [ 0.67359614 -0.23244596]\n",
            "  [ 0.9751656   0.7351639 ]\n",
            "  [-0.9751656  -0.7351639 ]\n",
            "  [-0.409631    0.36308146]\n",
            "  [ 0.409631   -0.36308146]]\n",
            "\n",
            " [[-0.36365747  0.6597967 ]\n",
            "  [ 0.36365747 -0.6597967 ]\n",
            "  [-0.5513475  -0.06735015]\n",
            "  [ 0.5513475   0.06735015]\n",
            "  [ 0.14791417 -0.22752285]\n",
            "  [-0.14791417  0.22752285]]\n",
            "\n",
            " [[ 0.6805365   0.947458  ]\n",
            "  [-0.6805365  -0.947458  ]\n",
            "  [-0.96540594  0.9653716 ]\n",
            "  [ 0.96540594 -0.9653716 ]\n",
            "  [ 0.7951803   0.17333078]\n",
            "  [-0.7951803  -0.17333078]]\n",
            "\n",
            " [[ 0.92432976 -0.6706135 ]\n",
            "  [-0.92432976  0.6706135 ]\n",
            "  [-0.44455552  0.32516837]\n",
            "  [ 0.44455552 -0.32516837]\n",
            "  [ 0.19427776 -0.53044415]\n",
            "  [-0.19427776  0.53044415]]\n",
            "\n",
            " [[-0.97995996 -0.33771276]\n",
            "  [ 0.97995996  0.33771276]\n",
            "  [ 0.6923804   0.2300241 ]\n",
            "  [-0.6923804  -0.2300241 ]\n",
            "  [ 0.36396432 -0.645983  ]\n",
            "  [-0.36396432  0.645983  ]]\n",
            "\n",
            " [[ 0.92063594  0.7852998 ]\n",
            "  [-0.92063594 -0.7852998 ]\n",
            "  [-0.86212254 -0.9780693 ]\n",
            "  [ 0.86212254  0.9780693 ]\n",
            "  [-0.12471628  0.7207382 ]\n",
            "  [ 0.12471628 -0.7207382 ]]\n",
            "\n",
            " [[-0.27365732  0.35644388]\n",
            "  [ 0.27365732 -0.35644388]\n",
            "  [-0.89305425 -0.2647648 ]\n",
            "  [ 0.89305425  0.2647648 ]\n",
            "  [ 0.09169698 -0.8917556 ]\n",
            "  [-0.09169698  0.8917556 ]]\n",
            "\n",
            " [[ 0.8357334   0.30336785]\n",
            "  [-0.8357334  -0.30336785]\n",
            "  [ 0.3405826  -0.06565857]\n",
            "  [-0.3405826   0.06565857]\n",
            "  [-0.99633145 -0.15831542]\n",
            "  [ 0.99633145  0.15831542]]\n",
            "\n",
            " [[ 0.26316762  0.73353434]\n",
            "  [-0.26316762 -0.73353434]\n",
            "  [-0.26960588  0.85358405]\n",
            "  [ 0.26960588 -0.85358405]\n",
            "  [-0.58926916  0.65870094]\n",
            "  [ 0.58926916 -0.65870094]]\n",
            "\n",
            " [[ 0.9271734  -0.4204464 ]\n",
            "  [-0.9271734   0.4204464 ]\n",
            "  [-0.1301043   0.64625645]\n",
            "  [ 0.1301043  -0.64625645]\n",
            "  [-0.5981586  -0.60473657]\n",
            "  [ 0.5981586   0.60473657]]\n",
            "\n",
            " [[-0.47278214  0.00673604]\n",
            "  [ 0.47278214 -0.00673604]\n",
            "  [-0.5393584   0.28980994]\n",
            "  [ 0.5393584  -0.28980994]\n",
            "  [-0.48344803 -0.6339519 ]\n",
            "  [ 0.48344803  0.6339519 ]]\n",
            "\n",
            " [[ 0.7451978  -0.94713974]\n",
            "  [-0.7451978   0.94713974]\n",
            "  [ 0.95530057  0.7947223 ]\n",
            "  [-0.95530057 -0.7947223 ]\n",
            "  [ 0.19836116 -0.87244654]\n",
            "  [-0.19836116  0.87244654]]\n",
            "\n",
            " [[ 0.777262   -0.6708114 ]\n",
            "  [-0.777262    0.6708114 ]\n",
            "  [ 0.9666674   0.9147117 ]\n",
            "  [-0.9666674  -0.9147117 ]\n",
            "  [-0.59427667  0.97701263]\n",
            "  [ 0.59427667 -0.97701263]]\n",
            "\n",
            " [[ 0.8507204  -0.30827332]\n",
            "  [-0.8507204   0.30827332]\n",
            "  [ 0.75126314 -0.22531414]\n",
            "  [-0.75126314  0.22531414]\n",
            "  [ 0.03916025  0.7413089 ]\n",
            "  [-0.03916025 -0.7413089 ]]\n",
            "\n",
            " [[-0.30926728  0.07991815]\n",
            "  [ 0.30926728 -0.07991815]\n",
            "  [ 0.98929834 -0.40078473]\n",
            "  [-0.98929834  0.40078473]\n",
            "  [-0.09261394  0.3568151 ]\n",
            "  [ 0.09261394 -0.3568151 ]]\n",
            "\n",
            " [[ 0.20574188  0.7562001 ]\n",
            "  [-0.20574188 -0.7562001 ]\n",
            "  [-0.9649091  -0.77351165]\n",
            "  [ 0.9649091   0.77351165]\n",
            "  [-0.49315977 -0.8483784 ]\n",
            "  [ 0.49315977  0.8483784 ]]\n",
            "\n",
            " [[ 0.5875826  -0.41174912]\n",
            "  [-0.5875826   0.41174912]\n",
            "  [-0.67049265 -0.20614147]\n",
            "  [ 0.67049265  0.20614147]\n",
            "  [ 0.9705317   0.22693229]\n",
            "  [-0.9705317  -0.22693229]]\n",
            "\n",
            " [[ 0.33948398 -0.49928856]\n",
            "  [-0.33948398  0.49928856]\n",
            "  [ 0.2900715  -0.63713026]\n",
            "  [-0.2900715   0.63713026]\n",
            "  [-0.36528015 -0.4367423 ]\n",
            "  [ 0.36528015  0.4367423 ]]\n",
            "\n",
            " [[ 0.3792901  -0.36259556]\n",
            "  [-0.3792901   0.36259556]\n",
            "  [ 0.55620384 -0.03987908]\n",
            "  [-0.55620384  0.03987908]\n",
            "  [ 0.09658575  0.30449843]\n",
            "  [-0.09658575 -0.30449843]]\n",
            "\n",
            " [[ 0.5819595  -0.69791484]\n",
            "  [-0.5819595   0.69791484]\n",
            "  [-0.34759068 -0.26853728]\n",
            "  [ 0.34759068  0.26853728]\n",
            "  [-0.7937293  -0.14316773]\n",
            "  [ 0.7937293   0.14316773]]\n",
            "\n",
            " [[-0.14645886  0.754333  ]\n",
            "  [ 0.14645886 -0.754333  ]\n",
            "  [-0.71161175 -0.38065338]\n",
            "  [ 0.71161175  0.38065338]\n",
            "  [-0.23605275  0.22339177]\n",
            "  [ 0.23605275 -0.22339177]]]\n",
            "\n",
            "Primaries After NECL:\n",
            " [[[ 0.08225523  0.20564882]\n",
            "  [-0.08225523 -0.20564882]\n",
            "  [ 0.03121988 -0.08079465]\n",
            "  [-0.03121988  0.08079465]\n",
            "  [-0.10250498 -0.00998279]\n",
            "  [-0.10250498 -0.00998279]]\n",
            "\n",
            " [[-0.18813464 -0.03411174]\n",
            "  [ 0.18813464  0.03411174]\n",
            "  [ 0.05471329 -0.15144627]\n",
            "  [-0.05471329  0.15144627]\n",
            "  [-0.10280439 -0.02544304]\n",
            "  [-0.10280439 -0.02544304]]\n",
            "\n",
            " [[-0.06567634 -0.07878063]\n",
            "  [ 0.06567634  0.07878063]\n",
            "  [-0.09611173  0.1169522 ]\n",
            "  [ 0.09611173 -0.1169522 ]\n",
            "  [-0.16686302 -0.08250728]\n",
            "  [-0.16686302 -0.08250728]]\n",
            "\n",
            " [[-0.04651025  0.0396634 ]\n",
            "  [ 0.04651025 -0.0396634 ]\n",
            "  [-0.15962073 -0.09226894]\n",
            "  [ 0.15962073  0.09226894]\n",
            "  [ 0.08832271  0.16168883]\n",
            "  [ 0.08832271  0.16168883]]\n",
            "\n",
            " [[ 0.21710703 -0.0867136 ]\n",
            "  [-0.21710703  0.0867136 ]\n",
            "  [-0.1649153   0.01990122]\n",
            "  [ 0.1649153  -0.01990122]\n",
            "  [ 0.10739225 -0.00177723]\n",
            "  [ 0.10739225 -0.00177723]]\n",
            "\n",
            " [[ 0.03782626 -0.11228705]\n",
            "  [-0.03782626  0.11228705]\n",
            "  [ 0.08746792 -0.0494947 ]\n",
            "  [-0.08746792  0.0494947 ]\n",
            "  [ 0.17854585  0.12264843]\n",
            "  [ 0.17854585  0.12264843]]\n",
            "\n",
            " [[-0.08671707  0.05098202]\n",
            "  [ 0.08671707 -0.05098202]\n",
            "  [ 0.20489171 -0.03553366]\n",
            "  [-0.20489171  0.03553366]\n",
            "  [-0.07485785 -0.13148075]\n",
            "  [-0.07485785 -0.13148075]]\n",
            "\n",
            " [[ 0.07410595  0.07398956]\n",
            "  [-0.07410595 -0.07398956]\n",
            "  [ 0.1361825  -0.09702307]\n",
            "  [-0.1361825   0.09702307]\n",
            "  [-0.09560587 -0.12639885]\n",
            "  [-0.09560587 -0.12639885]]\n",
            "\n",
            " [[-0.16355272 -0.19562708]\n",
            "  [ 0.16355272  0.19562708]\n",
            "  [-0.10795856 -0.04395908]\n",
            "  [ 0.10795856  0.04395908]\n",
            "  [ 0.06652994 -0.02887086]\n",
            "  [ 0.06652994 -0.02887086]]\n",
            "\n",
            " [[-0.06281731  0.01838978]\n",
            "  [ 0.06281731 -0.01838978]\n",
            "  [ 0.11213142 -0.12242736]\n",
            "  [-0.11213142  0.12242736]\n",
            "  [ 0.0897972   0.16491696]\n",
            "  [ 0.0897972   0.16491696]]\n",
            "\n",
            " [[ 0.1647934   0.09009289]\n",
            "  [-0.1647934  -0.09009289]\n",
            "  [-0.13516478 -0.04044816]\n",
            "  [ 0.13516478  0.04044816]\n",
            "  [ 0.15724628  0.04396351]\n",
            "  [ 0.15724628  0.04396351]]\n",
            "\n",
            " [[-0.12848794  0.09383841]\n",
            "  [ 0.12848794 -0.09383841]\n",
            "  [-0.01694616  0.1196421 ]\n",
            "  [ 0.01694616 -0.1196421 ]\n",
            "  [ 0.01369737  0.11950941]\n",
            "  [ 0.01369737  0.11950941]]\n",
            "\n",
            " [[ 0.13131674 -0.0300478 ]\n",
            "  [-0.13131674  0.0300478 ]\n",
            "  [-0.18165292 -0.0356609 ]\n",
            "  [ 0.18165292  0.0356609 ]\n",
            "  [ 0.09347098 -0.1231463 ]\n",
            "  [ 0.09347098 -0.1231463 ]]\n",
            "\n",
            " [[ 0.03825907 -0.1445889 ]\n",
            "  [-0.03825907  0.1445889 ]\n",
            "  [-0.1933525   0.06938948]\n",
            "  [ 0.1933525  -0.06938948]\n",
            "  [ 0.09478009 -0.02101098]\n",
            "  [ 0.09478009 -0.02101098]]\n",
            "\n",
            " [[-0.01448797  0.0774726 ]\n",
            "  [ 0.01448797 -0.0774726 ]\n",
            "  [-0.10995604  0.02070983]\n",
            "  [ 0.10995604 -0.02070983]\n",
            "  [-0.11967062 -0.19439705]\n",
            "  [-0.11967062 -0.19439705]]\n",
            "\n",
            " [[-0.14359573 -0.0766813 ]\n",
            "  [ 0.14359573  0.0766813 ]\n",
            "  [-0.04092467 -0.10806818]\n",
            "  [ 0.04092467  0.10806818]\n",
            "  [-0.09415283  0.11352885]\n",
            "  [-0.09415283  0.11352885]]\n",
            "\n",
            " [[-0.12970206 -0.16514824]\n",
            "  [ 0.12970206  0.16514824]\n",
            "  [ 0.14031008 -0.04950767]\n",
            "  [-0.14031008  0.04950767]\n",
            "  [-0.09800216 -0.01471116]\n",
            "  [-0.09800216 -0.01471116]]\n",
            "\n",
            " [[ 0.22042884  0.07204677]\n",
            "  [-0.22042884 -0.07204677]\n",
            "  [ 0.22992758  0.08203545]\n",
            "  [-0.22992758 -0.08203545]\n",
            "  [-0.02330675  0.00201218]\n",
            "  [-0.02330675  0.00201218]]\n",
            "\n",
            " [[-0.22168525  0.09858681]\n",
            "  [ 0.22168525 -0.09858681]\n",
            "  [ 0.02213506 -0.03364986]\n",
            "  [-0.02213506  0.03364986]\n",
            "  [-0.00856052  0.14816271]\n",
            "  [-0.00856052  0.14816271]]\n",
            "\n",
            " [[-0.16973768 -0.08925211]\n",
            "  [ 0.16973768  0.08925211]\n",
            "  [ 0.14443056  0.05149567]\n",
            "  [-0.14443056 -0.05149567]\n",
            "  [-0.13689044 -0.0448851 ]\n",
            "  [-0.13689044 -0.0448851 ]]\n",
            "\n",
            " [[ 0.17647369  0.10033461]\n",
            "  [-0.17647369 -0.10033461]\n",
            "  [ 0.19653983 -0.1364976 ]\n",
            "  [-0.19653983  0.1364976 ]\n",
            "  [ 0.00158402  0.01551666]\n",
            "  [ 0.00158402  0.01551666]]\n",
            "\n",
            " [[ 0.13784617  0.01656437]\n",
            "  [-0.13784617 -0.01656437]\n",
            "  [-0.1530017  -0.1034553 ]\n",
            "  [ 0.1530017   0.1034553 ]\n",
            "  [-0.13998896  0.07146968]\n",
            "  [-0.13998896  0.07146968]]\n",
            "\n",
            " [[-0.10379101 -0.11597143]\n",
            "  [ 0.10379101  0.11597143]\n",
            "  [-0.05212966 -0.06975825]\n",
            "  [ 0.05212966  0.06975825]\n",
            "  [ 0.05165724  0.15020853]\n",
            "  [ 0.05165724  0.15020853]]\n",
            "\n",
            " [[-0.17399818 -0.02000652]\n",
            "  [ 0.17399818  0.02000652]\n",
            "  [-0.06798321  0.07374553]\n",
            "  [ 0.06798321 -0.07374553]\n",
            "  [-0.12593739 -0.13049456]\n",
            "  [-0.12593739 -0.13049456]]\n",
            "\n",
            " [[-0.18199146 -0.0056456 ]\n",
            "  [ 0.18199146  0.0056456 ]\n",
            "  [ 0.10975327  0.10511529]\n",
            "  [-0.10975327 -0.10511529]\n",
            "  [-0.15001148 -0.03331686]\n",
            "  [-0.15001148 -0.03331686]]\n",
            "\n",
            " [[ 0.17316149 -0.08140475]\n",
            "  [-0.17316149  0.08140475]\n",
            "  [-0.02406467 -0.01337909]\n",
            "  [ 0.02406467  0.01337909]\n",
            "  [-0.1716588   0.16124177]\n",
            "  [-0.1716588   0.16124177]]\n",
            "\n",
            " [[ 0.15005927 -0.11847268]\n",
            "  [-0.15005927  0.11847268]\n",
            "  [ 0.02851222  0.05890234]\n",
            "  [-0.02851222 -0.05890234]\n",
            "  [ 0.19451804  0.05810019]\n",
            "  [ 0.19451804  0.05810019]]\n",
            "\n",
            " [[-0.07209085  0.04284314]\n",
            "  [ 0.07209085 -0.04284314]\n",
            "  [ 0.13767779 -0.11519434]\n",
            "  [-0.13767779  0.11519434]\n",
            "  [ 0.12609045 -0.12464318]\n",
            "  [ 0.12609045 -0.12464318]]\n",
            "\n",
            " [[-0.04651164 -0.14275055]\n",
            "  [ 0.04651164  0.14275055]\n",
            "  [ 0.17229079 -0.12110744]\n",
            "  [-0.17229079  0.12110744]\n",
            "  [-0.07235306 -0.01117299]\n",
            "  [-0.07235306 -0.01117299]]\n",
            "\n",
            " [[-0.02540198 -0.13682894]\n",
            "  [ 0.02540198  0.13682894]\n",
            "  [-0.01791761  0.11347137]\n",
            "  [ 0.01791761 -0.11347137]\n",
            "  [ 0.11741956 -0.08466083]\n",
            "  [ 0.11741956 -0.08466083]]\n",
            "\n",
            " [[-0.15014261 -0.13823195]\n",
            "  [ 0.15014261  0.13823195]\n",
            "  [ 0.1422735  -0.11797337]\n",
            "  [-0.1422735   0.11797337]\n",
            "  [ 0.03448931 -0.03327905]\n",
            "  [ 0.03448931 -0.03327905]]\n",
            "\n",
            " [[-0.0230449   0.0722027 ]\n",
            "  [ 0.0230449  -0.0722027 ]\n",
            "  [-0.21521217  0.01051084]\n",
            "  [ 0.21521217 -0.01051084]\n",
            "  [ 0.0424866  -0.14093587]\n",
            "  [ 0.0424866  -0.14093587]]\n",
            "\n",
            " [[-0.06131818 -0.05598698]\n",
            "  [ 0.06131818  0.05598698]\n",
            "  [-0.13478787  0.12204763]\n",
            "  [ 0.13478787 -0.12204763]\n",
            "  [-0.06324738 -0.13796227]\n",
            "  [-0.06324738 -0.13796227]]\n",
            "\n",
            " [[-0.15372178 -0.09495274]\n",
            "  [ 0.15372178  0.09495274]\n",
            "  [-0.14191222 -0.10897689]\n",
            "  [ 0.14191222  0.10897689]\n",
            "  [ 0.10168953 -0.03068706]\n",
            "  [ 0.10168953 -0.03068706]]\n",
            "\n",
            " [[-0.07369689 -0.11579853]\n",
            "  [ 0.07369689  0.11579853]\n",
            "  [-0.18647477 -0.084406  ]\n",
            "  [ 0.18647477  0.084406  ]\n",
            "  [ 0.11828618 -0.02435772]\n",
            "  [ 0.11828618 -0.02435772]]\n",
            "\n",
            " [[-0.23890159  0.05054054]\n",
            "  [ 0.23890159 -0.05054054]\n",
            "  [-0.01136465  0.01814935]\n",
            "  [ 0.01136465 -0.01814935]\n",
            "  [ 0.24637455  0.0024215 ]\n",
            "  [ 0.24637455  0.0024215 ]]\n",
            "\n",
            " [[-0.05001954  0.12525192]\n",
            "  [ 0.05001954 -0.12525192]\n",
            "  [ 0.13366503  0.08455767]\n",
            "  [-0.13366503 -0.08455767]\n",
            "  [ 0.11264893 -0.08120753]\n",
            "  [ 0.11264893 -0.08120753]]\n",
            "\n",
            " [[-0.05968979  0.07259835]\n",
            "  [ 0.05968979 -0.07259835]\n",
            "  [-0.0075974  -0.14129107]\n",
            "  [ 0.0075974   0.14129107]\n",
            "  [ 0.05438136  0.14020987]\n",
            "  [ 0.05438136  0.14020987]]\n",
            "\n",
            " [[ 0.10714728 -0.05266683]\n",
            "  [-0.10714728  0.05266683]\n",
            "  [-0.20952311 -0.03626043]\n",
            "  [ 0.20952311  0.03626043]\n",
            "  [ 0.08279601 -0.1114032 ]\n",
            "  [ 0.08279601 -0.1114032 ]]\n",
            "\n",
            " [[ 0.15925416  0.04678029]\n",
            "  [-0.15925416 -0.04678029]\n",
            "  [-0.11241248  0.05712055]\n",
            "  [ 0.11241248 -0.05712055]\n",
            "  [ 0.15379703 -0.10451277]\n",
            "  [ 0.15379703 -0.10451277]]\n",
            "\n",
            " [[-0.01076327 -0.14004764]\n",
            "  [ 0.01076327  0.14004764]\n",
            "  [ 0.08196405 -0.05454095]\n",
            "  [-0.08196405  0.05454095]\n",
            "  [-0.18786816  0.07145228]\n",
            "  [-0.18786816  0.07145228]]\n",
            "\n",
            " [[-0.0660315  -0.03591853]\n",
            "  [ 0.0660315   0.03591853]\n",
            "  [ 0.16439962  0.11253481]\n",
            "  [-0.16439962 -0.11253481]\n",
            "  [ 0.18336375  0.07521334]\n",
            "  [ 0.18336375  0.07521334]]\n",
            "\n",
            " [[ 0.06428822 -0.1596892 ]\n",
            "  [-0.06428822  0.1596892 ]\n",
            "  [ 0.00965538  0.03086032]\n",
            "  [-0.00965538 -0.03086032]\n",
            "  [-0.1890913   0.10969572]\n",
            "  [-0.1890913   0.10969572]]\n",
            "\n",
            " [[-0.14232866  0.0347296 ]\n",
            "  [ 0.14232866 -0.0347296 ]\n",
            "  [-0.20587872 -0.10974942]\n",
            "  [ 0.20587872  0.10974942]\n",
            "  [-0.08659027  0.05427069]\n",
            "  [-0.08659027  0.05427069]]\n",
            "\n",
            " [[-0.12059446  0.15471412]\n",
            "  [ 0.12059446 -0.15471412]\n",
            "  [ 0.1828574   0.01579467]\n",
            "  [-0.1828574  -0.01579467]\n",
            "  [ 0.04910848 -0.0534142 ]\n",
            "  [ 0.04910848 -0.0534142 ]]\n",
            "\n",
            " [[ 0.10663755  0.10497932]\n",
            "  [-0.10663755 -0.10497932]\n",
            "  [ 0.15122423 -0.10692788]\n",
            "  [-0.15122423  0.10692788]\n",
            "  [ 0.12462979  0.01920954]\n",
            "  [ 0.12462979  0.01920954]]\n",
            "\n",
            " [[ 0.21445143 -0.11001687]\n",
            "  [-0.21445143  0.11001687]\n",
            "  [ 0.10326306 -0.05340873]\n",
            "  [-0.10326306  0.05340873]\n",
            "  [ 0.04513538 -0.08714022]\n",
            "  [ 0.04513538 -0.08714022]]\n",
            "\n",
            " [[-0.2047585  -0.04989604]\n",
            "  [ 0.2047585   0.04989604]\n",
            "  [-0.14475565 -0.03400549]\n",
            "  [ 0.14475565  0.03400549]\n",
            "  [ 0.07611312 -0.09552275]\n",
            "  [ 0.07611312 -0.09552275]]\n",
            "\n",
            " [[ 0.1486867   0.08968187]\n",
            "  [-0.1486867  -0.08968187]\n",
            "  [ 0.1392301   0.11169114]\n",
            "  [-0.1392301  -0.11169114]\n",
            "  [-0.02015929  0.08237864]\n",
            "  [-0.02015929  0.08237864]]\n",
            "\n",
            " [[-0.06303611  0.05805751]\n",
            "  [ 0.06303611 -0.05805751]\n",
            "  [ 0.20546862  0.04307377]\n",
            "  [-0.20546862 -0.04307377]\n",
            "  [ 0.02110983 -0.14516453]\n",
            "  [ 0.02110983 -0.14516453]]\n",
            "\n",
            " [[ 0.19508332  0.05007339]\n",
            "  [-0.19508332 -0.05007339]\n",
            "  [-0.07959327  0.01085001]\n",
            "  [ 0.07959327 -0.01085001]\n",
            "  [-0.23249915 -0.02612316]\n",
            "  [-0.23249915 -0.02612316]]\n",
            "\n",
            " [[ 0.05394495  0.10632215]\n",
            "  [-0.05394495 -0.10632215]\n",
            "  [ 0.05525612 -0.1237036 ]\n",
            "  [-0.05525612  0.1237036 ]\n",
            "  [-0.12075034  0.09544385]\n",
            "  [-0.12075034  0.09544385]]\n",
            "\n",
            " [[ 0.1921903  -0.06162631]\n",
            "  [-0.1921903   0.06162631]\n",
            "  [ 0.0269954  -0.0948174 ]\n",
            "  [-0.0269954   0.0948174 ]\n",
            "  [-0.12404844 -0.0886801 ]\n",
            "  [-0.12404844 -0.0886801 ]]\n",
            "\n",
            " [[-0.13169494  0.00132678]\n",
            "  [ 0.13169494 -0.00132678]\n",
            "  [ 0.15019846 -0.05706717]\n",
            "  [-0.15019846  0.05706717]\n",
            "  [-0.13459936 -0.12480575]\n",
            "  [-0.13459936 -0.12480575]]\n",
            "\n",
            " [[ 0.11687098 -0.10503504]\n",
            "  [-0.11687098  0.10503504]\n",
            "  [-0.14979807 -0.08811839]\n",
            "  [ 0.14979807  0.08811839]\n",
            "  [ 0.03112587 -0.09680296]\n",
            "  [ 0.03112587 -0.09680296]]\n",
            "\n",
            " [[ 0.11640114 -0.07103547]\n",
            "  [-0.11640114  0.07103547]\n",
            "  [-0.144714   -0.09682839]\n",
            "  [ 0.144714    0.09682839]\n",
            "  [-0.08899756  0.10346051]\n",
            "  [-0.08899756  0.10346051]]\n",
            "\n",
            " [[ 0.1833517  -0.04698065]\n",
            "  [-0.1833517   0.04698065]\n",
            "  [-0.16195281  0.0343455 ]\n",
            "  [ 0.16195281 -0.0343455 ]\n",
            "  [ 0.00844613  0.11305682]\n",
            "  [ 0.00844613  0.11305682]]\n",
            "\n",
            " [[-0.09240866  0.01688531]\n",
            "  [ 0.09240866 -0.01688531]\n",
            "  [-0.29500106  0.08450694]\n",
            "  [ 0.29500106 -0.08450694]\n",
            "  [-0.02767651  0.07539859]\n",
            "  [-0.02767651  0.07539859]]\n",
            "\n",
            " [[ 0.03595052  0.09343382]\n",
            "  [-0.03595052 -0.09343382]\n",
            "  [ 0.16845405  0.09548759]\n",
            "  [-0.16845405 -0.09548759]\n",
            "  [-0.08614358 -0.10478761]\n",
            "  [-0.08614358 -0.10478761]]\n",
            "\n",
            " [[ 0.12752707 -0.06319041]\n",
            "  [-0.12752707  0.06319041]\n",
            "  [ 0.14551246  0.03163418]\n",
            "  [-0.14551246 -0.03163418]\n",
            "  [ 0.21049845  0.0348033 ]\n",
            "  [ 0.21049845  0.0348033 ]]\n",
            "\n",
            " [[ 0.09502324 -0.09882053]\n",
            "  [-0.09502324  0.09882053]\n",
            "  [-0.08118249  0.12608707]\n",
            "  [ 0.08118249 -0.12608707]\n",
            "  [-0.10224685 -0.08644386]\n",
            "  [-0.10224685 -0.08644386]]\n",
            "\n",
            " [[ 0.14181884 -0.09586718]\n",
            "  [-0.14181884  0.09586718]\n",
            "  [-0.2078946   0.01053997]\n",
            "  [ 0.2078946  -0.01053997]\n",
            "  [ 0.03614254  0.08057043]\n",
            "  [ 0.03614254  0.08057043]]\n",
            "\n",
            " [[ 0.14155936 -0.12004203]\n",
            "  [-0.14155936  0.12004203]\n",
            "  [ 0.08462202  0.04622797]\n",
            "  [-0.08462202 -0.04622797]\n",
            "  [-0.19305497 -0.02462287]\n",
            "  [-0.19305497 -0.02462287]]\n",
            "\n",
            " [[-0.04040064  0.1471366 ]\n",
            "  [ 0.04040064 -0.1471366 ]\n",
            "  [ 0.19619091  0.07420795]\n",
            "  [-0.19619091 -0.07420795]\n",
            "  [-0.06516117  0.04360456]\n",
            "  [-0.06516117  0.04360456]]]\n",
            "\n",
            "Pairs[0]:\n",
            " [[ 0.08225523  0.20564882]\n",
            " [-0.08225523 -0.20564882]\n",
            " [ 0.03121988 -0.08079465]\n",
            " [-0.03121988  0.08079465]\n",
            " [-0.10250498 -0.00998279]\n",
            " [-0.10250498 -0.00998279]\n",
            " [ 0.11347511  0.12485418]\n",
            " [ 0.002568   -0.01661532]\n",
            " [ 0.05103535  0.28644347]\n",
            " [-0.002568    0.01661532]\n",
            " [-0.05103535 -0.28644347]\n",
            " [-0.002568    0.01661532]\n",
            " [-0.11347511 -0.12485418]\n",
            " [ 0.002568   -0.01661532]\n",
            " [-0.02024975  0.19566603]\n",
            " [-0.00843157 -0.00205295]\n",
            " [-0.02024975  0.19566603]\n",
            " [-0.00843157 -0.00205295]\n",
            " [-0.18476021 -0.21563162]\n",
            " [ 0.00843157  0.00205295]\n",
            " [-0.18476021 -0.21563162]\n",
            " [ 0.00843157  0.00205295]\n",
            " [-0.07128511 -0.09077744]\n",
            " [-0.00320019  0.00080656]\n",
            " [-0.07128511 -0.09077744]\n",
            " [-0.00320019  0.00080656]\n",
            " [-0.13372485  0.07081185]\n",
            " [ 0.00320019 -0.00080656]\n",
            " [-0.13372485  0.07081185]\n",
            " [ 0.00320019 -0.00080656]]\n",
            "\n",
            "Triplets[0]:\n",
            " [[[ 0.08225523  0.20564882]\n",
            "  [-0.08225523 -0.20564882]\n",
            "  [ 0.03121988 -0.08079465]]\n",
            "\n",
            " [[-0.03121988  0.08079465]\n",
            "  [-0.10250498 -0.00998279]\n",
            "  [-0.10250498 -0.00998279]]\n",
            "\n",
            " [[ 0.11347511  0.12485418]\n",
            "  [ 0.002568   -0.01661532]\n",
            "  [ 0.05103535  0.28644347]]\n",
            "\n",
            " [[-0.002568    0.01661532]\n",
            "  [-0.05103535 -0.28644347]\n",
            "  [-0.002568    0.01661532]]\n",
            "\n",
            " [[-0.11347511 -0.12485418]\n",
            "  [ 0.002568   -0.01661532]\n",
            "  [-0.02024975  0.19566603]]\n",
            "\n",
            " [[-0.00843157 -0.00205295]\n",
            "  [-0.02024975  0.19566603]\n",
            "  [-0.00843157 -0.00205295]]\n",
            "\n",
            " [[-0.18476021 -0.21563162]\n",
            "  [ 0.00843157  0.00205295]\n",
            "  [-0.18476021 -0.21563162]]\n",
            "\n",
            " [[ 0.00843157  0.00205295]\n",
            "  [-0.07128511 -0.09077744]\n",
            "  [-0.00320019  0.00080656]]\n",
            "\n",
            " [[-0.07128511 -0.09077744]\n",
            "  [-0.00320019  0.00080656]\n",
            "  [-0.13372485  0.07081185]]\n",
            "\n",
            " [[ 0.00320019 -0.00080656]\n",
            "  [-0.13372485  0.07081185]\n",
            "  [ 0.00320019 -0.00080656]]]\n",
            "\n",
            "Bits (all qubits):\n",
            " [[1 1 1 ... 1 1 1]\n",
            " [0 1 0 ... 1 0 0]\n",
            " [0 1 1 ... 0 0 1]\n",
            " ...\n",
            " [1 0 1 ... 1 1 0]\n",
            " [1 0 0 ... 1 0 0]\n",
            " [0 1 0 ... 1 0 0]]\n",
            "\n",
            "Primaries Out (promoted):\n",
            " [[[ 3.20019270e-03 -8.06556141e-04]\n",
            "  [-3.20019270e-03  8.06556141e-04]\n",
            "  [-1.33724853e-01  7.08118528e-02]\n",
            "  [ 1.33724853e-01 -7.08118528e-02]\n",
            "  [ 3.20019270e-03 -8.06556141e-04]\n",
            "  [-3.20019270e-03  8.06556141e-04]]\n",
            "\n",
            " [[ 5.62476646e-03 -3.85325332e-03]\n",
            "  [-5.62476646e-03  3.85325332e-03]\n",
            "  [-1.57517686e-01  1.26003236e-01]\n",
            "  [ 1.57517686e-01 -1.26003236e-01]\n",
            "  [ 5.62476646e-03 -3.85325332e-03]\n",
            "  [-5.62476646e-03  3.85325332e-03]]\n",
            "\n",
            " [[-1.60374939e-02  9.64940805e-03]\n",
            "  [ 1.60374939e-02 -9.64940805e-03]\n",
            "  [-7.07512945e-02 -1.99459493e-01]\n",
            "  [ 7.07512945e-02  1.99459493e-01]\n",
            "  [-1.60374939e-02  9.64940805e-03]\n",
            "  [ 1.60374939e-02 -9.64940805e-03]]\n",
            "\n",
            " [[ 1.40981348e-02  1.49188582e-02]\n",
            "  [-1.40981348e-02 -1.49188582e-02]\n",
            "  [ 2.47943431e-01  2.53957778e-01]\n",
            "  [-2.47943431e-01 -2.53957778e-01]\n",
            "  [ 1.40981348e-02  1.49188582e-02]\n",
            "  [-1.40981348e-02 -1.49188582e-02]]\n",
            "\n",
            " [[ 1.77106243e-02  3.53689611e-05]\n",
            "  [-1.77106243e-02 -3.53689611e-05]\n",
            "  [ 2.72307545e-01 -2.16784459e-02]\n",
            "  [-2.72307545e-01  2.16784459e-02]\n",
            "  [ 1.77106243e-02  3.53689611e-05]\n",
            "  [-1.77106243e-02 -3.53689611e-05]]\n",
            "\n",
            " [[-1.56170335e-02  6.07044715e-03]\n",
            "  [ 1.56170335e-02 -6.07044715e-03]\n",
            "  [ 9.10779312e-02  1.72143131e-01]\n",
            "  [-9.10779312e-02 -1.72143131e-01]\n",
            "  [-1.56170335e-02  6.07044715e-03]\n",
            "  [ 1.56170335e-02 -6.07044715e-03]]\n",
            "\n",
            " [[ 1.53377540e-02 -4.67199180e-03]\n",
            "  [-1.53377540e-02  4.67199180e-03]\n",
            "  [-2.79749572e-01 -9.59471017e-02]\n",
            "  [ 2.79749572e-01  9.59471017e-02]\n",
            "  [ 1.53377540e-02 -4.67199180e-03]\n",
            "  [-1.53377540e-02  4.67199180e-03]]\n",
            "\n",
            " [[ 1.30198458e-02 -1.22636044e-02]\n",
            "  [-1.30198458e-02  1.22636044e-02]\n",
            "  [-2.31788367e-01 -2.93757766e-02]\n",
            "  [ 2.31788367e-01  2.93757766e-02]\n",
            "  [ 1.30198458e-02 -1.22636044e-02]\n",
            "  [-1.30198458e-02  1.22636044e-02]]\n",
            "\n",
            " [[ 7.18247704e-03 -1.26913632e-03]\n",
            "  [-7.18247704e-03  1.26913632e-03]\n",
            "  [ 1.74488515e-01  1.50882173e-02]\n",
            "  [-1.74488515e-01 -1.50882173e-02]\n",
            "  [ 7.18247704e-03 -1.26913632e-03]\n",
            "  [-7.18247704e-03  1.26913632e-03]]\n",
            "\n",
            " [[-1.00690881e-02  2.01903488e-02]\n",
            "  [ 1.00690881e-02 -2.01903488e-02]\n",
            "  [-2.23342255e-02  2.87344337e-01]\n",
            "  [ 2.23342255e-02 -2.87344337e-01]\n",
            "  [-1.00690881e-02  2.01903488e-02]\n",
            "  [ 1.00690881e-02 -2.01903488e-02]]\n",
            "\n",
            " [[ 2.12541595e-02  1.77824299e-03]\n",
            "  [-2.12541595e-02 -1.77824299e-03]\n",
            "  [ 2.92411059e-01  8.44116658e-02]\n",
            "  [-2.92411059e-01 -8.44116658e-02]\n",
            "  [ 2.12541595e-02  1.77824299e-03]\n",
            "  [-2.12541595e-02 -1.77824299e-03]]\n",
            "\n",
            " [[ 2.32117964e-04 -1.42983561e-02]\n",
            "  [-2.32117964e-04  1.42983561e-02]\n",
            "  [ 3.06435395e-02 -1.32694840e-04]\n",
            "  [-3.06435395e-02  1.32694840e-04]\n",
            "  [ 2.32117964e-04 -1.42983561e-02]\n",
            "  [-2.32117964e-04  1.42983561e-02]]\n",
            "\n",
            " [[ 1.69792753e-02 -4.39150818e-03]\n",
            "  [-1.69792753e-02  4.39150818e-03]\n",
            "  [ 2.75123894e-01 -8.74853879e-02]\n",
            "  [-2.75123894e-01  8.74853879e-02]\n",
            "  [ 1.69792753e-02 -4.39150818e-03]\n",
            "  [-1.69792753e-02  4.39150818e-03]]\n",
            "\n",
            " [[ 1.83259677e-02  1.45794079e-03]\n",
            "  [-1.83259677e-02 -1.45794079e-03]\n",
            "  [ 2.88132608e-01 -9.04004574e-02]\n",
            "  [-2.88132608e-01  9.04004574e-02]\n",
            "  [ 1.83259677e-02  1.45794079e-03]\n",
            "  [-1.83259677e-02 -1.45794079e-03]]\n",
            "\n",
            " [[-1.31585076e-02  4.02592914e-03]\n",
            "  [ 1.31585076e-02 -4.02592914e-03]\n",
            "  [-9.71458107e-03 -2.15106875e-01]\n",
            "  [ 9.71458107e-03  2.15106875e-01]\n",
            "  [-1.31585076e-02  4.02592914e-03]\n",
            "  [ 1.31585076e-02 -4.02592914e-03]]\n",
            "\n",
            " [[-3.85317369e-03  1.22688562e-02]\n",
            "  [ 3.85317369e-03 -1.22688562e-02]\n",
            "  [-5.32281585e-02  2.21597031e-01]\n",
            "  [ 5.32281585e-02 -2.21597031e-01]\n",
            "  [-3.85317369e-03  1.22688562e-02]\n",
            "  [ 3.85317369e-03 -1.22688562e-02]]\n",
            "\n",
            " [[ 1.37506910e-02 -7.28315033e-04]\n",
            "  [-1.37506910e-02  7.28315033e-04]\n",
            "  [-2.38312244e-01  3.47965099e-02]\n",
            "  [ 2.38312244e-01 -3.47965099e-02]\n",
            "  [ 1.37506910e-02 -7.28315033e-04]\n",
            "  [-1.37506910e-02  7.28315033e-04]]\n",
            "\n",
            " [[ 5.35886548e-03 -1.65069912e-04]\n",
            "  [-5.35886548e-03  1.65069912e-04]\n",
            "  [-2.53234327e-01 -8.00232738e-02]\n",
            "  [ 2.53234327e-01  8.00232738e-02]\n",
            "  [ 5.35886548e-03 -1.65069912e-04]\n",
            "  [-5.35886548e-03  1.65069912e-04]]\n",
            "\n",
            " [[ 1.89487662e-04  4.98565426e-03]\n",
            "  [-1.89487662e-04 -4.98565426e-03]\n",
            "  [-3.06955799e-02  1.81812569e-01]\n",
            "  [ 3.06955799e-02 -1.81812569e-01]\n",
            "  [ 1.89487662e-04  4.98565426e-03]\n",
            "  [-1.89487662e-04 -4.98565426e-03]]\n",
            "\n",
            " [[ 1.97711643e-02  2.31138850e-03]\n",
            "  [-1.97711643e-02 -2.31138850e-03]\n",
            "  [-2.81320989e-01 -9.63807702e-02]\n",
            "  [ 2.81320989e-01  9.63807702e-02]\n",
            "  [ 1.97711643e-02  2.31138850e-03]\n",
            "  [-1.97711643e-02 -2.31138850e-03]]\n",
            "\n",
            " [[-3.11322336e-04  2.11798749e-03]\n",
            "  [ 3.11322336e-04 -2.11798749e-03]\n",
            "  [-1.94955811e-01  1.52014270e-01]\n",
            "  [ 1.94955811e-01 -1.52014270e-01]\n",
            "  [-3.11322336e-04  2.11798749e-03]\n",
            "  [ 3.11322336e-04 -2.11798749e-03]]\n",
            "\n",
            " [[-2.14185473e-02  7.39391707e-03]\n",
            "  [ 2.14185473e-02 -7.39391707e-03]\n",
            "  [ 1.30127370e-02  1.74924970e-01]\n",
            "  [-1.30127370e-02 -1.74924970e-01]\n",
            "  [-2.14185473e-02  7.39391707e-03]\n",
            "  [ 2.14185473e-02 -7.39391707e-03]]\n",
            "\n",
            " [[ 2.69287429e-03  1.04782842e-02]\n",
            "  [-2.69287429e-03 -1.04782842e-02]\n",
            "  [ 1.03786901e-01  2.19966784e-01]\n",
            "  [-1.03786901e-01 -2.19966784e-01]\n",
            "  [ 2.69287429e-03  1.04782842e-02]\n",
            "  [-2.69287429e-03 -1.04782842e-02]]\n",
            "\n",
            " [[-8.56162794e-03  9.62339155e-03]\n",
            "  [ 8.56162794e-03 -9.62339155e-03]\n",
            "  [-5.79541773e-02 -2.04240099e-01]\n",
            "  [ 5.79541773e-02  2.04240099e-01]\n",
            "  [-8.56162794e-03  9.62339155e-03]\n",
            "  [ 8.56162794e-03 -9.62339155e-03]]\n",
            "\n",
            " [[ 1.64642502e-02  3.50211118e-03]\n",
            "  [-1.64642502e-02 -3.50211118e-03]\n",
            "  [-2.59764761e-01 -1.38432145e-01]\n",
            "  [ 2.59764761e-01  1.38432145e-01]\n",
            "  [ 1.64642502e-02  3.50211118e-03]\n",
            "  [-1.64642502e-02 -3.50211118e-03]]\n",
            "\n",
            " [[-4.13091294e-03  2.15726858e-03]\n",
            "  [ 4.13091294e-03 -2.15726858e-03]\n",
            "  [-1.47594124e-01  1.74620867e-01]\n",
            "  [ 1.47594124e-01 -1.74620867e-01]\n",
            "  [-4.13091294e-03  2.15726858e-03]\n",
            "  [ 4.13091294e-03 -2.15726858e-03]]\n",
            "\n",
            " [[-5.54614235e-03 -3.42223677e-03]\n",
            "  [ 5.54614235e-03  3.42223677e-03]\n",
            "  [ 1.66005820e-01 -8.02151859e-04]\n",
            "  [-1.66005820e-01  8.02151859e-04]\n",
            "  [-5.54614235e-03 -3.42223677e-03]\n",
            "  [ 5.54614235e-03  3.42223677e-03]]\n",
            "\n",
            " [[-1.73598547e-02 -1.43581890e-02]\n",
            "  [ 1.73598547e-02  1.43581890e-02]\n",
            "  [-1.15873367e-02 -9.44883376e-03]\n",
            "  [ 1.15873367e-02  9.44883376e-03]\n",
            "  [-1.73598547e-02 -1.43581890e-02]\n",
            "  [ 1.73598547e-02  1.43581890e-02]]\n",
            "\n",
            " [[ 1.24657657e-02 -1.35313254e-03]\n",
            "  [-1.24657657e-02  1.35313254e-03]\n",
            "  [-2.44643837e-01  1.09934442e-01]\n",
            "  [ 2.44643837e-01 -1.09934442e-01]\n",
            "  [ 1.24657657e-02 -1.35313254e-03]\n",
            "  [-1.24657657e-02  1.35313254e-03]]\n",
            "\n",
            " [[ 2.10387819e-03  9.60658025e-03]\n",
            "  [-2.10387819e-03 -9.60658025e-03]\n",
            "  [ 1.35337174e-01 -1.98132187e-01]\n",
            "  [-1.35337174e-01  1.98132187e-01]\n",
            "  [ 2.10387819e-03  9.60658025e-03]\n",
            "  [-2.10387819e-03 -9.60658025e-03]]\n",
            "\n",
            " [[-4.90691513e-03 -3.92604200e-03]\n",
            "  [ 4.90691513e-03  3.92604200e-03]\n",
            "  [-1.07784189e-01  8.46943185e-02]\n",
            "  [ 1.07784189e-01 -8.46943185e-02]\n",
            "  [-4.90691513e-03 -3.92604200e-03]\n",
            "  [ 4.90691513e-03  3.92604200e-03]]\n",
            "\n",
            " [[ 9.14363284e-03  1.48135459e-03]\n",
            "  [-9.14363284e-03 -1.48135459e-03]\n",
            "  [ 2.57698774e-01 -1.51446715e-01]\n",
            "  [-2.57698774e-01  1.51446715e-01]\n",
            "  [ 9.14363284e-03  1.48135459e-03]\n",
            "  [-9.14363284e-03 -1.48135459e-03]]\n",
            "\n",
            " [[-8.52498040e-03  1.68379676e-02]\n",
            "  [ 8.52498040e-03 -1.68379676e-02]\n",
            "  [ 7.15404898e-02 -2.60009885e-01]\n",
            "  [-7.15404898e-02  2.60009885e-01]\n",
            "  [-8.52498040e-03  1.68379676e-02]\n",
            "  [ 8.52498040e-03 -1.68379676e-02]]\n",
            "\n",
            " [[ 1.44309876e-02 -3.34418030e-03]\n",
            "  [-1.44309876e-02  3.34418030e-03]\n",
            "  [ 2.43601754e-01  7.82898217e-02]\n",
            "  [-2.43601754e-01 -7.82898217e-02]\n",
            "  [ 1.44309876e-02 -3.34418030e-03]\n",
            "  [-1.44309876e-02  3.34418030e-03]]\n",
            "\n",
            " [[ 2.20573898e-02 -2.05593812e-03]\n",
            "  [-2.20573898e-02  2.05593812e-03]\n",
            "  [ 3.04760963e-01  6.00482710e-02]\n",
            "  [-3.04760963e-01 -6.00482710e-02]\n",
            "  [ 2.20573898e-02 -2.05593812e-03]\n",
            "  [-2.20573898e-02  2.05593812e-03]]\n",
            "\n",
            " [[ 2.79996009e-03 -4.39485775e-05]\n",
            "  [-2.79996009e-03  4.39485775e-05]\n",
            "  [ 2.57739186e-01 -1.57278515e-02]\n",
            "  [-2.57739186e-01  1.57278515e-02]\n",
            "  [ 2.79996009e-03 -4.39485775e-05]\n",
            "  [-2.79996009e-03  4.39485775e-05]]\n",
            "\n",
            " [[-1.50572229e-02  6.86671911e-03]\n",
            "  [ 1.50572229e-02 -6.86671911e-03]\n",
            "  [-2.10160911e-02 -1.65765196e-01]\n",
            "  [ 2.10160911e-02  1.65765196e-01]\n",
            "  [-1.50572229e-02  6.86671911e-03]\n",
            "  [ 1.50572229e-02 -6.86671911e-03]]\n",
            "\n",
            " [[ 4.13156784e-04  1.98104028e-02]\n",
            "  [-4.13156784e-04 -1.98104028e-02]\n",
            "  [ 6.19787611e-02  2.81500936e-01]\n",
            "  [-6.19787611e-02 -2.81500936e-01]\n",
            "  [ 4.13156784e-04  1.98104028e-02]\n",
            "  [-4.13156784e-04 -1.98104028e-02]]\n",
            "\n",
            " [[ 1.73476785e-02 -4.03952785e-03]\n",
            "  [-1.73476785e-02  4.03952785e-03]\n",
            "  [ 2.92319119e-01 -7.51427710e-02]\n",
            "  [-2.92319119e-01  7.51427710e-02]\n",
            "  [ 1.73476785e-02 -4.03952785e-03]\n",
            "  [-1.73476785e-02  4.03952785e-03]]\n",
            "\n",
            " [[ 1.72887053e-02  5.96982660e-03]\n",
            "  [-1.72887053e-02 -5.96982660e-03]\n",
            "  [ 2.66209513e-01 -1.61633313e-01]\n",
            "  [-2.66209513e-01  1.61633313e-01]\n",
            "  [ 1.72887053e-02  5.96982660e-03]\n",
            "  [-1.72887053e-02 -5.96982660e-03]]\n",
            "\n",
            " [[ 1.53984344e-02  3.89707508e-03]\n",
            "  [-1.53984344e-02 -3.89707508e-03]\n",
            "  [-2.69832194e-01  1.25993222e-01]\n",
            "  [ 2.69832194e-01 -1.25993222e-01]\n",
            "  [ 1.53984344e-02  3.89707508e-03]\n",
            "  [-1.53984344e-02 -3.89707508e-03]]\n",
            "\n",
            " [[-3.01449317e-02 -8.46411940e-03]\n",
            "  [ 3.01449317e-02  8.46411940e-03]\n",
            "  [ 1.89641267e-02 -3.73214632e-02]\n",
            "  [-1.89641267e-02  3.73214632e-02]\n",
            "  [-3.01449317e-02 -8.46411940e-03]\n",
            "  [ 3.01449317e-02  8.46411940e-03]]\n",
            "\n",
            " [[ 1.82574824e-03 -3.38524464e-03]\n",
            "  [-1.82574824e-03  3.38524464e-03]\n",
            "  [-1.98746681e-01  7.88353980e-02]\n",
            "  [ 1.98746681e-01 -7.88353980e-02]\n",
            "  [ 1.82574824e-03 -3.38524464e-03]\n",
            "  [-1.82574824e-03  3.38524464e-03]]\n",
            "\n",
            " [[-1.78270936e-02  5.95617713e-03]\n",
            "  [ 1.78270936e-02 -5.95617713e-03]\n",
            "  [ 1.19288452e-01  1.64020121e-01]\n",
            "  [-1.19288452e-01 -1.64020121e-01]\n",
            "  [-1.78270936e-02  5.95617713e-03]\n",
            "  [ 1.78270936e-02 -5.95617713e-03]]\n",
            "\n",
            " [[-8.97984952e-03  8.43659858e-04]\n",
            "  [ 8.97984952e-03 -8.43659858e-04]\n",
            "  [-1.33748919e-01 -6.92088753e-02]\n",
            "  [ 1.33748919e-01  6.92088753e-02]\n",
            "  [-8.97984952e-03  8.43659858e-04]\n",
            "  [ 8.97984952e-03 -8.43659858e-04]]\n",
            "\n",
            " [[-1.88470427e-02  2.05403520e-03]\n",
            "  [ 1.88470427e-02 -2.05403520e-03]\n",
            "  [-2.65944377e-02  1.26137421e-01]\n",
            "  [ 2.65944377e-02 -1.26137421e-01]\n",
            "  [-1.88470427e-02  2.05403520e-03]\n",
            "  [ 1.88470427e-02 -2.05403520e-03]]\n",
            "\n",
            " [[-4.66081733e-03 -4.65404848e-03]\n",
            "  [ 4.66081733e-03  4.65404848e-03]\n",
            "  [-5.81276789e-02 -3.37314866e-02]\n",
            "  [ 5.81276789e-02  3.37314866e-02]\n",
            "  [-4.66081733e-03 -4.65404848e-03]\n",
            "  [ 4.66081733e-03  4.65404848e-03]]\n",
            "\n",
            " [[ 1.10178040e-02 -3.24829808e-03]\n",
            "  [-1.10178040e-02  3.24829808e-03]\n",
            "  [ 2.20868766e-01 -6.15172535e-02]\n",
            "  [-2.20868766e-01  6.15172535e-02]\n",
            "  [ 1.10178040e-02 -3.24829808e-03]\n",
            "  [-1.10178040e-02  3.24829808e-03]]\n",
            "\n",
            " [[ 2.80677993e-03 -9.20096412e-03]\n",
            "  [-2.80677993e-03  9.20096412e-03]\n",
            "  [-1.59389392e-01 -2.93124989e-02]\n",
            "  [ 1.59389392e-01  2.93124989e-02]\n",
            "  [ 2.80677993e-03 -9.20096412e-03]\n",
            "  [-2.80677993e-03  9.20096412e-03]]\n",
            "\n",
            " [[-4.33740765e-03  6.25278335e-03]\n",
            "  [ 4.33740765e-03 -6.25278335e-03]\n",
            "  [-1.84358791e-01 -1.88238293e-01]\n",
            "  [ 1.84358791e-01  1.88238293e-01]\n",
            "  [-4.33740765e-03  6.25278335e-03]\n",
            "  [ 4.33740765e-03 -6.25278335e-03]]\n",
            "\n",
            " [[-1.85053684e-02  2.83436646e-04]\n",
            "  [ 1.85053684e-02 -2.83436646e-04]\n",
            "  [-1.52905881e-01 -3.69731709e-02]\n",
            "  [ 1.52905881e-01  3.69731709e-02]\n",
            "  [-1.85053684e-02  2.83436646e-04]\n",
            "  [ 1.85053684e-02 -2.83436646e-04]]\n",
            "\n",
            " [[ 6.67219469e-03  1.18067479e-02]\n",
            "  [-6.67219469e-03 -1.18067479e-02]\n",
            "  [-1.76006451e-01  2.19147444e-01]\n",
            "  [ 1.76006451e-01 -2.19147444e-01]\n",
            "  [ 6.67219469e-03  1.18067479e-02]\n",
            "  [-6.67219469e-03 -1.18067479e-02]]\n",
            "\n",
            " [[ 3.34873726e-03 -8.40841606e-03]\n",
            "  [-3.34873726e-03  8.40841606e-03]\n",
            "  [-1.51043847e-01  6.13730401e-03]\n",
            "  [ 1.51043847e-01 -6.13730401e-03]\n",
            "  [ 3.34873726e-03 -8.40841606e-03]\n",
            "  [-3.34873726e-03  8.40841606e-03]]\n",
            "\n",
            " [[ 2.02166159e-02 -7.12231034e-03]\n",
            "  [-2.02166159e-02  7.12231034e-03]\n",
            "  [-2.84797817e-01 -6.77385777e-02]\n",
            "  [ 2.84797817e-01  6.77385777e-02]\n",
            "  [ 2.02166159e-02 -7.12231034e-03]\n",
            "  [-2.02166159e-02  7.12231034e-03]]\n",
            "\n",
            " [[ 4.66259429e-03 -8.53012130e-03]\n",
            "  [-4.66259429e-03  8.53012130e-03]\n",
            "  [ 1.80923939e-01 -8.68457556e-03]\n",
            "  [-1.80923939e-01  8.68457556e-03]\n",
            "  [ 4.66259429e-03 -8.53012130e-03]\n",
            "  [-4.66259429e-03  8.53012130e-03]]\n",
            "\n",
            " [[-1.28791928e-02  1.00179147e-02]\n",
            "  [ 1.28791928e-02 -1.00179147e-02]\n",
            "  [ 5.57164401e-02  2.00288892e-01]\n",
            "  [-5.57164401e-02 -2.00288892e-01]\n",
            "  [-1.28791928e-02  1.00179147e-02]\n",
            "  [ 1.28791928e-02 -1.00179147e-02]]\n",
            "\n",
            " [[ 1.36787526e-03 -3.88299301e-03]\n",
            "  [-1.36787526e-03  3.88299301e-03]\n",
            "  [ 1.70398951e-01  7.87113160e-02]\n",
            "  [-1.70398951e-01 -7.87113160e-02]\n",
            "  [ 1.36787526e-03 -3.88299301e-03]\n",
            "  [-1.36787526e-03  3.88299301e-03]]\n",
            "\n",
            " [[-8.16460047e-03 -6.37170486e-03]\n",
            "  [ 8.16460047e-03  6.37170486e-03]\n",
            "  [ 2.67324537e-01 -9.10834968e-03]\n",
            "  [-2.67324537e-01  9.10834968e-03]\n",
            "  [-8.16460047e-03 -6.37170486e-03]\n",
            "  [ 8.16460047e-03  6.37170486e-03]]\n",
            "\n",
            " [[ 1.45112360e-02  1.00059165e-02]\n",
            "  [-1.45112360e-02 -1.00059165e-02]\n",
            "  [-2.54597634e-01 -2.00275198e-01]\n",
            "  [ 2.54597634e-01  2.00275198e-01]\n",
            "  [ 1.45112360e-02  1.00059165e-02]\n",
            "  [-1.45112360e-02 -1.00059165e-02]]\n",
            "\n",
            " [[-3.06301471e-02 -1.10097392e-03]\n",
            "  [ 3.06301471e-02  1.10097392e-03]\n",
            "  [ 6.49859905e-02  3.16912681e-03]\n",
            "  [-6.49859905e-02 -3.16912681e-03]\n",
            "  [-3.06301471e-02 -1.10097392e-03]\n",
            "  [ 3.06301471e-02  1.10097392e-03]]\n",
            "\n",
            " [[-8.30065366e-03  1.08994525e-02]\n",
            "  [ 8.30065366e-03 -1.08994525e-02]\n",
            "  [-2.10643634e-02 -2.12530926e-01]\n",
            "  [ 2.10643634e-02  2.12530926e-01]\n",
            "  [-8.30065366e-03  1.08994525e-02]\n",
            "  [ 8.30065366e-03 -1.08994525e-02]]\n",
            "\n",
            " [[ 7.51383929e-03 -8.49209842e-04]\n",
            "  [-7.51383929e-03  8.49209842e-04]\n",
            "  [ 2.44037136e-01  7.00304583e-02]\n",
            "  [-2.44037136e-01 -7.00304583e-02]\n",
            "  [ 7.51383929e-03 -8.49209842e-04]\n",
            "  [-7.51383929e-03  8.49209842e-04]]\n",
            "\n",
            " [[ 1.63367018e-02  1.13826536e-03]\n",
            "  [-1.63367018e-02 -1.13826536e-03]\n",
            "  [-2.77677000e-01 -7.08508417e-02]\n",
            "  [ 2.77677000e-01  7.08508417e-02]\n",
            "  [ 1.63367018e-02  1.13826536e-03]\n",
            "  [-1.63367018e-02 -1.13826536e-03]]\n",
            "\n",
            " [[ 1.27840284e-02 -3.23580508e-03]\n",
            "  [-1.27840284e-02  3.23580508e-03]\n",
            "  [-2.61352062e-01 -3.06033827e-02]\n",
            "  [ 2.61352062e-01  3.06033827e-02]\n",
            "  [ 1.27840284e-02 -3.23580508e-03]\n",
            "  [-1.27840284e-02  3.23580508e-03]]]\n",
            "\n",
            "Nth Identities (Conceptual, per qubit):\n",
            "\n",
            "  Qubit 0:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.969383   -0.24431711]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 1:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.82486296 -0.5650734 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 2:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8568121   0.51552504]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 3:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.6867987  0.72678065]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 4:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9999415  0.00199693]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 5:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.93200636  0.3622772 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 6:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.95654505 -0.2913706 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 7:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.72789043 -0.68561184]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 8:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9846101 -0.1739796]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 9:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.4462686   0.89484954]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 10:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9964715  0.08337043]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 11:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.01623062 -0.9997983 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 12:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9680874  -0.25038546]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 13:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99679613 0.07930112]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 14:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.95617485  0.29254776]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 15:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.2996085   0.95398074]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 16:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9985277  -0.05288772]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 17:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9993396 -0.0307828]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 18:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.03797155 0.99907833]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 19:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9931857  0.11611041]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 20:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.14535914  0.98890704]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 21:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9452195  0.3263001]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 22:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.24888436 0.9684378 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 23:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.66463757  0.747062  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 24:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9780589  0.20804293]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 25:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.88621783  0.46280566]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 26:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8508953 -0.5250433]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 27:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.77054733 -0.6373132 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 28:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9940809  -0.10790538]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 29:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.21391179 0.9767489 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 30:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.78070503 -0.6246452 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 31:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9870227  0.15990697]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 32:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.45167702  0.8921221 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 33:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.97411865 -0.22573842]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 34:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99563926 -0.09280213]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 35:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99951994 -0.01568861]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 36:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9097981  0.4149057]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 37:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.02084996 0.9997321 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 38:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9738891  -0.22677687]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 39:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.945183  0.3263737]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 40:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9693742 0.2453317]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 41:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96273786 -0.27031836]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 42:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.4745657 -0.8799248]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 43:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9484121  0.3168722]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 44:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9955053   0.09352805]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 45:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9940611   0.10833724]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 46:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.70751303 -0.7064855 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 47:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.95909876 -0.28276402]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 48:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.29174834 -0.9563864 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 49:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.5698951   0.82155764]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 50:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9998287   0.01531383]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 51:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.49195477 0.8705361 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 52:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.36995596 -0.92893034]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 53:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.94313604 -0.33226666]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 54:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.47957963 -0.8773812 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 55:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.78928113  0.6139322 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 56:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.33217934 -0.94295883]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 57:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.78827083 -0.61517143]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 58:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.82321465 0.5676303 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 59:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99932206 -0.03591976]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 60:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.60582846  0.79550344]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 61:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9935425  -0.11228961]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 62:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9975205  0.06950258]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 63:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9693547  -0.24535638]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "\n",
            "Info-energy Output (all qubits):\n",
            " [ 3.5212703  6.1626883  9.359011  13.174902  11.080349   8.258005\n",
            " 12.595779  10.095257   4.4720016 12.644066   9.896723   2.220582\n",
            " 12.812871  12.837017   7.4136877  8.948345   5.91514    8.6834755\n",
            "  7.095695  11.860863   9.3510065  7.8417597  7.9200673  6.352889\n",
            "  9.350778   6.8039894  5.588159   1.7538126  5.8736343 10.207338\n",
            "  3.918892  10.646774   8.658127   6.597602  13.198542   7.0534143\n",
            "  4.1892014  8.355273   9.322881   7.781429  11.76941    3.1251283\n",
            "  5.808461   6.421604   4.028397   4.9975314  2.3165133  8.456684\n",
            "  4.793615   8.361288   6.0709257 10.930252   5.9930143  9.339655\n",
            "  7.7474966  6.889956   5.778677   6.3083606 14.218488   3.4310274\n",
            "  6.912668   8.295307   7.7507277  8.824234 ]\n",
            "\n",
            "Resonance Keys (all qubits):\n",
            " ['5bdf1ae0a53954eedae02e3a1803ea322c3f2314770a6549e317bfa26a28db6e', 'dec736a108855cbdb7b3007cfca6d797ded9b845f292e9efcc9662b99f148eec', 'faa349b6c726d30c49034f48acd935a966fde46aa03d646d585da16613523b49', '0f4360133dc1c703f1bb85f58de05e1934b805f183da0076145d2134482dbaf5', 'd879243460f477da2e303df7a0fdd56b6d906842910b2d1934fb96802b3c2cfa', '05d5b6fde551c0514386d5bbd6a95b71a67a3b80a35a01d28a5b034ea86e00d2', '1a993b2747601a9740457de2b0a0ee6d1f2e3aba0d4177f5903348b1fb4a785f', '8887d6f00832803c99f9a30be81b1007da5b97d1866cdbd51e08cf760925d309', '6c1f277a34f3637ff201fe44c2bca95a5f6d2c3066e87514d40ef74c2ab7e4fc', 'e9ae42f57fdf66f385b34854983b0f607b5fcc246d709d85f47829bbb06a9100', '76163a3075b43633847780899f66af33734c51a6be1e735fd4f1516337d7130a', 'f78f89e5389f00801463aca33fe00cac8087b64cc1585a9bb11c4b9323bb1117', '6decf04d84353470792bc4a41cc2081923663b00da2c5b8493bdc95d9a250d27', 'bfe81ae1df89d9fbe5ea4cf06551640a126c5470759878eba705242985022334', '900a703231352b94207c60b661eaaa1961bc9d85af8165396d9fa1248fb42a80', 'a020e51dacc5793b2a6dc1b80e6490647a2ce775aee48825dbd5a67c616e1b03', '9a97c8f0965195ac20b0a59159f7da11ce563ba87604aefe0443ed8ee52338da', 'f2a5fb9f2883cba7e7980b2b32757867902b753c084ae17e9afc82485ddde8f0', '41d62ad3da2588aa85d1e7c84ff926b532731a5f3376501dec94cf769a4a7712', '0623918cc596023b6e2f2b322cf1c7854b564f808d90694c39adfc70c5ad0864', 'c407eb28a04c02fad0004e8c1aacbd6d35ae9a287f450c1c467d695e534d23df', '8ab809902e6d35c22319c278d7678130f95a341033d64912045bf971074ded85', 'a68d59ab6f94d3305a793f7d44a8451bcebc3b8692f83cd33855e439b1e05eaf', '1d75fecc50ad7e3e0bb598f9f18cb4f48c89eb2fbf96b7e77e4f9ab3e42e75e7', 'c696b35a4996c5431e356ecd40ac41e852ca60a2a8a7f570119449f7b5379934', '850f4bd51cf7638c937b7061a2d8dbf18671f60713f6380404531dcc3949c9ae', 'ca1e1274fb8624c6f820574fa4822f54580f0e50899147eaf04436ffa2593693', '84a90bc268a39e37878676c07a3ec2e44badf437aa60ff69331e45af13971faa', 'dadb1d4c055eab188d265802ef7e8915893e96d138fcac7e338e99f0cc450be7', '8b81e57d002fe942d7bc04298107c6a2c35089ba8c028d13f0ee0891f7bbb482', '20d980d8d62171e444dacf088aaa3b403ff98c985f5d666043377c219f7e7f06', '03d7774e83b00741dd21687c82683885286bf8cb18bd60f7a711172287fd48bb', '242708c06dc20a4a5a20d39fbc1d086a07b8fdbf162a9b164df4cb816d331dc2', 'b5a97a00105c934ba088a68875450918921c7b9125aaf8f877d631c757449105', '6188ebeca611e27e29417c874b764f94ec6747add7b78d03873b3a806d896127', '7e389f4bebfe071e47c37a406c71e0061755afacb229d964af182402f8bd96cd', 'f0621b1adb6bad2789e4323e675d009080cce586204b1ce20da5d43aea768fe6', '060607ebf2a5e869eb87f7a2865e870e3b1de2cc53535f69396df47a23b5916a', '326e2d2a624b2f3634eb6c75ab7f08087e64bd4b01da43c8cb5f7cb6a47e97c9', '7f25dd5221193a911410e6be04562c4d0bbcc55610aef11ec6be3c0e6df6051b', '6a8806205c59f0fc26e5264a2f455e31ee344a9f55b0e8500ec9ad004c8ea9d0', '8433e447373174c6f7b47f10c8cb427dc63d4b7d8262edd488e5d94b7fa51b5a', '496f69518d9d264ca38850bdf7f9d31e62b911b2c9c55422d8718c7391e4cb45', 'e99dd821743e8bd27a85d484422a0203a92030f5c535923a9e4b8ddad85558ba', '9247300ab4865d3b2e239d486ba2d10a0cb27d8f6e33f5e8bc379c5661e89095', '16c94dc5e4bd16d4b7af7a647e14b3a545275d7f85d47321864b98a27ee1efb1', 'c0c70d5a81396902734505d7ffdd40b0818b32d1560bfc7bc9465462c4363928', '8a4f77d7baa7ff77dfbb56bc82dc06e918d0454c7ad10b23c11f781fd05d8883', 'a46e3289247b949ae3542d9ebdb5990a19cf44c3201f492edb9eb0ae1c1c63da', 'c8211aa7adaeaa0bd1111e4a9fe43e54af1a6e47d3e56db737d559bed2adb123', '5de003aab35b4da7deeb7d0ae79c83cbd48e4ee36f82f5429e15a6d0c45ee616', '5130be6a89ccc51af97e7eb62717dfbbf401094058e81b63c1deca7d653309c6', 'e9dd2f3f1576abedd07f9f7902bf3ff1a05ab52c6387b264ed55910564522060', '96bc0c20db5e564c9fc51217c88f53179a483c478d59db68eba5e17e169b7215', '800f747aebb88e708c274cdd3ed8ebc7d12c4432d4297aa6e98526345530b669', '93e9b2b9bf57360baea34669226810a328a725e5504be111fe0e1cded9b10d0a', '15769836772193e0d167e37f33be4570e2d470944eca22ed2de8e1f9945b37de', '6d81181b0272ec6c774773ad8a402836772eaff5319c5e5647cc36e3cf7de2f2', '51b50ab1cb975ab7dc4e06671898794adf19b3384a60382742d55f40b9159160', '6f82a4a68874cbd55712350574a3bee6f9adad7532be796085c7ba3bf7a281e6', '3b75c06f47a2d8eee0842bf3928a8983f407fd5592515e129bb01b381a95698e', '3e0a3a94e565cf22177bd5916a0d82ea4c6fe6a4b383e550f8e2e557f7d85345', 'dc7dde45443158d276185f038a5ecf3780caff2d337810351f6794a973bf49f8', 'c5cfe6f004f866e9e3cbb119faa5eac6d6fac795698277a2e9a272ed7c23b179']\n",
            "\n",
            "Spin (all qubits, conceptual):\n",
            " [[[ 0.551759   -0.7515748   0.36152086]\n",
            "  [ 0.8972904   0.25332317  0.36152086]]\n",
            "\n",
            " [[ 0.42732993 -0.3458313  -0.8353382 ]\n",
            "  [-0.5483687  -0.03875519 -0.8353382 ]]\n",
            "\n",
            " [[ 0.4914913   0.8221131   0.28734362]\n",
            "  [ 0.06800824 -0.9554101   0.28734362]]\n",
            "\n",
            " [[ 0.20108749  0.16944522  0.9648068 ]\n",
            "  [-0.23092647  0.12578087  0.9648068 ]]\n",
            "\n",
            " [[-0.17376061  0.7712687  -0.6123331 ]\n",
            "  [-0.38278565  0.6917538  -0.6123331 ]]\n",
            "\n",
            " [[ 0.48685223 -0.16592279 -0.8575806 ]\n",
            "  [-0.04984172  0.511929   -0.8575806 ]]\n",
            "\n",
            " [[ 0.39128107 -0.3401894   0.85508496]\n",
            "  [ 0.5168773  -0.0408357   0.85508496]]\n",
            "\n",
            " [[ 0.23159952 -0.59296346  0.77120423]\n",
            "  [ 0.15907499 -0.6163921   0.77120423]]\n",
            "\n",
            " [[-0.7169909   0.01214403 -0.6969767 ]\n",
            "  [ 0.68740463 -0.2042017  -0.6969767 ]]\n",
            "\n",
            " [[ 0.9687998  -0.21988124  0.11436412]\n",
            "  [ 0.10859154 -0.98748606  0.11436412]]\n",
            "\n",
            " [[-0.02007361  0.02886031  0.9993819 ]\n",
            "  [ 0.0273028   0.02214553  0.9993819 ]]\n",
            "\n",
            " [[-0.5864899  -0.7713139  -0.24719311]\n",
            "  [ 0.09743846 -0.96405464 -0.24719311]]\n",
            "\n",
            " [[-0.6109673  -0.78543735 -0.09903119]\n",
            "  [ 0.24412133 -0.9646749  -0.09903119]]\n",
            "\n",
            " [[ 0.95465034 -0.27673352 -0.10982395]\n",
            "  [-0.3681977   0.9232384  -0.10982395]]\n",
            "\n",
            " [[-0.90804464 -0.4134884  -0.06694962]\n",
            "  [-0.8003531   0.595779   -0.06694962]]\n",
            "\n",
            " [[ 0.9584299   0.22078477 -0.18073799]\n",
            "  [ 0.13139257  0.97471523 -0.18073799]]\n",
            "\n",
            " [[ 0.01796232  0.03546848  0.99920934]\n",
            "  [ 0.01774142  0.03557948  0.99920934]]\n",
            "\n",
            " [[ 0.6104469   0.5491965  -0.57073444]\n",
            "  [-0.4065968  -0.71340114 -0.57073444]]\n",
            "\n",
            " [[-0.25748488  0.88920027 -0.37818563]\n",
            "  [-0.70225596  0.6031685  -0.37818563]]\n",
            "\n",
            " [[-0.51099575  0.6912599   0.51092374]\n",
            "  [ 0.7315447  -0.45144135  0.51092374]]\n",
            "\n",
            " [[ 0.6648518  -0.4985064  -0.55629444]\n",
            "  [-0.48213598 -0.6768171  -0.55629444]]\n",
            "\n",
            " [[-0.570222   -0.28867197 -0.7691003 ]\n",
            "  [-0.45816123 -0.44561526 -0.7691003 ]]\n",
            "\n",
            " [[ 0.4773461  -0.39272672  0.7860702 ]\n",
            "  [ 0.41587433  0.45732057  0.7860702 ]]\n",
            "\n",
            " [[-0.33499336  0.1961151   0.92158467]\n",
            "  [ 0.37248346  0.10926005  0.92158467]]\n",
            "\n",
            " [[-0.6629145  -0.49289694 -0.5635574 ]\n",
            "  [-0.30097094 -0.7692981  -0.5635574 ]]\n",
            "\n",
            " [[-0.3346726   0.5108694   0.7918376 ]\n",
            "  [-0.33738986 -0.509079    0.7918376 ]]\n",
            "\n",
            " [[-0.02723902 -0.03704022  0.9989425 ]\n",
            "  [-0.00335218  0.04585526  0.9989425 ]]\n",
            "\n",
            " [[ 0.6200346  -0.10175461  0.777948  ]\n",
            "  [ 0.29968423  0.55225563  0.777948  ]]\n",
            "\n",
            " [[-0.7393974   0.42671007 -0.5207783 ]\n",
            "  [-0.40619794  0.75086164 -0.5207783 ]]\n",
            "\n",
            " [[ 0.97361857  0.08077814 -0.2134052 ]\n",
            "  [-0.64437103 -0.73433244 -0.2134052 ]]\n",
            "\n",
            " [[ 0.03822332 -0.2358344   0.97104126]\n",
            "  [ 0.06483322  0.22994682  0.97104126]]\n",
            "\n",
            " [[ 0.31892908 -0.9261362  -0.20138514]\n",
            "  [ 0.9773      0.0657936  -0.20138514]]\n",
            "\n",
            " [[-0.75598013 -0.6370664   0.1504674 ]\n",
            "  [-0.85055625  0.5038984   0.1504674 ]]\n",
            "\n",
            " [[-0.44571862  0.8843515  -0.13877077]\n",
            "  [ 0.9389735  -0.31475624 -0.13877077]]\n",
            "\n",
            " [[-0.9263107   0.332165    0.17780562]\n",
            "  [ 0.698343    0.69332695  0.17780562]]\n",
            "\n",
            " [[ 0.481507    0.29144615  0.82656527]\n",
            "  [-0.02372088  0.5623408   0.82656527]]\n",
            "\n",
            " [[-0.05332184 -0.17688441 -0.9827862 ]\n",
            "  [-0.14821285  0.11029172 -0.9827862 ]]\n",
            "\n",
            " [[ 0.87941223  0.42774153 -0.20897685]\n",
            "  [-0.19448672  0.95838594 -0.20897685]]\n",
            "\n",
            " [[ 0.51489806 -0.73377204 -0.44323647]\n",
            "  [-0.4141124   0.7950172  -0.44323647]]\n",
            "\n",
            " [[-0.5777973  -0.06891692  0.8132655 ]\n",
            "  [ 0.11697061 -0.570015    0.8132655 ]]\n",
            "\n",
            " [[-0.78627324 -0.1431594  -0.6010656 ]\n",
            "  [ 0.7032273   0.3797256  -0.6010656 ]]\n",
            "\n",
            " [[ 0.799672    0.5524955   0.23510301]\n",
            "  [-0.61000997  0.7567129   0.23510301]]\n",
            "\n",
            " [[ 0.06475301  0.23177448 -0.970612  ]\n",
            "  [-0.23396008 -0.05634753 -0.970612  ]]\n",
            "\n",
            " [[ 0.22207811  0.00371551  0.9750218 ]\n",
            "  [-0.19794235  0.10075378  0.9750218 ]]\n",
            "\n",
            " [[ 0.25839126  0.3831052   0.88682824]\n",
            "  [-0.4595437  -0.04853048  0.88682824]]\n",
            "\n",
            " [[ 0.14052601 -0.15098166 -0.9784973 ]\n",
            "  [ 0.20557322 -0.01681307 -0.9784973 ]]\n",
            "\n",
            " [[-0.7699538  -0.59028804  0.2423452 ]\n",
            "  [-0.6310658  -0.7369022   0.2423452 ]]\n",
            "\n",
            " [[ 0.5701597   0.6477225  -0.505345  ]\n",
            "  [ 0.8304737   0.23439257 -0.505345  ]]\n",
            "\n",
            " [[-0.10872731  0.91497004 -0.38859767]\n",
            "  [-0.75973946  0.52133274 -0.38859767]]\n",
            "\n",
            " [[ 0.5959274  -0.0886067  -0.7981349 ]\n",
            "  [-0.41841096  0.43348923 -0.7981349 ]]\n",
            "\n",
            " [[-0.25823283  0.8409953   0.47543943]\n",
            "  [ 0.8749215  -0.09203101  0.47543943]]\n",
            "\n",
            " [[-0.5391383   0.31595984 -0.7807043 ]\n",
            "  [ 0.12988605  0.6112531  -0.7807043 ]]\n",
            "\n",
            " [[ 0.9894761  -0.08537583  0.11682469]\n",
            "  [ 0.99265736  0.03135855  0.11682469]]\n",
            "\n",
            " [[-0.01842281  0.83100426 -0.5559609 ]\n",
            "  [-0.58138597 -0.5940521  -0.5559609 ]]\n",
            "\n",
            " [[ 0.54286206  0.79231066 -0.2784684 ]\n",
            "  [ 0.88792014 -0.36613268 -0.2784684 ]]\n",
            "\n",
            " [[ 0.01301599 -0.09568454  0.9953266 ]\n",
            "  [-0.08843303  0.03878849  0.9953266 ]]\n",
            "\n",
            " [[-0.23346703 -0.5184581   0.8226143 ]\n",
            "  [-0.5580001   0.1092775   0.8226143 ]]\n",
            "\n",
            " [[ 0.4164723  -0.43372038 -0.7990228 ]\n",
            "  [-0.19370924  0.5692445  -0.7990228 ]]\n",
            "\n",
            " [[-0.8264727   0.5391732  -0.16197252]\n",
            "  [ 0.2505947   0.954446   -0.16197252]]\n",
            "\n",
            " [[-0.9774337  -0.19988307  0.06833817]\n",
            "  [-0.956019   -0.28523248  0.06833817]]\n",
            "\n",
            " [[ 0.45453545 -0.8185592  -0.35122406]\n",
            "  [-0.26126567 -0.8991006  -0.35122406]]\n",
            "\n",
            " [[-0.06115215 -0.09742524  0.99336237]\n",
            "  [ 0.10253043 -0.05214185  0.99336237]]\n",
            "\n",
            " [[ 0.24501322 -0.46243706 -0.852127  ]\n",
            "  [ 0.41512913  0.3186649  -0.852127  ]]\n",
            "\n",
            " [[ 0.1349391  -0.1539136   0.9788269 ]\n",
            "  [ 0.203539    0.02167572  0.9788269 ]]]\n",
            "\n",
            "I_vec (all qubits, conceptual):\n",
            " [[0.3053163  0.09818663 0.0758867  ... 0.14131688 0.39044717 0.3004119 ]\n",
            " [0.000888   0.17786922 0.31814706 ... 0.33929157 0.24765024 0.24117398]\n",
            " [0.19530305 0.3398976  0.3003205  ... 0.15053555 0.17893073 0.31016704]\n",
            " ...\n",
            " [0.01517774 0.38064072 0.20812066 ... 0.37217057 0.16231571 0.2985118 ]\n",
            " [0.23648767 0.05508543 0.10693154 ... 0.38089904 0.34445143 0.288574  ]\n",
            " [0.25062615 0.10115969 0.35001987 ... 0.11018451 0.10073749 0.41763014]]\n",
            "\n",
            "NECL Manifest Checksums (per qubit, conceptual):\n",
            " ['1e9c36b179a49a9ccbab1e143258c053afa33031313a881416d140f8b9f803b8', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945']\n",
            "\n",
            "TRACE Log (Conceptual - detailed lineage for error correction):\n",
            " [{'qubit': 0, 'reason': 'binary_refactor', 'source': 'tuplets', 'r_metric': 0.9834799766540527, 'u_metric': 0.9714906215667725, 'dv_metric': 0.16457879543304443, 'invariant_pass': False, 'degenerate_check': False, 'correction_threshold_r': 1.02, 'correction_threshold_u': 1.02, 'correction_threshold_d': 0.765, 'corrected_bits': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1], 'old_key': '25b695204a5c6b4e0c71e67607dabca074b22cb01790bbbff4d566c2bde9b75a', 'new_key': '5bdf1ae0a53954eedae02e3a1803ea322c3f2314770a6549e317bfa26a28db6e'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a8bf102"
      },
      "source": [
        "# Task\n",
        "The previous request has been approved. The plan is to proceed with the specified refactoring and documentation.\n",
        "\n",
        "Here's the execution plan:\n",
        "\n",
        "1.  **Refactor `detect_collapse` function**:\n",
        "    *   Introduce a new constant `R_FOR_RATIO` (set to `2.0` as a default example).\n",
        "    *   Modify the `detect_collapse` function to implement the new triplet-level predicate: For each index `p` within a triplet `t={i,j,k}`, the collapse condition `[high(real_p) ∧ low(unreal_p)] ∨ [ratio(real_p / unreal_p) > R_FOR_RATIO]` will be evaluated. If this condition is true for *any* index within the triplet, all indices `i,j,k` of that triplet will be marked as collapsed.\n",
        "\n",
        "2.  **Review `apply_parity_rotation` and `COLLAPSE_Q` functions**: Confirm that these functions operate correctly with the refined `collapse_mask` produced by the updated `detect_collapse`. No code changes are expected for these functions, as their existing logic correctly utilizes the `collapse_mask`.\n",
        "\n",
        "3.  **Document `correct_bits` function**: Add comments to `correct_bits` to clarify its intended operational strategy regarding local re-evaluation and lineage recording within a unit, without advancing across units unless local exhaustion occurs.\n",
        "\n",
        "Here's the updated code with the changes:\n",
        "\n",
        "```python\n",
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "R_FOR_RATIO = 2.0 # NEW: Ratio threshold constant for collapse detection\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| + n_|y, η| = n_|x+y, ξ+η|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| · n_|y, η| = n_|x·y, ξ·η|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ξ| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ξ_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW, r_for_ratio=R_FOR_RATIO):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register.\n",
        "    A triplet block collapses if, for any index 'p' within the triplet,\n",
        "    the condition [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO] is met.\n",
        "    If this condition is true for *any* index within the triplet, all indices i,j,k\n",
        "    of that triplet are marked as collapsed.\n",
        "    COLL(x, χ) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for unreal component (should be negative).\n",
        "        r_for_ratio (float): Ratio threshold for collapse detection.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    # Initialize a collapse mask filled with zeros\n",
        "    collapse_mask = tf.zeros(tf.shape(real_parts), dtype=tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Iterate over each triplet block and apply collapse detection\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # Extract real and unreal parts for the current triplet across all Q qubits\n",
        "        # shape [Q, 3]\n",
        "        triplet_real_block = tf.gather(real_parts, current_triplet_indices, axis=1)\n",
        "        triplet_unreal_block = tf.gather(unreal_parts, current_triplet_indices, axis=1)\n",
        "\n",
        "        # Evaluate the new triplet-level predicate for each index 'p' within the triplet block\n",
        "        # The condition: [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO]\n",
        "        # high(real_p): real_p >= tau_hi\n",
        "        # low(unreal_p): unreal_p <= tau_low (using TAU_LOW for unreal too)\n",
        "\n",
        "        # Condition 1: high(real_p) AND low(unreal_p)\n",
        "        cond1 = tf.logical_and(triplet_real_block >= tau_hi, triplet_unreal_block <= tau_low) # [Q, 3]\n",
        "\n",
        "        # Condition 2: ratio(real_p / unreal_p) > r_for_ratio\n",
        "        # Handle potential division by zero for unreal_p\n",
        "        # If unreal_p is near zero, the ratio might be undefined or very large.\n",
        "        # Set ratio to 0 if unreal_p is ~0 to avoid NaNs and make the condition false.\n",
        "        ratio_term = tf.where(tf.abs(triplet_unreal_block) > EPS, triplet_real_block / triplet_unreal_block, tf.zeros_like(triplet_real_block))\n",
        "        cond2 = ratio_term > r_for_ratio # [Q, 3]\n",
        "\n",
        "        # Triplet collapse if (cond1 OR cond2) is true for *any* index within the triplet\n",
        "        # tf.reduce_any along the triplet dimension (axis=1) for each qubit\n",
        "        triplet_collapse_per_qubit = tf.reduce_any(tf.logical_or(cond1, cond2), axis=1) # [Q]\n",
        "\n",
        "        # Mark all 3 indices of the triplet as collapsed if triplet_collapse_per_qubit is true for that qubit\n",
        "        unit_collapse_flag_int = tf.cast(triplet_collapse_per_qubit, tf.int32) # [Q]\n",
        "        marked_triplet_block = tf.broadcast_to(tf.expand_dims(unit_collapse_flag_int, axis=1), tf.shape(triplet_real_block)) # [Q, 3]\n",
        "\n",
        "        # Construct indices for scatter_nd_max to update the global collapse_mask\n",
        "        # indices_to_update will be [Q*3, 2]\n",
        "        # First column is qubit index, second is original 30-index\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1)\n",
        "\n",
        "        # Flatten marked_triplet_block to [Q*3] for updates\n",
        "        updates = tf.reshape(marked_triplet_block, [-1])\n",
        "\n",
        "        # Use tf.tensor_scatter_nd_max to update the collapse_mask.\n",
        "        # This ensures that if any triplet marks an index as collapsed, it remains marked.\n",
        "        collapse_mask = tf.tensor_scatter_nd_max(collapse_mask, indices_to_update, updates)\n",
        "\n",
        "    return collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\" # This assertion was incorrect, changed axis_maps['x'] to axis_vals.\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components. Implements ASSOC(A, B, α) logic.\n",
        "\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`).\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode('utf-8')).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    for b_idx_triplet in tf.range(10):\n",
        "        current_triplet_indices = idx[b_idx_triplet, :] # Shape [3]\n",
        "        s = tf.gather(signs, current_triplet_indices) # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        trip_mix.extend([has_mix.numpy().item()]*3) # Extend with Python integers, then convert back to tensor\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook: Derives corrected bits from tuplet order if current bits are inconsistent.\n",
        "    Updates Bits[q] and ResonanceKey[q] if correction occurs.\n",
        "\n",
        "    User-specified scope for ErrorCorrectNext (represented by this function):\n",
        "    This function advances within the same triplet (or within the primaries 6-set),\n",
        "    re-evaluates locally, and records lineage. It must not advance across units\n",
        "    unless the local unit exhausts. The logic within this function (e.g., derive_bits_advanced)\n",
        "    operates on a per-qubit basis, ensuring local re-evaluation and lineage recording,\n",
        "    and does not inherently advance across distinct triplet units or qubits until\n",
        "    the current qubit's state is fully evaluated and potentially corrected.\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs)\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47750056"
      },
      "source": [
        "## Refactor Collapse Detection\n",
        "\n",
        "### Subtask:\n",
        "Modify the `detect_collapse` function to implement the new triplet-level predicate and introduce `R_FOR_RATIO`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6060e1d4"
      },
      "source": [
        "## Review Parity Application\n",
        "\n",
        "### Subtask:\n",
        "Confirm that the `apply_parity_rotation` function correctly applies half-rotation only to indices marked as collapsed (by the refined `detect_collapse`) and prime indices globally, without block-wide broadcast beyond the coherent unit. No code changes are expected here as the `collapse_mask` will now be sufficiently precise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "042707b9"
      },
      "source": [
        "## Review Parity Application\n",
        "\n",
        "### Subtask:\n",
        "Confirm that the `apply_parity_rotation` function correctly applies half-rotation only to indices marked as collapsed (by the refined `detect_collapse`) and prime indices globally, without block-wide broadcast beyond the coherent unit. No code changes are expected here as the `collapse_mask` will now be sufficiently precise.\n",
        "\n",
        "#### Instructions\n",
        "1. Examine the `apply_parity_rotation` function.\n",
        "2. Verify that it uses the `collapse_mask` (which is now generated by the refactored `detect_collapse` function) to determine which elements are 'affected'.\n",
        "3. Confirm that the application of the sign flip (`rotated = pairs * sign_expanded`) correctly modifies only the elements identified by the `affected` mask, ensuring that the parity rotation is applied precisely to the intended indices without unintended propagation.\n",
        "4. Document the confirmation that the function operates as expected given the refined `collapse_mask`.\n",
        "\n",
        "### Confirmation of `apply_parity_rotation`\n",
        "\n",
        "Upon reviewing the `apply_parity_rotation` function in the provided code, the following observations confirm its correct operation in conjunction with the refined `detect_collapse` function:\n",
        "\n",
        "1.  **Use of `collapse_mask`:** The function explicitly takes `collapse_mask` as an argument. This mask is generated by the `detect_collapse` function and now accurately reflects collapsed indices without block-wide broadcast beyond the coherent unit.\n",
        "\n",
        "2.  **Determination of 'affected' elements:** The `affected` tensor is computed using `tf.logical_or(prime > 0, collapse_mask > 0)`. This logic correctly identifies elements that should undergo half-rotation: those corresponding to global prime indices OR any specific index identified as collapsed by the `collapse_mask`. The `prime` mask is broadcasted to match the shape of `collapse_mask`, ensuring proper element-wise logical operation across all qubits.\n",
        "\n",
        "3.  **Precise Application of Sign Flip:** The `sign` tensor is created such that it is `-1.0` for `affected` indices and `1.0` otherwise. This `sign` is then expanded to `[Q, 30, 1]` via `tf.expand_dims(sign, axis=-1)` and multiplied element-wise with the `pairs` tensor: `rotated = pairs * sign_expanded`. This ensures that *only* the specific real and unreal components of the phase-dual units corresponding to affected indices are sign-flipped, while others remain unchanged. There is no unintended propagation or block-wide broadcast beyond the coherent unit for non-collapsed indices.\n",
        "\n",
        "Given this analysis, the `apply_parity_rotation` function operates as expected, applying half-rotation precisely to indices determined by the refined `collapse_mask` and global prime indices, thereby fulfilling the subtask requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "000b561c"
      },
      "source": [
        "## Review COLLAPSE_Q Function\n",
        "\n",
        "### Subtask:\n",
        "Confirm that the `COLLAPSE_Q` function continues to operate correctly by zeroing out only the specific primary units identified by the more granular collapse mask. No code changes are expected here.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c910c902"
      },
      "source": [
        "### Confirmation of `COLLAPSE_Q` Function Operation\n",
        "\n",
        "The `COLLAPSE_Q` function has been reviewed, and its operation aligns with the specified requirements:\n",
        "\n",
        "1.  **Extraction of Relevant Collapse Flags**: The function correctly extracts the collapse flags pertinent to the initial 6 primary units using `primary_collapse_flags = collapse_mask[:, 0:6]`. This ensures that only the collapse information directly corresponding to the `primaries` input is considered for zeroing.\n",
        "\n",
        "2.  **Conditional Zeroing**: The extracted `primary_collapse_flags` are expanded to match the `[Q, 6, 2]` shape of the `primaries` tensor. Subsequently, `tf.where` is used to conditionally set the elements of `primaries` to `[0.0, 0.0]` where the corresponding flag in `primary_collapse_flags_float` is `> 0`. For primary units not marked for collapse, their original values are preserved.\n",
        "\n",
        "This mechanism effectively zeroes out only the specific phase-dual primary units that are part of a collapsed block, as indicated by the granular collapse mask, without affecting other non-collapsed primary units. No unintended side effects were identified, confirming the correct and precise application of the zeroing operation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b32f5d3b"
      },
      "source": [
        "## Document `correct_bits` function\n",
        "\n",
        "### Subtask:\n",
        "Add comments to the `correct_bits` function to clarify its intended operational strategy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "245304ec"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires adding comments to the `correct_bits` function to explain its operational strategy regarding local re-evaluation and lineage recording. I will provide the updated function within a code block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ca4d60fd",
        "outputId": "110b4458-2821-47a4-a522-ce328f575d4e"
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ̇| + n_|y, ̇| = n_|x+y, ̇+̇|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ̇| · n_|y, ̇| = n_|x·y, ̇·̇|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ̇| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ̇_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register.\n",
        "    A triplet block collapses if 'both high AND low values coexist' in the real\n",
        "    component within that block, or similarly for the unreal component.\n",
        "    If a triplet collapses, all 3 indices corresponding to that triplet are marked.\n",
        "    COLL(x, ̇) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for real component (should be negative).\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    def _mark_block_phase_dual(block_real, block_unreal):\n",
        "        \"\"\"\n",
        "        Helper to mark collapse within a specific block for phase-dual components.\n",
        "        block_real and block_unreal shapes: [Q, block_size]\n",
        "        \"\"\"\n",
        "        # Collapse detection for REAL component: high AND low coexistence\n",
        "        high_real = tf.cast(block_real >= tau_hi, tf.int32)\n",
        "        low_real  = tf.cast(block_real <= tau_low, tf.int32)\n",
        "        any_h_real = tf.reduce_max(high_real, axis=1, keepdims=True) # [Q,1] (1 if any element is >= tau_hi)\n",
        "        any_l_real = tf.reduce_max(low_real,  axis=1, keepdims=True)  # [Q,1] (1 if any element is <= tau_low)\n",
        "        collapse_condition_real = tf.logical_and(any_h_real > 0, any_l_real > 0) # [Q,1]\n",
        "\n",
        "        # Collapse detection for UNREAL component: high AND low coexistence\n",
        "        high_unreal = tf.cast(block_unreal >= tau_hi, tf.int32)\n",
        "        low_unreal  = tf.cast(block_unreal <= tau_low, tf.int32)\n",
        "        any_h_unreal = tf.reduce_max(high_unreal, axis=1, keepdims=True) # [Q,1]\n",
        "        any_l_unreal = tf.reduce_max(low_unreal,  axis=1, keepdims=True)  # [Q,1]\n",
        "        collapse_condition_unreal = tf.logical_and(any_h_unreal > 0, any_l_unreal > 0) # [Q,1]\n",
        "\n",
        "        # A unit collapses if collapse is detected in EITHER real OR unreal components' blocks\n",
        "        unit_collapse_flag = tf.logical_or(collapse_condition_real, collapse_condition_unreal) # [Q,1]\n",
        "        unit_collapse_flag_int = tf.cast(unit_collapse_flag, tf.int32) # [Q,1]\n",
        "\n",
        "        # Mark all elements within the block if the block-level collapse flag is true\n",
        "        # for that qubit. This marks individual selectors within the block as collapsed.\n",
        "        mark = tf.broadcast_to(unit_collapse_flag_int, tf.shape(block_real)) # [Q, block_size]\n",
        "        return mark\n",
        "\n",
        "    # Initialize a collapse mask filled with zeros\n",
        "    collapse_mask = tf.zeros(tf.shape(real_parts), dtype=tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Iterate over each triplet block and apply collapse detection\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # Extract real and unreal parts for the current triplet across all Q qubits\n",
        "        # shape [Q, 3]\n",
        "        triplet_real_block = tf.gather(real_parts, current_triplet_indices, axis=1)\n",
        "        triplet_unreal_block = tf.gather(unreal_parts, current_triplet_indices, axis=1)\n",
        "\n",
        "        # Apply collapse detection for this triplet block\n",
        "        # Returns [Q, 3] where each element is marked if the *triplet block* collapsed\n",
        "        marked_triplet_block = _mark_block_phase_dual(triplet_real_block, triplet_unreal_block) # [Q, 3]\n",
        "\n",
        "        # Construct indices for scatter_nd_max to update the global collapse_mask\n",
        "        # indices_to_update will be [Q*3, 2]\n",
        "        # First column is qubit index, second is original 30-index\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1)\n",
        "\n",
        "        # Flatten marked_triplet_block to [Q*3] for updates\n",
        "        updates = tf.reshape(marked_triplet_block, [-1])\n",
        "\n",
        "        # Use tf.tensor_scatter_nd_max to update the collapse_mask.\n",
        "        # This ensures that if any triplet marks an index as collapsed, it remains marked.\n",
        "        collapse_mask = tf.tensor_scatter_nd_max(collapse_mask, indices_to_update, updates)\n",
        "\n",
        "    return collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components. Implements ASSOC(A, B, α) logic.\n",
        "\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`).\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode('utf-8')).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    for b_idx in range(10):\n",
        "        s = signs[b_idx*3:(b_idx+1)*3] # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        trip_mix.extend([has_mix]*3) # Apply this mix flag to all 3 indices of the triplet\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook for a single qubit (q_idx). This function performs a local\n",
        "    re-evaluation of the bit pattern for the current qubit if the initial derivation\n",
        "    is deemed 'inconsistent'.\n",
        "\n",
        "    This function is designed to:\n",
        "    - Advance *only* within the same triplet (or within the primaries 6-set) for local re-evaluation.\n",
        "      It uses the `pairs_q` and `triplets_q` already derived for this specific qubit `q_idx`.\n",
        "      It does not implicitly advance to other qubits or triplets; its scope is limited to the\n",
        "      current qubit's local tuplet structure.\n",
        "    - Record lineage for any local adjustments made. If a correction occurs, a specific\n",
        "      entry is added to the `TRACE` log, detailing the reason, source, metrics, and new key.\n",
        "    - *Not* advance across different units (triplets or qubits) unless the current local unit\n",
        "      has been exhausted. The `derive_bits_advanced` function, called internally,\n",
        "      operates solely on the provided `pairs_q` and `triplets_q` for the current qubit.\n",
        "\n",
        "    Args:\n",
        "        q_idx (int): The index of the current qubit being processed.\n",
        "        pairs_q (tf.Tensor): The 30-index phase-dual pair register for the current qubit [30, 2].\n",
        "        triplets_q (tf.Tensor): The 10 triplets for the current qubit [10, 3, 2].\n",
        "        current_bits_q (tf.Tensor): The initially derived 30-bit pattern for the current qubit [30].\n",
        "        resonance_key_q (str): The current resonance key string for the qubit.\n",
        "        TRACE (list): A list to append lineage information if corrections are made.\n",
        "        invariants (dict): Dictionary of invariant constants.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, str]:\n",
        "            - new_bits_q (tf.Tensor): The potentially corrected 30-bit pattern.\n",
        "            - updated_resonance_key_q (str): The updated resonance key string (with lineage if corrected).\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        # The updated key incorporates the correction lineage.\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs)\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '_value_unique_axis_axis_phase_dual' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2436661369.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;31m# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[0;31m# This step uses the full triplets and axis maps to promote new primaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m \u001b[0mprimaries_out_promoted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mASSOC_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_triplets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_maps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTHETA_PHIPI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;31m# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2436661369.py\u001b[0m in \u001b[0;36mASSOC_Q\u001b[0;34m(triplets, axis_maps, theta_phipi)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPromoted\u001b[0m \u001b[0mprimaries\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \"\"\"\n\u001b[0;32m--> 761\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpromote_primaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriplets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_maps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_phipi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mAPPLY_NECL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimaries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnecl_program_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprime_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconceptual_target_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2436661369.py\u001b[0m in \u001b[0;36mpromote_primaries\u001b[0;34m(triplets, axis_maps, theta)\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Determine uniqueness for all 10 candidates per axis (magnitudes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0mux_all_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_unique_axis_phase_dual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [Q, 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m     \u001b[0muy_all_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_unique_axis_axis_phase_dual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [Q, 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m     \u001b[0muz_all_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_unique_axis_phase_dual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [Q, 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_value_unique_axis_axis_phase_dual' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76c18f5f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution failed due to a `NameError` caused by a typo in the `promote_primaries` function. I need to correct `_value_unique_axis_axis_phase_dual` to `_value_unique_axis_phase_dual` to resolve this, while preserving the added comments in `correct_bits`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3dd206fd",
        "outputId": "2d747e42-5a2e-459f-f812-55e6444dcd88"
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ̇| + n_|y, ̇| = n_|x+y, ̇+̇|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ̇| · n_|y, ̇| = n_|x·y, ̇·̇|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ̇| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ̇_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register.\n",
        "    A triplet block collapses if 'both high AND low values coexist' in the real\n",
        "    component within that block, or similarly for the unreal component.\n",
        "    If a triplet collapses, all 3 indices corresponding to that triplet are marked.\n",
        "    COLL(x, ̇) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for real component (should be negative).\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    def _mark_block_phase_dual(block_real, block_unreal):\n",
        "        \"\"\"\n",
        "        Helper to mark collapse within a specific block for phase-dual components.\n",
        "        block_real and block_unreal shapes: [Q, block_size]\n",
        "        \"\"\"\n",
        "        # Collapse detection for REAL component: high AND low coexistence\n",
        "        high_real = tf.cast(block_real >= tau_hi, tf.int32)\n",
        "        low_real  = tf.cast(block_real <= tau_low, tf.int32)\n",
        "        any_h_real = tf.reduce_max(high_real, axis=1, keepdims=True) # [Q,1] (1 if any element is >= tau_hi)\n",
        "        any_l_real = tf.reduce_max(low_real,  axis=1, keepdims=True)  # [Q,1] (1 if any element is <= tau_low)\n",
        "        collapse_condition_real = tf.logical_and(any_h_real > 0, any_l_real > 0) # [Q,1]\n",
        "\n",
        "        # Collapse detection for UNREAL component: high AND low coexistence\n",
        "        high_unreal = tf.cast(block_unreal >= tau_hi, tf.int32)\n",
        "        low_unreal  = tf.cast(block_unreal <= tau_low, tf.int32)\n",
        "        any_h_unreal = tf.reduce_max(high_unreal, axis=1, keepdims=True) # [Q,1]\n",
        "        any_l_unreal = tf.reduce_max(low_unreal,  axis=1, keepdims=True)  # [Q,1]\n",
        "        collapse_condition_unreal = tf.logical_and(any_h_unreal > 0, any_l_unreal > 0) # [Q,1]\n",
        "\n",
        "        # A unit collapses if collapse is detected in EITHER real OR unreal components' blocks\n",
        "        unit_collapse_flag = tf.logical_or(collapse_condition_real, collapse_condition_unreal) # [Q,1]\n",
        "        unit_collapse_flag_int = tf.cast(unit_collapse_flag, tf.int32) # [Q,1]\n",
        "\n",
        "        # Mark all elements within the block if the block-level collapse flag is true\n",
        "        # for that qubit. This marks individual selectors within the block as collapsed.\n",
        "        mark = tf.broadcast_to(unit_collapse_flag_int, tf.shape(block_real)) # [Q, block_size]\n",
        "        return mark\n",
        "\n",
        "    # Initialize a collapse mask filled with zeros\n",
        "    collapse_mask = tf.zeros(tf.shape(real_parts), dtype=tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Iterate over each triplet block and apply collapse detection\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # Extract real and unreal parts for the current triplet across all Q qubits\n",
        "        # shape [Q, 3]\n",
        "        triplet_real_block = tf.gather(real_parts, current_triplet_indices, axis=1)\n",
        "        triplet_unreal_block = tf.gather(unreal_parts, current_triplet_indices, axis=1)\n",
        "\n",
        "        # Apply collapse detection for this triplet block\n",
        "        # Returns [Q, 3] where each element is marked if the *triplet block* collapsed\n",
        "        marked_triplet_block = _mark_block_phase_dual(triplet_real_block, triplet_unreal_block) # [Q, 3]\n",
        "\n",
        "        # Construct indices for scatter_nd_max to update the global collapse_mask\n",
        "        # indices_to_update will be [Q*3, 2]\n",
        "        # First column is qubit index, second is original 30-index\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1)\n",
        "\n",
        "        # Flatten marked_triplet_block to [Q*3] for updates\n",
        "        updates = tf.reshape(marked_triplet_block, [-1])\n",
        "\n",
        "        # Use tf.tensor_scatter_nd_max to update the collapse_mask.\n",
        "        # This ensures that if any triplet marks an index as collapsed, it remains marked.\n",
        "        collapse_mask = tf.tensor_scatter_nd_max(collapse_mask, indices_to_update, updates)\n",
        "\n",
        "    return collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components. Implements ASSOC(A, B, α) logic.\n",
        "\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10] <-- Fixed typo here\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`).\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode(\"utf-8\")).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode(\"utf-8\")).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    for b_idx in range(10):\n",
        "        s = signs[b_idx*3:(b_idx+1)*3] # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        trip_mix.extend([has_mix]*3) # Apply this mix flag to all 3 indices of the triplet\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook for a single qubit (q_idx). This function performs a local\n",
        "    re-evaluation of the bit pattern for the current qubit if the initial derivation\n",
        "    is deemed 'inconsistent'.\n",
        "\n",
        "    This function is designed to:\n",
        "    - Advance *only* within the same triplet (or within the primaries 6-set) for local re-evaluation.\n",
        "      It uses the `pairs_q` and `triplets_q` already derived for this specific qubit `q_idx`.\n",
        "      It does not implicitly advance to other qubits or triplets; its scope is limited to the\n",
        "      current qubit's local tuplet structure.\n",
        "    - Record lineage for any local adjustments made. If a correction occurs, a specific\n",
        "      entry is added to the `TRACE` log, detailing the reason, source, metrics, and new key.\n",
        "    - *Not* advance across different units (triplets or qubits) unless the current local unit\n",
        "      has been exhausted. The `derive_bits_advanced` function, called internally,\n",
        "      operates solely on the provided `pairs_q` and `triplets_q` for the current qubit.\n",
        "\n",
        "    Args:\n",
        "        q_idx (int): The index of the current qubit being processed.\n",
        "        pairs_q (tf.Tensor): The 30-index phase-dual pair register for the current qubit [30, 2].\n",
        "        triplets_q (tf.Tensor): The 10 triplets for the current qubit [10, 3, 2].\n",
        "        current_bits_q (tf.Tensor): The initially derived 30-bit pattern for the current qubit [30].\n",
        "        resonance_key_q (str): The current resonance key string for the qubit.\n",
        "        TRACE (list): A list to append lineage information if corrections are made.\n",
        "        invariants (dict): Dictionary of invariant constants.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, str]:\n",
        "            - new_bits_q (tf.Tensor): The potentially corrected 30-bit pattern.\n",
        "            - updated_resonance_key_q (str): The updated resonance key string (with lineage if corrected).\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        # The updated key incorporates the correction lineage.\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs)\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['quubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primaries In:\n",
            " [[[ 0.12260413 -0.264467  ]\n",
            "  [-0.12260413  0.264467  ]\n",
            "  [ 0.5133126  -0.17942071]\n",
            "  [-0.5133126   0.17942071]\n",
            "  [-0.84944797 -0.19150925]\n",
            "  [ 0.84944797  0.19150925]]\n",
            "\n",
            " [[-0.49797988 -0.10051513]\n",
            "  [ 0.49797988  0.10051513]\n",
            "  [-0.04035234 -0.00245523]\n",
            "  [ 0.04035234  0.00245523]\n",
            "  [ 0.36817956  0.08633685]\n",
            "  [-0.36817956 -0.08633685]]\n",
            "\n",
            " [[-0.04449058  0.59156895]\n",
            "  [ 0.04449058 -0.59156895]\n",
            "  [ 0.5117159  -0.8804784 ]\n",
            "  [-0.5117159   0.8804784 ]\n",
            "  [-0.7669594  -0.719141  ]\n",
            "  [ 0.7669594   0.719141  ]]\n",
            "\n",
            " [[-0.5652113   0.17396641]\n",
            "  [ 0.5652113  -0.17396641]\n",
            "  [ 0.58107734  0.16662025]\n",
            "  [-0.58107734 -0.16662025]\n",
            "  [-0.46410036 -0.8560734 ]\n",
            "  [ 0.46410036  0.8560734 ]]\n",
            "\n",
            " [[ 0.02902079  0.9663415 ]\n",
            "  [-0.02902079 -0.9663415 ]\n",
            "  [-0.57150507  0.7530916 ]\n",
            "  [ 0.57150507 -0.7530916 ]\n",
            "  [-0.66198707  0.45092034]\n",
            "  [ 0.66198707 -0.45092034]]\n",
            "\n",
            " [[ 0.19305778  0.9569731 ]\n",
            "  [-0.19305778 -0.9569731 ]\n",
            "  [ 0.41442156  0.85904694]\n",
            "  [-0.41442156 -0.85904694]\n",
            "  [ 0.6224258   0.25845885]\n",
            "  [-0.6224258  -0.25845885]]\n",
            "\n",
            " [[-0.79320717 -0.6915474 ]\n",
            "  [ 0.79320717  0.6915474 ]\n",
            "  [-0.50362253  0.06761336]\n",
            "  [ 0.50362253 -0.06761336]\n",
            "  [-0.8284948  -0.17036271]\n",
            "  [ 0.8284948   0.17036271]]\n",
            "\n",
            " [[ 0.08726788 -0.08997941]\n",
            "  [-0.08726788  0.08997941]\n",
            "  [-0.7913852   0.88823247]\n",
            "  [ 0.7913852  -0.88823247]\n",
            "  [-0.59713864 -0.87621474]\n",
            "  [ 0.59713864  0.87621474]]\n",
            "\n",
            " [[-0.85451984 -0.45989084]\n",
            "  [ 0.85451984  0.45989084]\n",
            "  [ 0.04129243 -0.76293445]\n",
            "  [-0.04129243  0.76293445]\n",
            "  [-0.5807407  -0.57130504]\n",
            "  [ 0.5807407   0.57130504]]\n",
            "\n",
            " [[-0.2290783   0.3454182 ]\n",
            "  [ 0.2290783  -0.3454182 ]\n",
            "  [-0.07624149  0.67073035]\n",
            "  [ 0.07624149 -0.67073035]\n",
            "  [-0.5560348   0.293638  ]\n",
            "  [ 0.5560348  -0.293638  ]]\n",
            "\n",
            " [[-0.55086803 -0.10035658]\n",
            "  [ 0.55086803  0.10035658]\n",
            "  [ 0.27841806  0.288764  ]\n",
            "  [-0.27841806 -0.288764  ]\n",
            "  [ 0.6472032   0.73529387]\n",
            "  [-0.6472032  -0.73529387]]\n",
            "\n",
            " [[-0.7891917   0.67037344]\n",
            "  [ 0.7891917  -0.67037344]\n",
            "  [ 0.80961657 -0.9827292 ]\n",
            "  [-0.80961657  0.9827292 ]\n",
            "  [ 0.44847488 -0.5410323 ]\n",
            "  [-0.44847488  0.5410323 ]]\n",
            "\n",
            " [[-0.36260462 -0.59354186]\n",
            "  [ 0.36260462  0.59354186]\n",
            "  [-0.5508044  -0.60668254]\n",
            "  [ 0.5508044   0.60668254]\n",
            "  [-0.08505011 -0.14191008]\n",
            "  [ 0.08505011  0.14191008]]\n",
            "\n",
            " [[-0.07023597  0.7599201 ]\n",
            "  [ 0.07023597 -0.7599201 ]\n",
            "  [-0.42695975 -0.35106897]\n",
            "  [ 0.42695975  0.35106897]\n",
            "  [ 0.51654696 -0.21258283]\n",
            "  [-0.51654696  0.21258283]]\n",
            "\n",
            " [[ 0.34667492 -0.46335793]\n",
            "  [-0.34667492  0.46335793]\n",
            "  [ 0.07284951 -0.8069577 ]\n",
            "  [-0.07284951  0.8069577 ]\n",
            "  [-0.36771297 -0.9120858 ]\n",
            "  [ 0.36771297  0.9120858 ]]\n",
            "\n",
            " [[ 0.7998643   0.33460903]\n",
            "  [-0.7998643  -0.33460903]\n",
            "  [ 0.64284325  0.07078791]\n",
            "  [-0.64284325 -0.07078791]\n",
            "  [-0.20303869 -0.7947371 ]\n",
            "  [ 0.20303869  0.7947371 ]]\n",
            "\n",
            " [[ 0.9451704   0.87128186]\n",
            "  [-0.9451704  -0.87128186]\n",
            "  [ 0.80006075  0.8784075 ]\n",
            "  [-0.80006075 -0.8784075 ]\n",
            "  [-0.5237591  -0.64875793]\n",
            "  [ 0.5237591   0.64875793]]\n",
            "\n",
            " [[-0.20368385  0.54570174]\n",
            "  [ 0.20368385 -0.54570174]\n",
            "  [-0.08244514 -0.7388258 ]\n",
            "  [ 0.08244514  0.7388258 ]\n",
            "  [-0.8335123   0.39113903]\n",
            "  [ 0.8335123  -0.39113903]]\n",
            "\n",
            " [[-0.26071167  0.7462578 ]\n",
            "  [ 0.26071167 -0.7462578 ]\n",
            "  [-0.94573593  0.75447845]\n",
            "  [ 0.94573593 -0.75447845]\n",
            "  [-0.7593751   0.85819817]\n",
            "  [ 0.7593751  -0.85819817]]\n",
            "\n",
            " [[-0.93806696  0.0122664 ]\n",
            "  [ 0.93806696 -0.0122664 ]\n",
            "  [ 0.11523962  0.19131517]\n",
            "  [-0.11523962 -0.19131517]\n",
            "  [-0.15255213 -0.26353955]\n",
            "  [ 0.15255213  0.26353955]]\n",
            "\n",
            " [[ 0.6988344  -0.28269243]\n",
            "  [-0.6988344   0.28269243]\n",
            "  [ 0.40902185  0.2625451 ]\n",
            "  [-0.40902185 -0.2625451 ]\n",
            "  [-0.15205312  0.32063198]\n",
            "  [ 0.15205312 -0.32063198]]\n",
            "\n",
            " [[-0.6999965   0.32643676]\n",
            "  [ 0.6999965  -0.32643676]\n",
            "  [ 0.2928486  -0.4972458 ]\n",
            "  [-0.2928486   0.4972458 ]\n",
            "  [ 0.2698028  -0.839782  ]\n",
            "  [-0.2698028   0.839782  ]]\n",
            "\n",
            " [[-0.38995743 -0.6342838 ]\n",
            "  [ 0.38995743  0.6342838 ]\n",
            "  [-0.3582332  -0.94487405]\n",
            "  [ 0.3582332   0.94487405]\n",
            "  [-0.15001321  0.003685  ]\n",
            "  [ 0.15001321 -0.003685  ]]\n",
            "\n",
            " [[ 0.7091596   0.57856035]\n",
            "  [-0.7091596  -0.57856035]\n",
            "  [ 0.07516122  0.80805206]\n",
            "  [-0.07516122 -0.80805206]\n",
            "  [ 0.19133377 -0.85544777]\n",
            "  [-0.19133377  0.85544777]]\n",
            "\n",
            " [[ 0.07431817 -0.89293504]\n",
            "  [-0.07431817  0.89293504]\n",
            "  [ 0.53378844  0.8136573 ]\n",
            "  [-0.53378844 -0.8136573 ]\n",
            "  [-0.6286423  -0.4554422 ]\n",
            "  [ 0.6286423   0.4554422 ]]\n",
            "\n",
            " [[ 0.26537037  0.9478638 ]\n",
            "  [-0.26537037 -0.9478638 ]\n",
            "  [ 0.7133484  -0.7397897 ]\n",
            "  [-0.7133484   0.7397897 ]\n",
            "  [-0.7606144  -0.77403593]\n",
            "  [ 0.7606144   0.77403593]]\n",
            "\n",
            " [[-0.50631404  0.40152192]\n",
            "  [ 0.50631404 -0.40152192]\n",
            "  [ 0.58336425  0.59096503]\n",
            "  [-0.58336425 -0.59096503]\n",
            "  [ 0.92197776 -0.04605699]\n",
            "  [-0.92197776  0.04605699]]\n",
            "\n",
            " [[-0.33022237  0.46880388]\n",
            "  [ 0.33022237 -0.46880388]\n",
            "  [ 0.45256782 -0.77356315]\n",
            "  [-0.45256782  0.77356315]\n",
            "  [-0.9324174   0.7620616 ]\n",
            "  [ 0.9324174  -0.7620616 ]]\n",
            "\n",
            " [[-0.22951293  0.46598625]\n",
            "  [ 0.22951293 -0.46598625]\n",
            "  [-0.06301689 -0.6056185 ]\n",
            "  [ 0.06301689  0.6056185 ]\n",
            "  [ 0.394444   -0.20250392]\n",
            "  [-0.394444    0.20250392]]\n",
            "\n",
            " [[-0.45516276  0.00260615]\n",
            "  [ 0.45516276 -0.00260615]\n",
            "  [ 0.70658827  0.23050141]\n",
            "  [-0.70658827 -0.23050141]\n",
            "  [ 0.1400311   0.2026999 ]\n",
            "  [-0.1400311  -0.2026999 ]]\n",
            "\n",
            " [[ 0.4227345   0.9999535 ]\n",
            "  [-0.4227345  -0.9999535 ]\n",
            "  [-0.01527238  0.67463017]\n",
            "  [ 0.01527238 -0.67463017]\n",
            "  [ 0.96030164  0.30727458]\n",
            "  [-0.96030164 -0.30727458]]\n",
            "\n",
            " [[ 0.9125514   0.24454117]\n",
            "  [-0.9125514  -0.24454117]\n",
            "  [ 0.80975556 -0.95920134]\n",
            "  [-0.80975556  0.95920134]\n",
            "  [-0.9703994  -0.76267743]\n",
            "  [ 0.9703994   0.76267743]]\n",
            "\n",
            " [[ 0.86955667 -0.36215305]\n",
            "  [-0.86955667  0.36215305]\n",
            "  [-0.4541006   0.46226835]\n",
            "  [ 0.4541006  -0.46226835]\n",
            "  [-0.22718096 -0.4584558 ]\n",
            "  [ 0.22718096  0.4584558 ]]\n",
            "\n",
            " [[-0.3892262   0.682446  ]\n",
            "  [ 0.3892262  -0.682446  ]\n",
            "  [ 0.8480177   0.8116205 ]\n",
            "  [-0.8480177  -0.8116205 ]\n",
            "  [ 0.24765682 -0.05032325]\n",
            "  [-0.24765682  0.05032325]]\n",
            "\n",
            " [[ 0.8440716  -0.07983541]\n",
            "  [-0.8440716   0.07983541]\n",
            "  [-0.01756167 -0.982955  ]\n",
            "  [ 0.01756167  0.982955  ]\n",
            "  [ 0.2699442   0.8821783 ]\n",
            "  [-0.2699442  -0.8821783 ]]\n",
            "\n",
            " [[ 0.9747813   0.5067115 ]\n",
            "  [-0.9747813  -0.5067115 ]\n",
            "  [ 0.20353103  0.79055977]\n",
            "  [-0.20353103 -0.79055977]\n",
            "  [ 0.7831507   0.40905952]\n",
            "  [-0.7831507  -0.40905952]]\n",
            "\n",
            " [[ 0.03429151 -0.08061671]\n",
            "  [-0.03429151  0.08061671]\n",
            "  [-0.04325652 -0.47139716]\n",
            "  [ 0.04325652  0.47139716]\n",
            "  [ 0.7984204   0.42226243]\n",
            "  [-0.7984204  -0.42226243]]\n",
            "\n",
            " [[-0.5314872  -0.4912629 ]\n",
            "  [ 0.5314872   0.4912629 ]\n",
            "  [ 0.8978455  -0.39804554]\n",
            "  [-0.8978455   0.39804554]\n",
            "  [-0.84335184 -0.56561065]\n",
            "  [ 0.84335184  0.56561065]]\n",
            "\n",
            " [[-0.5708587   0.968163  ]\n",
            "  [ 0.5708587  -0.968163  ]\n",
            "  [-0.76047826 -0.9874699 ]\n",
            "  [ 0.76047826  0.9874699 ]\n",
            "  [-0.8647404  -0.22799063]\n",
            "  [ 0.8647404   0.22799063]]\n",
            "\n",
            " [[-0.24669838 -0.3902359 ]\n",
            "  [ 0.24669838  0.3902359 ]\n",
            "  [ 0.4897442   0.922189  ]\n",
            "  [-0.4897442  -0.922189  ]\n",
            "  [-0.3355894  -0.16350293]\n",
            "  [ 0.3355894   0.16350293]]\n",
            "\n",
            " [[ 0.05625272  0.02377987]\n",
            "  [-0.05625272 -0.02377987]\n",
            "  [ 0.04886055  0.38388515]\n",
            "  [-0.04886055 -0.38388515]\n",
            "  [ 0.3852558   0.981411  ]\n",
            "  [-0.3852558  -0.981411  ]]\n",
            "\n",
            " [[ 0.02343059 -0.16100073]\n",
            "  [-0.02343059  0.16100073]\n",
            "  [-0.37985086 -0.2953763 ]\n",
            "  [ 0.37985086  0.2953763 ]\n",
            "  [ 0.00757051 -0.29745412]\n",
            "  [-0.00757051  0.29745412]]\n",
            "\n",
            " [[-0.87581396  0.86731124]\n",
            "  [ 0.87581396 -0.86731124]\n",
            "  [ 0.04179668  0.19786263]\n",
            "  [-0.04179668 -0.19786263]\n",
            "  [ 0.09982586 -0.711704  ]\n",
            "  [-0.09982586  0.711704  ]]\n",
            "\n",
            " [[ 0.63000464  0.27969933]\n",
            "  [-0.63000464 -0.27969933]\n",
            "  [ 0.6318407   0.549675  ]\n",
            "  [-0.6318407  -0.549675  ]\n",
            "  [-0.08618069 -0.45008922]\n",
            "  [ 0.08618069  0.45008922]]\n",
            "\n",
            " [[ 0.54310155 -0.9394419 ]\n",
            "  [-0.54310155  0.9394419 ]\n",
            "  [-0.7141316  -0.04360819]\n",
            "  [ 0.7141316   0.04360819]\n",
            "  [-0.03120542  0.5154598 ]\n",
            "  [ 0.03120542 -0.5154598 ]]\n",
            "\n",
            " [[ 0.5534525  -0.96971226]\n",
            "  [-0.5534525   0.96971226]\n",
            "  [-0.89017296  0.43805552]\n",
            "  [ 0.89017296 -0.43805552]\n",
            "  [-0.3105483  -0.10057712]\n",
            "  [ 0.3105483   0.10057712]]\n",
            "\n",
            " [[ 0.46513534  0.83424544]\n",
            "  [-0.46513534 -0.83424544]\n",
            "  [-0.43867993 -0.8154974 ]\n",
            "  [ 0.43867993  0.8154974 ]\n",
            "  [ 0.19367456  0.28856397]\n",
            "  [-0.19367456 -0.28856397]]\n",
            "\n",
            " [[ 0.75587606 -0.53545785]\n",
            "  [-0.75587606  0.53545785]\n",
            "  [ 0.6505792  -0.6300113 ]\n",
            "  [-0.6505792   0.6300113 ]\n",
            "  [ 0.23514938  0.7479954 ]\n",
            "  [-0.23514938 -0.7479954 ]]\n",
            "\n",
            " [[ 0.6408756   0.5409386 ]\n",
            "  [-0.6408756  -0.5409386 ]\n",
            "  [-0.99356294 -0.46795177]\n",
            "  [ 0.99356294  0.46795177]\n",
            "  [-0.2586019  -0.05147386]\n",
            "  [ 0.2586019   0.05147386]]\n",
            "\n",
            " [[-0.15731049 -0.45017076]\n",
            "  [ 0.15731049  0.45017076]\n",
            "  [-0.7546351   0.8596945 ]\n",
            "  [ 0.7546351  -0.8596945 ]\n",
            "  [-0.05103707 -0.11490774]\n",
            "  [ 0.05103707  0.11490774]]\n",
            "\n",
            " [[-0.25935173 -0.28028226]\n",
            "  [ 0.25935173  0.28028226]\n",
            "  [-0.12311578  0.31224608]\n",
            "  [ 0.12311578 -0.31224608]\n",
            "  [ 0.0320878  -0.03482795]\n",
            "  [-0.0320878   0.03482795]]\n",
            "\n",
            " [[ 0.78767014  0.08633208]\n",
            "  [-0.78767014 -0.08633208]\n",
            "  [-0.5313339   0.7301383 ]\n",
            "  [ 0.5313339  -0.7301383 ]\n",
            "  [ 0.73821187  0.00659227]\n",
            "  [-0.73821187 -0.00659227]]\n",
            "\n",
            " [[-0.84390783  0.24137425]\n",
            "  [ 0.84390783 -0.24137425]\n",
            "  [ 0.13417077  0.7267046 ]\n",
            "  [-0.13417077 -0.7267046 ]\n",
            "  [ 0.18158126  0.6610608 ]\n",
            "  [-0.18158126 -0.6610608 ]]\n",
            "\n",
            " [[-0.5387192   0.64079976]\n",
            "  [ 0.5387192  -0.64079976]\n",
            "  [ 0.7702453   0.68269587]\n",
            "  [-0.7702453  -0.68269587]\n",
            "  [ 0.9334278  -0.8201809 ]\n",
            "  [-0.9334278   0.8201809 ]]\n",
            "\n",
            " [[ 0.3031032   0.6623399 ]\n",
            "  [-0.3031032  -0.6623399 ]\n",
            "  [ 0.64531446 -0.9988439 ]\n",
            "  [-0.64531446  0.9988439 ]\n",
            "  [ 0.7044635   0.6033001 ]\n",
            "  [-0.7044635  -0.6033001 ]]\n",
            "\n",
            " [[ 0.27245855 -0.30234027]\n",
            "  [-0.27245855  0.30234027]\n",
            "  [-0.2648816   0.2733879 ]\n",
            "  [ 0.2648816  -0.2733879 ]\n",
            "  [ 0.15104485 -0.28120685]\n",
            "  [-0.15104485  0.28120685]]\n",
            "\n",
            " [[-0.97702     0.05815244]\n",
            "  [ 0.97702    -0.05815244]\n",
            "  [-0.815053   -0.7886219 ]\n",
            "  [ 0.815053    0.7886219 ]\n",
            "  [-0.33719492  0.59663486]\n",
            "  [ 0.33719492 -0.59663486]]\n",
            "\n",
            " [[ 0.25811172 -0.24201083]\n",
            "  [-0.25811172  0.24201083]\n",
            "  [ 0.89197135 -0.04332447]\n",
            "  [-0.89197135  0.04332447]\n",
            "  [ 0.507097   -0.8600826 ]\n",
            "  [-0.507097    0.8600826 ]]\n",
            "\n",
            " [[ 0.48164082  0.80985737]\n",
            "  [-0.48164082 -0.80985737]\n",
            "  [ 0.9038675   0.8134818 ]\n",
            "  [-0.9038675  -0.8134818 ]\n",
            "  [ 0.75452495  0.2556634 ]\n",
            "  [-0.75452495 -0.2556634 ]]\n",
            "\n",
            " [[-0.75724673 -0.64128995]\n",
            "  [ 0.75724673  0.64128995]\n",
            "  [ 0.95611334 -0.029948  ]\n",
            "  [-0.95611334  0.029948  ]\n",
            "  [-0.23485279  0.7988851 ]\n",
            "  [ 0.23485279 -0.7988851 ]]\n",
            "\n",
            " [[ 0.84499526 -0.70826006]\n",
            "  [-0.84499526  0.70826006]\n",
            "  [ 0.06908965 -0.04727292]\n",
            "  [-0.06908965  0.04727292]\n",
            "  [ 0.5535755   0.01946807]\n",
            "  [-0.5535755  -0.01946807]]\n",
            "\n",
            " [[ 0.05779171  0.18806124]\n",
            "  [-0.05779171 -0.18806124]\n",
            "  [ 0.34376407  0.38606668]\n",
            "  [-0.34376407 -0.38606668]\n",
            "  [ 0.96355915  0.28515792]\n",
            "  [-0.96355915 -0.28515792]]\n",
            "\n",
            " [[ 0.73082423 -0.41746163]\n",
            "  [-0.73082423  0.41746163]\n",
            "  [ 0.8159573   0.14315963]\n",
            "  [-0.8159573  -0.14315963]\n",
            "  [-0.4303348   0.23787332]\n",
            "  [ 0.4303348  -0.23787332]]\n",
            "\n",
            " [[-0.5454216  -0.763006  ]\n",
            "  [ 0.5454216   0.763006  ]\n",
            "  [-0.54435754 -0.09107161]\n",
            "  [ 0.54435754  0.09107161]\n",
            "  [ 0.79355    -0.2926035 ]\n",
            "  [-0.79355     0.2926035 ]]]\n",
            "\n",
            "Primaries After NECL:\n",
            " [[[ 0.0377043  -0.05750986]\n",
            "  [-0.0377043   0.05750986]\n",
            "  [-0.15771744  0.03898121]\n",
            "  [ 0.15771744 -0.03898121]\n",
            "  [-0.26074362 -0.04156728]\n",
            "  [-0.26074362 -0.04156728]]\n",
            "\n",
            " [[-0.28138015 -0.04016041]\n",
            "  [ 0.28138015  0.04016041]\n",
            "  [ 0.02285773  0.00098343]\n",
            "  [-0.02285773 -0.00098343]\n",
            "  [ 0.20818281  0.03451965]\n",
            "  [ 0.20818281  0.03451965]]\n",
            "\n",
            " [[-0.00876424  0.08240177]\n",
            "  [ 0.00876424 -0.08240177]\n",
            "  [-0.10073058  0.12255643]\n",
            "  [ 0.10073058 -0.12255643]\n",
            "  [-0.15094256 -0.10007795]\n",
            "  [-0.15094256 -0.10007795]]\n",
            "\n",
            " [[-0.13658439  0.02972628]\n",
            "  [ 0.13658439 -0.02972628]\n",
            "  [-0.14041376 -0.02847007]\n",
            "  [ 0.14041376  0.02847007]\n",
            "  [-0.11210316 -0.14621837]\n",
            "  [-0.11210316 -0.14621837]]\n",
            "\n",
            " [[ 0.00560853  0.1320552 ]\n",
            "  [-0.00560853 -0.1320552 ]\n",
            "  [ 0.11042877 -0.10289516]\n",
            "  [-0.11042877  0.10289516]\n",
            "  [-0.12792304  0.06161466]\n",
            "  [-0.12792304  0.06161466]]\n",
            "\n",
            " [[ 0.03887052  0.13624415]\n",
            "  [-0.03887052 -0.13624415]\n",
            "  [-0.08343516 -0.12229498]\n",
            "  [ 0.08343516  0.12229498]\n",
            "  [ 0.1253333   0.03680063]\n",
            "  [ 0.1253333   0.03680063]]\n",
            "\n",
            " [[-0.17272472 -0.10648165]\n",
            "  [ 0.17272472  0.10648165]\n",
            "  [ 0.10976321 -0.01042003]\n",
            "  [-0.10976321  0.01042003]\n",
            "  [-0.18044417 -0.0262369 ]\n",
            "  [-0.18044417 -0.0262369 ]]\n",
            "\n",
            " [[ 0.01928371 -0.01405932]\n",
            "  [-0.01928371  0.01405932]\n",
            "  [ 0.1745421  -0.13852364]\n",
            "  [-0.1745421   0.13852364]\n",
            "  [-0.13174197 -0.13669245]\n",
            "  [-0.13174197 -0.13669245]]\n",
            "\n",
            " [[-0.17567675 -0.06685469]\n",
            "  [ 0.17567675  0.06685469]\n",
            "  [-0.00849533  0.1109895 ]\n",
            "  [ 0.00849533 -0.1109895 ]\n",
            "  [-0.11944015 -0.0830847 ]\n",
            "  [-0.11944015 -0.0830847 ]]\n",
            "\n",
            " [[-0.06992184  0.07455198]\n",
            "  [ 0.06992184 -0.07455198]\n",
            "  [ 0.02326144 -0.14470324]\n",
            "  [-0.02326144  0.14470324]\n",
            "  [-0.16959165  0.06332857]\n",
            "  [-0.16959165  0.06332857]]\n",
            "\n",
            " [[-0.14881484 -0.01917033]\n",
            "  [ 0.14881484  0.01917033]\n",
            "  [-0.07525423 -0.05519015]\n",
            "  [ 0.07525423  0.05519015]\n",
            "  [ 0.17471589  0.14035816]\n",
            "  [ 0.17471589  0.14035816]]\n",
            "\n",
            " [[-0.13737108  0.08251152]\n",
            "  [ 0.13737108 -0.08251152]\n",
            "  [-0.14089215  0.12092784]\n",
            "  [ 0.14089215 -0.12092784]\n",
            "  [ 0.0781069  -0.0666284 ]\n",
            "  [ 0.0781069  -0.0666284 ]]\n",
            "\n",
            " [[-0.11310004 -0.13090788]\n",
            "  [ 0.11310004  0.13090788]\n",
            "  [ 0.17172824  0.13374908]\n",
            "  [-0.17172824 -0.13374908]\n",
            "  [-0.02656137 -0.03133819]\n",
            "  [-0.02656137 -0.03133819]]\n",
            "\n",
            " [[-0.01964292  0.15027937]\n",
            "  [ 0.01964292 -0.15027937]\n",
            "  [ 0.11942328  0.06943516]\n",
            "  [-0.11942328 -0.06943516]\n",
            "  [ 0.1444644  -0.04204015]\n",
            "  [ 0.1444644  -0.04204015]]\n",
            "\n",
            " [[ 0.07664193 -0.07243452]\n",
            "  [-0.07664193  0.07243452]\n",
            "  [-0.01610204  0.12612174]\n",
            "  [ 0.01610204 -0.12612174]\n",
            "  [-0.08124756 -0.14250237]\n",
            "  [-0.08124756 -0.14250237]]\n",
            "\n",
            " [[ 0.17959517  0.05312525]\n",
            "  [-0.17959517 -0.05312525]\n",
            "  [-0.14439738 -0.01124342]\n",
            "  [ 0.14439738  0.01124342]\n",
            "  [-0.04561177 -0.12624279]\n",
            "  [-0.04561177 -0.12624279]]\n",
            "\n",
            " [[ 0.14977479  0.09762752]\n",
            "  [-0.14977479 -0.09762752]\n",
            "  [-0.12680231 -0.09844308]\n",
            "  [ 0.12680231  0.09844308]\n",
            "  [-0.08305073 -0.07274105]\n",
            "  [-0.08305073 -0.07274105]]\n",
            "\n",
            " [[-0.04755174  0.09008453]\n",
            "  [ 0.04755174 -0.09008453]\n",
            "  [ 0.01924357  0.12194037]\n",
            "  [-0.01924357 -0.12194037]\n",
            "  [-0.19439961  0.06450591]\n",
            "  [-0.19439961  0.06450591]]\n",
            "\n",
            " [[-0.0434633   0.08797032]\n",
            "  [ 0.0434633  -0.08797032]\n",
            "  [ 0.1575395  -0.08886923]\n",
            "  [-0.1575395   0.08886923]\n",
            "  [-0.12651856  0.10110451]\n",
            "  [-0.12651856  0.10110451]]\n",
            "\n",
            " [[-0.3348671   0.00309628]\n",
            "  [ 0.3348671  -0.00309628]\n",
            "  [-0.04124437 -0.04841693]\n",
            "  [ 0.04124437  0.04841693]\n",
            "  [-0.05458681 -0.06668071]\n",
            "  [-0.05458681 -0.06668071]]\n",
            "\n",
            " [[ 0.22953828 -0.06565685]\n",
            "  [-0.22953828  0.06565685]\n",
            "  [-0.13446361 -0.06103053]\n",
            "  [ 0.13446361  0.06103053]\n",
            "  [-0.05001419  0.07457439]\n",
            "  [-0.05001419  0.07457439]]\n",
            "\n",
            " [[-0.16441484  0.05421622]\n",
            "  [ 0.16441484 -0.05421622]\n",
            "  [-0.06882717  0.08263668]\n",
            "  [ 0.06882717 -0.08263668]\n",
            "  [ 0.06338319 -0.1395016 ]\n",
            "  [ 0.06338319 -0.1395016 ]]\n",
            "\n",
            " [[-0.10729379 -0.12340309]\n",
            "  [ 0.10729379  0.12340309]\n",
            "  [ 0.09852284  0.18375114]\n",
            "  [-0.09852284 -0.18375114]\n",
            "  [-0.0413231   0.00071777]\n",
            "  [-0.0413231   0.00071777]]\n",
            "\n",
            " [[ 0.14278686  0.08237167]\n",
            "  [-0.14278686 -0.08237167]\n",
            "  [-0.01514049 -0.1150987 ]\n",
            "  [ 0.01514049  0.1150987 ]\n",
            "  [ 0.03853802 -0.12183616]\n",
            "  [ 0.03853802 -0.12183616]]\n",
            "\n",
            " [[ 0.01473114 -0.1251544 ]\n",
            "  [-0.01473114  0.1251544 ]\n",
            "  [-0.10577627 -0.11401071]\n",
            "  [ 0.10577627  0.11401071]\n",
            "  [-0.1245911  -0.06382659]\n",
            "  [-0.1245911  -0.06382659]]\n",
            "\n",
            " [[ 0.04492998  0.1134788 ]\n",
            "  [-0.04492998 -0.1134788 ]\n",
            "  [-0.12074547  0.08854467]\n",
            "  [ 0.12074547 -0.08854467]\n",
            "  [-0.1287351  -0.09263574]\n",
            "  [-0.1287351  -0.09263574]]\n",
            "\n",
            " [[-0.11063526  0.06203943]\n",
            "  [ 0.11063526 -0.06203943]\n",
            "  [-0.12743524 -0.09128438]\n",
            "  [ 0.12743524  0.09128438]\n",
            "  [ 0.2013191  -0.00711124]\n",
            "  [ 0.2013191  -0.00711124]]\n",
            "\n",
            " [[-0.06478062  0.06503015]\n",
            "  [ 0.06478062 -0.06503015]\n",
            "  [-0.08874132  0.10725635]\n",
            "  [ 0.08874132 -0.10725635]\n",
            "  [-0.18270695  0.10558927]\n",
            "  [-0.18270695  0.10558927]]\n",
            "\n",
            " [[-0.07656619  0.10992284]\n",
            "  [ 0.07656619 -0.10992284]\n",
            "  [ 0.02102053  0.1428469 ]\n",
            "  [-0.02102053 -0.1428469 ]\n",
            "  [ 0.13158013 -0.0477665 ]\n",
            "  [ 0.13158013 -0.0477665 ]]\n",
            "\n",
            " [[-0.16513662  0.00066859]\n",
            "  [ 0.16513662 -0.00066859]\n",
            "  [-0.25611684 -0.05907862]\n",
            "  [ 0.25611684  0.05907862]\n",
            "  [ 0.05084915  0.05204725]\n",
            "  [ 0.05084915  0.05204725]]\n",
            "\n",
            " [[ 0.08003951  0.13387562]\n",
            "  [-0.08003951 -0.13387562]\n",
            "  [ 0.00289344 -0.0903772 ]\n",
            "  [-0.00289344  0.0903772 ]\n",
            "  [ 0.18176845  0.04112657]\n",
            "  [ 0.18176845  0.04112657]]\n",
            "\n",
            " [[ 0.13931344  0.0263981 ]\n",
            "  [-0.13931344 -0.0263981 ]\n",
            "  [-0.12359735  0.10352614]\n",
            "  [ 0.12359735 -0.10352614]\n",
            "  [-0.14810567 -0.08230895]\n",
            "  [-0.14810567 -0.08230895]]\n",
            "\n",
            " [[ 0.21675502 -0.06383347]\n",
            "  [-0.21675502  0.06383347]\n",
            "  [ 0.11328731 -0.08154707]\n",
            "  [-0.11328731  0.08154707]\n",
            "  [-0.05669829 -0.08090595]\n",
            "  [-0.05669829 -0.08090595]]\n",
            "\n",
            " [[-0.09224279  0.1143625 ]\n",
            "  [ 0.09224279 -0.1143625 ]\n",
            "  [-0.2007888  -0.13588533]\n",
            "  [ 0.2007888   0.13588533]\n",
            "  [ 0.05874126 -0.00844008]\n",
            "  [ 0.05874126 -0.00844008]]\n",
            "\n",
            " [[ 0.1606889  -0.010747  ]\n",
            "  [-0.1606889   0.010747  ]\n",
            "  [ 0.00334419  0.13235608]\n",
            "  [-0.00334419 -0.13235608]\n",
            "  [ 0.05140572  0.11878972]\n",
            "  [ 0.05140572  0.11878972]]\n",
            "\n",
            " [[ 0.18253067  0.06709257]\n",
            "  [-0.18253067 -0.06709257]\n",
            "  [-0.03814196 -0.10475918]\n",
            "  [ 0.03814196  0.10475918]\n",
            "  [ 0.14670055  0.05418236]\n",
            "  [ 0.14670055  0.05418236]]\n",
            "\n",
            " [[ 0.01229276 -0.02043492]\n",
            "  [-0.01229276  0.02043492]\n",
            "  [ 0.01549227  0.11938103]\n",
            "  [-0.01549227 -0.11938103]\n",
            "  [ 0.28545055  0.10674971]\n",
            "  [ 0.28545055  0.10674971]]\n",
            "\n",
            " [[-0.10241501 -0.06693754]\n",
            "  [ 0.10241501  0.06693754]\n",
            "  [-0.17291337  0.05420567]\n",
            "  [ 0.17291337 -0.05420567]\n",
            "  [-0.16242082 -0.07702567]\n",
            "  [-0.16242082 -0.07702567]]\n",
            "\n",
            " [[-0.09167847  0.10994418]\n",
            "  [ 0.09167847 -0.10994418]\n",
            "  [ 0.12210456  0.11211248]\n",
            "  [-0.12210456 -0.11211248]\n",
            "  [-0.1388776  -0.02589098]\n",
            "  [-0.1388776  -0.02589098]]\n",
            "\n",
            " [[-0.06885546 -0.07701659]\n",
            "  [ 0.06885546  0.07701659]\n",
            "  [-0.13652983 -0.18178713]\n",
            "  [ 0.13652983  0.18178713]\n",
            "  [-0.09366943 -0.03227009]\n",
            "  [-0.09366943 -0.03227009]]\n",
            "\n",
            " [[ 0.01965349  0.00587477]\n",
            "  [-0.01965349 -0.00587477]\n",
            "  [-0.0170585  -0.09476956]\n",
            "  [ 0.0170585   0.09476956]\n",
            "  [ 0.13427171  0.241864  ]\n",
            "  [ 0.13427171  0.241864  ]]\n",
            "\n",
            " [[ 0.01305833 -0.06344792]\n",
            "  [-0.01305833  0.06344792]\n",
            "  [ 0.21134253  0.11620756]\n",
            "  [-0.21134253 -0.11620756]\n",
            "  [ 0.00421708 -0.11716349]\n",
            "  [ 0.00421708 -0.11716349]]\n",
            "\n",
            " [[-0.21298619  0.14914183]\n",
            "  [ 0.21298619 -0.14914183]\n",
            "  [-0.01018617 -0.03409713]\n",
            "  [ 0.01018617  0.03409713]\n",
            "  [ 0.02430761 -0.12254163]\n",
            "  [ 0.02430761 -0.12254163]]\n",
            "\n",
            " [[ 0.16634554  0.05222084]\n",
            "  [-0.16634554 -0.05222084]\n",
            "  [-0.16679615 -0.10260521]\n",
            "  [ 0.16679615  0.10260521]\n",
            "  [-0.02277396 -0.08410314]\n",
            "  [-0.02277396 -0.08410314]]\n",
            "\n",
            " [[ 0.12283194 -0.15023988]\n",
            "  [-0.12283194  0.15023988]\n",
            "  [ 0.16156326  0.00697618]\n",
            "  [-0.16156326 -0.00697618]\n",
            "  [-0.00706514  0.0825222 ]\n",
            "  [-0.00706514  0.0825222 ]]\n",
            "\n",
            " [[ 0.11910788 -0.14756657]\n",
            "  [-0.11910788  0.14756657]\n",
            "  [ 0.19154902 -0.066653  ]\n",
            "  [-0.19154902  0.066653  ]\n",
            "  [-0.0669099  -0.01532306]\n",
            "  [-0.0669099  -0.01532306]]\n",
            "\n",
            " [[ 0.10938516  0.13872603]\n",
            "  [-0.10938516 -0.13872603]\n",
            "  [ 0.10316985  0.13561653]\n",
            "  [-0.10316985 -0.13561653]\n",
            "  [ 0.04559414  0.04803564]\n",
            "  [ 0.04559414  0.04803564]]\n",
            "\n",
            " [[ 0.15144852 -0.07586207]\n",
            "  [-0.15144852  0.07586207]\n",
            "  [-0.13036522  0.08926782]\n",
            "  [ 0.13036522 -0.08926782]\n",
            "  [ 0.04713888  0.10602769]\n",
            "  [ 0.04713888  0.10602769]]\n",
            "\n",
            " [[ 0.1526375   0.09110045]\n",
            "  [-0.1526375  -0.09110045]\n",
            "  [ 0.23647575  0.07875486]\n",
            "  [-0.23647575 -0.07875486]\n",
            "  [-0.06165914 -0.00867836]\n",
            "  [-0.06165914 -0.00867836]]\n",
            "\n",
            " [[-0.04723927 -0.09558897]\n",
            "  [ 0.04723927  0.09558897]\n",
            "  [ 0.22621459 -0.18222702]\n",
            "  [-0.22621459  0.18222702]\n",
            "  [-0.01533745 -0.02441753]\n",
            "  [-0.01533745 -0.02441753]]\n",
            "\n",
            " [[-0.17763913 -0.13574696]\n",
            "  [ 0.17763913  0.13574696]\n",
            "  [ 0.08436684 -0.15130039]\n",
            "  [-0.08436684  0.15130039]\n",
            "  [ 0.02201914 -0.01689947]\n",
            "  [ 0.02201914 -0.01689947]]\n",
            "\n",
            " [[ 0.1696462   0.01314792]\n",
            "  [-0.1696462  -0.01314792]\n",
            "  [ 0.11444877 -0.11120741]\n",
            "  [-0.11444877  0.11120741]\n",
            "  [ 0.1590109   0.00100407]\n",
            "  [ 0.1590109   0.00100407]]\n",
            "\n",
            " [[-0.19208106  0.03884772]\n",
            "  [ 0.19208106 -0.03884772]\n",
            "  [-0.03056034 -0.11704239]\n",
            "  [ 0.03056034  0.11704239]\n",
            "  [ 0.04136178  0.1064767 ]\n",
            "  [ 0.04136178  0.1064767 ]]\n",
            "\n",
            " [[-0.0908682   0.07642876]\n",
            "  [ 0.0908682  -0.07642876]\n",
            "  [-0.12987798 -0.08139893]\n",
            "  [ 0.12987798  0.08139893]\n",
            "  [ 0.15734564 -0.09776168]\n",
            "  [ 0.15734564 -0.09776168]]\n",
            "\n",
            " [[ 0.05587699  0.08633929]\n",
            "  [-0.05587699 -0.08633929]\n",
            "  [-0.11888029  0.13011311]\n",
            "  [ 0.11888029 -0.13011311]\n",
            "  [ 0.12980708  0.07860648]\n",
            "  [ 0.12980708  0.07860648]]\n",
            "\n",
            " [[ 0.12902924 -0.10124385]\n",
            "  [-0.12902924  0.10124385]\n",
            "  [ 0.12545142 -0.09155626]\n",
            "  [-0.12545142  0.09155626]\n",
            "  [ 0.07156207 -0.09420802]\n",
            "  [ 0.07156207 -0.09420802]]\n",
            "\n",
            " [[-0.1829893   0.0077015 ]\n",
            "  [ 0.1829893  -0.0077015 ]\n",
            "  [ 0.15265131  0.10444041]\n",
            "  [-0.15265131 -0.10444041]\n",
            "  [-0.06320371  0.07907791]\n",
            "  [-0.06320371  0.07907791]]\n",
            "\n",
            " [[ 0.0603108  -0.03998592]\n",
            "  [-0.0603108   0.03998592]\n",
            "  [-0.20814952  0.00714896]\n",
            "  [ 0.20814952 -0.00714896]\n",
            "  [ 0.11836211 -0.14195375]\n",
            "  [ 0.11836211 -0.14195375]]\n",
            "\n",
            " [[ 0.08546395  0.10161392]\n",
            "  [-0.08546395 -0.10161392]\n",
            "  [-0.16029774 -0.10201298]\n",
            "  [ 0.16029774  0.10201298]\n",
            "  [ 0.13387917  0.03207694]\n",
            "  [ 0.13387917  0.03207694]]\n",
            "\n",
            " [[-0.14269753 -0.08545126]\n",
            "  [ 0.14269753  0.08545126]\n",
            "  [-0.18014862  0.00399001]\n",
            "  [ 0.18014862 -0.00399001]\n",
            "  [-0.04427779  0.10650244]\n",
            "  [-0.04427779  0.10650244]]\n",
            "\n",
            " [[ 0.25420907 -0.15066575]\n",
            "  [-0.25420907  0.15066575]\n",
            "  [-0.02083905  0.01008237]\n",
            "  [ 0.02083905 -0.01008237]\n",
            "  [ 0.16674283  0.00414647]\n",
            "  [ 0.16674283  0.00414647]]\n",
            "\n",
            " [[ 0.0176474   0.04060688]\n",
            "  [-0.0176474  -0.04060688]\n",
            "  [-0.1048829  -0.08328974]\n",
            "  [ 0.1048829   0.08328974]\n",
            "  [ 0.29351804  0.06142241]\n",
            "  [ 0.29351804  0.06142241]]\n",
            "\n",
            " [[ 0.17716195 -0.07155814]\n",
            "  [-0.17716195  0.07155814]\n",
            "  [-0.19778384 -0.02453742]\n",
            "  [ 0.19778384  0.02453742]\n",
            "  [-0.10439774  0.04080519]\n",
            "  [-0.10439774  0.04080519]]\n",
            "\n",
            " [[-0.12239952 -0.12107664]\n",
            "  [ 0.12239952  0.12107664]\n",
            "  [ 0.12221795  0.01445835]\n",
            "  [-0.12221795 -0.01445835]\n",
            "  [ 0.17806256 -0.04642617]\n",
            "  [ 0.17806256 -0.04642617]]]\n",
            "\n",
            "Pairs[0]:\n",
            " [[ 0.0377043  -0.05750986]\n",
            " [-0.0377043   0.05750986]\n",
            " [-0.15771744  0.03898121]\n",
            " [ 0.15771744 -0.03898121]\n",
            " [-0.26074362 -0.04156728]\n",
            " [-0.26074362 -0.04156728]\n",
            " [-0.12001313 -0.01852864]\n",
            " [-0.00594663 -0.0022418 ]\n",
            " [ 0.19542174 -0.09649107]\n",
            " [ 0.00594663  0.0022418 ]\n",
            " [-0.19542174  0.09649107]\n",
            " [ 0.00594663  0.0022418 ]\n",
            " [ 0.12001313  0.01852864]\n",
            " [-0.00594663 -0.0022418 ]\n",
            " [-0.22303931 -0.09907714]\n",
            " [-0.00983116  0.00239053]\n",
            " [-0.22303931 -0.09907714]\n",
            " [-0.00983116  0.00239053]\n",
            " [-0.2984479   0.01594258]\n",
            " [ 0.00983116 -0.00239053]\n",
            " [-0.2984479   0.01594258]\n",
            " [ 0.00983116 -0.00239053]\n",
            " [-0.41846105 -0.00258607]\n",
            " [ 0.04112381 -0.00162034]\n",
            " [-0.41846105 -0.00258607]\n",
            " [ 0.04112381 -0.00162034]\n",
            " [-0.10302618 -0.0805485 ]\n",
            " [-0.04112381  0.00162034]\n",
            " [-0.10302618 -0.0805485 ]\n",
            " [-0.04112381  0.00162034]]\n",
            "\n",
            "Triplets[0]:\n",
            " [[[ 0.0377043  -0.05750986]\n",
            "  [-0.0377043   0.05750986]\n",
            "  [-0.15771744  0.03898121]]\n",
            "\n",
            " [[ 0.15771744 -0.03898121]\n",
            "  [-0.26074362 -0.04156728]\n",
            "  [-0.26074362 -0.04156728]]\n",
            "\n",
            " [[-0.12001313 -0.01852864]\n",
            "  [-0.00594663 -0.0022418 ]\n",
            "  [ 0.19542174 -0.09649107]]\n",
            "\n",
            " [[ 0.00594663  0.0022418 ]\n",
            "  [-0.19542174  0.09649107]\n",
            "  [ 0.00594663  0.0022418 ]]\n",
            "\n",
            " [[ 0.12001313  0.01852864]\n",
            "  [-0.00594663 -0.0022418 ]\n",
            "  [-0.22303931 -0.09907714]]\n",
            "\n",
            " [[-0.00983116  0.00239053]\n",
            "  [-0.22303931 -0.09907714]\n",
            "  [-0.00983116  0.00239053]]\n",
            "\n",
            " [[-0.2984479   0.01594258]\n",
            "  [ 0.00983116 -0.00239053]\n",
            "  [-0.2984479   0.01594258]]\n",
            "\n",
            " [[ 0.00983116 -0.00239053]\n",
            "  [-0.41846105 -0.00258607]\n",
            "  [ 0.04112381 -0.00162034]]\n",
            "\n",
            " [[-0.41846105 -0.00258607]\n",
            "  [ 0.04112381 -0.00162034]\n",
            "  [-0.10302618 -0.0805485 ]]\n",
            "\n",
            " [[-0.04112381  0.00162034]\n",
            "  [-0.10302618 -0.0805485 ]\n",
            "  [-0.04112381  0.00162034]]]\n",
            "\n",
            "Bits (all qubits):\n",
            " [[1 1 1 ... 0 0 0]\n",
            " [0 1 0 ... 0 1 1]\n",
            " [0 1 1 ... 0 0 1]\n",
            " ...\n",
            " [1 0 1 ... 1 1 0]\n",
            " [1 0 1 ... 0 1 1]\n",
            " [0 1 0 ... 0 1 1]]\n",
            "\n",
            "Primaries Out (promoted):\n",
            " [[[-4.11238149e-02  1.62034307e-03]\n",
            "  [ 4.11238149e-02 -1.62034307e-03]\n",
            "  [-1.03026181e-01 -8.05484951e-02]\n",
            "  [ 1.03026181e-01  8.05484951e-02]\n",
            "  [-4.11238149e-02  1.62034307e-03]\n",
            "  [ 4.11238149e-02 -1.62034307e-03]]\n",
            "\n",
            " [[-4.75858618e-03 -3.39475664e-05]\n",
            "  [ 4.75858618e-03  3.39475664e-05]\n",
            "  [ 1.85325086e-01  3.35362218e-02]\n",
            "  [-1.85325086e-01 -3.35362218e-02]\n",
            "  [-4.75858618e-03 -3.39475664e-05]\n",
            "  [ 4.75858618e-03  3.39475664e-05]]\n",
            "\n",
            " [[-1.52045321e-02  1.22651961e-02]\n",
            "  [ 1.52045321e-02 -1.22651961e-02]\n",
            "  [-5.02119809e-02 -2.22634375e-01]\n",
            "  [ 5.02119809e-02  2.22634375e-01]\n",
            "  [-1.52045321e-02  1.22651961e-02]\n",
            "  [ 1.52045321e-02 -1.22651961e-02]]\n",
            "\n",
            " [[-1.57408267e-02 -4.16284706e-03]\n",
            "  [ 1.57408267e-02  4.16284706e-03]\n",
            "  [ 2.83105969e-02 -1.17748305e-01]\n",
            "  [-2.83105969e-02  1.17748305e-01]\n",
            "  [-1.57408267e-02 -4.16284706e-03]\n",
            "  [ 1.57408267e-02  4.16284706e-03]]\n",
            "\n",
            " [[ 1.41263846e-02  6.33985037e-03]\n",
            "  [-1.41263846e-02 -6.33985037e-03]\n",
            "  [-2.38351822e-01  1.64509818e-01]\n",
            "  [ 2.38351822e-01 -1.64509818e-01]\n",
            "  [ 1.41263846e-02  6.33985037e-03]\n",
            "  [-1.41263846e-02 -6.33985037e-03]]\n",
            "\n",
            " [[ 1.04572028e-02  4.50053252e-03]\n",
            "  [-1.04572028e-02 -4.50053252e-03]\n",
            "  [ 2.08768457e-01  1.59095615e-01]\n",
            "  [-2.08768457e-01 -1.59095615e-01]\n",
            "  [ 1.04572028e-02  4.50053252e-03]\n",
            "  [-1.04572028e-02 -4.50053252e-03]]\n",
            "\n",
            " [[ 1.98061299e-02 -2.73389451e-04]\n",
            "  [-1.98061299e-02  2.73389451e-04]\n",
            "  [-2.90207386e-01 -1.58168674e-02]\n",
            "  [ 2.90207386e-01  1.58168674e-02]\n",
            "  [ 1.98061299e-02 -2.73389451e-04]\n",
            "  [-1.98061299e-02  2.73389451e-04]]\n",
            "\n",
            " [[ 2.29945201e-02 -1.89351346e-02]\n",
            "  [-2.29945201e-02  1.89351346e-02]\n",
            "  [-3.06284070e-01  1.83118880e-03]\n",
            "  [ 3.06284070e-01 -1.83118880e-03]\n",
            "  [ 2.29945201e-02 -1.89351346e-02]\n",
            "  [-2.29945201e-02  1.89351346e-02]]\n",
            "\n",
            " [[-1.01468305e-03  9.22152959e-03]\n",
            "  [ 1.01468305e-03 -9.22152959e-03]\n",
            "  [-1.10944830e-01 -1.94074199e-01]\n",
            "  [ 1.10944830e-01  1.94074199e-01]\n",
            "  [-1.01468305e-03  9.22152959e-03]\n",
            "  [ 1.01468305e-03 -9.22152959e-03]]\n",
            "\n",
            " [[ 3.94494692e-03  9.16384906e-03]\n",
            "  [-3.94494692e-03 -9.16384906e-03]\n",
            "  [-1.92853093e-01  2.08031803e-01]\n",
            "  [ 1.92853093e-01 -2.08031803e-01]\n",
            "  [ 3.94494692e-03  9.16384906e-03]\n",
            "  [-3.94494692e-03 -9.16384906e-03]]\n",
            "\n",
            " [[ 1.31481104e-02  7.74638820e-03]\n",
            "  [-1.31481104e-02 -7.74638820e-03]\n",
            "  [ 2.49970123e-01  1.95548311e-01]\n",
            "  [-2.49970123e-01 -1.95548311e-01]\n",
            "  [ 1.31481104e-02  7.74638820e-03]\n",
            "  [-1.31481104e-02 -7.74638820e-03]]\n",
            "\n",
            " [[ 1.10046482e-02  8.05722922e-03]\n",
            "  [-1.10046482e-02 -8.05722922e-03]\n",
            "  [ 2.18999043e-01 -1.87556237e-01]\n",
            "  [-2.18999043e-01  1.87556237e-01]\n",
            "  [ 1.10046482e-02  8.05722922e-03]\n",
            "  [-1.10046482e-02 -8.05722922e-03]]\n",
            "\n",
            " [[ 4.56133718e-03  4.19145357e-03]\n",
            "  [-4.56133718e-03 -4.19145357e-03]\n",
            "  [-1.98289603e-01 -1.65087268e-01]\n",
            "  [ 1.98289603e-01  1.65087268e-01]\n",
            "  [ 4.56133718e-03  4.19145357e-03]\n",
            "  [-4.56133718e-03 -4.19145357e-03]]\n",
            "\n",
            " [[-1.72524117e-02  2.91906460e-03]\n",
            "  [ 1.72524117e-02 -2.91906460e-03]\n",
            "  [ 2.50411257e-02 -1.11475311e-01]\n",
            "  [-2.50411257e-02  1.11475311e-01]\n",
            "  [-1.72524117e-02  2.91906460e-03]\n",
            "  [ 1.72524117e-02 -2.91906460e-03]]\n",
            "\n",
            " [[-1.30825129e-03  1.79726463e-02]\n",
            "  [ 1.30825129e-03 -1.79726463e-02]\n",
            "  [-6.51455224e-02 -2.68624127e-01]\n",
            "  [ 6.51455224e-02  2.68624127e-01]\n",
            "  [-1.30825129e-03  1.79726463e-02]\n",
            "  [ 1.30825129e-03 -1.79726463e-02]]\n",
            "\n",
            " [[-6.58621918e-03 -1.41940021e-03]\n",
            "  [ 6.58621918e-03  1.41940021e-03]\n",
            "  [ 9.87856090e-02 -1.14999369e-01]\n",
            "  [-9.87856090e-02  1.14999369e-01]\n",
            "  [-6.58621918e-03 -1.41940021e-03]\n",
            "  [ 6.58621918e-03  1.41940021e-03]]\n",
            "\n",
            " [[-1.05310241e-02 -7.16085220e-03]\n",
            "  [ 1.05310241e-02  7.16085220e-03]\n",
            "  [ 4.37515825e-02  2.57020295e-02]\n",
            "  [-4.37515825e-02 -2.57020295e-02]\n",
            "  [-1.05310241e-02 -7.16085220e-03]\n",
            "  [ 1.05310241e-02  7.16085220e-03]]\n",
            "\n",
            " [[ 3.74094187e-03 -7.86587503e-03]\n",
            "  [-3.74094187e-03  7.86587503e-03]\n",
            "  [-2.13643178e-01 -5.74344620e-02]\n",
            "  [ 2.13643178e-01  5.74344620e-02]\n",
            "  [ 3.74094187e-03 -7.86587503e-03]\n",
            "  [-3.74094187e-03  7.86587503e-03]]\n",
            "\n",
            " [[ 1.99316721e-02  8.98507982e-03]\n",
            "  [-1.99316721e-02 -8.98507982e-03]\n",
            "  [-2.84058064e-01  1.89973742e-01]\n",
            "  [ 2.84058064e-01 -1.89973742e-01]\n",
            "  [ 1.99316721e-02  8.98507982e-03]\n",
            "  [-1.99316721e-02 -8.98507982e-03]]\n",
            "\n",
            " [[-2.25139828e-03 -3.22847487e-03]\n",
            "  [ 2.25139828e-03  3.22847487e-03]\n",
            "  [-1.33424364e-02 -1.82637796e-02]\n",
            "  [ 1.33424364e-02  1.82637796e-02]\n",
            "  [-2.25139828e-03 -3.22847487e-03]\n",
            "  [ 2.25139828e-03  3.22847487e-03]]\n",
            "\n",
            " [[-6.72508823e-03  4.55131475e-03]\n",
            "  [ 6.72508823e-03 -4.55131475e-03]\n",
            "  [ 8.44494253e-02  1.35604918e-01]\n",
            "  [-8.44494253e-02 -1.35604918e-01]\n",
            "  [-6.72508823e-03  4.55131475e-03]\n",
            "  [ 6.72508823e-03 -4.55131475e-03]]\n",
            "\n",
            " [[ 4.36248537e-03  1.15279499e-02]\n",
            "  [-4.36248537e-03 -1.15279499e-02]\n",
            "  [ 1.32210359e-01 -2.22138286e-01]\n",
            "  [-1.32210359e-01  2.22138286e-01]\n",
            "  [ 4.36248537e-03  1.15279499e-02]\n",
            "  [-4.36248537e-03 -1.15279499e-02]]\n",
            "\n",
            " [[ 4.07126872e-03 -1.31891138e-04]\n",
            "  [-4.07126872e-03  1.31891138e-04]\n",
            "  [-1.39845937e-01 -1.83033362e-01]\n",
            "  [ 1.39845937e-01  1.83033362e-01]\n",
            "  [ 4.07126872e-03 -1.31891138e-04]\n",
            "  [-4.07126872e-03  1.31891138e-04]]\n",
            "\n",
            " [[ 5.83484420e-04 -1.40231829e-02]\n",
            "  [-5.83484420e-04  1.40231829e-02]\n",
            "  [ 5.36785051e-02 -6.73745573e-03]\n",
            "  [-5.36785051e-02  6.73745573e-03]\n",
            "  [ 5.83484420e-04 -1.40231829e-02]\n",
            "  [-5.83484420e-04  1.40231829e-02]]\n",
            "\n",
            " [[-1.31787825e-02 -7.27691455e-03]\n",
            "  [ 1.31787825e-02  7.27691455e-03]\n",
            "  [-1.88148320e-02  5.01841158e-02]\n",
            "  [ 1.88148320e-02 -5.01841158e-02]\n",
            "  [-1.31787825e-02 -7.27691455e-03]\n",
            "  [ 1.31787825e-02  7.27691455e-03]]\n",
            "\n",
            " [[-1.55441789e-02  8.20240099e-03]\n",
            "  [ 1.55441789e-02 -8.20240099e-03]\n",
            "  [-7.98963010e-03 -1.81180418e-01]\n",
            "  [ 7.98963010e-03  1.81180418e-01]\n",
            "  [-1.55441789e-02  8.20240099e-03]\n",
            "  [ 1.55441789e-02 -8.20240099e-03]]\n",
            "\n",
            " [[ 2.56551467e-02 -6.49144698e-04]\n",
            "  [-2.56551467e-02  6.49144698e-04]\n",
            "  [ 3.28754336e-01  8.41731429e-02]\n",
            "  [-3.28754336e-01 -8.41731429e-02]\n",
            "  [ 2.56551467e-02 -6.49144698e-04]\n",
            "  [-2.56551467e-02  6.49144698e-04]]\n",
            "\n",
            " [[-1.62136573e-02 -1.13251191e-02]\n",
            "  [ 1.62136573e-02  1.13251191e-02]\n",
            "  [-9.39656273e-02 -1.66707486e-03]\n",
            "  [ 9.39656273e-02  1.66707486e-03]\n",
            "  [-1.62136573e-02 -1.13251191e-02]\n",
            "  [ 1.62136573e-02  1.13251191e-02]]\n",
            "\n",
            " [[-2.76588392e-03  6.82329573e-03]\n",
            "  [ 2.76588392e-03 -6.82329573e-03]\n",
            "  [ 1.10559598e-01 -1.90613389e-01]\n",
            "  [-1.10559598e-01  1.90613389e-01]\n",
            "  [-2.76588392e-03  6.82329573e-03]\n",
            "  [ 2.76588392e-03 -6.82329573e-03]]\n",
            "\n",
            " [[ 1.30233224e-02  3.07487906e-03]\n",
            "  [-1.30233224e-02 -3.07487906e-03]\n",
            "  [ 3.06965977e-01  1.11125857e-01]\n",
            "  [-3.06965977e-01 -1.11125857e-01]\n",
            "  [ 1.30233224e-02  3.07487906e-03]\n",
            "  [-1.30233224e-02 -3.07487906e-03]]\n",
            "\n",
            " [[-5.25936543e-04  3.71690420e-03]\n",
            "  [ 5.25936543e-04 -3.71690420e-03]\n",
            "  [ 1.78874999e-01  1.31503776e-01]\n",
            "  [-1.78874999e-01 -1.31503776e-01]\n",
            "  [-5.25936543e-04  3.71690420e-03]\n",
            "  [ 5.25936543e-04 -3.71690420e-03]]\n",
            "\n",
            " [[-1.83054693e-02  8.52112751e-03]\n",
            "  [ 1.83054693e-02 -8.52112751e-03]\n",
            "  [-2.45083123e-02 -1.85835093e-01]\n",
            "  [ 2.45083123e-02  1.85835093e-01]\n",
            "  [-1.83054693e-02  8.52112751e-03]\n",
            "  [ 1.83054693e-02 -8.52112751e-03]]\n",
            "\n",
            " [[ 6.42319676e-03 -6.59764279e-03]\n",
            "  [-6.42319676e-03  6.59764279e-03]\n",
            "  [-1.69985592e-01  6.41115010e-04]\n",
            "  [ 1.69985592e-01 -6.41115010e-04]\n",
            "  [ 6.42319676e-03 -6.59764279e-03]\n",
            "  [-6.42319676e-03  6.59764279e-03]]\n",
            "\n",
            " [[ 1.17945867e-02 -1.14688335e-03]\n",
            "  [-1.17945867e-02  1.14688335e-03]\n",
            "  [ 2.59530067e-01  1.27445251e-01]\n",
            "  [-2.59530067e-01 -1.27445251e-01]\n",
            "  [ 1.17945867e-02 -1.14688335e-03]\n",
            "  [-1.17945867e-02  1.14688335e-03]]\n",
            "\n",
            " [[-1.71910579e-04 -1.57225411e-02]\n",
            "  [ 1.71910579e-04  1.57225411e-02]\n",
            "  [ 4.80615273e-02 -1.35663599e-02]\n",
            "  [-4.80615273e-02  1.35663599e-02]\n",
            "  [-1.71910579e-04 -1.57225411e-02]\n",
            "  [ 1.71910579e-04  1.57225411e-02]]\n",
            "\n",
            " [[ 5.59544656e-03  5.67609956e-03]\n",
            "  [-5.59544656e-03 -5.67609956e-03]\n",
            "  [ 1.84842512e-01  1.58941537e-01]\n",
            "  [-1.84842512e-01 -1.58941537e-01]\n",
            "  [ 5.59544656e-03  5.67609956e-03]\n",
            "  [-5.59544656e-03 -5.67609956e-03]]\n",
            "\n",
            " [[-4.42227628e-03 -1.27438903e-02]\n",
            "  [ 4.42227628e-03  1.27438903e-02]\n",
            "  [ 2.69958287e-01 -1.26313269e-02]\n",
            "  [-2.69958287e-01  1.26313269e-02]\n",
            "  [-4.42227628e-03 -1.27438903e-02]\n",
            "  [ 4.42227628e-03  1.27438903e-02]]\n",
            "\n",
            " [[-2.80847326e-02  4.17522853e-03]\n",
            "  [ 2.80847326e-02 -4.17522853e-03]\n",
            "  [ 1.04925483e-02 -1.31231338e-01]\n",
            "  [-1.04925483e-02  1.31231338e-01]\n",
            "  [-2.80847326e-02  4.17522853e-03]\n",
            "  [ 2.80847326e-02 -4.17522853e-03]]\n",
            "\n",
            " [[ 1.69575885e-02  2.90270196e-03]\n",
            "  [-1.69575885e-02 -2.90270196e-03]\n",
            "  [-2.60982156e-01 -1.38003454e-01]\n",
            "  [ 2.60982156e-01  1.38003454e-01]\n",
            "  [ 1.69575885e-02  2.90270196e-03]\n",
            "  [-1.69575885e-02 -2.90270196e-03]]\n",
            "\n",
            " [[-1.27886720e-02 -5.86628681e-03]\n",
            "  [ 1.27886720e-02  5.86628681e-03]\n",
            "  [ 4.28604037e-02  1.49517044e-01]\n",
            "  [-4.28604037e-02 -1.49517044e-01]\n",
            "  [-1.27886720e-02 -5.86628681e-03]\n",
            "  [ 1.27886720e-02  5.86628681e-03]]\n",
            "\n",
            " [[ 2.29047448e-03  2.29213443e-02]\n",
            "  [-2.29047448e-03 -2.29213443e-02]\n",
            "  [ 1.51330218e-01  3.36633563e-01]\n",
            "  [-1.51330218e-01 -3.36633563e-01]\n",
            "  [ 2.29047448e-03  2.29213443e-02]\n",
            "  [-2.29047448e-03 -2.29213443e-02]]\n",
            "\n",
            " [[-8.91248987e-04  1.36152832e-02]\n",
            "  [ 8.91248987e-04 -1.36152832e-02]\n",
            "  [-2.07125440e-01 -2.33371049e-01]\n",
            "  [ 2.07125440e-01  2.33371049e-01]\n",
            "  [-8.91248987e-04  1.36152832e-02]\n",
            "  [ 8.91248987e-04 -1.36152832e-02]]\n",
            "\n",
            " [[ 2.47601449e-04 -4.17831820e-03]\n",
            "  [-2.47601449e-04  4.17831820e-03]\n",
            "  [ 3.44937816e-02 -8.84445012e-02]\n",
            "  [-3.44937816e-02  8.84445012e-02]\n",
            "  [ 2.47601449e-04 -4.17831820e-03]\n",
            "  [-2.47601449e-04  4.17831820e-03]]\n",
            "\n",
            " [[-3.79860890e-03 -8.62941984e-03]\n",
            "  [ 3.79860890e-03  8.62941984e-03]\n",
            "  [ 1.44022182e-01  1.85020715e-02]\n",
            "  [-1.44022182e-01 -1.85020715e-02]\n",
            "  [-3.79860890e-03 -8.62941984e-03]\n",
            "  [ 3.79860890e-03  8.62941984e-03]]\n",
            "\n",
            " [[ 1.14146760e-03 -5.75689366e-04]\n",
            "  [-1.14146760e-03  5.75689366e-04]\n",
            "  [-1.68628410e-01  7.55460262e-02]\n",
            "  [ 1.68628410e-01 -7.55460262e-02]\n",
            "  [ 1.14146760e-03 -5.75689366e-04]\n",
            "  [-1.14146760e-03  5.75689366e-04]]\n",
            "\n",
            " [[ 1.28165260e-02 -1.02132757e-03]\n",
            "  [-1.28165260e-02  1.02132757e-03]\n",
            "  [-2.58458912e-01  5.13299406e-02]\n",
            "  [ 2.58458912e-01 -5.13299406e-02]\n",
            "  [ 1.28165260e-02 -1.02132757e-03]\n",
            "  [-1.28165260e-02  1.02132757e-03]]\n",
            "\n",
            " [[-4.70394082e-03 -6.51442632e-03]\n",
            "  [ 4.70394082e-03  6.51442632e-03]\n",
            "  [-5.75757101e-02 -8.75808895e-02]\n",
            "  [ 5.75757101e-02  8.75808895e-02]\n",
            "  [-4.70394082e-03 -6.51442632e-03]\n",
            "  [ 4.70394082e-03  6.51442632e-03]]\n",
            "\n",
            " [[ 6.14527008e-03 -9.46486089e-03]\n",
            "  [-6.14527008e-03  9.46486089e-03]\n",
            "  [ 1.77504092e-01  1.67598724e-02]\n",
            "  [-1.77504092e-01 -1.67598724e-02]\n",
            "  [ 6.14527008e-03 -9.46486089e-03]\n",
            "  [-6.14527008e-03  9.46486089e-03]]\n",
            "\n",
            " [[ 1.45808915e-02  6.83462655e-04]\n",
            "  [-1.45808915e-02 -6.83462655e-04]\n",
            "  [-2.98134893e-01 -8.74332115e-02]\n",
            "  [ 2.98134893e-01  8.74332115e-02]\n",
            "  [ 1.45808915e-02  6.83462655e-04]\n",
            "  [-1.45808915e-02 -6.83462655e-04]]\n",
            "\n",
            " [[ 3.46955517e-03 -4.44953423e-03]\n",
            "  [-3.46955517e-03  4.44953423e-03]\n",
            "  [-2.41552040e-01  1.57809481e-01]\n",
            "  [ 2.41552040e-01 -1.57809481e-01]\n",
            "  [ 3.46955517e-03 -4.44953423e-03]\n",
            "  [-3.46955517e-03  4.44953423e-03]]\n",
            "\n",
            " [[-1.85768504e-03 -2.55689700e-03]\n",
            "  [ 1.85768504e-03  2.55689700e-03]\n",
            "  [-6.23476952e-02  1.34400904e-01]\n",
            "  [ 6.23476952e-02 -1.34400904e-01]\n",
            "  [-1.85768504e-03 -2.55689700e-03]\n",
            "  [ 1.85768504e-03  2.55689700e-03]]\n",
            "\n",
            " [[-1.81986019e-02  1.11660571e-04]\n",
            "  [ 1.81986019e-02 -1.11660571e-04]\n",
            "  [ 4.45621312e-02  1.12211488e-01]\n",
            "  [-4.45621312e-02 -1.12211488e-01]\n",
            "  [-1.81986019e-02  1.11660571e-04]\n",
            "  [ 1.81986019e-02 -1.11660571e-04]]\n",
            "\n",
            " [[ 1.26403000e-03  1.24622881e-02]\n",
            "  [-1.26403000e-03 -1.24622881e-02]\n",
            "  [ 7.19221160e-02  2.23519087e-01]\n",
            "  [-7.19221160e-02 -2.23519087e-01]\n",
            "  [ 1.26403000e-03  1.24622881e-02]\n",
            "  [-1.26403000e-03 -1.24622881e-02]]\n",
            "\n",
            " [[ 2.04357337e-02 -7.95769598e-03]\n",
            "  [-2.04357337e-02  7.95769598e-03]\n",
            "  [ 2.87223637e-01 -1.63627416e-02]\n",
            "  [-2.87223637e-01  1.63627416e-02]\n",
            "  [ 2.04357337e-02 -7.95769598e-03]\n",
            "  [-2.04357337e-02  7.95769598e-03]]\n",
            "\n",
            " [[ 1.54315038e-02 -1.02277333e-02]\n",
            "  [-1.54315038e-02  1.02277333e-02]\n",
            "  [ 2.48687372e-01 -5.15066311e-02]\n",
            "  [-2.48687372e-01  5.15066311e-02]\n",
            "  [ 1.54315038e-02 -1.02277333e-02]\n",
            "  [-1.54315038e-02  1.02277333e-02]]\n",
            "\n",
            " [[-8.97756312e-03 -8.62533320e-03]\n",
            "  [ 8.97756312e-03  8.62533320e-03]\n",
            "  [-5.38893417e-02 -2.65175849e-03]\n",
            "  [ 5.38893417e-02  2.65175849e-03]\n",
            "  [-8.97756312e-03 -8.62533320e-03]\n",
            "  [ 8.97756312e-03  8.62533320e-03]]\n",
            "\n",
            " [[ 9.64812841e-03 -8.25893041e-03]\n",
            "  [-9.64812841e-03  8.25893041e-03]\n",
            "  [-2.15855017e-01 -2.53624991e-02]\n",
            "  [ 2.15855017e-01  2.53624991e-02]\n",
            "  [ 9.64812841e-03 -8.25893041e-03]\n",
            "  [-9.64812841e-03  8.25893041e-03]]\n",
            "\n",
            " [[ 2.46370155e-02  1.01482146e-03]\n",
            "  [-2.46370155e-02 -1.01482146e-03]\n",
            "  [ 3.26511621e-01 -1.49102718e-01]\n",
            "  [-3.26511621e-01  1.49102718e-01]\n",
            "  [ 2.46370155e-02  1.01482146e-03]\n",
            "  [-2.46370155e-02 -1.01482146e-03]]\n",
            "\n",
            " [[ 2.14605276e-02  3.27226450e-03]\n",
            "  [-2.14605276e-02 -3.27226450e-03]\n",
            "  [ 2.94176906e-01  1.34089917e-01]\n",
            "  [-2.94176906e-01 -1.34089917e-01]\n",
            "  [ 2.14605276e-02  3.27226450e-03]\n",
            "  [-2.14605276e-02 -3.27226450e-03]]\n",
            "\n",
            " [[-7.97658321e-03 -4.24946164e-04]\n",
            "  [ 7.97658321e-03  4.24946164e-04]\n",
            "  [ 1.35870814e-01  1.02512434e-01]\n",
            "  [-1.35870814e-01 -1.02512434e-01]\n",
            "  [-7.97658321e-03 -4.24946164e-04]\n",
            "  [ 7.97658321e-03  4.24946164e-04]]\n",
            "\n",
            " [[ 3.47476266e-03 -4.18061900e-05]\n",
            "  [-3.47476266e-03  4.18061900e-05]\n",
            "  [ 1.87581882e-01 -5.93589852e-03]\n",
            "  [-1.87581882e-01  5.93589852e-03]\n",
            "  [ 3.47476266e-03 -4.18061900e-05]\n",
            "  [-3.47476266e-03  4.18061900e-05]]\n",
            "\n",
            " [[ 3.07850223e-02  5.11585595e-03]\n",
            "  [-3.07850223e-02 -5.11585595e-03]\n",
            "  [ 3.98400933e-01  1.44712150e-01]\n",
            "  [-3.98400933e-01 -1.44712150e-01]\n",
            "  [ 3.07850223e-02  5.11585595e-03]\n",
            "  [-3.07850223e-02 -5.11585595e-03]]\n",
            "\n",
            " [[-2.06481870e-02  1.00125407e-03]\n",
            "  [ 2.06481870e-02 -1.00125407e-03]\n",
            "  [ 9.33860987e-02  6.53426051e-02]\n",
            "  [-9.33860987e-02 -6.53426051e-02]\n",
            "  [-2.06481870e-02  1.00125407e-03]\n",
            "  [ 2.06481870e-02 -1.00125407e-03]]\n",
            "\n",
            " [[-2.17624400e-02  6.71245798e-04]\n",
            "  [ 2.17624400e-02 -6.71245798e-04]\n",
            "  [ 5.58446124e-02 -6.08845167e-02]\n",
            "  [-5.58446124e-02  6.08845167e-02]\n",
            "  [-2.17624400e-02  6.71245798e-04]\n",
            "  [ 2.17624400e-02 -6.71245798e-04]]]\n",
            "\n",
            "Nth Identities (Conceptual, per qubit):\n",
            "\n",
            "  Qubit 0:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9992004   0.03937007]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 1:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9997645  -0.00713228]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 2:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.77828616  0.6278281 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 3:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96670425 -0.25565633]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 4:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9122735  0.40942377]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 5:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.918463   0.39528474]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 6:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99985427 -0.01380126]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 7:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.77192944 -0.6356553 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 8:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.10936221  0.9938935 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 9:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.39536807 0.9184137 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 10:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.86152804 0.50758094]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 11:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.8067947  0.59070766]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 12:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.7362123 0.6765121]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 13:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.98592997  0.16681686]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 14:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.07259513  0.99730587]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 15:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9774113  -0.21064253]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 16:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8268705  -0.56225276]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 17:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.42944312 -0.90296674]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 18:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.91160864 0.4109478 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 19:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.57186097 -0.82004094]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 20:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.82806766  0.56040853]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 21:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.353903  0.9351954]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 22:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9992305  -0.03237066]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 23:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.04156962 -0.99906427]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 24:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.87535477 -0.48334375]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 25:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.88436896  0.46666658]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 26:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9996411  -0.02529363]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 27:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.81977063 -0.5726037 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 28:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.37561712  0.9266284 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 29:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.973168  0.2297704]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 30:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.14006563  0.98987323]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 31:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.90654445  0.42199305]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 32:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.697495  -0.7164381]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 33:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9952216  -0.09677347]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 34:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.01093267 -0.9998767 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 35:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.701941   0.71205884]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 36:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.32780972 -0.9446653 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 37:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9890943   0.14704412]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 38:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9856067  0.16871046]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 39:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.90887064 -0.4169077 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 40:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.09942806 0.99500114]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 41:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.06531487  0.99779123]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 42:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.05914074 -0.9980104 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 43:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.40284374 -0.91515285]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 44:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.8921734 -0.44996  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 45:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99676234 -0.07943033]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 46:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.5853422 -0.8106328]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 47:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.54451084 -0.83864814]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 48:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9988348  0.04681924]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 49:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.6148037  -0.78845555]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 50:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.58759737 -0.8087625 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 51:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9999262   0.00613521]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 52:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.10090261 0.99481606]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 53:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.93180084 -0.36284423]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 54:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.83349645 -0.552427  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 55:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.72105354 -0.6927634 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 56:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.7596205  -0.65024555]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 57:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9991121  0.04115435]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 58:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9885285  0.15072913]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 59:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.998459   -0.05319211]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 60:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9996399  -0.01202705]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 61:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.98644006 0.16392663]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 62:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9987781   0.04843188]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 63:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99947876  0.03082816]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "\n",
            "Info-energy Output (all qubits):\n",
            " [ 7.714237   5.0375266  8.607647   5.4778857  6.8588095 10.447913\n",
            "  9.114554   9.3644285  8.279012   9.611114  10.325088  11.477955\n",
            "  6.9638557  3.8699138  8.313864   3.9083984  1.5840087  9.50471\n",
            " 14.559112   1.0342495  4.6891055  6.7010574  7.1764946  2.8681061\n",
            "  3.1984403  6.2254024  8.135188   3.8860373  5.1130967 12.330447\n",
            "  4.856871   6.9345818  5.2109475 10.002922   2.1808267  7.03182\n",
            "  8.46331    4.712852   6.938736   6.684578  12.339659   9.72945\n",
            "  2.0915966  5.532517   7.0289783  7.3071413  4.7029467  7.733567\n",
            "  7.775117   8.905607   6.065051   5.6713724 10.3673315  8.408076\n",
            "  9.873484   3.0088496  6.0087996 12.974201   9.487834   6.321372\n",
            "  4.3692937 11.5925455  5.5601654  2.9311323]\n",
            "\n",
            "Resonance Keys (all qubits):\n",
            " ['881f2070f199b91277052832c153d6842463f85cd12d1d95ec84f5acbdcf9b90', '208851a4df38dea9b7180ea6a144f2406f57c4ccffcf4680e9013282a2105eae', '9f75d3a00a3ca16f9ff3eef392ef8c22e59e56f465e759d9ec5492ab770711c7', '66fe83faaf5680d79225711d108d35943c43f115e8cc0a9855df7ee799361056', '60375aae9006886e04c5c11d85ea00d38fc0f869cb916da03f15c4da3bcda70c', 'ba95380935b14af2e47b4e4cc4e2a39fb20e2ecf061584eb4ff28228f3261db3', '94ce9b37c97545919d4a2c2fc6f045cc7c62ea12f7c56858fcc76fe3b4289d72', '075c0d6910b3685da73dfc3d801ece524eec1a98999e573e2c5770345154c3a8', '71d1234465074e52b2c4edcc4f1a0f77960220be0d46c812184e73be22382db1', 'd90da40716cedb36a4eebc14be4bd2badd6c499900224014c478a888bb10a6d1', 'ae8490eec652bb5ae80a7c1913762e18355a445268e48cd2d5f7e0a32c3b954d', '09d979add17d10c9c13233c696158b6192aa41ba98c92c4ddde5829781c9927e', '73f835f90f37fc990364f989c27afb8637fab1822b61ee17d0fa692677fd9733', '7f154e2e36a831c6771b4721541ff9d36e5d2526c79dc442f489639e5e0c0f9e', '0e4727bdad1151f4a738d10c958e3a8c6dd7c49e69413526d94c7279593d4140', 'ed7ca4ee5425a7b235953bd0b61ad919d66f40d52b87769792a4af6afc8e2c78', '854b23be6d322a9897a78c44052d56d25e257aa60f21e3f7a2465860ca3291d6', '14bb8ff43568e8a3de2732d8edb69e6f45736e6febc0017814cdc99ca0e08e5e', '5dc401817706111b7cc5f5e7af0cffa5d1dadc5beadf79e709aaf8a2f3e37b4b', '66e932d2a9618f5aed0bc0f76e78640b2af729c6a900440658d7a203e1736aca', '2bae55330d2ab51ece0b2c91d38b8bdcd1c765973cf75681b1a011092dbf1c6d', '87850482489758d0d1ddb17115940c37148e8888ad30f21292f01d661043f024', '84f4f022ff39babc0c8fac3d5ed06c59bfe19fe0dbba46f15502a64b2a594857', '27d0c621fc760f4f5fd6f5877330ac8323d767db715256790203435c4fd0243c', '4f47bc17bd338c701827a8d79b37f8b2d9eea0ff74af433962f1aae6999e44fe', '002e2faf326547263a73e239dbdebdc3bd6b951050cb5c222309b6d50d277fd4', '9327009deec1dfb0610ba6ce89292e6d477dbd289f44b1c13b80dc8cce455cc3', 'c07b5420df29dadc984a3be0aea4cda536a680b5c113590fe54cb657686af807', 'bfd01849d815384dc5ac3bfacfa05eaa9ce2e9b53de7c63f8dee5eaa635a4a9b', '14ee412331c9278b58fbb9631bf1844ef7694e67735cdddd121a4af90276c45c', '7a982ead816f2fc33fe65da84ffe31b46e42a93ec07500b4cc7c159cbc5ece22', '5e21a88c30f0a9d4b0975c87e8e4c7e100a5cc95ad19f4d0a6e71d4fcfd5b74b', '644d96beb186b583b40f26ed12be964d69a53fc769df11a35385c832b805d499', '69011cd82e724f8b4aa7aece4ec365b65a6c3a53788f6eb5b7a24b6ea48b7ba9', '1c7f998b6aa65a537e16a33035130fa86626dd2b68f284f5eaea22af388ea83d', '8ea176a0a90bada963d84a8942f014ddf2b833389f503751c6dd71ebf65f7e9f', '1630735a46fcd2a50a5c4a2bd13958184b9b4d9a69548cd073e561daea9fdc61', 'a9b98235a6c32687e25d195b891682d1293bcc7f323df77e5c5980222fd00327', '5b128223ef111d272bcf3175fc69144e011c8c3c6dd722775371b62e1a170090', '83915e8ed37283ae8cdda3c5d2cb21b647fba5e1095d61ed5085ea1f41ded3b7', '6df72d230914db8a99c9c0b9b0261118c74472fbff324b9283b3f6690076ea6a', '9d4d398a4a961339e32b606d510830e25829bf683480b355a18eb47e75648347', '21b5472e78fa29394db6fce6643a81f1f6f919a50f3a09d05b74848b4c3d731d', 'd6cfcf4b984702c5726e13843b6905f5896d6c10a135cb4f4c0e5fb9500af4ae', '88ddbff57fd88c816a764964821c4a7af7990d4e5fbf34634eaf837754041d14', '0b6fa99a5b85f7c7d5e904050b11c5df88d210419f603e8a6d593c8c1930a9d9', '723aa5202fb518b6998525c850333dcadbe4157ad68671ad0cf588d4f559180b', '4f02adae8fb50664be7e668623ad38cf3d8e0e46ac9a6ae80b8c21d2b2150394', 'd299edb3034e8c5ca5d046dd7b284f079e76108f884512ca3da522fac9c2172d', '3e84e880f4caf1751d8b642168568cb2631ef7d9644ae56eab9fb96b19a0bd98', '5be22e7a914668f93254f580fb03d5a97309e4dd350ad85ccb7a29be455583fc', '612af6a6c6218fd76757e48e5ac225c56e8f0f6e24ff09f09e5f8ca8bf14eb86', '4b154abc6ad642ec464dc10c38bddaabb710889e390ee0b2bc78adf5a2338a08', 'e0e9920ddebd582d8f8a9518e518cda517ce8071468b45835cfd9f6f635f9d8b', '80ae86d13fa8cadba0c2a2f591b6195d17a8a872fe06ec606784261a05abb36e', 'a1fb299cbcde26ab7fa109f6bb343c6601703267736d1e64b3b541c5614fa442', '6ebc13e191e4e99f574250d6035e4f3cc10c1f3b82d4730d84f53c85b02af2a4', 'f76f745931c89a44b2fc51805cdbef9b447c692a4e04e90d7b6f47771d19d335', '9e5b6045af7acc87d108b620e5e279af9c013d59c99bdca03c5281cf761c5dba', 'd53b7fb3b70e8bb0c4de95c9a5942020e76f473261f6f6bdef53e83f0d0de715', '20bd034690d804e4bf169bff438a8f1a41479437d6895a1def3c0e387c0dbb6a', '20193a5a09bc1bb88fc1ec5c990e52c0ea14013ff7e7bbf9272bcc172594ea65', 'dee64ccce66b92ea076f0d8106dedeeb405da97f5e5dff982e0a1db4c45e921f', '287d51af8369f602cbf1e626cfda660ccaac5364ddc2a119d5f600ee489a78dc']\n",
            "\n",
            "Spin (all qubits, conceptual):\n",
            " [[[ 2.55505264e-01  8.66153657e-01 -4.29528683e-01]\n",
            "  [-1.95882514e-01  8.81552696e-01 -4.29528683e-01]]\n",
            "\n",
            " [[-1.68334335e-01 -2.62882143e-01  9.50029731e-01]\n",
            "  [-3.04513395e-01 -6.86664134e-02  9.50029731e-01]]\n",
            "\n",
            " [[-3.53777818e-02  4.85177815e-01  8.73699546e-01]\n",
            "  [-3.12511683e-01 -3.72807652e-01  8.73699546e-01]]\n",
            "\n",
            " [[ 2.10402623e-01 -7.82082230e-02  9.74481523e-01]\n",
            "  [-2.09730119e-01 -7.99941793e-02  9.74481523e-01]]\n",
            "\n",
            " [[-5.91743700e-02 -1.47252381e-01  9.87327278e-01]\n",
            "  [-2.54741218e-02  1.56639516e-01  9.87327278e-01]]\n",
            "\n",
            " [[-1.56650215e-01  8.30912054e-01 -5.33896863e-01]\n",
            "  [-5.10702729e-01 -6.73896790e-01 -5.33896863e-01]]\n",
            "\n",
            " [[ 1.66532829e-01 -3.02673668e-01 -9.38432455e-01]\n",
            "  [-1.61675379e-01  3.05295914e-01 -9.38432455e-01]]\n",
            "\n",
            " [[ 8.44319314e-02  8.74488149e-03  9.96390879e-01]\n",
            "  [-5.45856543e-02 -6.50048554e-02  9.96390879e-01]]\n",
            "\n",
            " [[-1.79778829e-01 -6.49973229e-02  9.81557369e-01]\n",
            "  [ 1.49343498e-02  1.90583423e-01  9.81557369e-01]]\n",
            "\n",
            " [[-9.23913419e-02 -9.60710585e-01 -2.61723101e-01]\n",
            "  [ 5.13864994e-01  8.16972315e-01 -2.61723101e-01]]\n",
            "\n",
            " [[ 4.90938514e-01  5.92778385e-01 -6.38430238e-01]\n",
            "  [ 7.69637167e-01  8.09052307e-03 -6.38430238e-01]]\n",
            "\n",
            " [[-5.66042006e-01  2.95432150e-01  7.69620895e-01]\n",
            "  [ 6.07099593e-01  1.97771952e-01  7.69620895e-01]]\n",
            "\n",
            " [[-1.56324759e-01  2.20280096e-01  9.62828755e-01]\n",
            "  [-2.21472129e-01  1.54631317e-01  9.62828755e-01]]\n",
            "\n",
            " [[ 1.33811489e-01  8.24959159e-01 -5.49123764e-01]\n",
            "  [-6.66578293e-01 -5.04119515e-01 -5.49123764e-01]]\n",
            "\n",
            " [[ 4.39077407e-01  8.35183620e-01  3.31178755e-01]\n",
            "  [ 8.54937509e-02  9.39686894e-01  3.31178755e-01]]\n",
            "\n",
            " [[-4.20072734e-01  9.06760395e-01 -3.63939330e-02]\n",
            "  [-8.30912113e-01  5.55212140e-01 -3.63939330e-02]]\n",
            "\n",
            " [[ 5.21702409e-01 -5.95898807e-01  6.10517144e-01]\n",
            "  [ 3.66590619e-01 -7.02054203e-01  6.10517144e-01]]\n",
            "\n",
            " [[-5.51127970e-01 -3.70749444e-01  7.47531116e-01]\n",
            "  [ 1.39957264e-01  6.49314404e-01  7.47531116e-01]]\n",
            "\n",
            " [[ 6.93115522e-04  1.62319317e-02 -9.99868035e-01]\n",
            "  [ 4.40831343e-03 -1.56372245e-02 -9.99868035e-01]]\n",
            "\n",
            " [[-1.33687198e-01  4.73974377e-01  8.70330989e-01]\n",
            "  [-9.54241529e-02 -4.83133733e-01  8.70330989e-01]]\n",
            "\n",
            " [[-6.53975010e-02  1.31916061e-01  9.89101291e-01]\n",
            "  [-6.06433265e-02  1.34168044e-01  9.89101291e-01]]\n",
            "\n",
            " [[-7.47203767e-01  6.35593116e-01 -1.94185302e-01]\n",
            "  [-9.60501552e-01  1.99321061e-01 -1.94185302e-01]]\n",
            "\n",
            " [[-8.11363980e-02  8.26813281e-01  5.56593776e-01]\n",
            "  [ 5.67179680e-01  6.07050717e-01  5.56593776e-01]]\n",
            "\n",
            " [[ 4.04201299e-01 -9.04677391e-01  1.34833843e-01]\n",
            "  [ 9.22516644e-01  3.61639142e-01  1.34833843e-01]]\n",
            "\n",
            " [[ 9.22644436e-01 -1.79434180e-01  3.41365814e-01]\n",
            "  [ 9.39520955e-01 -2.77439598e-02  3.41365814e-01]]\n",
            "\n",
            " [[ 1.05154611e-01 -7.60314226e-01 -6.40987337e-01]\n",
            "  [ 3.76620650e-01 -6.68799043e-01 -6.40987337e-01]]\n",
            "\n",
            " [[-2.01425739e-02 -8.99413168e-01 -4.36635107e-01]\n",
            "  [-3.75444582e-03 -8.99630845e-01 -4.36635107e-01]]\n",
            "\n",
            " [[-7.51823008e-01 -4.05174881e-01  5.20187914e-01]\n",
            "  [-7.89343715e-01  3.26099843e-01  5.20187914e-01]]\n",
            "\n",
            " [[-6.51908457e-01  4.12208050e-01 -6.36474550e-01]\n",
            "  [ 7.35444903e-01 -2.32423976e-01 -6.36474550e-01]]\n",
            "\n",
            " [[-4.98225242e-01 -8.66094530e-01 -4.06436622e-02]\n",
            "  [ 3.77393551e-02  9.98460710e-01 -4.06436622e-02]]\n",
            "\n",
            " [[ 9.92513359e-01 -1.21793739e-01  9.14037693e-03]\n",
            "  [ 3.56814206e-01  9.34130669e-01  9.14037693e-03]]\n",
            "\n",
            " [[-6.98343813e-01  6.50112689e-01 -2.99448609e-01]\n",
            "  [ 7.39523113e-01  6.02856636e-01 -2.99448609e-01]]\n",
            "\n",
            " [[-8.12515557e-01  2.06934482e-01 -5.44973969e-01]\n",
            "  [-8.21991026e-01  1.65330485e-01 -5.44973969e-01]]\n",
            "\n",
            " [[ 6.49616241e-01  1.93990260e-01  7.35096216e-01]\n",
            "  [-5.41498959e-01  4.07936722e-01  7.35096216e-01]]\n",
            "\n",
            " [[ 4.62662339e-01  6.27734900e-01  6.26013160e-01]\n",
            "  [ 4.59715158e-01  6.29896462e-01  6.26013160e-01]]\n",
            "\n",
            " [[ 3.31801921e-01  1.96571693e-01  9.22641337e-01]\n",
            "  [-3.85140032e-01 -2.00025924e-02  9.22641337e-01]]\n",
            "\n",
            " [[-8.82970020e-02  6.17741525e-01  7.81408370e-01]\n",
            "  [ 3.79692540e-02  6.22863770e-01  7.81408370e-01]]\n",
            "\n",
            " [[-1.60861462e-02 -3.02540977e-02 -9.99412775e-01]\n",
            "  [ 3.39738466e-02 -4.45557293e-03 -9.99412775e-01]]\n",
            "\n",
            " [[ 3.87043983e-01  3.78985256e-01  8.40575457e-01]\n",
            "  [-2.56830782e-01  4.76938993e-01  8.40575457e-01]]\n",
            "\n",
            " [[-1.55737605e-02 -3.81872952e-01 -9.24083591e-01]\n",
            "  [ 1.18141308e-01  3.63472313e-01 -9.24083591e-01]]\n",
            "\n",
            " [[ 9.22854900e-01  2.98433721e-01  2.43466884e-01]\n",
            "  [-4.38499182e-01  8.65125597e-01  2.43466884e-01]]\n",
            "\n",
            " [[ 6.83826864e-01  4.93435055e-01  5.37496626e-01]\n",
            "  [ 7.64207661e-01 -3.56488466e-01  5.37496626e-01]]\n",
            "\n",
            " [[-1.92867577e-01 -8.13834906e-01  5.48155844e-01]\n",
            "  [-5.41588187e-01 -6.37344003e-01  5.48155844e-01]]\n",
            "\n",
            " [[ 5.55810452e-01 -8.30635190e-01 -3.34643275e-02]\n",
            "  [ 4.87917550e-02  9.98248219e-01 -3.34643275e-02]]\n",
            "\n",
            " [[-1.84349149e-01  3.62367928e-01 -9.13621843e-01]\n",
            "  [ 3.19889247e-01 -2.50930279e-01 -9.13621843e-01]]\n",
            "\n",
            " [[-7.73176432e-01 -1.91071808e-01 -6.04722917e-01]\n",
            "  [ 1.36896193e-01  7.84582436e-01 -6.04722917e-01]]\n",
            "\n",
            " [[-9.00442421e-01  4.09000576e-01  1.48060754e-01]\n",
            "  [ 9.24865186e-01 -3.50289077e-01  1.48060754e-01]]\n",
            "\n",
            " [[ 4.60369647e-01  9.88914892e-02 -8.82201910e-01]\n",
            "  [ 4.69213605e-01  3.94757725e-02 -8.82201910e-01]]\n",
            "\n",
            " [[-4.51133728e-01  6.33856133e-02 -8.90202582e-01]\n",
            "  [ 9.72354263e-02 -4.45067018e-01 -8.90202582e-01]]\n",
            "\n",
            " [[ 3.30370992e-01  4.02175844e-01  8.53879154e-01]\n",
            "  [ 6.28981367e-02 -5.16656756e-01  8.53879154e-01]]\n",
            "\n",
            " [[-6.41063273e-01 -1.70682684e-01  7.48268247e-01]\n",
            "  [-1.94623575e-01  6.34205282e-01  7.48268247e-01]]\n",
            "\n",
            " [[-2.02846855e-01 -8.00083756e-01  5.64552128e-01]\n",
            "  [-7.50650406e-01 -3.43227118e-01  5.64552128e-01]]\n",
            "\n",
            " [[-1.61756088e-05  5.01905620e-01  8.64922404e-01]\n",
            "  [ 2.05816999e-01  4.57764775e-01  8.64922404e-01]]\n",
            "\n",
            " [[ 7.08731413e-02 -8.87074973e-03  9.97445881e-01]\n",
            "  [ 2.33462136e-02  6.75029382e-02  9.97445881e-01]]\n",
            "\n",
            " [[ 2.07081169e-01 -5.10408640e-01  8.34625900e-01]\n",
            "  [ 5.41679025e-01  9.99169797e-02  8.34625900e-01]]\n",
            "\n",
            " [[-1.31450146e-01  6.90559685e-01 -7.11230040e-01]\n",
            "  [ 4.47005391e-01  5.42529285e-01 -7.11230040e-01]]\n",
            "\n",
            " [[ 5.55906594e-01  6.72083944e-02  8.28523338e-01]\n",
            "  [ 4.02375996e-01  3.89413238e-01  8.28523338e-01]]\n",
            "\n",
            " [[-3.11346173e-01  2.68578798e-01  9.11553085e-01]\n",
            "  [-2.35073879e-01  3.37359250e-01  9.11553085e-01]]\n",
            "\n",
            " [[-6.27048388e-02 -9.30676997e-01  3.60428065e-01]\n",
            "  [-2.72619337e-01  8.92059565e-01  3.60428065e-01]]\n",
            "\n",
            " [[-9.81709480e-01  1.58751726e-01  1.05092138e-01]\n",
            "  [ 2.84560584e-03  9.94458437e-01  1.05092138e-01]]\n",
            "\n",
            " [[-7.46494114e-01 -6.06111646e-01  2.74545461e-01]\n",
            "  [ 9.58759129e-01  7.35236034e-02  2.74545461e-01]]\n",
            "\n",
            " [[ 7.99762249e-01  5.94795048e-01  8.12353268e-02]\n",
            "  [-6.34373724e-01 -7.68746257e-01  8.12353268e-02]]\n",
            "\n",
            " [[ 2.11610943e-01  4.07857634e-02  9.76502597e-01]\n",
            "  [ 2.14142397e-01 -2.42012553e-02  9.76502597e-01]]\n",
            "\n",
            " [[-1.60350278e-01 -4.79990765e-02  9.85892415e-01]\n",
            "  [-1.38453096e-02 -1.66806579e-01  9.85892415e-01]]]\n",
            "\n",
            "I_vec (all qubits, conceptual):\n",
            " [[0.36121222 0.13906923 0.30771425 ... 0.2333968  0.05453715 0.08343836]\n",
            " [0.3927553  0.11617208 0.43749455 ... 0.25566646 0.02216703 0.18736489]\n",
            " [0.0492227  0.27989528 0.40396297 ... 0.22605212 0.11850775 0.30459026]\n",
            " ...\n",
            " [0.234461   0.3806695  0.38816577 ... 0.14299817 0.19076751 0.3046699 ]\n",
            " [0.28057367 0.3446286  0.03832289 ... 0.2967863  0.01695627 0.3863351 ]\n",
            " [0.3703261  0.07833447 0.31471527 ... 0.25682375 0.31827345 0.09399743]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'quubit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3698916540.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[0mnecl_manifest_checksums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m     \u001b[0mqubit_trace_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mentry\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTRACE\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quubit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mq_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m     \u001b[0mmanifest_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqubit_trace_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m     \u001b[0mchecksum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanifest_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'quubit'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67a72648"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous execution failed due to a `KeyError` stemming from a typo in the `TRACE` log's key. I need to correct 'quubit' to 'qubit' in the final loop to properly access the dictionary entries and resolve the error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41471bb8",
        "outputId": "e6ebbdaa-2e44-4d68-8db9-fb19da0f9994"
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ̇| + n_|y, ̇| = n_|x+y, ̇+̇|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ̇| · n_|y, ̇| = n_|x·y, ̇·̇|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ̇| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ̇_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register.\n",
        "    A triplet block collapses if 'both high AND low values coexist' in the real\n",
        "    component within that block, or similarly for the unreal component.\n",
        "    If a triplet collapses, all 3 indices corresponding to that triplet are marked.\n",
        "    COLL(x, ̇) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for real component (should be negative).\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    def _mark_block_phase_dual(block_real, block_unreal):\n",
        "        \"\"\"\n",
        "        Helper to mark collapse within a specific block for phase-dual components.\n",
        "        block_real and block_unreal shapes: [Q, block_size]\n",
        "        \"\"\"\n",
        "        # Collapse detection for REAL component: high AND low coexistence\n",
        "        high_real = tf.cast(block_real >= tau_hi, tf.int32)\n",
        "        low_real  = tf.cast(block_real <= tau_low, tf.int32)\n",
        "        any_h_real = tf.reduce_max(high_real, axis=1, keepdims=True) # [Q,1] (1 if any element is >= tau_hi)\n",
        "        any_l_real = tf.reduce_max(low_real,  axis=1, keepdims=True)  # [Q,1] (1 if any element is <= tau_low)\n",
        "        collapse_condition_real = tf.logical_and(any_h_real > 0, any_l_real > 0) # [Q,1]\n",
        "\n",
        "        # Collapse detection for UNREAL component: high AND low coexistence\n",
        "        high_unreal = tf.cast(block_unreal >= tau_hi, tf.int32)\n",
        "        low_unreal  = tf.cast(block_unreal <= tau_low, tf.int32)\n",
        "        any_h_unreal = tf.reduce_max(high_unreal, axis=1, keepdims=True) # [Q,1]\n",
        "        any_l_unreal = tf.reduce_max(low_unreal,  axis=1, keepdims=True)  # [Q,1]\n",
        "        collapse_condition_unreal = tf.logical_and(any_h_unreal > 0, any_l_unreal > 0) # [Q,1]\n",
        "\n",
        "        # A unit collapses if collapse is detected in EITHER real OR unreal components' blocks\n",
        "        unit_collapse_flag = tf.logical_or(collapse_condition_real, collapse_condition_unreal) # [Q,1]\n",
        "        unit_collapse_flag_int = tf.cast(unit_collapse_flag, tf.int32) # [Q,1]\n",
        "\n",
        "        # Mark all elements within the block if the block-level collapse flag is true\n",
        "        # for that qubit. This marks individual selectors within the block as collapsed.\n",
        "        mark = tf.broadcast_to(unit_collapse_flag_int, tf.shape(block_real)) # [Q, block_size]\n",
        "        return mark\n",
        "\n",
        "    # Initialize a collapse mask filled with zeros\n",
        "    collapse_mask = tf.zeros(tf.shape(real_parts), dtype=tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Iterate over each triplet block and apply collapse detection\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # Extract real and unreal parts for the current triplet across all Q qubits\n",
        "        # shape [Q, 3]\n",
        "        triplet_real_block = tf.gather(real_parts, current_triplet_indices, axis=1)\n",
        "        triplet_unreal_block = tf.gather(unreal_parts, current_triplet_indices, axis=1)\n",
        "\n",
        "        # Apply collapse detection for this triplet block\n",
        "        # Returns [Q, 3] where each element is marked if the *triplet block* collapsed\n",
        "        marked_triplet_block = _mark_block_phase_dual(triplet_real_block, triplet_unreal_block) # [Q, 3]\n",
        "\n",
        "        # Construct indices for scatter_nd_max to update the global collapse_mask\n",
        "        # indices_to_update will be [Q*3, 2]\n",
        "        # First column is qubit index, second is original 30-index\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1)\n",
        "\n",
        "        # Flatten marked_triplet_block to [Q*3] for updates\n",
        "        updates = tf.reshape(marked_triplet_block, [-1])\n",
        "\n",
        "        # Use tf.tensor_scatter_nd_max to update the collapse_mask.\n",
        "        # This ensures that if any triplet marks an index as collapsed, it remains marked.\n",
        "        collapse_mask = tf.tensor_scatter_nd_max(collapse_mask, indices_to_update, updates)\n",
        "\n",
        "    return collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components. Implements ASSOC(A, B, α) logic.\n",
        "\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`).\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode(\"utf-8\")).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    for b_idx in range(10):\n",
        "        s = signs[b_idx*3:(b_idx+1)*3] # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        trip_mix.extend([has_mix]*3) # Apply this mix flag to all 3 indices of the triplet\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook for a single qubit (q_idx). This function performs a local\n",
        "    re-evaluation of the bit pattern for the current qubit if the initial derivation\n",
        "    is deemed 'inconsistent'.\n",
        "\n",
        "    This function is designed to:\n",
        "    - Advance *only* within the same triplet (or within the primaries 6-set) for local re-evaluation.\n",
        "      It uses the `pairs_q` and `triplets_q` already derived for this specific qubit `q_idx`.\n",
        "      It does not implicitly advance to other qubits or triplets; its scope is limited to the\n",
        "      current qubit's local tuplet structure.\n",
        "    - Record lineage for any local adjustments made. If a correction occurs, a specific\n",
        "      entry is added to the `TRACE` log, detailing the reason, source, metrics, and new key.\n",
        "    - *Not* advance across different units (triplets or qubits) unless the current local unit\n",
        "      has been exhausted. The `derive_bits_advanced` function, called internally,\n",
        "      operates solely on the provided `pairs_q` and `triplets_q` for the current qubit.\n",
        "\n",
        "    Args:\n",
        "        q_idx (int): The index of the current qubit being processed.\n",
        "        pairs_q (tf.Tensor): The 30-index phase-dual pair register for the current qubit [30, 2].\n",
        "        triplets_q (tf.Tensor): The 10 triplets for the current qubit [10, 3, 2].\n",
        "        current_bits_q (tf.Tensor): The initially derived 30-bit pattern for the current qubit [30].\n",
        "        resonance_key_q (str): The current resonance key string for the qubit.\n",
        "        TRACE (list): A list to append lineage information if corrections are made.\n",
        "        invariants (dict): Dictionary of invariant constants.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, str]:\n",
        "            - new_bits_q (tf.Tensor): The potentially corrected 30-bit pattern.\n",
        "            - updated_resonance_key_q (str): The updated resonance key string (with lineage if corrected).\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        # The updated key incorporates the correction lineage.\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs)\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primaries In:\n",
            " [[[ 0.0742445   0.86564183]\n",
            "  [-0.0742445  -0.86564183]\n",
            "  [-0.82527566  0.44523573]\n",
            "  [ 0.82527566 -0.44523573]\n",
            "  [ 0.3293748  -0.38157153]\n",
            "  [-0.3293748   0.38157153]]\n",
            "\n",
            " [[ 0.46982217  0.35681462]\n",
            "  [-0.46982217 -0.35681462]\n",
            "  [ 0.70410204 -0.68199396]\n",
            "  [-0.70410204  0.68199396]\n",
            "  [-0.9894619  -0.8150301 ]\n",
            "  [ 0.9894619   0.8150301 ]]\n",
            "\n",
            " [[-0.2522223   0.7746639 ]\n",
            "  [ 0.2522223  -0.7746639 ]\n",
            "  [-0.7889981  -0.938113  ]\n",
            "  [ 0.7889981   0.938113  ]\n",
            "  [-0.32451677 -0.8098786 ]\n",
            "  [ 0.32451677  0.8098786 ]]\n",
            "\n",
            " [[ 0.15753198 -0.70426416]\n",
            "  [-0.15753198  0.70426416]\n",
            "  [ 0.12965727  0.7186651 ]\n",
            "  [-0.12965727 -0.7186651 ]\n",
            "  [ 0.30446243  0.75358605]\n",
            "  [-0.30446243 -0.75358605]]\n",
            "\n",
            " [[ 0.19514418 -0.40123606]\n",
            "  [-0.19514418  0.40123606]\n",
            "  [ 0.3935175   0.02179813]\n",
            "  [-0.3935175  -0.02179813]\n",
            "  [ 0.38572145  0.9292939 ]\n",
            "  [-0.38572145 -0.9292939 ]]\n",
            "\n",
            " [[ 0.87045074  0.43117285]\n",
            "  [-0.87045074 -0.43117285]\n",
            "  [ 0.96099067  0.05321097]\n",
            "  [-0.96099067 -0.05321097]\n",
            "  [ 0.00996351 -0.38163114]\n",
            "  [-0.00996351  0.38163114]]\n",
            "\n",
            " [[ 0.8322263   0.9480374 ]\n",
            "  [-0.8322263  -0.9480374 ]\n",
            "  [ 0.3188553   0.67630506]\n",
            "  [-0.3188553  -0.67630506]\n",
            "  [-0.8794899   0.5153172 ]\n",
            "  [ 0.8794899  -0.5153172 ]]\n",
            "\n",
            " [[ 0.5581975   0.89205813]\n",
            "  [-0.5581975  -0.89205813]\n",
            "  [ 0.9780464   0.48184395]\n",
            "  [-0.9780464  -0.48184395]\n",
            "  [ 0.16588569  0.6251745 ]\n",
            "  [-0.16588569 -0.6251745 ]]\n",
            "\n",
            " [[-0.3243456   0.54601717]\n",
            "  [ 0.3243456  -0.54601717]\n",
            "  [ 0.60554314  0.24763799]\n",
            "  [-0.60554314 -0.24763799]\n",
            "  [ 0.5195372  -0.27022195]\n",
            "  [-0.5195372   0.27022195]]\n",
            "\n",
            " [[ 0.95162606 -0.75960183]\n",
            "  [-0.95162606  0.75960183]\n",
            "  [ 0.27743363 -0.4775586 ]\n",
            "  [-0.27743363  0.4775586 ]\n",
            "  [-0.77612495  0.05104876]\n",
            "  [ 0.77612495 -0.05104876]]\n",
            "\n",
            " [[-0.7046106   0.34601045]\n",
            "  [ 0.7046106  -0.34601045]\n",
            "  [ 0.5210979   0.8183863 ]\n",
            "  [-0.5210979  -0.8183863 ]\n",
            "  [-0.30848718  0.2528758 ]\n",
            "  [ 0.30848718 -0.2528758 ]]\n",
            "\n",
            " [[ 0.8796139  -0.0565629 ]\n",
            "  [-0.8796139   0.0565629 ]\n",
            "  [-0.645195    0.4763198 ]\n",
            "  [ 0.645195   -0.4763198 ]\n",
            "  [ 0.5181675  -0.96099734]\n",
            "  [-0.5181675   0.96099734]]\n",
            "\n",
            " [[ 0.9456954   0.47057486]\n",
            "  [-0.9456954  -0.47057486]\n",
            "  [ 0.34923172 -0.7016566 ]\n",
            "  [-0.34923172  0.7016566 ]\n",
            "  [ 0.18697691  0.46247196]\n",
            "  [-0.18697691 -0.46247196]]\n",
            "\n",
            " [[ 0.37855625 -0.55763507]\n",
            "  [-0.37855625  0.55763507]\n",
            "  [ 0.47675133  0.30794024]\n",
            "  [-0.47675133 -0.30794024]\n",
            "  [ 0.36586332  0.6672766 ]\n",
            "  [-0.36586332 -0.6672766 ]]\n",
            "\n",
            " [[ 0.3111515  -0.32328296]\n",
            "  [-0.3111515   0.32328296]\n",
            "  [-0.76822996 -0.94383883]\n",
            "  [ 0.76822996  0.94383883]\n",
            "  [-0.2919848  -0.39685464]\n",
            "  [ 0.2919848   0.39685464]]\n",
            "\n",
            " [[-0.5701201   0.5130844 ]\n",
            "  [ 0.5701201  -0.5130844 ]\n",
            "  [-0.35718727  0.26093197]\n",
            "  [ 0.35718727 -0.26093197]\n",
            "  [ 0.3204744  -0.15090394]\n",
            "  [-0.3204744   0.15090394]]\n",
            "\n",
            " [[ 0.8564482   0.48260117]\n",
            "  [-0.8564482  -0.48260117]\n",
            "  [ 0.70799065  0.0354774 ]\n",
            "  [-0.70799065 -0.0354774 ]\n",
            "  [ 0.55935335  0.13164902]\n",
            "  [-0.55935335 -0.13164902]]\n",
            "\n",
            " [[ 0.57540727 -0.7262013 ]\n",
            "  [-0.57540727  0.7262013 ]\n",
            "  [-0.4545548   0.92429566]\n",
            "  [ 0.4545548  -0.92429566]\n",
            "  [ 0.0924232   0.23146415]\n",
            "  [-0.0924232  -0.23146415]]\n",
            "\n",
            " [[ 0.6979718  -0.5137203 ]\n",
            "  [-0.6979718   0.5137203 ]\n",
            "  [ 0.9936657  -0.15707254]\n",
            "  [-0.9936657   0.15707254]\n",
            "  [ 0.5117004  -0.81782746]\n",
            "  [-0.5117004   0.81782746]]\n",
            "\n",
            " [[ 0.6054323  -0.0532043 ]\n",
            "  [-0.6054323   0.0532043 ]\n",
            "  [ 0.15032077  0.4867916 ]\n",
            "  [-0.15032077 -0.4867916 ]\n",
            "  [-0.43836737 -0.7533729 ]\n",
            "  [ 0.43836737  0.7533729 ]]\n",
            "\n",
            " [[-0.6741271  -0.48271084]\n",
            "  [ 0.6741271   0.48271084]\n",
            "  [-0.6552341   0.1804049 ]\n",
            "  [ 0.6552341  -0.1804049 ]\n",
            "  [ 0.8186445   0.58245444]\n",
            "  [-0.8186445  -0.58245444]]\n",
            "\n",
            " [[-0.5910115   0.65458465]\n",
            "  [ 0.5910115  -0.65458465]\n",
            "  [ 0.9646988  -0.6640091 ]\n",
            "  [-0.9646988   0.6640091 ]\n",
            "  [ 0.4399445  -0.20467973]\n",
            "  [-0.4399445   0.20467973]]\n",
            "\n",
            " [[-0.71102333 -0.7487197 ]\n",
            "  [ 0.71102333  0.7487197 ]\n",
            "  [-0.29609776  0.16322207]\n",
            "  [ 0.29609776 -0.16322207]\n",
            "  [ 0.71898365  0.09556007]\n",
            "  [-0.71898365 -0.09556007]]\n",
            "\n",
            " [[-0.00892067 -0.32147336]\n",
            "  [ 0.00892067  0.32147336]\n",
            "  [ 0.8122444  -0.19092178]\n",
            "  [-0.8122444   0.19092178]\n",
            "  [-0.39704013 -0.24720168]\n",
            "  [ 0.39704013  0.24720168]]\n",
            "\n",
            " [[ 0.5755086   0.3467903 ]\n",
            "  [-0.5755086  -0.3467903 ]\n",
            "  [ 0.75623155 -0.47183824]\n",
            "  [-0.75623155  0.47183824]\n",
            "  [ 0.5578041  -0.25747895]\n",
            "  [-0.5578041   0.25747895]]\n",
            "\n",
            " [[ 0.56792593  0.97219014]\n",
            "  [-0.56792593 -0.97219014]\n",
            "  [ 0.2537434  -0.3191576 ]\n",
            "  [-0.2537434   0.3191576 ]\n",
            "  [-0.13361049 -0.37288642]\n",
            "  [ 0.13361049  0.37288642]]\n",
            "\n",
            " [[-0.01835537  0.30754733]\n",
            "  [ 0.01835537 -0.30754733]\n",
            "  [ 0.8280492  -0.86591744]\n",
            "  [-0.8280492   0.86591744]\n",
            "  [ 0.12884426 -0.5179601 ]\n",
            "  [-0.12884426  0.5179601 ]]\n",
            "\n",
            " [[ 0.60126877 -0.40724874]\n",
            "  [-0.60126877  0.40724874]\n",
            "  [ 0.55505466 -0.63743806]\n",
            "  [-0.55505466  0.63743806]\n",
            "  [-0.8274834  -0.45487618]\n",
            "  [ 0.8274834   0.45487618]]\n",
            "\n",
            " [[-0.5084593  -0.1431408 ]\n",
            "  [ 0.5084593   0.1431408 ]\n",
            "  [-0.3833115   0.565928  ]\n",
            "  [ 0.3833115  -0.565928  ]\n",
            "  [-0.82704735 -0.4571433 ]\n",
            "  [ 0.82704735  0.4571433 ]]\n",
            "\n",
            " [[-0.5186868  -0.82373786]\n",
            "  [ 0.5186868   0.82373786]\n",
            "  [-0.9987118  -0.91264653]\n",
            "  [ 0.9987118   0.91264653]\n",
            "  [ 0.3613882  -0.12468791]\n",
            "  [-0.3613882   0.12468791]]\n",
            "\n",
            " [[-0.17718601 -0.41089678]\n",
            "  [ 0.17718601  0.41089678]\n",
            "  [-0.30881596 -0.23586607]\n",
            "  [ 0.30881596  0.23586607]\n",
            "  [-0.19829106 -0.6264541 ]\n",
            "  [ 0.19829106  0.6264541 ]]\n",
            "\n",
            " [[-0.5039418  -0.89861727]\n",
            "  [ 0.5039418   0.89861727]\n",
            "  [ 0.8209739  -0.04525137]\n",
            "  [-0.8209739   0.04525137]\n",
            "  [-0.82377553  0.19911838]\n",
            "  [ 0.82377553 -0.19911838]]\n",
            "\n",
            " [[ 0.94510865 -0.9435289 ]\n",
            "  [-0.94510865  0.9435289 ]\n",
            "  [ 0.5877671   0.7784333 ]\n",
            "  [-0.5877671  -0.7784333 ]\n",
            "  [ 0.01940155 -0.64793587]\n",
            "  [-0.01940155  0.64793587]]\n",
            "\n",
            " [[-0.68992853  0.40821743]\n",
            "  [ 0.68992853 -0.40821743]\n",
            "  [ 0.9075544   0.37391043]\n",
            "  [-0.9075544  -0.37391043]\n",
            "  [-0.89226055 -0.6959839 ]\n",
            "  [ 0.89226055  0.6959839 ]]\n",
            "\n",
            " [[-0.7771764  -0.02494049]\n",
            "  [ 0.7771764   0.02494049]\n",
            "  [ 0.6743059  -0.80595136]\n",
            "  [-0.6743059   0.80595136]\n",
            "  [ 0.37366366  0.95355654]\n",
            "  [-0.37366366 -0.95355654]]\n",
            "\n",
            " [[-0.7560873   0.45126247]\n",
            "  [ 0.7560873  -0.45126247]\n",
            "  [ 0.08472466  0.41585064]\n",
            "  [-0.08472466 -0.41585064]\n",
            "  [ 0.82322526  0.6614287 ]\n",
            "  [-0.82322526 -0.6614287 ]]\n",
            "\n",
            " [[-0.31773567 -0.90921783]\n",
            "  [ 0.31773567  0.90921783]\n",
            "  [-0.5618911  -0.3604324 ]\n",
            "  [ 0.5618911   0.3604324 ]\n",
            "  [-0.59444165  0.85931706]\n",
            "  [ 0.59444165 -0.85931706]]\n",
            "\n",
            " [[-0.85718966  0.00133848]\n",
            "  [ 0.85718966 -0.00133848]\n",
            "  [-0.62031937  0.43327403]\n",
            "  [ 0.62031937 -0.43327403]\n",
            "  [ 0.27814245  0.4552815 ]\n",
            "  [-0.27814245 -0.4552815 ]]\n",
            "\n",
            " [[-0.5825169  -0.37624598]\n",
            "  [ 0.5825169   0.37624598]\n",
            "  [ 0.6046622  -0.8565166 ]\n",
            "  [-0.6046622   0.8565166 ]\n",
            "  [-0.5680108   0.6885462 ]\n",
            "  [ 0.5680108  -0.6885462 ]]\n",
            "\n",
            " [[ 0.7029476  -0.11133909]\n",
            "  [-0.7029476   0.11133909]\n",
            "  [ 0.2668314  -0.49848938]\n",
            "  [-0.2668314   0.49848938]\n",
            "  [ 0.06055784  0.07908869]\n",
            "  [-0.06055784 -0.07908869]]\n",
            "\n",
            " [[ 0.05221105  0.08373451]\n",
            "  [-0.05221105 -0.08373451]\n",
            "  [ 0.41819024 -0.5580702 ]\n",
            "  [-0.41819024  0.5580702 ]\n",
            "  [-0.9140961  -0.6685643 ]\n",
            "  [ 0.9140961   0.6685643 ]]\n",
            "\n",
            " [[-0.47784257 -0.06012416]\n",
            "  [ 0.47784257  0.06012416]\n",
            "  [-0.07612729 -0.8462336 ]\n",
            "  [ 0.07612729  0.8462336 ]\n",
            "  [ 0.4668579  -0.6798413 ]\n",
            "  [-0.4668579   0.6798413 ]]\n",
            "\n",
            " [[-0.10674119 -0.00875235]\n",
            "  [ 0.10674119  0.00875235]\n",
            "  [ 0.530061    0.9133184 ]\n",
            "  [-0.530061   -0.9133184 ]\n",
            "  [ 0.9839816  -0.17074776]\n",
            "  [-0.9839816   0.17074776]]\n",
            "\n",
            " [[ 0.6245127   0.7423122 ]\n",
            "  [-0.6245127  -0.7423122 ]\n",
            "  [-0.05434418 -0.3808    ]\n",
            "  [ 0.05434418  0.3808    ]\n",
            "  [-0.6468134   0.8372061 ]\n",
            "  [ 0.6468134  -0.8372061 ]]\n",
            "\n",
            " [[-0.42307425  0.07870603]\n",
            "  [ 0.42307425 -0.07870603]\n",
            "  [ 0.7760973   0.8688729 ]\n",
            "  [-0.7760973  -0.8688729 ]\n",
            "  [ 0.79656625 -0.08411694]\n",
            "  [-0.79656625  0.08411694]]\n",
            "\n",
            " [[-0.40290022  0.6178038 ]\n",
            "  [ 0.40290022 -0.6178038 ]\n",
            "  [-0.19282031  0.54487514]\n",
            "  [ 0.19282031 -0.54487514]\n",
            "  [-0.29875422 -0.85123014]\n",
            "  [ 0.29875422  0.85123014]]\n",
            "\n",
            " [[-0.92590284 -0.4839456 ]\n",
            "  [ 0.92590284  0.4839456 ]\n",
            "  [ 0.50719285 -0.8282542 ]\n",
            "  [-0.50719285  0.8282542 ]\n",
            "  [ 0.3529427  -0.3566568 ]\n",
            "  [-0.3529427   0.3566568 ]]\n",
            "\n",
            " [[ 0.5262909  -0.27879238]\n",
            "  [-0.5262909   0.27879238]\n",
            "  [ 0.9626317  -0.90307975]\n",
            "  [-0.9626317   0.90307975]\n",
            "  [-0.92669463  0.5613301 ]\n",
            "  [ 0.92669463 -0.5613301 ]]\n",
            "\n",
            " [[-0.4336095  -0.20369005]\n",
            "  [ 0.4336095   0.20369005]\n",
            "  [ 0.6340039  -0.05810714]\n",
            "  [-0.6340039   0.05810714]\n",
            "  [ 0.5717256   0.74049854]\n",
            "  [-0.5717256  -0.74049854]]\n",
            "\n",
            " [[-0.89170337  0.7322793 ]\n",
            "  [ 0.89170337 -0.7322793 ]\n",
            "  [-0.79478765  0.6245003 ]\n",
            "  [ 0.79478765 -0.6245003 ]\n",
            "  [ 0.21304965 -0.3805387 ]\n",
            "  [-0.21304965  0.3805387 ]]\n",
            "\n",
            " [[-0.82503605  0.4873023 ]\n",
            "  [ 0.82503605 -0.4873023 ]\n",
            "  [-0.5764456   0.15389967]\n",
            "  [ 0.5764456  -0.15389967]\n",
            "  [ 0.4416542  -0.95513535]\n",
            "  [-0.4416542   0.95513535]]\n",
            "\n",
            " [[ 0.6249764   0.74798393]\n",
            "  [-0.6249764  -0.74798393]\n",
            "  [ 0.42277575 -0.66787815]\n",
            "  [-0.42277575  0.66787815]\n",
            "  [ 0.8675828   0.22677064]\n",
            "  [-0.8675828  -0.22677064]]\n",
            "\n",
            " [[-0.24343085 -0.08336282]\n",
            "  [ 0.24343085  0.08336282]\n",
            "  [ 0.28386474  0.95786905]\n",
            "  [-0.28386474 -0.95786905]\n",
            "  [-0.0659771  -0.12586117]\n",
            "  [ 0.0659771   0.12586117]]\n",
            "\n",
            " [[-0.6779077   0.08304071]\n",
            "  [ 0.6779077  -0.08304071]\n",
            "  [-0.19928932 -0.6470239 ]\n",
            "  [ 0.19928932  0.6470239 ]\n",
            "  [ 0.9933157   0.39942813]\n",
            "  [-0.9933157  -0.39942813]]\n",
            "\n",
            " [[ 0.09972143 -0.10321784]\n",
            "  [-0.09972143  0.10321784]\n",
            "  [ 0.8329959   0.29194188]\n",
            "  [-0.8329959  -0.29194188]\n",
            "  [ 0.27608252  0.23406792]\n",
            "  [-0.27608252 -0.23406792]]\n",
            "\n",
            " [[-0.9525676   0.7062931 ]\n",
            "  [ 0.9525676  -0.7062931 ]\n",
            "  [-0.66239214 -0.54970837]\n",
            "  [ 0.66239214  0.54970837]\n",
            "  [-0.18697977  0.3821652 ]\n",
            "  [ 0.18697977 -0.3821652 ]]\n",
            "\n",
            " [[-0.40252256 -0.6499884 ]\n",
            "  [ 0.40252256  0.6499884 ]\n",
            "  [ 0.00164604  0.66503024]\n",
            "  [-0.00164604 -0.66503024]\n",
            "  [ 0.54901433 -0.81034446]\n",
            "  [-0.54901433  0.81034446]]\n",
            "\n",
            " [[ 0.63879395  0.22362137]\n",
            "  [-0.63879395 -0.22362137]\n",
            "  [-0.47042537  0.6570301 ]\n",
            "  [ 0.47042537 -0.6570301 ]\n",
            "  [-0.9963689   0.34048963]\n",
            "  [ 0.9963689  -0.34048963]]\n",
            "\n",
            " [[ 0.75430346 -0.47710776]\n",
            "  [-0.75430346  0.47710776]\n",
            "  [-0.21772552  0.04393697]\n",
            "  [ 0.21772552 -0.04393697]\n",
            "  [ 0.91149163  0.11731052]\n",
            "  [-0.91149163 -0.11731052]]\n",
            "\n",
            " [[-0.42039514 -0.7936404 ]\n",
            "  [ 0.42039514  0.7936404 ]\n",
            "  [-0.02963781  0.75345707]\n",
            "  [ 0.02963781 -0.75345707]\n",
            "  [ 0.8856044   0.5795405 ]\n",
            "  [-0.8856044  -0.5795405 ]]\n",
            "\n",
            " [[-0.22540045  0.6522751 ]\n",
            "  [ 0.22540045 -0.6522751 ]\n",
            "  [ 0.19659019 -0.32199335]\n",
            "  [-0.19659019  0.32199335]\n",
            "  [ 0.97142243  0.8965812 ]\n",
            "  [-0.97142243 -0.8965812 ]]\n",
            "\n",
            " [[-0.78866553  0.24466157]\n",
            "  [ 0.78866553 -0.24466157]\n",
            "  [-0.8598006  -0.19828486]\n",
            "  [ 0.8598006   0.19828486]\n",
            "  [ 0.90521216 -0.17367649]\n",
            "  [-0.90521216  0.17367649]]\n",
            "\n",
            " [[-0.74637103 -0.89504004]\n",
            "  [ 0.74637103  0.89504004]\n",
            "  [ 0.92012334  0.5346494 ]\n",
            "  [-0.92012334 -0.5346494 ]\n",
            "  [-0.6411598  -0.32718635]\n",
            "  [ 0.6411598   0.32718635]]\n",
            "\n",
            " [[ 0.40887308 -0.3609364 ]\n",
            "  [-0.40887308  0.3609364 ]\n",
            "  [ 0.01765084 -0.8133795 ]\n",
            "  [-0.01765084  0.8133795 ]\n",
            "  [ 0.9924202   0.9562483 ]\n",
            "  [-0.9924202  -0.9562483 ]]]\n",
            "\n",
            "Primaries After NECL:\n",
            " [[[ 1.68468431e-02  1.38892069e-01]\n",
            "  [-1.68468431e-02 -1.38892069e-01]\n",
            "  [ 1.87155694e-01 -7.13968500e-02]\n",
            "  [-1.87155694e-01  7.13968500e-02]\n",
            "  [ 7.47693777e-02 -6.12483434e-02]\n",
            "  [ 7.47693777e-02 -6.12483434e-02]]\n",
            "\n",
            " [[ 8.64011869e-02  4.63995636e-02]\n",
            "  [-8.64011869e-02 -4.63995636e-02]\n",
            "  [-1.29413143e-01  8.86356235e-02]\n",
            "  [ 1.29413143e-01 -8.86356235e-02]\n",
            "  [-1.81769177e-01 -1.05871670e-01]\n",
            "  [-1.81769177e-01 -1.05871670e-01]]\n",
            "\n",
            " [[-4.54107448e-02  9.86219198e-02]\n",
            "  [ 4.54107448e-02 -9.86219198e-02]\n",
            "  [ 1.41949117e-01  1.19342968e-01]\n",
            "  [-1.41949117e-01 -1.19342968e-01]\n",
            "  [-5.84212951e-02 -1.03095315e-01]\n",
            "  [-5.84212951e-02 -1.03095315e-01]]\n",
            "\n",
            " [[ 3.64767723e-02 -1.15310334e-01]\n",
            "  [-3.64767723e-02  1.15310334e-01]\n",
            "  [-3.00221965e-02 -1.17667668e-01]\n",
            "  [ 3.00221965e-02  1.17667668e-01]\n",
            "  [ 7.04845339e-02  1.23361014e-01]\n",
            "  [ 7.04845339e-02  1.23361014e-01]]\n",
            "\n",
            " [[ 5.54332137e-02 -8.05933848e-02]\n",
            "  [-5.54332137e-02  8.05933848e-02]\n",
            "  [-1.11768737e-01 -4.37784707e-03]\n",
            "  [ 1.11768737e-01  4.37784707e-03]\n",
            "  [ 1.09445490e-01  1.86449900e-01]\n",
            "  [ 1.09445490e-01  1.86449900e-01]]\n",
            "\n",
            " [[ 1.96957976e-01  6.89867660e-02]\n",
            "  [-1.96957976e-01 -6.89867660e-02]\n",
            "  [-2.17426091e-01 -8.51292256e-03]\n",
            "  [ 2.17426091e-01  8.51292256e-03]\n",
            "  [ 2.25763000e-03 -6.11461475e-02]\n",
            "  [ 2.25763000e-03 -6.11461475e-02]]\n",
            "\n",
            " [[ 1.44013107e-01  1.16003476e-01]\n",
            "  [-1.44013107e-01 -1.16003476e-01]\n",
            "  [-5.52214533e-02 -8.28212574e-02]\n",
            "  [ 5.52214533e-02  8.28212574e-02]\n",
            "  [-1.52221128e-01  6.30672276e-02]\n",
            "  [-1.52221128e-01  6.30672276e-02]]\n",
            "\n",
            " [[ 1.04900829e-01  1.18541166e-01]\n",
            "  [-1.04900829e-01 -1.18541166e-01]\n",
            "  [-1.83738515e-01 -6.40076920e-02]\n",
            "  [ 1.83738515e-01  6.40076920e-02]\n",
            "  [ 3.11951973e-02  8.31313953e-02]\n",
            "  [ 3.11951973e-02  8.31313953e-02]]\n",
            "\n",
            " [[-9.06987041e-02  1.07965343e-01]\n",
            "  [ 9.06987041e-02 -1.07965343e-01]\n",
            "  [-1.69274807e-01 -4.89496402e-02]\n",
            "  [ 1.69274807e-01  4.89496402e-02]\n",
            "  [ 1.45262226e-01 -5.34246452e-02]\n",
            "  [ 1.45262226e-01 -5.34246452e-02]]\n",
            "\n",
            " [[ 1.95679113e-01 -1.10445790e-01]\n",
            "  [-1.95679113e-01  1.10445790e-01]\n",
            "  [-5.71209379e-02  6.95260987e-02]\n",
            "  [ 5.71209379e-02 -6.95260987e-02]\n",
            "  [-1.59690261e-01  7.42706098e-03]\n",
            "  [-1.59690261e-01  7.42706098e-03]]\n",
            "\n",
            " [[-1.71433657e-01  5.95279783e-02]\n",
            "  [ 1.71433657e-01 -5.95279783e-02]\n",
            "  [-1.26774862e-01 -1.40785247e-01]\n",
            "  [ 1.26774862e-01  1.40785247e-01]\n",
            "  [-7.51235262e-02  4.35442775e-02]\n",
            "  [-7.51235262e-02  4.35442775e-02]]\n",
            "\n",
            " [[ 1.66138157e-01 -7.55429501e-03]\n",
            "  [-1.66138157e-01  7.55429501e-03]\n",
            "  [ 1.21895477e-01 -6.36326820e-02]\n",
            "  [-1.21895477e-01  6.36326820e-02]\n",
            "  [ 9.78740901e-02 -1.28352627e-01]\n",
            "  [ 9.78740901e-02 -1.28352627e-01]]\n",
            "\n",
            " [[ 2.11820349e-01  7.45298341e-02]\n",
            "  [-2.11820349e-01 -7.45298341e-02]\n",
            "  [-7.82883093e-02  1.11222543e-01]\n",
            "  [ 7.82883093e-02 -1.11222543e-01]\n",
            "  [ 4.19357643e-02  7.33444020e-02]\n",
            "  [ 4.19357643e-02  7.33444020e-02]]\n",
            "\n",
            " [[ 9.91096720e-02 -1.03233516e-01]\n",
            "  [-9.91096720e-02  1.03233516e-01]\n",
            "  [-1.24825090e-01 -5.70113622e-02]\n",
            "  [ 1.24825090e-01  5.70113622e-02]\n",
            "  [ 9.57745016e-02  1.23515636e-01]\n",
            "  [ 9.57745016e-02  1.23515636e-01]]\n",
            "\n",
            " [[ 7.56170079e-02 -5.55540062e-02]\n",
            "  [-7.56170079e-02  5.55540062e-02]\n",
            "  [ 1.86425135e-01  1.61955625e-01]\n",
            "  [-1.86425135e-01 -1.61955625e-01]\n",
            "  [-7.09559545e-02 -6.81938231e-02]\n",
            "  [-7.09559545e-02 -6.81938231e-02]]\n",
            "\n",
            " [[-1.91016167e-01  1.21556342e-01]\n",
            "  [ 1.91016167e-01 -1.21556342e-01]\n",
            "  [ 1.19778626e-01 -6.18722029e-02]\n",
            "  [-1.19778626e-01  6.18722029e-02]\n",
            "  [ 1.07489437e-01 -3.57896946e-02]\n",
            "  [ 1.07489437e-01 -3.57896946e-02]]\n",
            "\n",
            " [[ 1.97973758e-01  7.88823664e-02]\n",
            "  [-1.97973758e-01 -7.88823664e-02]\n",
            "  [-1.63733751e-01 -5.80159575e-03]\n",
            "  [ 1.63733751e-01  5.80159575e-03]\n",
            "  [ 1.29399389e-01  2.15351861e-02]\n",
            "  [ 1.29399389e-01  2.15351861e-02]]\n",
            "\n",
            " [[ 1.36713833e-01 -1.22005403e-01]\n",
            "  [-1.36713833e-01  1.22005403e-01]\n",
            "  [ 1.07993811e-01 -1.55277506e-01]\n",
            "  [-1.07993811e-01  1.55277506e-01]\n",
            "  [ 2.19883006e-02  3.89385149e-02]\n",
            "  [ 2.19883006e-02  3.89385149e-02]]\n",
            "\n",
            " [[ 1.28967449e-01 -6.71203062e-02]\n",
            "  [-1.28967449e-01  6.71203062e-02]\n",
            "  [-1.83535352e-01  2.05146782e-02]\n",
            "  [ 1.83535352e-01 -2.05146782e-02]\n",
            "  [ 9.45516452e-02 -1.06856287e-01]\n",
            "  [ 9.45516452e-02 -1.06856287e-01]]\n",
            "\n",
            " [[ 1.59572184e-01 -9.91569925e-03]\n",
            "  [-1.59572184e-01  9.91569925e-03]\n",
            "  [-3.96426357e-02 -9.07761231e-02]\n",
            "  [ 3.96426357e-02  9.07761231e-02]\n",
            "  [-1.15515187e-01 -1.40376970e-01]\n",
            "  [-1.15515187e-01 -1.40376970e-01]]\n",
            "\n",
            " [[-1.40597716e-01 -7.11882859e-02]\n",
            "  [ 1.40597716e-01  7.11882859e-02]\n",
            "  [ 1.36681259e-01 -2.66100597e-02]\n",
            "  [-1.36681259e-01  2.66100597e-02]\n",
            "  [ 1.70684129e-01  8.58706459e-02]\n",
            "  [ 1.70684129e-01  8.58706459e-02]]\n",
            "\n",
            " [[-1.22060366e-01  9.55937579e-02]\n",
            "  [ 1.22060366e-01 -9.55937579e-02]\n",
            "  [-1.99111030e-01  9.69086736e-02]\n",
            "  [ 1.99111030e-01 -9.69086736e-02]\n",
            "  [ 9.09122378e-02 -2.99077872e-02]\n",
            "  [ 9.09122378e-02 -2.99077872e-02]]\n",
            "\n",
            " [[-1.77723408e-01 -1.32332057e-01]\n",
            "  [ 1.77723408e-01  1.32332057e-01]\n",
            "  [ 7.41112605e-02 -2.88877022e-02]\n",
            "  [-7.41112605e-02  2.88877022e-02]\n",
            "  [ 1.79783449e-01  1.68963224e-02]\n",
            "  [ 1.79783449e-01  1.68963224e-02]]\n",
            "\n",
            " [[-2.88237585e-03 -7.34485388e-02]\n",
            "  [ 2.88237585e-03  7.34485388e-02]\n",
            "  [-2.61965632e-01  4.35409620e-02]\n",
            "  [ 2.61965632e-01 -4.35409620e-02]\n",
            "  [-1.28207073e-01 -5.64435087e-02]\n",
            "  [-1.28207073e-01 -5.64435087e-02]]\n",
            "\n",
            " [[ 1.38548598e-01  5.90340123e-02]\n",
            "  [-1.38548598e-01 -5.90340123e-02]\n",
            "  [-1.81972206e-01  8.02838877e-02]\n",
            "  [ 1.81972206e-01 -8.02838877e-02]\n",
            "  [ 1.34298339e-01 -4.38344628e-02]\n",
            "  [ 1.34298339e-01 -4.38344628e-02]]\n",
            "\n",
            " [[ 1.54151082e-01  1.86591163e-01]\n",
            "  [-1.54151082e-01 -1.86591163e-01]\n",
            "  [-6.89715520e-02  6.13430552e-02]\n",
            "  [ 6.89715520e-02 -6.13430552e-02]\n",
            "  [-3.63216177e-02 -7.16780499e-02]\n",
            "  [-3.63216177e-02 -7.16780499e-02]]\n",
            "\n",
            " [[-4.72138822e-03  5.59375621e-02]\n",
            "  [ 4.72138822e-03 -5.59375621e-02]\n",
            "  [-2.12569088e-01  1.57182962e-01]\n",
            "  [ 2.12569088e-01 -1.57182962e-01]\n",
            "  [ 3.31276618e-02 -9.41687971e-02]\n",
            "  [ 3.31276618e-02 -9.41687971e-02]]\n",
            "\n",
            " [[ 1.25312209e-01 -6.00163378e-02]\n",
            "  [-1.25312209e-01  6.00163378e-02]\n",
            "  [-1.15669489e-01  9.39303786e-02]\n",
            "  [ 1.15669489e-01 -9.39303786e-02]\n",
            "  [-1.72382608e-01 -6.70057982e-02]\n",
            "  [-1.72382608e-01 -6.70057982e-02]]\n",
            "\n",
            " [[-1.23622887e-01 -2.46088337e-02]\n",
            "  [ 1.23622887e-01  2.46088337e-02]\n",
            "  [ 9.31876972e-02 -9.72865596e-02]\n",
            "  [-9.31876972e-02  9.72865596e-02]\n",
            "  [-2.00909987e-01 -7.85251036e-02]\n",
            "  [-2.00909987e-01 -7.85251036e-02]]\n",
            "\n",
            " [[-1.00389689e-01 -1.12734780e-01]\n",
            "  [ 1.00389689e-01  1.12734780e-01]\n",
            "  [ 1.93150893e-01  1.24808475e-01]\n",
            "  [-1.93150893e-01 -1.24808475e-01]\n",
            "  [ 6.99978322e-02 -1.70773286e-02]\n",
            "  [ 6.99978322e-02 -1.70773286e-02]]\n",
            "\n",
            " [[-6.22288026e-02 -1.02042191e-01]\n",
            "  [ 6.22288026e-02  1.02042191e-01]\n",
            "  [ 1.08454183e-01  5.85729368e-02]\n",
            "  [-1.08454183e-01 -5.85729368e-02]\n",
            "  [-6.96072727e-02 -1.55498311e-01]\n",
            "  [-6.96072727e-02 -1.55498311e-01]]\n",
            "\n",
            " [[-9.78418663e-02 -1.23368464e-01]\n",
            "  [ 9.78418663e-02  1.23368464e-01]\n",
            "  [-1.59391508e-01  6.21230248e-03]\n",
            "  [ 1.59391508e-01 -6.21230248e-03]\n",
            "  [-1.59931287e-01  2.73351129e-02]\n",
            "  [-1.59931287e-01  2.73351129e-02]]\n",
            "\n",
            " [[ 1.67352468e-01 -1.18138261e-01]\n",
            "  [-1.67352468e-01  1.18138261e-01]\n",
            "  [-1.04138970e-01 -9.75246578e-02]\n",
            "  [ 1.04138970e-01  9.75246578e-02]\n",
            "  [ 3.43952561e-03 -8.12230259e-02]\n",
            "  [ 3.43952561e-03 -8.12230259e-02]]\n",
            "\n",
            " [[-1.24106824e-01  5.19239977e-02]\n",
            "  [ 1.24106824e-01 -5.19239977e-02]\n",
            "  [-1.63198963e-01 -4.75441776e-02]\n",
            "  [ 1.63198963e-01  4.75441776e-02]\n",
            "  [-1.60428524e-01 -8.84858966e-02]\n",
            "  [-1.60428524e-01 -8.84858966e-02]]\n",
            "\n",
            " [[-1.42840773e-01 -3.24132526e-03]\n",
            "  [ 1.42840773e-01  3.24132526e-03]\n",
            "  [-1.23910867e-01  1.04723997e-01]\n",
            "  [ 1.23910867e-01 -1.04723997e-01]\n",
            "  [ 6.86781183e-02  1.23927861e-01]\n",
            "  [ 6.86781183e-02  1.23927861e-01]]\n",
            "\n",
            " [[-1.67839199e-01  7.08330050e-02]\n",
            "  [ 1.67839199e-01 -7.08330050e-02]\n",
            "  [-1.88279971e-02 -6.53456375e-02]\n",
            "  [ 1.88279971e-02  6.53456375e-02]\n",
            "  [ 1.82694003e-01  1.03794336e-01]\n",
            "  [ 1.82694003e-01  1.03794336e-01]]\n",
            "\n",
            " [[-6.22623451e-02 -1.25983149e-01]\n",
            "  [ 6.22623451e-02  1.25983149e-01]\n",
            "  [ 1.10126756e-01  4.99516092e-02]\n",
            "  [-1.10126756e-01 -4.99516092e-02]\n",
            "  [-1.16455786e-01  1.19039267e-01]\n",
            "  [-1.16455786e-01  1.19039267e-01]]\n",
            "\n",
            " [[-2.09153220e-01  2.30932535e-04]\n",
            "  [ 2.09153220e-01 -2.30932535e-04]\n",
            "  [ 1.51415363e-01 -7.47828856e-02]\n",
            "  [-1.51415363e-01  7.47828856e-02]\n",
            "  [ 6.79345727e-02  7.86300525e-02]\n",
            "  [ 6.79345727e-02  7.86300525e-02]]\n",
            "\n",
            " [[-1.15942150e-01 -5.29528931e-02]\n",
            "  [ 1.15942150e-01  5.29528931e-02]\n",
            "  [-1.20300755e-01  1.20497033e-01]\n",
            "  [ 1.20300755e-01 -1.20497033e-01]\n",
            "  [-1.13031834e-01  9.68862697e-02]\n",
            "  [-1.13031834e-01  9.68862697e-02]]\n",
            "\n",
            " [[ 2.67373383e-01 -2.99452450e-02]\n",
            "  [-2.67373383e-01  2.99452450e-02]\n",
            "  [-1.01589695e-01  1.34200335e-01]\n",
            "  [ 1.01589695e-01 -1.34200335e-01]\n",
            "  [ 2.30860636e-02  2.13195905e-02]\n",
            "  [ 2.30860636e-02  2.13195905e-02]]\n",
            "\n",
            " [[ 1.42102810e-02  1.61149781e-02]\n",
            "  [-1.42102810e-02 -1.61149781e-02]\n",
            "  [-1.13672681e-01  1.07264489e-01]\n",
            "  [ 1.13672681e-01 -1.07264489e-01]\n",
            "  [-2.48178288e-01 -1.28351256e-01]\n",
            "  [-2.48178288e-01 -1.28351256e-01]]\n",
            "\n",
            " [[-1.16230182e-01 -1.03411321e-02]\n",
            "  [ 1.16230182e-01  1.03411321e-02]\n",
            "  [ 1.85118690e-02  1.45507410e-01]\n",
            "  [-1.85118690e-02 -1.45507410e-01]\n",
            "  [ 1.13508217e-01 -1.16878629e-01]\n",
            "  [ 1.13508217e-01 -1.16878629e-01]]\n",
            "\n",
            " [[-2.59163119e-02 -1.50262518e-03]\n",
            "  [ 2.59163119e-02  1.50262518e-03]\n",
            "  [-1.28480121e-01 -1.56537116e-01]\n",
            "  [ 1.28480121e-01  1.56537116e-01]\n",
            "  [ 2.38418967e-01 -2.92545762e-02]\n",
            "  [ 2.38418967e-01 -2.92545762e-02]]\n",
            "\n",
            " [[ 1.35664046e-01  1.14023685e-01]\n",
            "  [-1.35664046e-01 -1.14023685e-01]\n",
            "  [ 1.18185161e-02  5.85587621e-02]\n",
            "  [-1.18185161e-02 -5.85587621e-02]\n",
            "  [-1.40490726e-01  1.28583729e-01]\n",
            "  [-1.40490726e-01  1.28583729e-01]]\n",
            "\n",
            " [[-9.26061198e-02  1.21819284e-02]\n",
            "  [ 9.26061198e-02 -1.21819284e-02]\n",
            "  [-1.69679642e-01 -1.34324372e-01]\n",
            "  [ 1.69679642e-01  1.34324372e-01]\n",
            "  [ 1.74224123e-01 -1.30093284e-02]\n",
            "  [ 1.74224123e-01 -1.30093284e-02]]\n",
            "\n",
            " [[-9.52519774e-02  1.03279024e-01]\n",
            "  [ 9.52519774e-02 -1.03279024e-01]\n",
            "  [ 4.56025563e-02 -9.11209732e-02]\n",
            "  [-4.56025563e-02  9.11209732e-02]\n",
            "  [-7.06178695e-02 -1.42276287e-01]\n",
            "  [-7.06178695e-02 -1.42276287e-01]]\n",
            "\n",
            " [[-1.92692682e-01 -7.12166205e-02]\n",
            "  [ 1.92692682e-01  7.12166205e-02]\n",
            "  [-1.05598003e-01  1.21935800e-01]\n",
            "  [ 1.05598003e-01 -1.21935800e-01]\n",
            "  [ 7.35327080e-02 -5.25426343e-02]\n",
            "  [ 7.35327080e-02 -5.25426343e-02]]\n",
            "\n",
            " [[ 9.20469537e-02 -3.44785899e-02]\n",
            "  [-9.20469537e-02  3.44785899e-02]\n",
            "  [-1.68195695e-01  1.11574724e-01]\n",
            "  [ 1.68195695e-01 -1.11574724e-01]\n",
            "  [-1.61956221e-01  6.93688169e-02]\n",
            "  [-1.61956221e-01  6.93688169e-02]]\n",
            "\n",
            " [[-1.10854872e-01 -3.68222892e-02]\n",
            "  [ 1.10854872e-01  3.68222892e-02]\n",
            "  [-1.62016526e-01  1.04998201e-02]\n",
            "  [ 1.62016526e-01 -1.04998201e-02]\n",
            "  [ 1.46051884e-01  1.33760765e-01]\n",
            "  [ 1.46051884e-01  1.33760765e-01]]\n",
            "\n",
            " [[-1.79647133e-01  1.04318567e-01]\n",
            "  [ 1.79647133e-01 -1.04318567e-01]\n",
            "  [ 1.60159454e-01 -8.89854655e-02]\n",
            "  [-1.60159454e-01  8.89854655e-02]\n",
            "  [ 4.29788008e-02 -5.42821810e-02]\n",
            "  [ 4.29788008e-02 -5.42821810e-02]]\n",
            "\n",
            " [[-1.65853187e-01  6.92682639e-02]\n",
            "  [ 1.65853187e-01 -6.92682639e-02]\n",
            "  [ 1.15948439e-01 -2.18891688e-02]\n",
            "  [-1.15948439e-01  2.18891688e-02]\n",
            "  [ 8.87985155e-02 -1.35791704e-01]\n",
            "  [ 8.87985155e-02 -1.35791704e-01]]\n",
            "\n",
            " [[ 1.23073645e-01  1.04154661e-01]\n",
            "  [-1.23073645e-01 -1.04154661e-01]\n",
            "  [-8.32841024e-02  9.30324122e-02]\n",
            "  [ 8.32841024e-02 -9.30324122e-02]\n",
            "  [ 1.70828640e-01  3.15734148e-02]\n",
            "  [ 1.70828640e-01  3.15734148e-02]]\n",
            "\n",
            " [[-9.13052782e-02 -2.21094340e-02]\n",
            "  [ 9.13052782e-02  2.21094340e-02]\n",
            "  [-1.06287360e-01 -2.53607064e-01]\n",
            "  [ 1.06287360e-01  2.53607064e-01]\n",
            "  [-2.47588344e-02 -3.33974883e-02]\n",
            "  [-2.47588344e-02 -3.33974883e-02]]\n",
            "\n",
            " [[-1.46220013e-01  1.26652075e-02]\n",
            "  [ 1.46220013e-01 -1.26652075e-02]\n",
            "  [ 4.30013537e-02  9.87196118e-02]\n",
            "  [-4.30013537e-02 -9.87196118e-02]\n",
            "  [ 2.14096427e-01  6.08759522e-02]\n",
            "  [ 2.14096427e-01  6.08759522e-02]]\n",
            "\n",
            " [[ 3.76980677e-02 -2.75911856e-02]\n",
            "  [-3.76980677e-02  2.75911856e-02]\n",
            "  [-3.14069927e-01 -7.78331980e-02]\n",
            "  [ 3.14069927e-01  7.78331980e-02]\n",
            "  [ 1.04294047e-01  6.25241101e-02]\n",
            "  [ 1.04294047e-01  6.25241101e-02]]\n",
            "\n",
            " [[-2.01859072e-01  1.05833322e-01]\n",
            "  [ 2.01859072e-01 -1.05833322e-01]\n",
            "  [ 1.40455022e-01  8.24212953e-02]\n",
            "  [-1.40455022e-01 -8.24212953e-02]\n",
            "  [-3.96828018e-02  5.73513731e-02]\n",
            "  [-3.96828018e-02  5.73513731e-02]]\n",
            "\n",
            " [[-8.76343548e-02 -1.00063287e-01]\n",
            "  [ 8.76343548e-02  1.00063287e-01]\n",
            "  [-3.58469086e-04 -1.02408789e-01]\n",
            "  [ 3.58469086e-04  1.02408789e-01]\n",
            "  [ 1.19482264e-01 -1.24702297e-01]\n",
            "  [ 1.19482264e-01 -1.24702297e-01]]\n",
            "\n",
            " [[ 1.31976336e-01  3.26688290e-02]\n",
            "  [-1.31976336e-01 -3.26688290e-02]\n",
            "  [ 9.71904024e-02 -9.59849060e-02]\n",
            "  [-9.71904024e-02  9.59849060e-02]\n",
            "  [-2.05703631e-01  4.97062169e-02]\n",
            "  [-2.05703631e-01  4.97062169e-02]]\n",
            "\n",
            " [[ 1.94333330e-01 -8.69165808e-02]\n",
            "  [-1.94333330e-01  8.69165808e-02]\n",
            "  [ 5.61768152e-02 -8.01609550e-03]\n",
            "  [-5.61768152e-02  8.01609550e-03]\n",
            "  [ 2.34778896e-01  2.13662535e-02]\n",
            "  [ 2.34778896e-01  2.13662535e-02]]\n",
            "\n",
            " [[-8.13208967e-02 -1.08555853e-01]\n",
            "  [ 8.13208967e-02  1.08555853e-01]\n",
            "  [ 5.73488558e-03 -1.03091314e-01]\n",
            "  [-5.73488558e-03  1.03091314e-01]\n",
            "  [ 1.71223968e-01  7.92307109e-02]\n",
            "  [ 1.71223968e-01  7.92307109e-02]]\n",
            "\n",
            " [[-4.94735278e-02  1.01235740e-01]\n",
            "  [ 4.94735278e-02 -1.01235740e-01]\n",
            "  [-4.31690961e-02  4.99968901e-02]\n",
            "  [ 4.31690961e-02 -4.99968901e-02]\n",
            "  [ 2.12931350e-01  1.38965204e-01]\n",
            "  [ 2.12931350e-01  1.38965204e-01]]\n",
            "\n",
            " [[-1.57201782e-01  3.44838202e-02]\n",
            "  [ 1.57201782e-01 -3.44838202e-02]\n",
            "  [ 1.71360120e-01  2.79438738e-02]\n",
            "  [-1.71360120e-01 -2.79438738e-02]\n",
            "  [ 1.80396274e-01 -2.44739018e-02]\n",
            "  [ 1.80396274e-01 -2.44739018e-02]]\n",
            "\n",
            " [[-1.32635698e-01 -1.12469077e-01]\n",
            "  [ 1.32635698e-01  1.12469077e-01]\n",
            "  [-1.63508326e-01 -6.71812147e-02]\n",
            "  [ 1.63508326e-01  6.71812147e-02]\n",
            "  [-1.13996170e-01 -4.11343090e-02]\n",
            "  [-1.13996170e-01 -4.11343090e-02]]\n",
            "\n",
            " [[ 7.83559829e-02 -4.89101857e-02]\n",
            "  [-7.83559829e-02  4.89101857e-02]\n",
            "  [-3.38201108e-03  1.10201582e-01]\n",
            "  [ 3.38201108e-03 -1.10201582e-01]\n",
            "  [ 1.89937100e-01  1.29410610e-01]\n",
            "  [ 1.89937100e-01  1.29410610e-01]]]\n",
            "\n",
            "Pairs[0]:\n",
            " [[ 0.01684684  0.13889207]\n",
            " [-0.01684684 -0.13889207]\n",
            " [ 0.1871557  -0.07139685]\n",
            " [-0.1871557   0.07139685]\n",
            " [ 0.07476938 -0.06124834]\n",
            " [ 0.07476938 -0.06124834]\n",
            " [ 0.20400253  0.06749522]\n",
            " [ 0.00315298 -0.00991646]\n",
            " [-0.17030886  0.21028891]\n",
            " [-0.00315298  0.00991646]\n",
            " [ 0.17030886 -0.21028891]\n",
            " [-0.00315298  0.00991646]\n",
            " [-0.20400253 -0.06749522]\n",
            " [ 0.00315298 -0.00991646]\n",
            " [ 0.09161622  0.07764372]\n",
            " [ 0.00125963 -0.00850691]\n",
            " [ 0.09161622  0.07764372]\n",
            " [ 0.00125963 -0.00850691]\n",
            " [ 0.05792253 -0.20014042]\n",
            " [-0.00125963  0.00850691]\n",
            " [ 0.05792253 -0.20014042]\n",
            " [-0.00125963  0.00850691]\n",
            " [ 0.26192507 -0.13264519]\n",
            " [ 0.01399351  0.00437294]\n",
            " [ 0.26192507 -0.13264519]\n",
            " [ 0.01399351  0.00437294]\n",
            " [-0.11238632  0.01014851]\n",
            " [-0.01399351 -0.00437294]\n",
            " [-0.11238632  0.01014851]\n",
            " [-0.01399351 -0.00437294]]\n",
            "\n",
            "Triplets[0]:\n",
            " [[[ 0.01684684  0.13889207]\n",
            "  [-0.01684684 -0.13889207]\n",
            "  [ 0.1871557  -0.07139685]]\n",
            "\n",
            " [[-0.1871557   0.07139685]\n",
            "  [ 0.07476938 -0.06124834]\n",
            "  [ 0.07476938 -0.06124834]]\n",
            "\n",
            " [[ 0.20400253  0.06749522]\n",
            "  [ 0.00315298 -0.00991646]\n",
            "  [-0.17030886  0.21028891]]\n",
            "\n",
            " [[-0.00315298  0.00991646]\n",
            "  [ 0.17030886 -0.21028891]\n",
            "  [-0.00315298  0.00991646]]\n",
            "\n",
            " [[-0.20400253 -0.06749522]\n",
            "  [ 0.00315298 -0.00991646]\n",
            "  [ 0.09161622  0.07764372]]\n",
            "\n",
            " [[ 0.00125963 -0.00850691]\n",
            "  [ 0.09161622  0.07764372]\n",
            "  [ 0.00125963 -0.00850691]]\n",
            "\n",
            " [[ 0.05792253 -0.20014042]\n",
            "  [-0.00125963  0.00850691]\n",
            "  [ 0.05792253 -0.20014042]]\n",
            "\n",
            " [[-0.00125963  0.00850691]\n",
            "  [ 0.26192507 -0.13264519]\n",
            "  [ 0.01399351  0.00437294]]\n",
            "\n",
            " [[ 0.26192507 -0.13264519]\n",
            "  [ 0.01399351  0.00437294]\n",
            "  [-0.11238632  0.01014851]]\n",
            "\n",
            " [[-0.01399351 -0.00437294]\n",
            "  [-0.11238632  0.01014851]\n",
            "  [-0.01399351 -0.00437294]]]\n",
            "\n",
            "Bits (all qubits):\n",
            " [[1 1 1 ... 0 0 0]\n",
            " [1 0 1 ... 0 0 1]\n",
            " [0 1 0 ... 1 0 0]\n",
            " ...\n",
            " [0 1 0 ... 0 1 1]\n",
            " [0 1 1 ... 0 1 1]\n",
            " [1 0 1 ... 1 1 0]]\n",
            "\n",
            "Primaries Out (promoted):\n",
            " [[[-1.39935147e-02 -4.37293900e-03]\n",
            "  [ 1.39935147e-02  4.37293900e-03]\n",
            "  [-1.12386316e-01  1.01485066e-02]\n",
            "  [ 1.12386316e-01 -1.01485066e-02]\n",
            "  [-1.39935147e-02 -4.37293900e-03]\n",
            "  [ 1.39935147e-02  4.37293900e-03]]\n",
            "\n",
            " [[-2.35233214e-02  9.38400161e-03]\n",
            "  [ 2.35233214e-02 -9.38400161e-03]\n",
            "  [-5.23560345e-02 -1.94507301e-01]\n",
            "  [ 5.23560345e-02  1.94507301e-01]\n",
            "  [-2.35233214e-02  9.38400161e-03]\n",
            "  [ 2.35233214e-02 -9.38400161e-03]]\n",
            "\n",
            " [[ 8.29285104e-03  1.23037007e-02]\n",
            "  [-8.29285104e-03 -1.23037007e-02]\n",
            "  [-2.00370416e-01 -2.22438276e-01]\n",
            "  [ 2.00370416e-01  2.22438276e-01]\n",
            "  [ 8.29285104e-03  1.23037007e-02]\n",
            "  [-8.29285104e-03 -1.23037007e-02]]\n",
            "\n",
            " [[ 2.11610063e-03  1.45156030e-02]\n",
            "  [-2.11610063e-03 -1.45156030e-02]\n",
            "  [ 1.00506730e-01  2.41028681e-01]\n",
            "  [-1.00506730e-01 -2.41028681e-01]\n",
            "  [ 2.11610063e-03  1.45156030e-02]\n",
            "  [-2.11610063e-03 -1.45156030e-02]]\n",
            "\n",
            " [[ 1.22325839e-02  8.16249172e-04]\n",
            "  [-1.22325839e-02 -8.16249172e-04]\n",
            "  [ 2.21214235e-01  1.90827742e-01]\n",
            "  [-2.21214235e-01 -1.90827742e-01]\n",
            "  [ 1.22325839e-02  8.16249172e-04]\n",
            "  [-1.22325839e-02 -8.16249172e-04]]\n",
            "\n",
            " [[ 4.90867649e-04 -5.20532427e-04]\n",
            "  [-4.90867649e-04  5.20532427e-04]\n",
            "  [ 2.19683722e-01 -5.26332259e-02]\n",
            "  [-2.19683722e-01  5.26332259e-02]\n",
            "  [ 4.90867649e-04 -5.20532427e-04]\n",
            "  [-4.90867649e-04  5.20532427e-04]]\n",
            "\n",
            " [[-8.40587169e-03  5.22330729e-03]\n",
            "  [ 8.40587169e-03 -5.22330729e-03]\n",
            "  [-9.69996750e-02  1.45888478e-01]\n",
            "  [ 9.69996750e-02 -1.45888478e-01]\n",
            "  [-8.40587169e-03  5.22330729e-03]\n",
            "  [ 8.40587169e-03 -5.22330729e-03]]\n",
            "\n",
            " [[ 5.73175913e-03  5.32104867e-03]\n",
            "  [-5.73175913e-03 -5.32104867e-03]\n",
            "  [ 2.14933708e-01  1.47139087e-01]\n",
            "  [-2.14933708e-01 -1.47139087e-01]\n",
            "  [ 5.73175913e-03  5.32104867e-03]\n",
            "  [-5.73175913e-03 -5.32104867e-03]]\n",
            "\n",
            " [[ 2.45892350e-02 -2.61511724e-03]\n",
            "  [-2.45892350e-02  2.61511724e-03]\n",
            "  [ 3.14537048e-01 -4.47500497e-03]\n",
            "  [-3.14537048e-01  4.47500497e-03]\n",
            "  [ 2.45892350e-02 -2.61511724e-03]\n",
            "  [-2.45892350e-02  2.61511724e-03]]\n",
            "\n",
            " [[-9.12165735e-03 -5.16374595e-04]\n",
            "  [ 9.12165735e-03  5.16374595e-04]\n",
            "  [-1.02569327e-01 -6.20990396e-02]\n",
            "  [ 1.02569327e-01  6.20990396e-02]\n",
            "  [-9.12165735e-03 -5.16374595e-04]\n",
            "  [ 9.12165735e-03  5.16374595e-04]]\n",
            "\n",
            " [[-9.52377450e-03  6.13039173e-03]\n",
            "  [ 9.52377450e-03 -6.13039173e-03]\n",
            "  [ 5.16513363e-02  1.84329525e-01]\n",
            "  [-5.16513363e-02 -1.84329525e-01]\n",
            "  [-9.52377450e-03  6.13039173e-03]\n",
            "  [ 9.52377450e-03 -6.13039173e-03]]\n",
            "\n",
            " [[-1.19304089e-02 -8.16742145e-03]\n",
            "  [ 1.19304089e-02  8.16742145e-03]\n",
            "  [-2.40213871e-02 -6.47199452e-02]\n",
            "  [ 2.40213871e-02  6.47199452e-02]\n",
            "  [-1.19304089e-02 -8.16742145e-03]\n",
            "  [ 1.19304089e-02  8.16742145e-03]]\n",
            "\n",
            " [[ 3.28308018e-03 -8.15755129e-03]\n",
            "  [-3.28308018e-03  8.15755129e-03]\n",
            "  [ 1.20224074e-01 -3.78781408e-02]\n",
            "  [-1.20224074e-01  3.78781408e-02]\n",
            "  [ 3.28308018e-03 -8.15755129e-03]\n",
            "  [-3.28308018e-03  8.15755129e-03]]\n",
            "\n",
            " [[ 1.19550610e-02  7.04179471e-03]\n",
            "  [-1.19550610e-02 -7.04179471e-03]\n",
            "  [ 2.20599592e-01  1.80527002e-01]\n",
            "  [-2.20599592e-01 -1.80527002e-01]\n",
            "  [ 1.19550610e-02  7.04179471e-03]\n",
            "  [-1.19550610e-02 -7.04179471e-03]]\n",
            "\n",
            " [[ 1.32279731e-02  1.10443728e-02]\n",
            "  [-1.32279731e-02 -1.10443728e-02]\n",
            "  [-2.57381082e-01 -2.30149448e-01]\n",
            "  [ 2.57381082e-01  2.30149448e-01]\n",
            "  [ 1.32279731e-02  1.10443728e-02]\n",
            "  [-1.32279731e-02 -1.10443728e-02]]\n",
            "\n",
            " [[-1.28749367e-02 -2.21438729e-03]\n",
            "  [ 1.28749367e-02  2.21438729e-03]\n",
            "  [-1.22891888e-02  2.60825083e-02]\n",
            "  [ 1.22891888e-02 -2.60825083e-02]\n",
            "  [-1.28749367e-02 -2.21438729e-03]\n",
            "  [ 1.28749367e-02  2.21438729e-03]]\n",
            "\n",
            " [[ 2.11870465e-02  1.24938451e-04]\n",
            "  [-2.11870465e-02 -1.24938451e-04]\n",
            "  [ 2.93133140e-01  2.73367818e-02]\n",
            "  [-2.93133140e-01 -2.73367818e-02]\n",
            "  [ 2.11870465e-02  1.24938451e-04]\n",
            "  [-2.11870465e-02 -1.24938451e-04]]\n",
            "\n",
            " [[-2.37460039e-03  6.04627561e-03]\n",
            "  [ 2.37460039e-03 -6.04627561e-03]\n",
            "  [-8.60055089e-02  1.94216013e-01]\n",
            "  [ 8.60055089e-02 -1.94216013e-01]\n",
            "  [-2.37460039e-03  6.04627561e-03]\n",
            "  [ 2.37460039e-03 -6.04627561e-03]]\n",
            "\n",
            " [[ 1.73535701e-02  2.19212240e-03]\n",
            "  [-1.73535701e-02 -2.19212240e-03]\n",
            "  [ 2.78086990e-01 -1.27370968e-01]\n",
            "  [-2.78086990e-01  1.27370968e-01]\n",
            "  [ 1.73535701e-02  2.19212240e-03]\n",
            "  [-1.73535701e-02 -2.19212240e-03]]\n",
            "\n",
            " [[-4.57932660e-03 -1.27428770e-02]\n",
            "  [ 4.57932660e-03  1.27428770e-02]\n",
            "  [-7.58725554e-02 -4.96008471e-02]\n",
            "  [ 7.58725554e-02  4.96008471e-02]\n",
            "  [-4.57932660e-03 -1.27428770e-02]\n",
            "  [ 4.57932660e-03  1.27428770e-02]]\n",
            "\n",
            " [[-2.33293213e-02  2.28502299e-03]\n",
            "  [ 2.33293213e-02 -2.28502299e-03]\n",
            "  [ 3.40028703e-02  1.12480707e-01]\n",
            "  [-3.40028703e-02 -1.12480707e-01]\n",
            "  [-2.33293213e-02  2.28502299e-03]\n",
            "  [ 2.33293213e-02 -2.28502299e-03]]\n",
            "\n",
            " [[ 1.81016289e-02  2.89832405e-03]\n",
            "  [-1.81016289e-02 -2.89832405e-03]\n",
            "  [ 2.90023267e-01 -1.26816466e-01]\n",
            "  [-2.90023267e-01  1.26816466e-01]\n",
            "  [ 1.81016289e-02  2.89832405e-03]\n",
            "  [-1.81016289e-02 -2.89832405e-03]]\n",
            "\n",
            " [[-1.33239776e-02  4.88095917e-04]\n",
            "  [ 1.33239776e-02 -4.88095917e-04]\n",
            "  [ 1.05672188e-01  4.57840264e-02]\n",
            "  [-1.05672188e-01 -4.57840264e-02]\n",
            "  [-1.33239776e-02  4.88095917e-04]\n",
            "  [ 1.33239776e-02 -4.88095917e-04]]\n",
            "\n",
            " [[-3.35858464e-02  2.45760474e-03]\n",
            "  [ 3.35858464e-02 -2.45760474e-03]\n",
            "  [ 1.33758560e-01 -9.99844670e-02]\n",
            "  [-1.33758560e-01  9.99844670e-02]\n",
            "  [-3.35858464e-02  2.45760474e-03]\n",
            "  [ 3.35858464e-02 -2.45760474e-03]]\n",
            "\n",
            " [[ 2.44385656e-02  3.51920119e-03]\n",
            "  [-2.44385656e-02 -3.51920119e-03]\n",
            "  [ 3.16270530e-01 -1.24118350e-01]\n",
            "  [-3.16270530e-01  1.24118350e-01]\n",
            "  [ 2.44385656e-02  3.51920119e-03]\n",
            "  [-2.44385656e-02 -3.51920119e-03]]\n",
            "\n",
            " [[-2.50515831e-03  4.39695036e-03]\n",
            "  [ 2.50515831e-03 -4.39695036e-03]\n",
            "  [ 3.26499343e-02 -1.33021101e-01]\n",
            "  [-3.26499343e-02  1.33021101e-01]\n",
            "  [-2.50515831e-03  4.39695036e-03]\n",
            "  [ 2.50515831e-03 -4.39695036e-03]]\n",
            "\n",
            " [[ 7.04191672e-03  1.48017304e-02]\n",
            "  [-7.04191672e-03 -1.48017304e-02]\n",
            "  [ 2.45696753e-01 -2.51351774e-01]\n",
            "  [-2.45696753e-01  2.51351774e-01]\n",
            "  [ 7.04191672e-03  1.48017304e-02]\n",
            "  [-7.04191672e-03 -1.48017304e-02]]\n",
            "\n",
            " [[-1.99394077e-02  6.29387982e-03]\n",
            "  [ 1.99394077e-02 -6.29387982e-03]\n",
            "  [-5.67131191e-02 -1.60936177e-01]\n",
            "  [ 5.67131191e-02  1.60936177e-01]\n",
            "  [-1.99394077e-02  6.29387982e-03]\n",
            "  [ 1.99394077e-02 -6.29387982e-03]]\n",
            "\n",
            " [[ 1.87223386e-02 -7.63943698e-03]\n",
            "  [-1.87223386e-02  7.63943698e-03]\n",
            "  [-2.94097692e-01  1.87614560e-02]\n",
            "  [ 2.94097692e-01 -1.87614560e-02]\n",
            "  [ 1.87223386e-02 -7.63943698e-03]\n",
            "  [-1.87223386e-02  7.63943698e-03]]\n",
            "\n",
            " [[-1.35201439e-02  2.13139527e-03]\n",
            "  [ 1.35201439e-02 -2.13139527e-03]\n",
            "  [-1.23153061e-01 -1.41885802e-01]\n",
            "  [ 1.23153061e-01  1.41885802e-01]\n",
            "  [-1.35201439e-02  2.13139527e-03]\n",
            "  [ 1.35201439e-02 -2.13139527e-03]]\n",
            "\n",
            " [[ 7.54919974e-03  9.10799298e-03]\n",
            "  [-7.54919974e-03 -9.10799298e-03]\n",
            "  [-1.78061455e-01 -2.14071244e-01]\n",
            "  [ 1.78061455e-01  2.14071244e-01]\n",
            "  [ 7.54919974e-03  9.10799298e-03]\n",
            "  [-7.54919974e-03 -9.10799298e-03]]\n",
            "\n",
            " [[-2.54916884e-02 -1.69813997e-04]\n",
            "  [ 2.54916884e-02  1.69813997e-04]\n",
            "  [-5.39779663e-04  2.11228095e-02]\n",
            "  [ 5.39779663e-04 -2.11228095e-02]\n",
            "  [-2.54916884e-02 -1.69813997e-04]\n",
            "  [ 2.54916884e-02  1.69813997e-04]]\n",
            "\n",
            " [[ 3.58188641e-04 -7.92124774e-03]\n",
            "  [-3.58188641e-04  7.92124774e-03]\n",
            "  [ 1.07578494e-01  1.63016319e-02]\n",
            "  [-1.07578494e-01 -1.63016319e-02]\n",
            "  [ 3.58188641e-04 -7.92124774e-03]\n",
            "  [-3.58188641e-04  7.92124774e-03]]\n",
            "\n",
            " [[-2.61817686e-02 -4.20698896e-03]\n",
            "  [ 2.61817686e-02  4.20698896e-03]\n",
            "  [ 2.77043879e-03 -4.09417190e-02]\n",
            "  [-2.77043879e-03  4.09417190e-02]\n",
            "  [-2.61817686e-02 -4.20698896e-03]\n",
            "  [ 2.61817686e-02  4.20698896e-03]]\n",
            "\n",
            " [[ 8.50996561e-03 -1.29782213e-02]\n",
            "  [-8.50996561e-03  1.29782213e-02]\n",
            "  [ 1.92588985e-01  1.92038640e-02]\n",
            "  [-1.92588985e-01 -1.92038640e-02]\n",
            "  [ 8.50996561e-03 -1.29782213e-02]\n",
            "  [-8.50996561e-03  1.29782213e-02]]\n",
            "\n",
            " [[ 3.43976216e-03  6.78250706e-03]\n",
            "  [-3.43976216e-03 -6.78250706e-03]\n",
            "  [ 2.01521993e-01  1.69139981e-01]\n",
            "  [-2.01521993e-01 -1.69139981e-01]\n",
            "  [ 3.43976216e-03  6.78250706e-03]\n",
            "  [-3.43976216e-03 -6.78250706e-03]]\n",
            "\n",
            " [[ 1.28248977e-02 -5.94620313e-03]\n",
            "  [-1.28248977e-02  5.94620313e-03]\n",
            "  [-2.26582542e-01  6.90876544e-02]\n",
            "  [ 2.26582542e-01 -6.90876544e-02]\n",
            "  [ 1.28248977e-02 -5.94620313e-03]\n",
            "  [-1.28248977e-02  5.94620313e-03]]\n",
            "\n",
            " [[-1.02863377e-02  5.88018214e-03]\n",
            "  [ 1.02863377e-02 -5.88018214e-03]\n",
            "  [-8.34807903e-02  1.53412938e-01]\n",
            "  [ 8.34807903e-02 -1.53412938e-01]\n",
            "  [-1.02863377e-02  5.88018214e-03]\n",
            "  [ 1.02863377e-02 -5.88018214e-03]]\n",
            "\n",
            " [[-1.35978153e-02 -1.16745085e-02]\n",
            "  [ 1.35978153e-02  1.16745085e-02]\n",
            "  [ 7.26892054e-03 -2.36107633e-02]\n",
            "  [-7.26892054e-03  2.36107633e-02]\n",
            "  [-1.35978153e-02 -1.16745085e-02]\n",
            "  [ 1.35978153e-02  1.16745085e-02]]\n",
            "\n",
            " [[ 2.34530610e-03 -2.86109629e-03]\n",
            "  [-2.34530610e-03  2.86109629e-03]\n",
            "  [ 1.24675758e-01 -1.12880744e-01]\n",
            "  [-1.24675758e-01  1.12880744e-01]\n",
            "  [ 2.34530610e-03 -2.86109629e-03]\n",
            "  [-2.34530610e-03  2.86109629e-03]]\n",
            "\n",
            " [[-2.82110907e-02  1.37675321e-02]\n",
            "  [ 2.82110907e-02 -1.37675321e-02]\n",
            "  [-1.34505600e-01 -2.35615745e-01]\n",
            "  [ 1.34505600e-01  2.35615745e-01]\n",
            "  [-2.82110907e-02  1.37675321e-02]\n",
            "  [ 2.82110907e-02 -1.37675321e-02]]\n",
            "\n",
            " [[-2.10124929e-03  1.70067064e-02]\n",
            "  [ 2.10124929e-03 -1.70067064e-02]\n",
            "  [ 9.49963480e-02 -2.62386024e-01]\n",
            "  [-9.49963480e-02  2.62386024e-01]\n",
            "  [-2.10124929e-03  1.70067064e-02]\n",
            "  [ 2.10124929e-03 -1.70067064e-02]]\n",
            "\n",
            " [[ 3.06320973e-02 -4.57942719e-03]\n",
            "  [-3.06320973e-02  4.57942719e-03]\n",
            "  [ 3.66899073e-01  1.27282545e-01]\n",
            "  [-3.66899073e-01 -1.27282545e-01]\n",
            "  [ 3.06320973e-02 -4.57942719e-03]\n",
            "  [-3.06320973e-02  4.57942719e-03]]\n",
            "\n",
            " [[ 1.66039192e-03 -7.52970390e-03]\n",
            "  [-1.66039192e-03  7.52970390e-03]\n",
            "  [-1.52309239e-01  7.00249672e-02]\n",
            "  [ 1.52309239e-01 -7.00249672e-02]\n",
            "  [ 1.66039192e-03 -7.52970390e-03]\n",
            "  [-1.66039192e-03  7.52970390e-03]]\n",
            "\n",
            " [[ 2.95622870e-02 -1.74746988e-03]\n",
            "  [-2.95622870e-02  1.74746988e-03]\n",
            "  [ 3.43903780e-01  1.21315047e-01]\n",
            "  [-3.43903780e-01 -1.21315047e-01]\n",
            "  [ 2.95622870e-02 -1.74746988e-03]\n",
            "  [-2.95622870e-02  1.74746988e-03]]\n",
            "\n",
            " [[ 3.22035537e-03 -1.29643539e-02]\n",
            "  [-3.22035537e-03  1.29643539e-02]\n",
            "  [-1.16220430e-01 -5.11553138e-02]\n",
            "  [ 1.16220430e-01  5.11553138e-02]\n",
            "  [ 3.22035537e-03 -1.29643539e-02]\n",
            "  [-3.22035537e-03  1.29643539e-02]]\n",
            "\n",
            " [[ 7.76490709e-03  6.40682830e-03]\n",
            "  [-7.76490709e-03 -6.40682830e-03]\n",
            "  [ 1.79130703e-01 -1.74478441e-01]\n",
            "  [-1.79130703e-01  1.74478441e-01]\n",
            "  [ 7.76490709e-03  6.40682830e-03]\n",
            "  [-7.76490709e-03 -6.40682830e-03]]\n",
            "\n",
            " [[-2.72403397e-02 -7.73980655e-03]\n",
            "  [ 2.72403397e-02  7.73980655e-03]\n",
            "  [ 6.23947382e-03 -4.22059074e-02]\n",
            "  [-6.23947382e-03  4.22059074e-02]\n",
            "  [-2.72403397e-02 -7.73980655e-03]\n",
            "  [ 2.72403397e-02  7.73980655e-03]]\n",
            "\n",
            " [[ 2.36628186e-02 -1.40446401e-03]\n",
            "  [-2.36628186e-02  1.40446401e-03]\n",
            "  [ 3.08068395e-01  1.23260945e-01]\n",
            "  [-3.08068395e-01 -1.23260945e-01]\n",
            "  [ 2.36628186e-02 -1.40446401e-03]\n",
            "  [-2.36628186e-02  1.40446401e-03]]\n",
            "\n",
            " [[-6.88346149e-03 -4.83032502e-03]\n",
            "  [ 6.88346149e-03  4.83032502e-03]\n",
            "  [-1.17180653e-01  3.47032845e-02]\n",
            "  [ 1.17180653e-01 -3.47032845e-02]\n",
            "  [-6.88346149e-03 -4.83032502e-03]\n",
            "  [ 6.88346149e-03  4.83032502e-03]]\n",
            "\n",
            " [[-1.02960495e-02 -2.97236745e-03]\n",
            "  [ 1.02960495e-02  2.97236745e-03]\n",
            "  [-2.71499231e-02 -1.13902539e-01]\n",
            "  [ 2.71499231e-02  1.13902539e-01]\n",
            "  [-1.02960495e-02 -2.97236745e-03]\n",
            "  [ 1.02960495e-02  2.97236745e-03]]\n",
            "\n",
            " [[ 1.42273102e-02 -2.93735089e-03]\n",
            "  [-1.42273102e-02  2.93735089e-03]\n",
            "  [ 2.54112750e-01 -6.14589974e-02]\n",
            "  [-2.54112750e-01  6.14589974e-02]\n",
            "  [ 1.42273102e-02 -2.93735089e-03]\n",
            "  [-1.42273102e-02  2.93735089e-03]]\n",
            "\n",
            " [[-2.63155112e-03 -8.46983865e-03]\n",
            "  [ 2.63155112e-03  8.46983865e-03]\n",
            "  [ 8.15285295e-02  2.20209569e-01]\n",
            "  [-8.15285295e-02 -2.20209569e-01]\n",
            "  [-2.63155112e-03 -8.46983865e-03]\n",
            "  [ 2.63155112e-03  8.46983865e-03]]\n",
            "\n",
            " [[-9.20643657e-03 -6.00965042e-03]\n",
            "  [ 9.20643657e-03  6.00965042e-03]\n",
            "  [ 1.71095073e-01 -3.78436595e-02]\n",
            "  [-1.71095073e-01  3.78436595e-02]\n",
            "  [-9.20643657e-03 -6.00965042e-03]\n",
            "  [ 9.20643657e-03  6.00965042e-03]]\n",
            "\n",
            " [[ 3.27556245e-02  4.86645149e-03]\n",
            "  [-3.27556245e-02 -4.86645149e-03]\n",
            "  [ 4.18363988e-01  1.40357316e-01]\n",
            "  [-4.18363988e-01 -1.40357316e-01]\n",
            "  [ 3.27556245e-02  4.86645149e-03]\n",
            "  [-3.27556245e-02 -4.86645149e-03]]\n",
            "\n",
            " [[ 5.57364896e-03 -4.72697429e-03]\n",
            "  [-5.57364896e-03  4.72697429e-03]\n",
            "  [-1.80137828e-01 -2.50699222e-02]\n",
            "  [ 1.80137828e-01  2.50699222e-02]\n",
            "  [ 5.57364896e-03 -4.72697429e-03]\n",
            "  [-5.57364896e-03  4.72697429e-03]]\n",
            "\n",
            " [[ 4.28306994e-05 -1.27706109e-02]\n",
            "  [-4.28306994e-05  1.27706109e-02]\n",
            "  [ 1.19840734e-01 -2.22935081e-02]\n",
            "  [-1.19840734e-01  2.22935081e-02]\n",
            "  [ 4.28306994e-05 -1.27706109e-02]\n",
            "  [-4.28306994e-05  1.27706109e-02]]\n",
            "\n",
            " [[ 1.99924186e-02  4.77104634e-03]\n",
            "  [-1.99924186e-02 -4.77104634e-03]\n",
            "  [-3.02894026e-01  1.45691127e-01]\n",
            "  [ 3.02894026e-01 -1.45691127e-01]\n",
            "  [ 1.99924186e-02  4.77104634e-03]\n",
            "  [-1.99924186e-02 -4.77104634e-03]]\n",
            "\n",
            " [[-1.31891305e-02  1.71273932e-04]\n",
            "  [ 1.31891305e-02 -1.71273932e-04]\n",
            "  [ 1.78602085e-01  2.93823481e-02]\n",
            "  [-1.78602085e-01 -2.93823481e-02]\n",
            "  [-1.31891305e-02  1.71273932e-04]\n",
            "  [ 1.31891305e-02 -1.71273932e-04]]\n",
            "\n",
            " [[-9.81949852e-04  8.16799793e-03]\n",
            "  [ 9.81949852e-04 -8.16799793e-03]\n",
            "  [ 1.65489078e-01  1.82322025e-01]\n",
            "  [-1.65489078e-01 -1.82322025e-01]\n",
            "  [-9.81949852e-04  8.16799793e-03]\n",
            "  [ 9.81949852e-04 -8.16799793e-03]]\n",
            "\n",
            " [[ 9.19205416e-03 -6.94782799e-03]\n",
            "  [-9.19205416e-03  6.94782799e-03]\n",
            "  [ 2.56100446e-01  8.89683142e-02]\n",
            "  [-2.56100446e-01 -8.89683142e-02]\n",
            "  [ 9.19205416e-03 -6.94782799e-03]\n",
            "  [-9.19205416e-03  6.94782799e-03]]\n",
            "\n",
            " [[-3.09127271e-02  6.83895603e-04]\n",
            "  [ 3.09127271e-02 -6.83895603e-04]\n",
            "  [ 9.03615355e-03 -5.24177775e-02]\n",
            "  [-9.03615355e-03  5.24177775e-02]\n",
            "  [-3.09127271e-02  6.83895603e-04]\n",
            "  [ 3.09127271e-02 -6.83895603e-04]]\n",
            "\n",
            " [[-1.86393224e-02 -2.76345294e-03]\n",
            "  [ 1.86393224e-02  2.76345294e-03]\n",
            "  [ 4.95121554e-02  2.60469057e-02]\n",
            "  [-4.95121554e-02 -2.60469057e-02]\n",
            "  [-1.86393224e-02 -2.76345294e-03]\n",
            "  [ 1.86393224e-02  2.76345294e-03]]\n",
            "\n",
            " [[ 6.42369385e-04 -1.42612541e-02]\n",
            "  [-6.42369385e-04  1.42612541e-02]\n",
            "  [ 1.93319112e-01  1.92090273e-02]\n",
            "  [-1.93319112e-01 -1.92090273e-02]\n",
            "  [ 6.42369385e-04 -1.42612541e-02]\n",
            "  [-6.42369385e-04  1.42612541e-02]]]\n",
            "\n",
            "Nth Identities (Conceptual, per qubit):\n",
            "\n",
            "  Qubit 0:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.95441556 -0.29825252]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 1:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9287844   0.37051377]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 2:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.55887264 0.82917225]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 3:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.14424646 0.9894729 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 4:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99769974 0.06657396]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 5:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.68511444 -0.7265182 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 6:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.84928846  0.5277376 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 7:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.7327826 0.6802749]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 8:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9943519  -0.10575143]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 9:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9982922  -0.05651306]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 10:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8407842  0.5412073]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 11:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8251048 -0.5648573]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 12:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.3733139 -0.9275824]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 13:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.8615757 0.5074871]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 14:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.76757526 0.64086825]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 15:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.98545414 -0.16949032]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 16:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9999354  0.00589655]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 17:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.36549982  0.9306461 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 18:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99205905 0.125318  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 19:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.33816427 -0.9410086 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 20:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99519503  0.09747577]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 21:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9873691  0.15809162]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 22:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99925476  0.0366056 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 23:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99730384  0.07297654]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 24:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9897501  0.14252594]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 25:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.4949407   0.86869943]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 26:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.42958277 0.9029599 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 27:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.95357513  0.30099627]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 28:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9258422  -0.37777936]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 29:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9877286   0.15571137]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 30:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.63809305 0.7698494 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 31:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99993855 -0.00666113]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 32:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.04516686 -0.9988532 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 33:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.98729783 -0.15864287]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 34:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.54830617 -0.8362006 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 35:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.45224974 0.89174396]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 36:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9071666  -0.42060348]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 37:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8680871   0.49624175]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 38:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.7586836 -0.6513736]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 39:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.6337801 -0.7731639]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 40:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8986642  0.4385647]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 41:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.12261459  0.9923955 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 42:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9889772  -0.14784978]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 43:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.21531098 -0.9764128 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 44:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9982238  -0.05900646]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 45:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.24105653 -0.97043395]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 46:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.77125865 0.63636583]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 47:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9618914  -0.27330253]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 48:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99820113 -0.05924643]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 49:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.81846905 -0.57434356]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 50:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9606754  -0.27733746]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 51:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.979278   -0.20218039]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 52:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.29667225 -0.9548612 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 53:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8373074  -0.54656595]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 54:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9891133 0.146951 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 55:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.76255214 -0.64671534]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 56:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.00335357 -0.9999161 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 57:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.97263867 0.2321132 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 58:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9998399   0.01298391]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 59:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.11934521  0.9927304 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 60:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.7976845 -0.602931 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 61:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.999723   0.0221173]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 62:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.989135   -0.14664847]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 63:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.04499421 -0.9989171 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "\n",
            "Info-energy Output (all qubits):\n",
            " [ 4.8843884  8.460483  10.864811   7.3740697 12.158441   9.039692\n",
            "  4.7364206  9.083887  13.995625   5.0991015  6.9314127  3.7858253\n",
            "  5.016361   7.5089684  9.233651   2.037242  10.759615   4.9577255\n",
            "  9.187411   3.1100929  6.070661  11.956248   3.2208877  7.6777654\n",
            " 10.867371   5.030712  13.868041   5.8137436  9.70015    5.521923\n",
            " 10.75308    1.9517281  3.6575093  2.4754896  7.0165634 10.51515\n",
            " 10.252036   4.81412    2.4178636  4.338871   9.192143   8.012918\n",
            " 16.200602   3.7442217 13.521819   5.5425744  5.5030394  3.8300204\n",
            "  8.221956   2.810055   3.2641113  9.634262   9.430703   6.539163\n",
            " 13.112574   5.0277762  5.8211956 14.213834   6.8580866  9.227292\n",
            " 10.1287155  4.130127   3.3742976  4.671466 ]\n",
            "\n",
            "Resonance Keys (all qubits):\n",
            " ['27fe562d477f10ed7253ad412abe886cf39f05922646c0c6c085c5124656ea19', 'e833ce786c17046b8d4c5a6fb6b12860a5ee5904fa0ef88529fb65e5cb50aa66', '42c0bb7362c8bbb0f4a3117e002f8a9dd3511692816640b1885d4734d02c143b', '4c612510b3eba093290d51206de0ce8ec149f9eb9617bfe29372af9febc8fe27', 'c0e193a610c49bb4e45d0a6b03c01ccc39d1187858a5053533ad35e12c9cb9f7', '5cef20b268256bcc21a123e2c979ce802aa63e72771ed4abcd029d6e2a7bdba7', '8d086e222ebae87498ef8f571ed1c0e6f535aa7c625cb981826ece11ad3706fb', '091c50c2702a74b8a08b0697b465c04a5266546de1ea63a82548e765b77afcd5', '7fe1011415bbbca7dbffce15acba0a9a27007b175b0e57dc105437be3e7de7e3', '84977601b4ffbe56228ad965c9c278ff4bf171666ef9afed05566ce76000c991', 'b39803b382f9a0115fb73b303522da7c991606243dc2aeb61975531216ff78b6', '8a87f6c6bf1e40cc830c240ee1f21d8f45222067a60ef512c82b48d27ff03dd8', '16c1f2468ca3b5d9961ad20b22f88bd170fa74f21de1d0ae3ab0e05e1f380d0c', '9c8996f77d8effea89736a50090e891fd96b485d4c1616e839f9854964c022dc', 'ff8496b78974477420353f4c06ebb926a555950abf4bea3e3c27bf9dcaef1676', '34b960c4d737ffd6fde824966d9bce30e52864a970f49c8a46440b9d685905ae', '04504e06d96dc344cd4e3789f6549b8168b6365b020ce7c6448ea08e0c8e86da', '63bcb6128188fb33609375ff42bd26e53799cf5705dd09972d0fc9192b3e7b2a', '29a73ee7ac33244fadc980f1f645db6fad71e32acaacec35f799a7aaf9d38623', '974d81beaec9188ecc899c2510af4228d0a5511b4658c552ced922f0b1846b6d', 'cd21833d50fbc1d3e0485f690f6d0518ca92a3acefe1ce322038e6a67d37ffe1', '70bd08390af82a4a5fffa9f7c047418708fc54205175ad181610ca5be70f5b92', 'd89d34d1dadf3492c7265f5f61eded0c3926ed420baf92b9c284bb54c90317da', 'd3a0b61123fc21e8cf32b58e9d202f1ff478b09321a28d762df30d11d2210819', '8d8aede6db0cd714a7a6d104ec71dbcbc0f014cb60cb777e886670a93d85da4e', '850f4bd51cf7638c937b7061a2d8dbf18671f60713f6380404531dcc3949c9ae', '1022d54d8eeeb81ada9e67af18e2b6ec561d223e79bd1e0f5eeb053d669ef785', 'b061a92279567254f78efe1ca4cf53f29959903e385ed9ffee1b663cf57d24a7', 'da30f9d8fc2d195f9fe812015e939fda3b1470c9128b35ad26f87beb40c73dc8', 'caea5174c1c801fe0526339fdd39efbe766b5f04b4d97b54a9d668047758d858', '8a7d48316cb861230a0cef7e2180f58f61ec93d18c41918844a9c624f991fc83', '2bdaf51c824d1f13f4c08cda3e07d8e63ec2a10509a17aedec855884ade08bfe', 'bab1ea09aabbfa9b808b0b3faea0196ce42d3f42e24922d26905dc8b5525ebe2', '7e19227b06d29fe240c7536a8586d6983c7c78eed609e3403cbae6386f6325b2', '9cc41b127bd6c4e8b07e9334cd8263179a766fbc66e42bd9da1ba0b594e2ec55', '9f32a5674c6e77e0bed20b4bf469d5d20b890ade5b906687c8fff7bce8bc3eab', 'b2497d25443a82c59d916eac5c9bb9da444b0386865fcc7dff53dd2e28c66fed', '7e77f0f4a46b08b2c1795842fe210f6c2b9da1c9629ce635183a74022d3a1d2e', '979c5e950da9533ef9be218e4096a713e207d5373362aa6d067731ad145bca86', 'ac144af420e11ca8e2134d5a7dda8fbe4643e42b65334641194ee75217de9179', '5d602a78667c89fa98c777b5045fb93f9549987c9deac1e3229ec44aff6261f3', '1bcd18268211a9e9628a05bf70a0d1bacba0608a7626476d75da00eae8eebddb', '98332a6e636a0961bbcadd0a6983ceb28fe30ef7f1c38bf05a5211e235faedf3', '1c135947a6159b7ac71b4a2bb2914c36379fcaf036583e0b52f85bac9f8e8328', '731e45735872ba148515da973e14a8ee026ad92164165d48f8e9890cae7fb052', 'c8de93201985762fa5ff3722403e28e5442b4d9d1d797c422fb2000d54702681', 'afb2746ecdd4dae91f3b3406c8192d379953deca7f5c07a46db4cb1667315bce', '86232a78c2f84d121a73ab7fe25df04791cd7d21367ecfdeee9fe0f6c707576c', 'afa11f5691b6101a12e44a514438c9396cfabb11e920f91e742dcf78d656018f', 'fd7e00b258fe0bf2f3d655328204a37aa955a56d4d611082577717dbf1700703', '1e314e0e60b44afb639e27759f56315937b3f42598aad8f76e968614bd002cde', 'dfae01a89c6acd920f6d0e19bdda07a62ca34534a62773b8cd5eecb3447035db', '5bbd2ffcda33bcdd19e5159258756ee785fbc1b3053f08b2d4cb758ca148f760', '326ca5eb811bcabbbc964cca56887d6ba47d4cb971d225882267599e5aab38b6', '7a42ff4fc6b3bf72de841cc45c95ec2ab719721f61e87f2f56127e6c634039a6', 'f9e1cff57ef3d360669209e0d3238e1ab904e880aaa724e60a8956fae9ddcf6d', '45063af0a867062079d104a6393bae0e36753da6fef38d55b9fde44e1fc5ea49', '68d635601d54f2ea478ab2c9dd18852ef5277eaf3dc3b8a69be2afb6c784d5a6', 'e329953fcac4e2dd0c4524a90c38b23accebaeb3873d86f907760214122608cb', '1a9ddaa8577bc3a676371c232ba2803919a5fb3bc579d52a5804c2c89a63abbc', '513aac2caf47b214ac9eb0d2b9cc2cfa17ba5f77456126074b18e4b95f80b58d', '5a4783252dcdb9024019d857318aa5c41f5fe9c5499347ad76a25dc2db19acab', 'eb934de79009419d96233bff27564306eba8a09160c5305f93b7ad29fb0c8db5', '6486cf7282aa14dd9922b9be8b11e1d3e09a4621a3a8389fb1ecb24ec090b0a3']\n",
            "\n",
            "Spin (all qubits, conceptual):\n",
            " [[[-0.3503472   0.67709225  0.6471498 ]\n",
            "  [ 0.2985651   0.70146704  0.6471498 ]]\n",
            "\n",
            " [[ 0.20091362  0.5651743   0.80013233]\n",
            "  [ 0.578356   -0.15903628  0.80013233]]\n",
            "\n",
            " [[ 0.6793835   0.31801146 -0.6612917 ]\n",
            "  [-0.26964194 -0.6999904  -0.6612917 ]]\n",
            "\n",
            " [[-0.10882615 -0.3179861  -0.9418289 ]\n",
            "  [ 0.2861216  -0.1763313  -0.9418289 ]]\n",
            "\n",
            " [[ 0.6285533  -0.7503584   0.2046534 ]\n",
            "  [-0.7529779   0.6254129   0.2046534 ]]\n",
            "\n",
            " [[ 0.03769999  0.35571006 -0.9338357 ]\n",
            "  [-0.34788197 -0.08324099 -0.9338357 ]]\n",
            "\n",
            " [[ 0.3756849   0.13576595  0.9167489 ]\n",
            "  [-0.39042342 -0.08450493  0.9167489 ]]\n",
            "\n",
            " [[ 0.2512522   0.9198149  -0.30135173]\n",
            "  [ 0.4734087  -0.82769036 -0.30135173]]\n",
            "\n",
            " [[-0.9304897   0.29993922 -0.21029827]\n",
            "  [ 0.36700922  0.906134   -0.21029827]]\n",
            "\n",
            " [[-0.9296843   0.36823848  0.00935452]\n",
            "  [-0.68593365 -0.727604    0.00935452]]\n",
            "\n",
            " [[-0.11728316 -0.77863103  0.61642385]\n",
            "  [-0.6925824  -0.3746348   0.61642385]]\n",
            "\n",
            " [[-0.68312854 -0.12308    -0.71985185]\n",
            "  [-0.0321855  -0.69338113 -0.71985185]]\n",
            "\n",
            " [[-0.14644156  0.10710013  0.9834045 ]\n",
            "  [ 0.03751469  0.17750554  0.9834045 ]]\n",
            "\n",
            " [[ 0.9344736  -0.24871483 -0.25475493]\n",
            "  [ 0.94356424 -0.21162817 -0.25475493]]\n",
            "\n",
            " [[-0.41983524 -0.7519871  -0.50818676]\n",
            "  [-0.8512635   0.13075411 -0.50818676]]\n",
            "\n",
            " [[-0.60199237 -0.28159824 -0.7471999 ]\n",
            "  [-0.00335461  0.6645909  -0.7471999 ]]\n",
            "\n",
            " [[ 0.00930518 -0.01447287  0.99985194]\n",
            "  [ 0.00448367  0.01661165  0.99985194]]\n",
            "\n",
            " [[ 0.752734   -0.4213523   0.50581986]\n",
            "  [-0.5424201   0.67076576  0.50581986]]\n",
            "\n",
            " [[ 0.30912784  0.13265462  0.9417233 ]\n",
            "  [ 0.12016809  0.31419244  0.9417233 ]]\n",
            "\n",
            " [[-0.2928496  -0.6902037   0.66170835]\n",
            "  [-0.58060884  0.474379    0.66170835]]\n",
            "\n",
            " [[-0.39898777 -0.9135177  -0.07933575]\n",
            "  [ 0.9248974  -0.3718477  -0.07933575]]\n",
            "\n",
            " [[-0.2616759  -0.12413116  0.9571401 ]\n",
            "  [ 0.27892333  0.07800381  0.9571401 ]]\n",
            "\n",
            " [[-0.06866661  0.01775365  0.9974817 ]\n",
            "  [-0.05069463 -0.04960191  0.9974817 ]]\n",
            "\n",
            " [[ 0.834567   -0.54440683  0.08437441]\n",
            "  [-0.73201954 -0.6760387   0.08437441]]\n",
            "\n",
            " [[ 0.11074986  0.16329616 -0.9803412 ]\n",
            "  [ 0.19726805  0.00405972 -0.9803412 ]]\n",
            "\n",
            " [[-0.3346726   0.5108694   0.7918376 ]\n",
            "  [-0.33738986 -0.509079    0.7918376 ]]\n",
            "\n",
            " [[-0.65619916 -0.6184812  -0.43230045]\n",
            "  [ 0.5464653   0.71728104 -0.43230045]]\n",
            "\n",
            " [[-0.06893303  0.65088934  0.7560366 ]\n",
            "  [ 0.5980248   0.2660358   0.7560366 ]]\n",
            "\n",
            " [[ 0.6435069   0.6177117  -0.45202994]\n",
            "  [-0.21789834 -0.8649793  -0.45202994]]\n",
            "\n",
            " [[ 0.79021335 -0.29122153 -0.5392151 ]\n",
            "  [-0.51531595 -0.6661055  -0.5392151 ]]\n",
            "\n",
            " [[-0.20331565 -0.36657283  0.9079026 ]\n",
            "  [-0.12343568 -0.4005952   0.9079026 ]]\n",
            "\n",
            " [[ 0.00594497 -0.07547446  0.99713004]\n",
            "  [-0.06285546 -0.04220103  0.99713004]]\n",
            "\n",
            " [[ 0.030056   -0.9399502  -0.33998552]\n",
            "  [ 0.65925527 -0.6706656  -0.33998552]]\n",
            "\n",
            " [[ 0.3272112   0.8351046   0.4421913 ]\n",
            "  [-0.06747606 -0.894379    0.4421913 ]]\n",
            "\n",
            " [[-0.06680177  0.15327683  0.9859228 ]\n",
            "  [-0.1656373  -0.02281554  0.9859228 ]]\n",
            "\n",
            " [[-0.75655186  0.5988787  -0.2626283 ]\n",
            "  [-0.827704   -0.49591577 -0.2626283 ]]\n",
            "\n",
            " [[ 0.772905    0.24639222 -0.5847296 ]\n",
            "  [ 0.45672062  0.6704458  -0.5847296 ]]\n",
            "\n",
            " [[ 0.55566484  0.6812671  -0.4765624 ]\n",
            "  [ 0.00510832  0.8791258  -0.4765624 ]]\n",
            "\n",
            " [[ 0.26936477 -0.13396929  0.9536744 ]\n",
            "  [-0.24893601  0.16892603  0.9536744 ]]\n",
            "\n",
            " [[-0.77970713  0.05545414 -0.62368387]\n",
            "  [-0.7662829  -0.15436624 -0.62368387]]\n",
            "\n",
            " [[ 0.98323464  0.01846645 -0.18140747]\n",
            "  [-0.12143122  0.97588205 -0.18140747]]\n",
            "\n",
            " [[ 0.7028974   0.52912384 -0.47535586]\n",
            "  [ 0.12464052 -0.87091994 -0.47535586]]\n",
            "\n",
            " [[ 0.11798808  0.8385941  -0.5318259 ]\n",
            "  [-0.8235905  -0.19712922 -0.5318259 ]]\n",
            "\n",
            " [[-0.05776704  0.735892    0.6746302 ]\n",
            "  [-0.72197413 -0.15371217  0.6746302 ]]\n",
            "\n",
            " [[-0.78170305 -0.04483145 -0.62203735]\n",
            "  [-0.02979935 -0.78242034 -0.62203735]]\n",
            "\n",
            " [[-0.6047383  -0.00471149 -0.7964103 ]\n",
            "  [ 0.0571106   0.602054   -0.7964103 ]]\n",
            "\n",
            " [[ 0.9946163  -0.06523626 -0.08051443]\n",
            "  [ 0.8046797   0.5882244  -0.08051443]]\n",
            "\n",
            " [[-0.30537313 -0.4863922   0.81863904]\n",
            "  [-0.06870095  0.5701844   0.81863904]]\n",
            "\n",
            " [[-0.8914779   0.09372931  0.44326288]\n",
            "  [-0.4872786  -0.75238127  0.44326288]]\n",
            "\n",
            " [[ 0.15859452  0.8730989  -0.46102723]\n",
            "  [ 0.16026312 -0.87279415 -0.46102723]]\n",
            "\n",
            " [[-0.47113404 -0.33239186  0.81703633]\n",
            "  [-0.43143627 -0.3825106   0.81703633]]\n",
            "\n",
            " [[ 0.1874406   0.19287512 -0.9631538 ]\n",
            "  [ 0.04557046  0.2650625  -0.9631538 ]]\n",
            "\n",
            " [[ 0.5614939  -0.37599272  0.7371256 ]\n",
            "  [ 0.6110728   0.2885064   0.7371256 ]]\n",
            "\n",
            " [[-0.31318694 -0.1393561   0.9394114 ]\n",
            "  [ 0.32369274 -0.11282374  0.9394114 ]]\n",
            "\n",
            " [[ 0.6527106  -0.70266086  0.28326067]\n",
            "  [ 0.5257225  -0.80210924  0.28326067]]\n",
            "\n",
            " [[-0.01994862 -0.08931094  0.995804  ]\n",
            "  [ 0.07788149 -0.04805066  0.995804  ]]\n",
            "\n",
            " [[-0.49917498  0.29514316 -0.81468695]\n",
            "  [-0.57824004  0.04385936 -0.81468695]]\n",
            "\n",
            " [[ 0.8330778  -0.44983268 -0.32191914]\n",
            "  [ 0.4350549   0.8408896  -0.32191914]]\n",
            "\n",
            " [[-0.906273    0.39331403  0.1548332 ]\n",
            "  [ 0.480377    0.8632871   0.1548332 ]]\n",
            "\n",
            " [[ 0.30869174  0.492354    0.8138163 ]\n",
            "  [ 0.5615865  -0.14941095  0.8138163 ]]\n",
            "\n",
            " [[-0.98719466 -0.0190301  -0.1583812 ]\n",
            "  [ 0.6226556   0.76629984 -0.1583812 ]]\n",
            "\n",
            " [[ 0.06955785  0.07988528  0.9943742 ]\n",
            "  [-0.03542741  0.0998241   0.9943742 ]]\n",
            "\n",
            " [[-0.14277731  0.36027086 -0.9218566 ]\n",
            "  [ 0.18141751 -0.34244436 -0.9218566 ]]\n",
            "\n",
            " [[-0.68278086 -0.5205637  -0.5126634 ]\n",
            "  [-0.6547713  -0.5553834  -0.5126634 ]]]\n",
            "\n",
            "I_vec (all qubits, conceptual):\n",
            " [[0.1521312  0.15430088 0.29837176 ... 0.1432516  0.14231788 0.5345384 ]\n",
            " [0.42293108 0.2507531  0.13685037 ... 0.11320334 0.38175064 0.47471678]\n",
            " [0.2948465  0.3829355  0.16458596 ... 0.0577345  0.2531477  0.10626662]\n",
            " ...\n",
            " [0.36609814 0.19297035 0.08257188 ... 0.28323355 0.2345983  0.43900886]\n",
            " [0.25851685 0.19641256 0.25670552 ... 0.02096382 0.3274834  0.30892122]\n",
            " [0.13589843 0.20287316 0.07322701 ... 0.26122466 0.3171237  0.34530637]]\n",
            "\n",
            "NECL Manifest Checksums (per qubit, conceptual):\n",
            " ['1fec385b4f3801e2b8ba84afa6996883c7455ac2a4e3812543a608bf8620fb2e', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945']\n",
            "\n",
            "TRACE Log (Conceptual - detailed lineage for error correction):\n",
            " [{'qubit': 0, 'reason': 'binary_refactor', 'source': 'tuplets', 'r_metric': 0.9720121622085571, 'u_metric': 0.978628396987915, 'dv_metric': -0.03279685974121094, 'invariant_pass': False, 'degenerate_check': False, 'correction_threshold_r': 1.02, 'correction_threshold_u': 1.02, 'correction_threshold_d': 0.765, 'corrected_bits': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], 'old_key': '894c9f1f2bbc52d440c3c629bab275705df49af4ebd23f53fc3c6ab7ed481eec', 'new_key': '27fe562d477f10ed7253ad412abe886cf39f05922646c0c6c085c5124656ea19'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5c793c6"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review the updated code block to ensure all refactoring instructions related to collapse scope and parity application have been correctly implemented and verify that the system behaves as expected with the new collapse rules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d7efdca"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Refactoring of `detect_collapse`**: The `detect_collapse` function was found to have already incorporated the specified refactoring instructions. This included the introduction of the `R_FOR_RATIO` constant (set to `2.0`) and the implementation of the new triplet-level predicate for collapse detection. The logic correctly evaluates if `[high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO]` is met for any index within a triplet, marking all indices of that triplet as collapsed.\n",
        "*   **Review of `apply_parity_rotation`**: The `apply_parity_rotation` function was confirmed to operate correctly and precisely with the refined `collapse_mask` generated by the updated `detect_collapse`. It accurately applies half-rotation to elements corresponding to prime indices or those specifically marked as collapsed, without unintended propagation. No code changes were required.\n",
        "*   **Review of `COLLAPSE_Q`**: The `COLLAPSE_Q` function was verified to correctly zero out only the specific primary units identified by the granular `collapse_mask`. Its logic ensures that only the affected real and unreal components are set to zero, preserving other non-collapsed primary units. No code changes were required.\n",
        "*   **Documentation of `correct_bits`**: Comprehensive comments were successfully added to the `correct_bits` function, clarifying its operational strategy regarding local re-evaluation, lineage recording, and its scope (i.e., operating per-qubit without advancing across units unless local exhaustion occurs).\n",
        "*   **Code Quality during Verification**: During the verification phase, two typos were identified and corrected: a `NameError` in a function call within `promote_primaries` and a `KeyError` when accessing dictionary elements in the final output logging. These corrections ensured the full execution of the refactored and documented code.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Insight**: The initial codebase demonstrated a high degree of alignment with the refactoring instructions for collapse detection and parity application, indicating a robust design for these core functions.\n",
        "*   **Next Step**: Implement a formal unit testing suite for the error correction mechanisms, especially for `derive_bits_advanced` and `correct_bits`, to proactively catch logical errors or unexpected behavior (like the sparse/dense bit pattern checks) and ensure robustness against diverse edge cases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eceb0e67"
      },
      "source": [
        "# Task\n",
        "All refactoring, review, and documentation tasks have been successfully completed and verified. The updated code now implements the new collapse detection predicate, and the dependent functions (`apply_parity_rotation` and `COLLAPSE_Q`) correctly utilize the refined `collapse_mask`. The `correct_bits` function has also been appropriately documented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6c74107"
      },
      "source": [
        "## Refactor Collapse Detection with New Predicate\n",
        "\n",
        "### Subtask:\n",
        "Update the global constant R_FOR_RATIO and modify the detect_collapse function to implement the new triplet-level predicate for collapse detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dd2bf30"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires updating the `R_FOR_RATIO` constant and refactoring the `detect_collapse` function to implement the new triplet-level predicate for collapse detection, removing the nested helper function, and applying the specified logic for marking collapsed indices. I will update the code to reflect these changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d599cad0",
        "outputId": "cf1cabed-ad20-4e1f-c258-02b71f7a2ae1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "R_FOR_RATIO = 64.0 # NEW: Ratio threshold constant for collapse detection, updated to 64.0 as per instructions\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| + n_|y, η| = n_|x+y, ξ+η|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| · n_|y, η| = n_|x·y, ξ·η|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ξ| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ξ_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW, r_for_ratio=R_FOR_RATIO):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register.\n",
        "    A triplet block collapses if, for any index 'p' within the triplet,\n",
        "    the condition [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO] is met.\n",
        "    If this condition is true for *any* index within the triplet, all indices i,j,k\n",
        "    of that triplet are marked as collapsed.\n",
        "    COLL(x, χ) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for unreal component (should be negative).\n",
        "        r_for_ratio (float): Ratio threshold for collapse detection.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    # Initialize a collapse mask filled with zeros\n",
        "    collapse_mask = tf.zeros(tf.shape(real_parts), dtype=tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Iterate over each triplet block and apply collapse detection\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # Extract real and unreal parts for the current triplet across all Q qubits\n",
        "        # shape [Q, 3]\n",
        "        triplet_real_block = tf.gather(real_parts, current_triplet_indices, axis=1)\n",
        "        triplet_unreal_block = tf.gather(unreal_parts, current_triplet_indices, axis=1)\n",
        "\n",
        "        # Evaluate the new triplet-level predicate for each index 'p' within the triplet block\n",
        "        # The condition: [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO]\n",
        "        # high(real_p): triplet_real_block >= tau_hi\n",
        "        # low(unreal_p): triplet_unreal_block <= tau_low (using TAU_LOW for unreal too)\n",
        "\n",
        "        # Condition 1: high(real_p) AND low(unreal_p)\n",
        "        cond1 = tf.logical_and(triplet_real_block >= tau_hi, triplet_unreal_block <= tau_low) # [Q, 3]\n",
        "\n",
        "        # Condition 2: ratio(real_p / unreal_p) > r_for_ratio\n",
        "        # Handle potential division by zero for unreal_p\n",
        "        # If unreal_p is near zero, the ratio might be undefined or very large.\n",
        "        # Set ratio to 0 if unreal_p is ~0 to avoid NaNs and make the condition false.\n",
        "        ratio_term = tf.where(tf.abs(triplet_unreal_block) > EPS, triplet_real_block / triplet_unreal_block, tf.zeros_like(triplet_real_block))\n",
        "        cond2 = ratio_term > r_for_ratio # [Q, 3]\n",
        "\n",
        "        # Triplet collapse if (cond1 OR cond2) is true for *any* index within the triplet\n",
        "        # tf.reduce_any along the triplet dimension (axis=1) for each qubit\n",
        "        triplet_collapse_per_qubit = tf.reduce_any(tf.logical_or(cond1, cond2), axis=1) # [Q]\n",
        "\n",
        "        # Mark all 3 indices of the triplet as collapsed if triplet_collapse_per_qubit is true for that qubit\n",
        "        unit_collapse_flag_int = tf.cast(triplet_collapse_per_qubit, tf.int32) # [Q]\n",
        "        marked_triplet_block = tf.broadcast_to(tf.expand_dims(unit_collapse_flag_int, axis=1), tf.shape(triplet_real_block)) # [Q, 3]\n",
        "\n",
        "        # Construct indices for scatter_nd_max to update the global collapse_mask\n",
        "        # indices_to_update will be [Q*3, 2]\n",
        "        # First column is qubit index, second is original 30-index\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1)\n",
        "\n",
        "        # Flatten marked_triplet_block to [Q*3] for updates\n",
        "        updates = tf.reshape(marked_triplet_block, [-1])\n",
        "\n",
        "        # Use tf.tensor_scatter_nd_max to update the collapse_mask.\n",
        "        # This ensures that if any triplet marks an index as collapsed, it remains marked.\n",
        "        collapse_mask = tf.tensor_scatter_nd_max(collapse_mask, indices_to_update, updates)\n",
        "\n",
        "    return collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components. Implements ASSOC(A, B, α) logic.\n",
        "\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`).\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode('utf-8')).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    for b_idx_triplet in tf.range(10):\n",
        "        current_triplet_indices = idx[b_idx_triplet, :] # Shape [3]\n",
        "        s = tf.gather(signs, current_triplet_indices) # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        # Ensure the list extension is compatible with TF operations if trip_mix is later converted to Tensor\n",
        "        # Here, it's converted to Python list and then to Tensor once.\n",
        "        trip_mix.extend([has_mix.numpy().item()]*3)\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook for a single qubit (q_idx). This function performs a local\n",
        "    re-evaluation of the bit pattern for the current qubit if the initial derivation\n",
        "    is deemed 'inconsistent'.\n",
        "\n",
        "    This function is designed to:\n",
        "    - Advance *only* within the same triplet (or within the primaries 6-set) for local re-evaluation.\n",
        "      It uses the `pairs_q` and `triplets_q` already derived for this specific qubit `q_idx`.\n",
        "      It does not implicitly advance to other qubits or triplets; its scope is limited to the\n",
        "      current qubit's local tuplet structure.\n",
        "    - Record lineage for any local adjustments made. If a correction occurs, a specific\n",
        "      entry is added to the `TRACE` log, detailing the reason, source, metrics, and new key.\n",
        "    - *Not* advance across different units (triplets or qubits) unless the current local unit\n",
        "      has been exhausted. The `derive_bits_advanced` function, called internally,\n",
        "      operates solely on the provided `pairs_q` and `triplets_q` for the current qubit.\n",
        "\n",
        "    Args:\n",
        "        q_idx (int): The index of the current qubit being processed.\n",
        "        pairs_q (tf.Tensor): The 30-index phase-dual pair register for the current qubit [30, 2].\n",
        "        triplets_q (tf.Tensor): The 10 triplets for the current qubit [10, 3, 2].\n",
        "        current_bits_q (tf.Tensor): The initially derived 30-bit pattern for the current qubit [30].\n",
        "        resonance_key_q (str): The current resonance key string for the qubit.\n",
        "        TRACE (list): A list to append lineage information if corrections are made.\n",
        "        invariants (dict): Dictionary of invariant constants.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, str]:\n",
        "            - new_bits_q (tf.Tensor): The potentially corrected 30-bit pattern.\n",
        "            - updated_resonance_key_q (str): The updated resonance key string (with lineage if corrected).\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        # The updated key incorporates the correction lineage.\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs) # Pass R_FOR_RATIO implicitly from constants\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primaries In:\n",
            " [[[-0.417485   -0.5565157 ]\n",
            "  [ 0.417485    0.5565157 ]\n",
            "  [-0.6204579   0.6172738 ]\n",
            "  [ 0.6204579  -0.6172738 ]\n",
            "  [-0.00817251  0.95951533]\n",
            "  [ 0.00817251 -0.95951533]]\n",
            "\n",
            " [[ 0.08210111 -0.0605588 ]\n",
            "  [-0.08210111  0.0605588 ]\n",
            "  [ 0.44932246 -0.06976032]\n",
            "  [-0.44932246  0.06976032]\n",
            "  [-0.5854747  -0.03292513]\n",
            "  [ 0.5854747   0.03292513]]\n",
            "\n",
            " [[ 0.4349773   0.715029  ]\n",
            "  [-0.4349773  -0.715029  ]\n",
            "  [-0.8964765  -0.5290761 ]\n",
            "  [ 0.8964765   0.5290761 ]\n",
            "  [-0.9421675  -0.13442492]\n",
            "  [ 0.9421675   0.13442492]]\n",
            "\n",
            " [[ 0.7020836   0.42065287]\n",
            "  [-0.7020836  -0.42065287]\n",
            "  [ 0.66939545 -0.8689885 ]\n",
            "  [-0.66939545  0.8689885 ]\n",
            "  [ 0.54820776  0.28364325]\n",
            "  [-0.54820776 -0.28364325]]\n",
            "\n",
            " [[-0.5596812  -0.27298903]\n",
            "  [ 0.5596812   0.27298903]\n",
            "  [-0.18120861 -0.27927017]\n",
            "  [ 0.18120861  0.27927017]\n",
            "  [ 0.01503325 -0.27959418]\n",
            "  [-0.01503325  0.27959418]]\n",
            "\n",
            " [[ 0.19639373 -0.41473103]\n",
            "  [-0.19639373  0.41473103]\n",
            "  [ 0.77364206 -0.82868147]\n",
            "  [-0.77364206  0.82868147]\n",
            "  [-0.19839263  0.23978329]\n",
            "  [ 0.19839263 -0.23978329]]\n",
            "\n",
            " [[-0.51950383 -0.7434695 ]\n",
            "  [ 0.51950383  0.7434695 ]\n",
            "  [ 0.5175915   0.35800076]\n",
            "  [-0.5175915  -0.35800076]\n",
            "  [ 0.6643257   0.96271706]\n",
            "  [-0.6643257  -0.96271706]]\n",
            "\n",
            " [[-0.98901796  0.11977458]\n",
            "  [ 0.98901796 -0.11977458]\n",
            "  [ 0.2666905   0.00928473]\n",
            "  [-0.2666905  -0.00928473]\n",
            "  [ 0.65014577 -0.6633878 ]\n",
            "  [-0.65014577  0.6633878 ]]\n",
            "\n",
            " [[-0.29414034 -0.12138939]\n",
            "  [ 0.29414034  0.12138939]\n",
            "  [-0.04513407  0.2368784 ]\n",
            "  [ 0.04513407 -0.2368784 ]\n",
            "  [-0.6180525   0.78977776]\n",
            "  [ 0.6180525  -0.78977776]]\n",
            "\n",
            " [[-0.3825829  -0.68674374]\n",
            "  [ 0.3825829   0.68674374]\n",
            "  [-0.35031748  0.16168833]\n",
            "  [ 0.35031748 -0.16168833]\n",
            "  [ 0.9145148   0.1975677 ]\n",
            "  [-0.9145148  -0.1975677 ]]\n",
            "\n",
            " [[ 0.25249195 -0.60595155]\n",
            "  [-0.25249195  0.60595155]\n",
            "  [ 0.905617   -0.99574757]\n",
            "  [-0.905617    0.99574757]\n",
            "  [ 0.11007929 -0.44126987]\n",
            "  [-0.11007929  0.44126987]]\n",
            "\n",
            " [[ 0.51480055  0.7741301 ]\n",
            "  [-0.51480055 -0.7741301 ]\n",
            "  [-0.9952619   0.06005836]\n",
            "  [ 0.9952619  -0.06005836]\n",
            "  [ 0.5464208   0.8803725 ]\n",
            "  [-0.5464208  -0.8803725 ]]\n",
            "\n",
            " [[ 0.93649244  0.67175746]\n",
            "  [-0.93649244 -0.67175746]\n",
            "  [ 0.8368206  -0.3600366 ]\n",
            "  [-0.8368206   0.3600366 ]\n",
            "  [ 0.43791723  0.04857874]\n",
            "  [-0.43791723 -0.04857874]]\n",
            "\n",
            " [[-0.97065854  0.49104214]\n",
            "  [ 0.97065854 -0.49104214]\n",
            "  [-0.42143226 -0.5591712 ]\n",
            "  [ 0.42143226  0.5591712 ]\n",
            "  [ 0.2379477  -0.31354594]\n",
            "  [-0.2379477   0.31354594]]\n",
            "\n",
            " [[ 0.49537563 -0.804404  ]\n",
            "  [-0.49537563  0.804404  ]\n",
            "  [-0.76982    -0.16137147]\n",
            "  [ 0.76982     0.16137147]\n",
            "  [ 0.67500734 -0.8122783 ]\n",
            "  [-0.67500734  0.8122783 ]]\n",
            "\n",
            " [[ 0.19462037  0.06974721]\n",
            "  [-0.19462037 -0.06974721]\n",
            "  [-0.59914994 -0.73215294]\n",
            "  [ 0.59914994  0.73215294]\n",
            "  [-0.0770328   0.13446927]\n",
            "  [ 0.0770328  -0.13446927]]\n",
            "\n",
            " [[ 0.17140746  0.6444626 ]\n",
            "  [-0.17140746 -0.6444626 ]\n",
            "  [-0.22988844  0.38153815]\n",
            "  [ 0.22988844 -0.38153815]\n",
            "  [ 0.05802846  0.7434194 ]\n",
            "  [-0.05802846 -0.7434194 ]]\n",
            "\n",
            " [[-0.71989465 -0.3004217 ]\n",
            "  [ 0.71989465  0.3004217 ]\n",
            "  [-0.99856377 -0.9121599 ]\n",
            "  [ 0.99856377  0.9121599 ]\n",
            "  [-0.17669702 -0.2834618 ]\n",
            "  [ 0.17669702  0.2834618 ]]\n",
            "\n",
            " [[ 0.8477185   0.8119943 ]\n",
            "  [-0.8477185  -0.8119943 ]\n",
            "  [ 0.35590458  0.8006425 ]\n",
            "  [-0.35590458 -0.8006425 ]\n",
            "  [ 0.50442386 -0.7172303 ]\n",
            "  [-0.50442386  0.7172303 ]]\n",
            "\n",
            " [[ 0.4022491   0.7453692 ]\n",
            "  [-0.4022491  -0.7453692 ]\n",
            "  [ 0.1533668   0.9743788 ]\n",
            "  [-0.1533668  -0.9743788 ]\n",
            "  [-0.6672244   0.60265565]\n",
            "  [ 0.6672244  -0.60265565]]\n",
            "\n",
            " [[ 0.59933376 -0.05460787]\n",
            "  [-0.59933376  0.05460787]\n",
            "  [ 0.1071527   0.3442626 ]\n",
            "  [-0.1071527  -0.3442626 ]\n",
            "  [-0.81454706  0.6382911 ]\n",
            "  [ 0.81454706 -0.6382911 ]]\n",
            "\n",
            " [[ 0.6484513  -0.76044583]\n",
            "  [-0.6484513   0.76044583]\n",
            "  [-0.08107972 -0.8010981 ]\n",
            "  [ 0.08107972  0.8010981 ]\n",
            "  [-0.83647704 -0.93435407]\n",
            "  [ 0.83647704  0.93435407]]\n",
            "\n",
            " [[ 0.05326462 -0.6666999 ]\n",
            "  [-0.05326462  0.6666999 ]\n",
            "  [-0.48504353 -0.23791027]\n",
            "  [ 0.48504353  0.23791027]\n",
            "  [ 0.9098954  -0.5192864 ]\n",
            "  [-0.9098954   0.5192864 ]]\n",
            "\n",
            " [[-0.28602147  0.8927779 ]\n",
            "  [ 0.28602147 -0.8927779 ]\n",
            "  [-0.8576803  -0.3201394 ]\n",
            "  [ 0.8576803   0.3201394 ]\n",
            "  [ 0.07808661  0.8202903 ]\n",
            "  [-0.07808661 -0.8202903 ]]\n",
            "\n",
            " [[ 0.6469879  -0.21227431]\n",
            "  [-0.6469879   0.21227431]\n",
            "  [ 0.13867164  0.53871655]\n",
            "  [-0.13867164 -0.53871655]\n",
            "  [ 0.8649359   0.61092496]\n",
            "  [-0.8649359  -0.61092496]]\n",
            "\n",
            " [[-0.98799276 -0.79592156]\n",
            "  [ 0.98799276  0.79592156]\n",
            "  [ 0.5030153   0.47268534]\n",
            "  [-0.5030153  -0.47268534]\n",
            "  [-0.82832813  0.99337673]\n",
            "  [ 0.82832813 -0.99337673]]\n",
            "\n",
            " [[ 0.8588195  -0.7671468 ]\n",
            "  [-0.8588195   0.7671468 ]\n",
            "  [-0.49678922 -0.5695305 ]\n",
            "  [ 0.49678922  0.5695305 ]\n",
            "  [-0.29890203  0.22941136]\n",
            "  [ 0.29890203 -0.22941136]]\n",
            "\n",
            " [[ 0.14743972 -0.83900857]\n",
            "  [-0.14743972  0.83900857]\n",
            "  [ 0.0258038   0.7549195 ]\n",
            "  [-0.0258038  -0.7549195 ]\n",
            "  [-0.9566276  -0.60742164]\n",
            "  [ 0.9566276   0.60742164]]\n",
            "\n",
            " [[-0.2970128  -0.4074452 ]\n",
            "  [ 0.2970128   0.4074452 ]\n",
            "  [ 0.08501911  0.74255395]\n",
            "  [-0.08501911 -0.74255395]\n",
            "  [-0.40991306  0.5733876 ]\n",
            "  [ 0.40991306 -0.5733876 ]]\n",
            "\n",
            " [[-0.0412426   0.34126687]\n",
            "  [ 0.0412426  -0.34126687]\n",
            "  [-0.26202345  0.1315279 ]\n",
            "  [ 0.26202345 -0.1315279 ]\n",
            "  [ 0.7665651  -0.7821219 ]\n",
            "  [-0.7665651   0.7821219 ]]\n",
            "\n",
            " [[ 0.23373055  0.3495965 ]\n",
            "  [-0.23373055 -0.3495965 ]\n",
            "  [-0.7736788  -0.83455706]\n",
            "  [ 0.7736788   0.83455706]\n",
            "  [-0.2776463  -0.94473267]\n",
            "  [ 0.2776463   0.94473267]]\n",
            "\n",
            " [[-0.9946282   0.784307  ]\n",
            "  [ 0.9946282  -0.784307  ]\n",
            "  [-0.23035812  0.9469309 ]\n",
            "  [ 0.23035812 -0.9469309 ]\n",
            "  [-0.9200764  -0.8236685 ]\n",
            "  [ 0.9200764   0.8236685 ]]\n",
            "\n",
            " [[ 0.28639102 -0.21029377]\n",
            "  [-0.28639102  0.21029377]\n",
            "  [-0.97246385  0.37800837]\n",
            "  [ 0.97246385 -0.37800837]\n",
            "  [-0.5883651   0.7436843 ]\n",
            "  [ 0.5883651  -0.7436843 ]]\n",
            "\n",
            " [[ 0.7566047   0.14261818]\n",
            "  [-0.7566047  -0.14261818]\n",
            "  [ 0.18900418  0.7023847 ]\n",
            "  [-0.18900418 -0.7023847 ]\n",
            "  [ 0.9615576   0.82685924]\n",
            "  [-0.9615576  -0.82685924]]\n",
            "\n",
            " [[ 0.20826364  0.7560246 ]\n",
            "  [-0.20826364 -0.7560246 ]\n",
            "  [-0.36638212 -0.497993  ]\n",
            "  [ 0.36638212  0.497993  ]\n",
            "  [-0.6200056  -0.7384925 ]\n",
            "  [ 0.6200056   0.7384925 ]]\n",
            "\n",
            " [[-0.9467242  -0.15590072]\n",
            "  [ 0.9467242   0.15590072]\n",
            "  [-0.95069075 -0.033463  ]\n",
            "  [ 0.95069075  0.033463  ]\n",
            "  [ 0.29939485 -0.24862671]\n",
            "  [-0.29939485  0.24862671]]\n",
            "\n",
            " [[ 0.00329447  0.61667657]\n",
            "  [-0.00329447 -0.61667657]\n",
            "  [ 0.2143085  -0.9183233 ]\n",
            "  [-0.2143085   0.9183233 ]\n",
            "  [-0.8008592  -0.39405322]\n",
            "  [ 0.8008592   0.39405322]]\n",
            "\n",
            " [[ 0.05320787  0.33868456]\n",
            "  [-0.05320787 -0.33868456]\n",
            "  [-0.08322525 -0.98134065]\n",
            "  [ 0.08322525  0.98134065]\n",
            "  [ 0.08029103 -0.47551465]\n",
            "  [-0.08029103  0.47551465]]\n",
            "\n",
            " [[ 0.68255424 -0.33162785]\n",
            "  [-0.68255424  0.33162785]\n",
            "  [ 0.67840505  0.5561962 ]\n",
            "  [-0.67840505 -0.5561962 ]\n",
            "  [ 0.84182763 -0.99723005]\n",
            "  [-0.84182763  0.99723005]]\n",
            "\n",
            " [[-0.7067001  -0.4979117 ]\n",
            "  [ 0.7067001   0.4979117 ]\n",
            "  [-0.10862923 -0.62974524]\n",
            "  [ 0.10862923  0.62974524]\n",
            "  [ 0.13951302 -0.8171637 ]\n",
            "  [-0.13951302  0.8171637 ]]\n",
            "\n",
            " [[ 0.45495296  0.7772031 ]\n",
            "  [-0.45495296 -0.7772031 ]\n",
            "  [-0.57620573  0.19743562]\n",
            "  [ 0.57620573 -0.19743562]\n",
            "  [-0.19582343  0.06681943]\n",
            "  [ 0.19582343 -0.06681943]]\n",
            "\n",
            " [[ 0.12380743  0.7531023 ]\n",
            "  [-0.12380743 -0.7531023 ]\n",
            "  [-0.32732177 -0.13265133]\n",
            "  [ 0.32732177  0.13265133]\n",
            "  [ 0.61041594  0.22330523]\n",
            "  [-0.61041594 -0.22330523]]\n",
            "\n",
            " [[-0.6500592   0.18266106]\n",
            "  [ 0.6500592  -0.18266106]\n",
            "  [ 0.28090096  0.10665464]\n",
            "  [-0.28090096 -0.10665464]\n",
            "  [ 0.52496743 -0.17224503]\n",
            "  [-0.52496743  0.17224503]]\n",
            "\n",
            " [[ 0.71018076 -0.38753963]\n",
            "  [-0.71018076  0.38753963]\n",
            "  [ 0.21243477  0.20565319]\n",
            "  [-0.21243477 -0.20565319]\n",
            "  [ 0.28445077 -0.8941035 ]\n",
            "  [-0.28445077  0.8941035 ]]\n",
            "\n",
            " [[ 0.23080778 -0.12016797]\n",
            "  [-0.23080778  0.12016797]\n",
            "  [-0.4352467   0.56268716]\n",
            "  [ 0.4352467  -0.56268716]\n",
            "  [ 0.7513046   0.24151874]\n",
            "  [-0.7513046  -0.24151874]]\n",
            "\n",
            " [[ 0.4402659  -0.66213274]\n",
            "  [-0.4402659   0.66213274]\n",
            "  [ 0.9249115  -0.29417706]\n",
            "  [-0.9249115   0.29417706]\n",
            "  [-0.83226347 -0.64174867]\n",
            "  [ 0.83226347  0.64174867]]\n",
            "\n",
            " [[-0.5488839  -0.7415068 ]\n",
            "  [ 0.5488839   0.7415068 ]\n",
            "  [ 0.5821929   0.26499152]\n",
            "  [-0.5821929  -0.26499152]\n",
            "  [ 0.68682694 -0.01552224]\n",
            "  [-0.68682694  0.01552224]]\n",
            "\n",
            " [[ 0.9467571   0.17721963]\n",
            "  [-0.9467571  -0.17721963]\n",
            "  [ 0.7345865  -0.54352546]\n",
            "  [-0.7345865   0.54352546]\n",
            "  [-0.96946144 -0.4506731 ]\n",
            "  [ 0.96946144  0.4506731 ]]\n",
            "\n",
            " [[-0.4356172  -0.81488204]\n",
            "  [ 0.4356172   0.81488204]\n",
            "  [ 0.09661508  0.73581195]\n",
            "  [-0.09661508 -0.73581195]\n",
            "  [ 0.56903887  0.4028747 ]\n",
            "  [-0.56903887 -0.4028747 ]]\n",
            "\n",
            " [[-0.09375191 -0.44213772]\n",
            "  [ 0.09375191  0.44213772]\n",
            "  [ 0.64803815 -0.25237775]\n",
            "  [-0.64803815  0.25237775]\n",
            "  [ 0.40135384  0.36987448]\n",
            "  [-0.40135384 -0.36987448]]\n",
            "\n",
            " [[-0.09257889  0.14560318]\n",
            "  [ 0.09257889 -0.14560318]\n",
            "  [ 0.7513168   0.09066892]\n",
            "  [-0.7513168  -0.09066892]\n",
            "  [-0.2725532  -0.4498372 ]\n",
            "  [ 0.2725532   0.4498372 ]]\n",
            "\n",
            " [[ 0.26002407 -0.39685774]\n",
            "  [-0.26002407  0.39685774]\n",
            "  [-0.8422482   0.04699063]\n",
            "  [ 0.8422482  -0.04699063]\n",
            "  [ 0.02024436  0.15168452]\n",
            "  [-0.02024436 -0.15168452]]\n",
            "\n",
            " [[-0.6532192  -0.6335461 ]\n",
            "  [ 0.6532192   0.6335461 ]\n",
            "  [-0.6668341   0.49523664]\n",
            "  [ 0.6668341  -0.49523664]\n",
            "  [ 0.5314796  -0.31977963]\n",
            "  [-0.5314796   0.31977963]]\n",
            "\n",
            " [[-0.08190441  0.5174415 ]\n",
            "  [ 0.08190441 -0.5174415 ]\n",
            "  [-0.684649   -0.30972123]\n",
            "  [ 0.684649    0.30972123]\n",
            "  [-0.56334805  0.83513427]\n",
            "  [ 0.56334805 -0.83513427]]\n",
            "\n",
            " [[-0.13970757 -0.44353843]\n",
            "  [ 0.13970757  0.44353843]\n",
            "  [-0.64567614  0.9954934 ]\n",
            "  [ 0.64567614 -0.9954934 ]\n",
            "  [ 0.6426625   0.07646036]\n",
            "  [-0.6426625  -0.07646036]]\n",
            "\n",
            " [[-0.99258137 -0.0532825 ]\n",
            "  [ 0.99258137  0.0532825 ]\n",
            "  [ 0.97599626 -0.4602139 ]\n",
            "  [-0.97599626  0.4602139 ]\n",
            "  [-0.14652205  0.25800443]\n",
            "  [ 0.14652205 -0.25800443]]\n",
            "\n",
            " [[-0.7275276  -0.6472757 ]\n",
            "  [ 0.7275276   0.6472757 ]\n",
            "  [-0.24307418  0.16458464]\n",
            "  [ 0.24307418 -0.16458464]\n",
            "  [ 0.2813511   0.8034985 ]\n",
            "  [-0.2813511  -0.8034985 ]]\n",
            "\n",
            " [[ 0.5167608   0.92162514]\n",
            "  [-0.5167608  -0.92162514]\n",
            "  [-0.8933749   0.5864258 ]\n",
            "  [ 0.8933749  -0.5864258 ]\n",
            "  [-0.65248775  0.37416506]\n",
            "  [ 0.65248775 -0.37416506]]\n",
            "\n",
            " [[-0.00480175 -0.69283795]\n",
            "  [ 0.00480175  0.69283795]\n",
            "  [ 0.66909456  0.23482203]\n",
            "  [-0.66909456 -0.23482203]\n",
            "  [ 0.83711433 -0.14329624]\n",
            "  [-0.83711433  0.14329624]]\n",
            "\n",
            " [[-0.9765785  -0.47640204]\n",
            "  [ 0.9765785   0.47640204]\n",
            "  [ 0.86164093  0.9086697 ]\n",
            "  [-0.86164093 -0.9086697 ]\n",
            "  [-0.8638871  -0.2939868 ]\n",
            "  [ 0.8638871   0.2939868 ]]\n",
            "\n",
            " [[ 0.12277627 -0.43135858]\n",
            "  [-0.12277627  0.43135858]\n",
            "  [ 0.47325563 -0.22016883]\n",
            "  [-0.47325563  0.22016883]\n",
            "  [-0.5392146   0.21975279]\n",
            "  [ 0.5392146  -0.21975279]]\n",
            "\n",
            " [[ 0.12604642 -0.30528092]\n",
            "  [-0.12604642  0.30528092]\n",
            "  [-0.5717902  -0.09196663]\n",
            "  [ 0.5717902   0.09196663]\n",
            "  [-0.9139726   0.47747588]\n",
            "  [ 0.9139726  -0.47747588]]\n",
            "\n",
            " [[-0.00585413  0.09468532]\n",
            "  [ 0.00585413 -0.09468532]\n",
            "  [-0.4763248   0.0575819 ]\n",
            "  [ 0.4763248  -0.0575819 ]\n",
            "  [-0.83493114  0.13461733]\n",
            "  [ 0.83493114 -0.13461733]]\n",
            "\n",
            " [[-0.5822799  -0.09925461]\n",
            "  [ 0.5822799   0.09925461]\n",
            "  [ 0.36095643  0.24177456]\n",
            "  [-0.36095643 -0.24177456]\n",
            "  [-0.2213912   0.02484369]\n",
            "  [ 0.2213912  -0.02484369]]]\n",
            "\n",
            "Primaries After NECL:\n",
            " [[[-0.08651824 -0.08155099]\n",
            "  [ 0.08651824  0.08155099]\n",
            "  [ 0.12853478 -0.0904214 ]\n",
            "  [-0.12853478  0.0904214 ]\n",
            "  [-0.00169329  0.14057688]\n",
            "  [-0.00169329  0.14057688]]\n",
            "\n",
            " [[ 0.03769108 -0.01965856]\n",
            "  [-0.03769108  0.01965856]\n",
            "  [-0.2059519   0.02261003]\n",
            "  [ 0.2059519  -0.02261003]\n",
            "  [-0.26820198 -0.01066513]\n",
            "  [-0.26820198 -0.01066513]]\n",
            "\n",
            " [[ 0.08060984  0.09369796]\n",
            "  [-0.08060984 -0.09369796]\n",
            "  [ 0.16604549  0.06929331]\n",
            "  [-0.16604549 -0.06929331]\n",
            "  [-0.1745159  -0.01760644]\n",
            "  [-0.1745159  -0.01760644]]\n",
            "\n",
            " [[ 0.14532006  0.06156667]\n",
            "  [-0.14532006 -0.06156667]\n",
            "  [-0.13851424  0.12714835]\n",
            "  [ 0.13851424 -0.12714835]\n",
            "  [ 0.11351024  0.0415286 ]\n",
            "  [ 0.11351024  0.0415286 ]]\n",
            "\n",
            " [[-0.23723416 -0.08182137]\n",
            "  [ 0.23723416  0.08182137]\n",
            "  [ 0.07691017  0.0838136 ]\n",
            "  [-0.07691017 -0.0838136 ]\n",
            "  [ 0.00638234 -0.08393451]\n",
            "  [ 0.00638234 -0.08393451]]\n",
            "\n",
            " [[ 0.05410876 -0.08079632]\n",
            "  [-0.05410876  0.08079632]\n",
            "  [-0.21280259  0.16117936]\n",
            "  [ 0.21280259 -0.16117936]\n",
            "  [-0.05467268  0.04672494]\n",
            "  [-0.05467268  0.04672494]]\n",
            "\n",
            " [[-0.10065287 -0.10185575]\n",
            "  [ 0.10065287  0.10185575]\n",
            "  [-0.10031251 -0.04906106]\n",
            "  [ 0.10031251  0.04906106]\n",
            "  [ 0.1286615   0.13184121]\n",
            "  [ 0.1286615   0.13184121]]\n",
            "\n",
            " [[-0.236347    0.0202393 ]\n",
            "  [ 0.236347   -0.0202393 ]\n",
            "  [-0.06383685 -0.00157151]\n",
            "  [ 0.06383685  0.00157151]\n",
            "  [ 0.15543376 -0.11214685]\n",
            "  [ 0.15543376 -0.11214685]]\n",
            "\n",
            " [[-0.09875268 -0.02881775]\n",
            "  [ 0.09875268  0.02881775]\n",
            "  [ 0.01515945 -0.05625867]\n",
            "  [-0.01515945  0.05625867]\n",
            "  [-0.207152    0.18717751]\n",
            "  [-0.207152    0.18717751]]\n",
            "\n",
            " [[-0.09516284 -0.12078737]\n",
            "  [ 0.09516284  0.12078737]\n",
            "  [ 0.08718878 -0.02845525]\n",
            "  [-0.08718878  0.02845525]\n",
            "  [ 0.22730914  0.03472379]\n",
            "  [ 0.22730914  0.03472379]]\n",
            "\n",
            " [[ 0.05389184 -0.09145308]\n",
            "  [-0.05389184  0.09145308]\n",
            "  [-0.19303975  0.15008469]\n",
            "  [ 0.19303975 -0.15008469]\n",
            "  [ 0.02350326 -0.06662108]\n",
            "  [ 0.02350326 -0.06662108]]\n",
            "\n",
            " [[ 0.09110232  0.09687001]\n",
            "  [-0.09110232 -0.09687001]\n",
            "  [ 0.17605513 -0.00751224]\n",
            "  [-0.17605513  0.00751224]\n",
            "  [ 0.09668549  0.11015028]\n",
            "  [ 0.09668549  0.11015028]]\n",
            "\n",
            " [[ 0.19593076  0.09937927]\n",
            "  [-0.19593076 -0.09937927]\n",
            "  [-0.17513883  0.05328215]\n",
            "  [ 0.17513883 -0.05328215]\n",
            "  [ 0.09173165  0.00719546]\n",
            "  [ 0.09173165  0.00719546]]\n",
            "\n",
            " [[-0.23303676  0.08336077]\n",
            "  [ 0.23303676 -0.08336077]\n",
            "  [ 0.10128283  0.095025  ]\n",
            "  [-0.10128283 -0.095025  ]\n",
            "  [ 0.05721907 -0.05331451]\n",
            "  [ 0.05721907 -0.05331451]]\n",
            "\n",
            " [[ 0.09317691 -0.10698745]\n",
            "  [-0.09317691  0.10698745]\n",
            "  [ 0.14479189  0.02146183]\n",
            "  [-0.14479189 -0.02146183]\n",
            "  [ 0.12693442 -0.10800921]\n",
            "  [ 0.12693442 -0.10800921]]\n",
            "\n",
            " [[ 0.07806967  0.01978362]\n",
            "  [-0.07806967 -0.01978362]\n",
            "  [ 0.23980044  0.2072055 ]\n",
            "  [-0.23980044 -0.2072055 ]\n",
            "  [-0.03091006  0.03815331]\n",
            "  [-0.03091006  0.03815331]]\n",
            "\n",
            " [[ 0.04837003  0.12859656]\n",
            "  [-0.04837003 -0.12859656]\n",
            "  [ 0.06489607 -0.07615952]\n",
            "  [-0.06489607  0.07615952]\n",
            "  [ 0.01637339  0.14832574]\n",
            "  [ 0.01637339  0.14832574]]\n",
            "\n",
            " [[-0.15299487 -0.04514651]\n",
            "  [ 0.15299487  0.04514651]\n",
            "  [ 0.2120307   0.1369553 ]\n",
            "  [-0.2120307  -0.1369553 ]\n",
            "  [-0.03758913 -0.04263954]\n",
            "  [-0.03758913 -0.04263954]]\n",
            "\n",
            " [[ 0.15179044  0.10280892]\n",
            "  [-0.15179044 -0.10280892]\n",
            "  [-0.06376604 -0.10143306]\n",
            "  [ 0.06376604  0.10143306]\n",
            "  [ 0.09036848 -0.09085839]\n",
            "  [ 0.09036848 -0.09085839]]\n",
            "\n",
            " [[ 0.07719233  0.10114292]\n",
            "  [-0.07719233 -0.10114292]\n",
            "  [-0.02942906 -0.13220806]\n",
            "  [ 0.02942906  0.13220806]\n",
            "  [-0.12801147  0.08175816]\n",
            "  [-0.12801147  0.08175816]]\n",
            "\n",
            " [[ 0.15730806 -0.01013497]\n",
            "  [-0.15730806  0.01013497]\n",
            "  [-0.02814808 -0.06394704]\n",
            "  [ 0.02814808  0.06394704]\n",
            "  [-0.21361884  0.11836606]\n",
            "  [-0.21361884  0.11836606]]\n",
            "\n",
            " [[ 0.11114985 -0.09216897]\n",
            "  [-0.11114985  0.09216897]\n",
            "  [ 0.01390386  0.09713904]\n",
            "  [-0.01390386 -0.09713904]\n",
            "  [-0.1433267  -0.11320602]\n",
            "  [-0.1433267  -0.11320602]]\n",
            "\n",
            " [[ 0.01237838 -0.10955703]\n",
            "  [-0.01237838  0.10955703]\n",
            "  [ 0.11271149  0.0390918 ]\n",
            "  [-0.11271149 -0.0390918 ]\n",
            "  [ 0.21121733 -0.08523737]\n",
            "  [ 0.21121733 -0.08523737]]\n",
            "\n",
            " [[-0.05602153  0.12364734]\n",
            "  [ 0.05602153 -0.12364734]\n",
            "  [ 0.1679286   0.04432241]\n",
            "  [-0.1679286  -0.04432241]\n",
            "  [ 0.01529749  0.11363086]\n",
            "  [ 0.01529749  0.11363086]]\n",
            "\n",
            " [[ 0.14771698 -0.0342702 ]\n",
            "  [-0.14771698  0.0342702 ]\n",
            "  [-0.03167862 -0.08702099]\n",
            "  [ 0.03167862  0.08702099]\n",
            "  [ 0.19734785  0.09856469]\n",
            "  [ 0.19734785  0.09856469]]\n",
            "\n",
            " [[-0.15920362 -0.09068897]\n",
            "  [ 0.15920362  0.09068897]\n",
            "  [-0.08112147 -0.05390285]\n",
            "  [ 0.08112147  0.05390285]\n",
            "  [-0.13348594  0.11319627]\n",
            "  [-0.13348594  0.11319627]]\n",
            "\n",
            " [[ 0.19696115 -0.12440624]\n",
            "  [-0.19696115  0.12440624]\n",
            "  [ 0.11402708  0.09243529]\n",
            "  [-0.11402708 -0.09243529]\n",
            "  [-0.06865134  0.03725805]\n",
            "  [-0.06865134  0.03725805]]\n",
            "\n",
            " [[ 0.02821466 -0.11353027]\n",
            "  [-0.02821466  0.11353027]\n",
            "  [-0.00493861 -0.10216609]\n",
            "  [ 0.00493861  0.10216609]\n",
            "  [-0.1829183  -0.08212767]\n",
            "  [-0.1829183  -0.08212767]]\n",
            "\n",
            " [[-0.07961683 -0.07722962]\n",
            "  [ 0.07961683  0.07722962]\n",
            "  [-0.02278323 -0.14070572]\n",
            "  [ 0.02278323  0.14070572]\n",
            "  [-0.10983508  0.10863821]\n",
            "  [-0.10983508  0.10863821]]\n",
            "\n",
            " [[-0.012492    0.07309117]\n",
            "  [ 0.012492   -0.07309117]\n",
            "  [ 0.07935682 -0.02816741]\n",
            "  [-0.07935682  0.02816741]\n",
            "  [ 0.23171717 -0.16717395]\n",
            "  [ 0.23171717 -0.16717395]]\n",
            "\n",
            " [[ 0.04821687  0.05099594]\n",
            "  [-0.04821687 -0.05099594]\n",
            "  [ 0.15940596  0.12158637]\n",
            "  [-0.15940596 -0.12158637]\n",
            "  [-0.05723327 -0.13770528]\n",
            "  [-0.05723327 -0.13770528]]\n",
            "\n",
            " [[-0.14997423  0.08362322]\n",
            "  [ 0.14997423 -0.08362322]\n",
            "  [ 0.03475586 -0.10102476]\n",
            "  [-0.03475586  0.10102476]\n",
            "  [-0.13874292 -0.08782627]\n",
            "  [-0.13874292 -0.08782627]]\n",
            "\n",
            " [[ 0.06402041 -0.03324072]\n",
            "  [-0.06402041  0.03324072]\n",
            "  [ 0.21706952 -0.05966392]\n",
            "  [-0.21706952  0.05966392]\n",
            "  [-0.13139382  0.1174361 ]\n",
            "  [-0.13139382  0.1174361 ]]\n",
            "\n",
            " [[ 0.14343607  0.0191183 ]\n",
            "  [-0.14343607 -0.0191183 ]\n",
            "  [-0.03584616 -0.09419575]\n",
            "  [ 0.03584616  0.09419575]\n",
            "  [ 0.18217169  0.11077   ]\n",
            "  [ 0.18217169  0.11077   ]]\n",
            "\n",
            " [[ 0.04614302  0.11844411]\n",
            "  [-0.04614302 -0.11844411]\n",
            "  [ 0.08118708  0.07802987]\n",
            "  [-0.08118708 -0.07802987]\n",
            "  [-0.1373002  -0.1156396 ]\n",
            "  [-0.1373002  -0.1156396 ]]\n",
            "\n",
            " [[-0.21566036 -0.02511192]\n",
            "  [ 0.21566036  0.02511192]\n",
            "  [ 0.21656492  0.00539012]\n",
            "  [-0.21656492 -0.00539012]\n",
            "  [ 0.06829084 -0.0401006 ]\n",
            "  [ 0.06829084 -0.0401006 ]]\n",
            "\n",
            " [[ 0.00070469  0.09327237]\n",
            "  [-0.00070469 -0.09327237]\n",
            "  [-0.04581744  0.13882641]\n",
            "  [ 0.04581744 -0.13882641]\n",
            "  [-0.1711601  -0.05955061]\n",
            "  [-0.1711601  -0.05955061]]\n",
            "\n",
            " [[ 0.01542321  0.06941915]\n",
            "  [-0.01542321 -0.06941915]\n",
            "  [ 0.02409409  0.20089088]\n",
            "  [-0.02409409 -0.20089088]\n",
            "  [ 0.02326728 -0.09743781]\n",
            "  [ 0.02326728 -0.09743781]]\n",
            "\n",
            " [[ 0.12168735 -0.04180654]\n",
            "  [-0.12168735  0.04180654]\n",
            "  [-0.12093478 -0.07010923]\n",
            "  [ 0.12093478  0.07010923]\n",
            "  [ 0.1499871  -0.12563513]\n",
            "  [ 0.1499871  -0.12563513]]\n",
            "\n",
            " [[-0.15879403 -0.07911091]\n",
            "  [ 0.15879403  0.07911091]\n",
            "  [ 0.02442607  0.10012829]\n",
            "  [-0.02442607 -0.10012829]\n",
            "  [ 0.03136138 -0.12988962]\n",
            "  [ 0.03136138 -0.12988962]]\n",
            "\n",
            " [[ 0.13885511  0.16773163]\n",
            "  [-0.13885511 -0.16773163]\n",
            "  [ 0.17592405 -0.04262439]\n",
            "  [-0.17592405  0.04262439]\n",
            "  [-0.05985589  0.01444209]\n",
            "  [-0.05985589  0.01444209]]\n",
            "\n",
            " [[ 0.03674114  0.15803194]\n",
            "  [-0.03674114 -0.15803194]\n",
            "  [ 0.09719278  0.02785196]\n",
            "  [-0.09719278 -0.02785196]\n",
            "  [ 0.18110435  0.04684756]\n",
            "  [ 0.18110435  0.04684756]]\n",
            "\n",
            " [[-0.22283831  0.04427595]\n",
            "  [ 0.22283831 -0.04427595]\n",
            "  [-0.09640903 -0.02588387]\n",
            "  [ 0.09640903  0.02588387]\n",
            "  [ 0.18003    -0.04176806]\n",
            "  [ 0.18003    -0.04176806]]\n",
            "\n",
            " [[ 0.18216188 -0.07028938]\n",
            "  [-0.18216188  0.07028938]\n",
            "  [-0.05455682 -0.03734598]\n",
            "  [ 0.05455682  0.03734598]\n",
            "  [ 0.07297394 -0.16219352]\n",
            "  [ 0.07297394 -0.16219352]]\n",
            "\n",
            " [[ 0.068771   -0.02531795]\n",
            "  [-0.068771    0.02531795]\n",
            "  [ 0.12955883 -0.11843594]\n",
            "  [-0.12955883  0.11843594]\n",
            "  [ 0.22352448  0.0508095 ]\n",
            "  [ 0.22352448  0.0508095 ]]\n",
            "\n",
            " [[ 0.08196791 -0.08716834]\n",
            "  [-0.08196791  0.08716834]\n",
            "  [-0.17210516  0.03870682]\n",
            "  [ 0.17210516 -0.03870682]\n",
            "  [-0.15486546 -0.08443912]\n",
            "  [-0.15486546 -0.08443912]]\n",
            "\n",
            " [[-0.1279015  -0.12217864]\n",
            "  [ 0.1279015   0.12217864]\n",
            "  [-0.13570762 -0.04367715]\n",
            "  [ 0.13570762  0.04367715]\n",
            "  [ 0.16007076 -0.00255802]\n",
            "  [ 0.16007076 -0.00255802]]\n",
            "\n",
            " [[ 0.16844076  0.0222949 ]\n",
            "  [-0.16844076 -0.0222949 ]\n",
            "  [-0.13072066  0.06839214]\n",
            "  [ 0.13072066 -0.06839214]\n",
            "  [-0.17246102 -0.05669008]\n",
            "  [-0.17246102 -0.05669008]]\n",
            "\n",
            " [[-0.09662106 -0.12780459]\n",
            "  [ 0.09662106  0.12780459]\n",
            "  [-0.02143823 -0.11545049]\n",
            "  [ 0.02143823  0.11545049]\n",
            "  [ 0.12623726  0.06319761]\n",
            "  [ 0.12623726  0.06319761]]\n",
            "\n",
            " [[-0.02904088 -0.09684389]\n",
            "  [ 0.02904088  0.09684389]\n",
            "  [-0.20053375  0.05522338]\n",
            "  [ 0.20053375 -0.05522338]\n",
            "  [ 0.12426864  0.0809792 ]\n",
            "  [ 0.12426864  0.0809792 ]]\n",
            "\n",
            " [[-0.03338253  0.03712472]\n",
            "  [ 0.03338253 -0.03712472]\n",
            "  [-0.27034184 -0.02306926]\n",
            "  [ 0.27034184  0.02306926]\n",
            "  [-0.09818397 -0.1145855 ]\n",
            "  [-0.09818397 -0.1145855 ]]\n",
            "\n",
            " [[ 0.09267931 -0.10002052]\n",
            "  [-0.09267931  0.10002052]\n",
            "  [ 0.2997307  -0.01182463]\n",
            "  [-0.2997307   0.01182463]\n",
            "  [ 0.00722232  0.03826474]\n",
            "  [ 0.00722232  0.03826474]]\n",
            "\n",
            " [[-0.1450167  -0.099454  ]\n",
            "  [ 0.1450167   0.099454  ]\n",
            "  [ 0.14805143 -0.07774859]\n",
            "  [-0.14805143  0.07774859]\n",
            "  [ 0.11804365 -0.05022175]\n",
            "  [ 0.11804365 -0.05022175]]\n",
            "\n",
            " [[-0.01882173  0.08408114]\n",
            "  [ 0.01882173 -0.08408114]\n",
            "  [ 0.15721485  0.05028999]\n",
            "  [-0.15721485 -0.05028999]\n",
            "  [-0.12933318  0.13557339]\n",
            "  [-0.12933318  0.13557339]]\n",
            "\n",
            " [[-0.03188305 -0.07157414]\n",
            "  [ 0.03188305  0.07157414]\n",
            "  [ 0.14715585 -0.16043022]\n",
            "  [-0.14715585  0.16043022]\n",
            "  [ 0.14656772  0.01233039]\n",
            "  [ 0.14656772  0.01233039]]\n",
            "\n",
            " [[-0.21943651 -0.00832937]\n",
            "  [ 0.21943651  0.00832937]\n",
            "  [-0.21575381  0.07193745]\n",
            "  [ 0.21575381 -0.07193745]\n",
            "  [-0.03244447  0.04039707]\n",
            "  [-0.03244447  0.04039707]]\n",
            "\n",
            " [[-0.17991383 -0.11318513]\n",
            "  [ 0.17991383  0.11318513]\n",
            "  [ 0.06019465 -0.02881996]\n",
            "  [-0.06019465  0.02881996]\n",
            "  [ 0.06961366  0.14057754]\n",
            "  [ 0.06961366  0.14057754]]\n",
            "\n",
            " [[ 0.09414951  0.11873198]\n",
            "  [-0.09414951 -0.11873198]\n",
            "  [ 0.16272217 -0.07552853]\n",
            "  [-0.16272217  0.07552853]\n",
            "  [-0.11890415  0.04821396]\n",
            "  [-0.11890415  0.04821396]]\n",
            "\n",
            " [[-0.00111857 -0.11412477]\n",
            "  [ 0.00111857  0.11412477]\n",
            "  [-0.15579684 -0.03866295]\n",
            "  [ 0.15579684  0.03866295]\n",
            "  [ 0.1948533  -0.02358538]\n",
            "  [ 0.1948533  -0.02358538]]\n",
            "\n",
            " [[-0.15743867 -0.05430789]\n",
            "  [ 0.15743867  0.05430789]\n",
            "  [-0.13890015 -0.10357797]\n",
            "  [ 0.13890015  0.10357797]\n",
            "  [-0.13930209 -0.03352073]\n",
            "  [-0.13930209 -0.03352073]]\n",
            "\n",
            " [[ 0.04146852 -0.1030214 ]\n",
            "  [-0.04146852  0.1030214 ]\n",
            "  [-0.15975823  0.0525543 ]\n",
            "  [ 0.15975823 -0.0525543 ]\n",
            "  [-0.18198735  0.05244438]\n",
            "  [-0.18198735  0.05244438]]\n",
            "\n",
            " [[ 0.03407806 -0.05836184]\n",
            "  [-0.03407806  0.05836184]\n",
            "  [ 0.15446043  0.01756693]\n",
            "  [-0.15446043 -0.01756693]\n",
            "  [-0.24664268  0.09111115]\n",
            "  [-0.24664268  0.09111115]]\n",
            "\n",
            " [[-0.0021633   0.02474126]\n",
            "  [ 0.0021633  -0.02474126]\n",
            "  [ 0.17576393 -0.01502442]\n",
            "  [-0.17576393  0.01502442]\n",
            "  [-0.307698    0.03508003]\n",
            "  [-0.307698    0.03508003]]\n",
            "\n",
            " [[-0.2443934  -0.02945733]\n",
            "  [ 0.2443934   0.02945733]\n",
            "  [-0.1516133  -0.07180887]\n",
            "  [ 0.1516133   0.07180887]\n",
            "  [-0.09305742  0.007384  ]\n",
            "  [-0.09305742  0.007384  ]]]\n",
            "\n",
            "Pairs[0]:\n",
            " [[-8.6518243e-02 -8.1550986e-02]\n",
            " [ 8.6518243e-02  8.1550986e-02]\n",
            " [ 1.2853478e-01 -9.0421401e-02]\n",
            " [-1.2853478e-01  9.0421401e-02]\n",
            " [-1.6932946e-03  1.4057688e-01]\n",
            " [-1.6932946e-03  1.4057688e-01]\n",
            " [ 4.2016536e-02 -1.7197239e-01]\n",
            " [-1.1120603e-02  7.3739542e-03]\n",
            " [-2.1505302e-01  8.8704154e-03]\n",
            " [ 1.1120603e-02 -7.3739542e-03]\n",
            " [ 2.1505302e-01 -8.8704154e-03]\n",
            " [ 1.1120603e-02 -7.3739542e-03]\n",
            " [-4.2016536e-02  1.7197239e-01]\n",
            " [-1.1120603e-02  7.3739542e-03]\n",
            " [-8.8211536e-02  5.9025899e-02]\n",
            " [ 1.4650087e-04 -1.1464183e-02]\n",
            " [-8.8211536e-02  5.9025899e-02]\n",
            " [ 1.4650087e-04 -1.1464183e-02]\n",
            " [ 8.4824950e-02  2.2212787e-01]\n",
            " [-1.4650087e-04  1.1464183e-02]\n",
            " [ 8.4824950e-02  2.2212787e-01]\n",
            " [-1.4650087e-04  1.1464183e-02]\n",
            " [ 1.2684149e-01  5.0155483e-02]\n",
            " [-2.1764725e-04 -1.2711159e-02]\n",
            " [ 1.2684149e-01  5.0155483e-02]\n",
            " [-2.1764725e-04 -1.2711159e-02]\n",
            " [-1.3022807e-01  2.3099828e-01]\n",
            " [ 2.1764725e-04  1.2711159e-02]\n",
            " [-1.3022807e-01  2.3099828e-01]\n",
            " [ 2.1764725e-04  1.2711159e-02]]\n",
            "\n",
            "Triplets[0]:\n",
            " [[[-8.6518243e-02 -8.1550986e-02]\n",
            "  [ 8.6518243e-02  8.1550986e-02]\n",
            "  [ 1.2853478e-01 -9.0421401e-02]]\n",
            "\n",
            " [[-1.2853478e-01  9.0421401e-02]\n",
            "  [-1.6932946e-03  1.4057688e-01]\n",
            "  [-1.6932946e-03  1.4057688e-01]]\n",
            "\n",
            " [[ 4.2016536e-02 -1.7197239e-01]\n",
            "  [-1.1120603e-02  7.3739542e-03]\n",
            "  [-2.1505302e-01  8.8704154e-03]]\n",
            "\n",
            " [[ 1.1120603e-02 -7.3739542e-03]\n",
            "  [ 2.1505302e-01 -8.8704154e-03]\n",
            "  [ 1.1120603e-02 -7.3739542e-03]]\n",
            "\n",
            " [[-4.2016536e-02  1.7197239e-01]\n",
            "  [-1.1120603e-02  7.3739542e-03]\n",
            "  [-8.8211536e-02  5.9025899e-02]]\n",
            "\n",
            " [[ 1.4650087e-04 -1.1464183e-02]\n",
            "  [-8.8211536e-02  5.9025899e-02]\n",
            "  [ 1.4650087e-04 -1.1464183e-02]]\n",
            "\n",
            " [[ 8.4824950e-02  2.2212787e-01]\n",
            "  [-1.4650087e-04  1.1464183e-02]\n",
            "  [ 8.4824950e-02  2.2212787e-01]]\n",
            "\n",
            " [[-1.4650087e-04  1.1464183e-02]\n",
            "  [ 1.2684149e-01  5.0155483e-02]\n",
            "  [-2.1764725e-04 -1.2711159e-02]]\n",
            "\n",
            " [[ 1.2684149e-01  5.0155483e-02]\n",
            "  [-2.1764725e-04 -1.2711159e-02]\n",
            "  [-1.3022807e-01  2.3099828e-01]]\n",
            "\n",
            " [[ 2.1764725e-04  1.2711159e-02]\n",
            "  [-1.3022807e-01  2.3099828e-01]\n",
            "  [ 2.1764725e-04  1.2711159e-02]]]\n",
            "\n",
            "Bits (all qubits):\n",
            " [[1 1 1 ... 1 1 1]\n",
            " [1 0 1 ... 0 0 1]\n",
            " [1 0 0 ... 1 0 0]\n",
            " ...\n",
            " [1 0 0 ... 1 0 0]\n",
            " [0 1 0 ... 0 1 0]\n",
            " [0 1 1 ... 0 1 1]]\n",
            "\n",
            "Primaries Out (promoted):\n",
            " [[[ 2.17647248e-04  1.27111590e-02]\n",
            "  [-2.17647248e-04 -1.27111590e-02]\n",
            "  [-1.30228072e-01  2.30998278e-01]\n",
            "  [ 1.30228072e-01 -2.30998278e-01]\n",
            "  [ 2.17647248e-04  1.27111590e-02]\n",
            "  [-2.17647248e-04 -1.27111590e-02]]\n",
            "\n",
            " [[-5.52367084e-02  2.41138987e-04]\n",
            "  [ 5.52367084e-02 -2.41138987e-04]\n",
            "  [-6.22500777e-02 -3.32751647e-02]\n",
            "  [ 6.22500777e-02  3.32751647e-02]\n",
            "  [-5.52367084e-02  2.41138987e-04]\n",
            "  [ 5.52367084e-02 -2.41138987e-04]]\n",
            "\n",
            " [[ 2.89775785e-02  1.22000871e-03]\n",
            "  [-2.89775785e-02 -1.22000871e-03]\n",
            "  [-3.40561390e-01 -8.68997499e-02]\n",
            "  [ 3.40561390e-01  8.68997499e-02]\n",
            "  [ 2.89775785e-02  1.22000871e-03]\n",
            "  [-2.89775785e-02 -1.22000871e-03]]\n",
            "\n",
            " [[ 1.57227833e-02 -5.28029259e-03]\n",
            "  [-1.57227833e-02  5.28029259e-03]\n",
            "  [ 2.52024472e-01 -8.56197476e-02]\n",
            "  [-2.52024472e-01  8.56197476e-02]\n",
            "  [ 1.57227833e-02 -5.28029259e-03]\n",
            "  [-1.57227833e-02  5.28029259e-03]]\n",
            "\n",
            " [[-4.90867125e-04  7.03485310e-03]\n",
            "  [ 4.90867125e-04 -7.03485310e-03]\n",
            "  [-7.05278218e-02 -1.67748109e-01]\n",
            "  [ 7.05278218e-02  1.67748109e-01]\n",
            "  [-4.90867125e-04  7.03485310e-03]\n",
            "  [ 4.90867125e-04 -7.03485310e-03]]\n",
            "\n",
            " [[-1.16344877e-02 -7.53109623e-03]\n",
            "  [ 1.16344877e-02  7.53109623e-03]\n",
            "  [ 1.58129901e-01 -1.14454418e-01]\n",
            "  [-1.58129901e-01  1.14454418e-01]\n",
            "  [-1.16344877e-02 -7.53109623e-03]\n",
            "  [ 1.16344877e-02  7.53109623e-03]]\n",
            "\n",
            " [[ 1.29063576e-02  6.46826904e-03]\n",
            "  [-1.29063576e-02 -6.46826904e-03]\n",
            "  [ 2.28974015e-01  1.80902272e-01]\n",
            "  [-2.28974015e-01 -1.80902272e-01]\n",
            "  [ 1.29063576e-02  6.46826904e-03]\n",
            "  [-1.29063576e-02 -6.46826904e-03]]\n",
            "\n",
            " [[ 9.92240198e-03 -1.76240414e-04]\n",
            "  [-9.92240198e-03  1.76240414e-04]\n",
            "  [ 2.19270617e-01 -1.10575341e-01]\n",
            "  [-2.19270617e-01  1.10575341e-01]\n",
            "  [ 9.92240198e-03 -1.76240414e-04]\n",
            "  [-9.92240198e-03  1.76240414e-04]]\n",
            "\n",
            " [[ 3.14031076e-03  1.05303572e-02]\n",
            "  [-3.14031076e-03 -1.05303572e-02]\n",
            "  [-2.22311452e-01  2.43436173e-01]\n",
            "  [ 2.22311452e-01 -2.43436173e-01]\n",
            "  [ 3.14031076e-03  1.05303572e-02]\n",
            "  [-3.14031076e-03 -1.05303572e-02]]\n",
            "\n",
            " [[-1.98188070e-02  9.88074346e-04]\n",
            "  [ 1.98188070e-02 -9.88074346e-04]\n",
            "  [ 1.40120357e-01  6.31790459e-02]\n",
            "  [-1.40120357e-01 -6.31790459e-02]\n",
            "  [-1.98188070e-02  9.88074346e-04]\n",
            "  [ 1.98188070e-02 -9.88074346e-04]]\n",
            "\n",
            " [[ 4.53706272e-03  9.99880396e-03]\n",
            "  [-4.53706272e-03 -9.99880396e-03]\n",
            "  [ 2.16543004e-01 -2.16705769e-01]\n",
            "  [-2.16543004e-01  2.16705769e-01]\n",
            "  [ 4.53706272e-03  9.99880396e-03]\n",
            "  [-4.53706272e-03 -9.99880396e-03]]\n",
            "\n",
            " [[-1.70219764e-02  8.27475858e-04]\n",
            "  [ 1.70219764e-02 -8.27475858e-04]\n",
            "  [-7.93696418e-02  1.17662519e-01]\n",
            "  [ 7.93696418e-02 -1.17662519e-01]\n",
            "  [-1.70219764e-02  8.27475858e-04]\n",
            "  [ 1.70219764e-02 -8.27475858e-04]]\n",
            "\n",
            " [[ 1.60657745e-02 -3.83389444e-04]\n",
            "  [-1.60657745e-02  3.83389444e-04]\n",
            "  [ 2.66870499e-01 -4.60866913e-02]\n",
            "  [-2.66870499e-01  4.60866913e-02]\n",
            "  [ 1.60657745e-02 -3.83389444e-04]\n",
            "  [-1.60657745e-02  3.83389444e-04]]\n",
            "\n",
            " [[-5.79530885e-03  5.06621134e-03]\n",
            "  [ 5.79530885e-03 -5.06621134e-03]\n",
            "  [-4.40637618e-02 -1.48339510e-01]\n",
            "  [ 4.40637618e-02  1.48339510e-01]\n",
            "  [-5.79530885e-03  5.06621134e-03]\n",
            "  [ 5.79530885e-03 -5.06621134e-03]]\n",
            "\n",
            " [[-1.83790755e-02  2.31807563e-03]\n",
            "  [ 1.83790755e-02 -2.31807563e-03]\n",
            "  [-1.78574622e-02 -1.29471049e-01]\n",
            "  [ 1.78574622e-02  1.29471049e-01]\n",
            "  [-1.83790755e-02  2.31807563e-03]\n",
            "  [ 1.83790755e-02 -2.31807563e-03]]\n",
            "\n",
            " [[ 7.41224596e-03 -7.90557452e-03]\n",
            "  [-7.41224596e-03  7.90557452e-03]\n",
            "  [-2.70710498e-01 -1.69052199e-01]\n",
            "  [ 2.70710498e-01  1.69052199e-01]\n",
            "  [ 7.41224596e-03 -7.90557452e-03]\n",
            "  [-7.41224596e-03  7.90557452e-03]]\n",
            "\n",
            " [[-1.06256874e-03  1.12964176e-02]\n",
            "  [ 1.06256874e-03 -1.12964176e-02]\n",
            "  [-4.85226773e-02  2.24485263e-01]\n",
            "  [ 4.85226773e-02 -2.24485263e-01]\n",
            "  [-1.06256874e-03  1.12964176e-02]\n",
            "  [ 1.06256874e-03 -1.12964176e-02]]\n",
            "\n",
            " [[ 7.97004905e-03  5.83971152e-03]\n",
            "  [-7.97004905e-03 -5.83971152e-03]\n",
            "  [-2.49619827e-01 -1.79594845e-01]\n",
            "  [ 2.49619827e-01  1.79594845e-01]\n",
            "  [ 7.97004905e-03  5.83971152e-03]\n",
            "  [-7.97004905e-03 -5.83971152e-03]]\n",
            "\n",
            " [[ 5.76244015e-03 -9.21604503e-03]\n",
            "  [-5.76244015e-03  9.21604503e-03]\n",
            "  [ 1.54134512e-01  1.05746686e-02]\n",
            "  [-1.54134512e-01 -1.05746686e-02]\n",
            "  [ 5.76244015e-03 -9.21604503e-03]\n",
            "  [-5.76244015e-03  9.21604503e-03]]\n",
            "\n",
            " [[-3.76725756e-03  1.08090881e-02]\n",
            "  [ 3.76725756e-03 -1.08090881e-02]\n",
            "  [-9.85824019e-02  2.13966221e-01]\n",
            "  [ 9.85824019e-02 -2.13966221e-01]\n",
            "  [-3.76725756e-03  1.08090881e-02]\n",
            "  [ 3.76725756e-03 -1.08090881e-02]]\n",
            "\n",
            " [[-6.01295941e-03  7.56915845e-03]\n",
            "  [ 6.01295941e-03 -7.56915845e-03]\n",
            "  [-1.85470775e-01  1.82313085e-01]\n",
            "  [ 1.85470775e-01 -1.82313085e-01]\n",
            "  [-6.01295941e-03  7.56915845e-03]\n",
            "  [ 6.01295941e-03 -7.56915845e-03]]\n",
            "\n",
            " [[ 1.99279399e-03  1.09967245e-02]\n",
            "  [-1.99279399e-03 -1.09967245e-02]\n",
            "  [-1.57230556e-01 -2.10345060e-01]\n",
            "  [ 1.57230556e-01  2.10345060e-01]\n",
            "  [ 1.99279399e-03  1.09967245e-02]\n",
            "  [-1.99279399e-03 -1.09967245e-02]]\n",
            "\n",
            " [[-2.38066204e-02  3.33208172e-03]\n",
            "  [ 2.38066204e-02 -3.33208172e-03]\n",
            "  [ 9.85058397e-02 -1.24329165e-01]\n",
            "  [-9.85058397e-02  1.24329165e-01]\n",
            "  [-2.38066204e-02  3.33208172e-03]\n",
            "  [ 2.38066204e-02 -3.33208172e-03]]\n",
            "\n",
            " [[-2.56888685e-03 -5.03639411e-03]\n",
            "  [ 2.56888685e-03  5.03639411e-03]\n",
            "  [-1.52631119e-01  6.93084449e-02]\n",
            "  [ 1.52631119e-01 -6.93084449e-02]\n",
            "  [-2.56888685e-03 -5.03639411e-03]\n",
            "  [ 2.56888685e-03  5.03639411e-03]]\n",
            "\n",
            " [[ 6.25170860e-03  8.57719779e-03]\n",
            "  [-6.25170860e-03 -8.57719779e-03]\n",
            "  [ 2.29026467e-01  1.85585678e-01]\n",
            "  [-2.29026467e-01 -1.85585678e-01]\n",
            "  [ 6.25170860e-03  8.57719779e-03]\n",
            "  [-6.25170860e-03 -8.57719779e-03]]\n",
            "\n",
            " [[-1.08285770e-02  6.10160176e-03]\n",
            "  [ 1.08285770e-02 -6.10160176e-03]\n",
            "  [-5.23644686e-02  1.67099118e-01]\n",
            "  [ 5.23644686e-02 -1.67099118e-01]\n",
            "  [-1.08285770e-02  6.10160176e-03]\n",
            "  [ 1.08285770e-02 -6.10160176e-03]]\n",
            "\n",
            " [[ 7.82811176e-03 -3.44395824e-03]\n",
            "  [-7.82811176e-03  3.44395824e-03]\n",
            "  [-1.82678416e-01 -5.51772378e-02]\n",
            "  [ 1.82678416e-01  5.51772378e-02]\n",
            "  [ 7.82811176e-03 -3.44395824e-03]\n",
            "  [-7.82811176e-03  3.44395824e-03]]\n",
            "\n",
            " [[-9.03362292e-04 -8.39066226e-03]\n",
            "  [ 9.03362292e-04  8.39066226e-03]\n",
            "  [-1.77979678e-01  2.00384185e-02]\n",
            "  [ 1.77979678e-01 -2.00384185e-02]\n",
            "  [-9.03362292e-04 -8.39066226e-03]\n",
            "  [ 9.03362292e-04  8.39066226e-03]]\n",
            "\n",
            " [[-2.50239833e-03  1.52860181e-02]\n",
            "  [ 2.50239833e-03 -1.52860181e-02]\n",
            "  [-8.70518461e-02  2.49343932e-01]\n",
            "  [ 8.70518461e-02 -2.49343932e-01]\n",
            "  [-2.50239833e-03  1.52860181e-02]\n",
            "  [ 2.50239833e-03 -1.52860181e-02]]\n",
            "\n",
            " [[-1.83883384e-02 -4.70885774e-03]\n",
            "  [ 1.83883384e-02  4.70885774e-03]\n",
            "  [ 1.52360350e-01 -1.39006540e-01]\n",
            "  [-1.52360350e-01  1.39006540e-01]\n",
            "  [-1.83883384e-02 -4.70885774e-03]\n",
            "  [ 1.83883384e-02  4.70885774e-03]]\n",
            "\n",
            " [[ 9.12332442e-03  1.67430863e-02]\n",
            "  [-9.12332442e-03 -1.67430863e-02]\n",
            "  [-2.16639236e-01 -2.59291649e-01]\n",
            "  [ 2.16639236e-01  2.59291649e-01]\n",
            "  [ 9.12332442e-03  1.67430863e-02]\n",
            "  [-9.12332442e-03 -1.67430863e-02]]\n",
            "\n",
            " [[ 4.82213032e-03 -8.87262728e-03]\n",
            "  [-4.82213032e-03  8.87262728e-03]\n",
            "  [-1.73498780e-01  1.31984949e-02]\n",
            "  [ 1.73498780e-01 -1.31984949e-02]\n",
            "  [ 4.82213032e-03 -8.87262728e-03]\n",
            "  [-4.82213032e-03  8.87262728e-03]]\n",
            "\n",
            " [[ 2.85215937e-02  7.00669782e-03]\n",
            "  [-2.85215937e-02 -7.00669782e-03]\n",
            "  [-3.48463356e-01  1.77100018e-01]\n",
            "  [ 3.48463356e-01 -1.77100018e-01]\n",
            "  [ 2.85215937e-02  7.00669782e-03]\n",
            "  [-2.85215937e-02 -7.00669782e-03]]\n",
            "\n",
            " [[ 6.53015543e-03  1.04340632e-02]\n",
            "  [-6.53015543e-03 -1.04340632e-02]\n",
            "  [ 2.18017846e-01  2.04965740e-01]\n",
            "  [-2.18017846e-01 -2.04965740e-01]\n",
            "  [ 6.53015543e-03  1.04340632e-02]\n",
            "  [-6.53015543e-03 -1.04340632e-02]]\n",
            "\n",
            " [[ 1.11470018e-02  9.02334321e-03]\n",
            "  [-1.11470018e-02 -9.02334321e-03]\n",
            "  [-2.18487263e-01 -1.93669468e-01]\n",
            "  [ 2.18487263e-01  1.93669468e-01]\n",
            "  [ 1.11470018e-02  9.02334321e-03]\n",
            "  [-1.11470018e-02 -9.02334321e-03]]\n",
            "\n",
            " [[-1.47893997e-02  2.16147222e-04]\n",
            "  [ 1.47893997e-02 -2.16147222e-04]\n",
            "  [-1.48274094e-01 -4.54907268e-02]\n",
            "  [ 1.48274094e-01  4.54907268e-02]\n",
            "  [-1.47893997e-02  2.16147222e-04]\n",
            "  [ 1.47893997e-02 -2.16147222e-04]]\n",
            "\n",
            " [[-7.84211792e-03  8.26719776e-03]\n",
            "  [ 7.84211792e-03 -8.26719776e-03]\n",
            "  [-1.25342667e-01 -1.98377028e-01]\n",
            "  [ 1.25342667e-01  1.98377028e-01]\n",
            "  [-7.84211792e-03  8.26719776e-03]\n",
            "  [ 7.84211792e-03 -8.26719776e-03]]\n",
            "\n",
            " [[-5.60604036e-04  1.95743665e-02]\n",
            "  [ 5.60604036e-04 -1.95743665e-02]\n",
            "  [-8.26813281e-04 -2.98328698e-01]\n",
            "  [ 8.26813281e-04  2.98328698e-01]\n",
            "  [-5.60604036e-04  1.95743665e-02]\n",
            "  [ 5.60604036e-04 -1.95743665e-02]]\n",
            "\n",
            " [[ 1.81386583e-02 -8.80818162e-03]\n",
            "  [-1.81386583e-02  8.80818162e-03]\n",
            "  [ 2.70921886e-01 -5.55259064e-02]\n",
            "  [-2.70921886e-01  5.55259064e-02]\n",
            "  [ 1.81386583e-02 -8.80818162e-03]\n",
            "  [-1.81386583e-02  8.80818162e-03]]\n",
            "\n",
            " [[-7.66035169e-04  1.30056264e-02]\n",
            "  [ 7.66035169e-04 -1.30056264e-02]\n",
            "  [ 6.93530403e-03 -2.30017915e-01]\n",
            "  [-6.93530403e-03  2.30017915e-01]\n",
            "  [-7.66035169e-04  1.30056264e-02]\n",
            "  [ 7.66035169e-04 -1.30056264e-02]]\n",
            "\n",
            " [[ 1.05300900e-02  6.15585188e-04]\n",
            "  [-1.05300900e-02 -6.15585188e-04]\n",
            "  [-2.35779941e-01  5.70664778e-02]\n",
            "  [ 2.35779941e-01 -5.70664778e-02]\n",
            "  [ 1.05300900e-02  6.15585188e-04]\n",
            "  [-1.05300900e-02 -6.15585188e-04]]\n",
            "\n",
            " [[-1.76020339e-02 -1.30479608e-03]\n",
            "  [ 1.76020339e-02  1.30479608e-03]\n",
            "  [ 8.39115679e-02  1.89955998e-02]\n",
            "  [-8.39115679e-02 -1.89955998e-02]\n",
            "  [-1.76020339e-02 -1.30479608e-03]\n",
            "  [ 1.76020339e-02  1.30479608e-03]]\n",
            "\n",
            " [[ 1.73565187e-02 -1.08111906e-03]\n",
            "  [-1.73565187e-02  1.08111906e-03]\n",
            "  [ 2.76439041e-01 -1.58841815e-02]\n",
            "  [-2.76439041e-01  1.58841815e-02]\n",
            "  [ 1.73565187e-02 -1.08111906e-03]\n",
            "  [-1.73565187e-02  1.08111906e-03]]\n",
            "\n",
            " [[ 3.98122612e-03 -6.05727639e-03]\n",
            "  [-3.98122612e-03  6.05727639e-03]\n",
            "  [ 1.27530754e-01 -1.24847539e-01]\n",
            "  [-1.27530754e-01  1.24847539e-01]\n",
            "  [ 3.98122612e-03 -6.05727639e-03]\n",
            "  [-3.98122612e-03  6.05727639e-03]]\n",
            "\n",
            " [[-2.89595705e-02  6.01767050e-03]\n",
            "  [ 2.89595705e-02 -6.01767050e-03]\n",
            "  [ 9.39656496e-02  1.69245437e-01]\n",
            "  [-9.39656496e-02 -1.69245437e-01]\n",
            "  [-2.89595705e-02  6.01767050e-03]\n",
            "  [ 2.89595705e-02 -6.01767050e-03]]\n",
            "\n",
            " [[-2.66531445e-02  3.26836994e-03]\n",
            "  [ 2.66531445e-02 -3.26836994e-03]\n",
            "  [ 1.72397047e-02 -1.23145938e-01]\n",
            "  [-1.72397047e-02  1.23145938e-01]\n",
            "  [-2.66531445e-02  3.26836994e-03]\n",
            "  [ 2.66531445e-02 -3.26836994e-03]]\n",
            "\n",
            " [[ 2.17228215e-02 -1.11727088e-04]\n",
            "  [-2.17228215e-02  1.11727088e-04]\n",
            "  [ 2.95778394e-01  4.11191285e-02]\n",
            "  [-2.95778394e-01 -4.11191285e-02]\n",
            "  [ 2.17228215e-02 -1.11727088e-04]\n",
            "  [-2.17228215e-02  1.11727088e-04]]\n",
            "\n",
            " [[-2.25442182e-02  3.87715595e-03]\n",
            "  [ 2.25442182e-02 -3.87715595e-03]\n",
            "  [-4.17403579e-02 -1.25082225e-01]\n",
            "  [ 4.17403579e-02  1.25082225e-01]\n",
            "  [-2.25442182e-02  3.87715595e-03]\n",
            "  [ 2.25442182e-02 -3.87715595e-03]]\n",
            "\n",
            " [[ 2.70630280e-03  7.29619479e-03]\n",
            "  [-2.70630280e-03 -7.29619479e-03]\n",
            "  [ 1.47675484e-01  1.78648099e-01]\n",
            "  [-1.47675484e-01 -1.78648099e-01]\n",
            "  [ 2.70630280e-03  7.29619479e-03]\n",
            "  [-2.70630280e-03 -7.29619479e-03]]\n",
            "\n",
            " [[ 2.49200556e-02 -4.47194465e-03]\n",
            "  [-2.49200556e-02  4.47194465e-03]\n",
            "  [ 3.24802399e-01  2.57558227e-02]\n",
            "  [-3.24802399e-01 -2.57558227e-02]\n",
            "  [ 2.49200556e-02 -4.47194465e-03]\n",
            "  [-2.49200556e-02  4.47194465e-03]]\n",
            "\n",
            " [[-2.65432354e-02 -2.64340267e-03]\n",
            "  [ 2.65432354e-02  2.64340267e-03]\n",
            "  [ 1.72157884e-01 -9.15162414e-02]\n",
            "  [-1.72157884e-01  9.15162414e-02]\n",
            "  [-2.65432354e-02 -2.64340267e-03]\n",
            "  [ 2.65432354e-02  2.64340267e-03]]\n",
            "\n",
            " [[-2.16475013e-03  4.52466280e-04]\n",
            "  [ 2.16475013e-03 -4.52466280e-04]\n",
            "  [-2.92508364e-01  5.00893705e-02]\n",
            "  [ 2.92508364e-01 -5.00893705e-02]\n",
            "  [-2.16475013e-03  4.52466280e-04]\n",
            "  [ 2.16475013e-03 -4.52466280e-04]]\n",
            "\n",
            " [[-1.74765307e-02 -3.90467048e-03]\n",
            "  [ 1.74765307e-02  3.90467048e-03]\n",
            "  [-3.00077721e-02  2.75268368e-02]\n",
            "  [ 3.00077721e-02 -2.75268368e-02]\n",
            "  [-1.74765307e-02 -3.90467048e-03]\n",
            "  [ 1.74765307e-02  3.90467048e-03]]\n",
            "\n",
            " [[ 2.03330964e-02 -6.81798393e-03]\n",
            "  [-2.03330964e-02  6.81798393e-03]\n",
            "  [-2.86548018e-01  8.52833986e-02]\n",
            "  [ 2.86548018e-01 -8.52833986e-02]\n",
            "  [ 2.03330964e-02 -6.81798393e-03]\n",
            "  [-2.03330964e-02  6.81798393e-03]]\n",
            "\n",
            " [[-2.15682965e-02  1.97816687e-03]\n",
            "  [ 2.15682965e-02 -1.97816687e-03]\n",
            "  [-5.88133931e-04  1.72760606e-01]\n",
            "  [ 5.88133931e-04 -1.72760606e-01]\n",
            "  [-2.15682965e-02  1.97816687e-03]\n",
            "  [ 2.15682965e-02 -1.97816687e-03]]\n",
            "\n",
            " [[-7.00001791e-03 -2.90606217e-03]\n",
            "  [ 7.00001791e-03  2.90606217e-03]\n",
            "  [ 1.83309346e-01 -3.15403789e-02]\n",
            "  [-1.83309346e-01  3.15403789e-02]\n",
            "  [-7.00001791e-03 -2.90606217e-03]\n",
            "  [ 7.00001791e-03  2.90606217e-03]]\n",
            "\n",
            " [[-4.19036951e-03  4.05143853e-03]\n",
            "  [ 4.19036951e-03 -4.05143853e-03]\n",
            "  [ 9.41901281e-03  1.69397503e-01]\n",
            "  [-9.41901281e-03 -1.69397503e-01]\n",
            "  [-4.19036951e-03  4.05143853e-03]\n",
            "  [ 4.19036951e-03 -4.05143853e-03]]\n",
            "\n",
            " [[ 1.93483420e-02  3.64152971e-03]\n",
            "  [-1.93483420e-02 -3.64152971e-03]\n",
            "  [-2.81626314e-01  1.23742491e-01]\n",
            "  [ 2.81626314e-01 -1.23742491e-01]\n",
            "  [ 1.93483420e-02  3.64152971e-03]\n",
            "  [-1.93483420e-02 -3.64152971e-03]]\n",
            "\n",
            " [[ 3.03575303e-02 -9.11880226e-04]\n",
            "  [-3.03575303e-02  9.11880226e-04]\n",
            "  [ 3.50650132e-01  1.50775760e-02]\n",
            "  [-3.50650132e-01 -1.50775760e-02]\n",
            "  [ 3.03575303e-02 -9.11880226e-04]\n",
            "  [-3.03575303e-02  9.11880226e-04]]\n",
            "\n",
            " [[-1.93490814e-02 -3.47200898e-03]\n",
            "  [ 1.93490814e-02  3.47200898e-03]\n",
            "  [-4.01943922e-04  7.00572431e-02]\n",
            "  [ 4.01943922e-04 -7.00572431e-02]\n",
            "  [-1.93490814e-02 -3.47200898e-03]\n",
            "  [ 1.93490814e-02  3.47200898e-03]]\n",
            "\n",
            " [[-2.90739760e-02 -2.75617791e-03]\n",
            "  [ 2.90739760e-02  2.75617791e-03]\n",
            "  [-2.22291201e-02 -1.09918416e-04]\n",
            "  [ 2.22291201e-02  1.09918416e-04]\n",
            "  [-2.90739760e-02 -2.75617791e-03]\n",
            "  [ 2.90739760e-02  2.75617791e-03]]\n",
            "\n",
            " [[ 3.80965360e-02 -1.60054292e-03]\n",
            "  [-3.80965360e-02  1.60054292e-03]\n",
            "  [-4.01103109e-01  7.35442266e-02]\n",
            "  [ 4.01103109e-01 -7.35442266e-02]\n",
            "  [ 3.80965360e-02 -1.60054292e-03]\n",
            "  [-3.80965360e-02  1.60054292e-03]]\n",
            "\n",
            " [[ 5.40822148e-02  5.27056982e-04]\n",
            "  [-5.40822148e-02 -5.27056982e-04]\n",
            "  [-4.83461946e-01  5.01044467e-02]\n",
            "  [ 4.83461946e-01 -5.01044467e-02]\n",
            "  [ 5.40822148e-02  5.27056982e-04]\n",
            "  [-5.40822148e-02 -5.27056982e-04]]\n",
            "\n",
            " [[-1.41087417e-02  5.30236866e-04]\n",
            "  [ 1.41087417e-02 -5.30236866e-04]\n",
            "  [ 5.85558787e-02  7.91928768e-02]\n",
            "  [-5.85558787e-02 -7.91928768e-02]\n",
            "  [-1.41087417e-02  5.30236866e-04]\n",
            "  [ 1.41087417e-02 -5.30236866e-04]]]\n",
            "\n",
            "Nth Identities (Conceptual, per qubit):\n",
            "\n",
            "  Qubit 0:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.01711868 0.99977475]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 1:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99997234  0.00436544]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 2:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9990804 0.0420631]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 3:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9479117  -0.31834382]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 4:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.06959735  0.99743307]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 5:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8394142  -0.54335946]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 6:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.89394677 0.44801858]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 7:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99974155 -0.01775728]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 8:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.28575218 0.95820856]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 9:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9987092   0.04979104]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 10:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.41317287 0.9105526 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 11:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99876183  0.04855202]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 12:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9996532  -0.02385546]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 13:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.7527804   0.65807444]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 14:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9920863   0.12512767]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 15:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.6839158  -0.72943443]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 16:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.09364082  0.9955175 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 17:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.80656415 0.5909753 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 18:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.53010976 -0.8478206 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 19:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.32908213  0.9442088 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 20:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.6219546   0.78292114]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 21:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.17829688 0.9838858 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 22:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99030536  0.13860759]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 23:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.45429146 -0.89065456]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 24:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.588963  0.8080434]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 25:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8711433  0.490865 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 26:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.91522574 -0.40265128]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 27:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.10703152 -0.9941364 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 28:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.16154414  0.9868001 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 29:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9686901  -0.24806069]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 30:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.47845235 0.8780538 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 31:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.4774699 -0.8785354]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 32:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9710924  0.23856139]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 33:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.5304737 0.8476055]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 34:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.777205  0.6291367]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 35:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9998256   0.01461246]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 36:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.68814826  0.72544914]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 37:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.0286265  0.9995391]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 38:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.89950293 -0.43680108]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 39:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.05879387  0.99819326]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 40:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99820095 0.05835446]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 41:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9972073  -0.07392056]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 42:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9980083  -0.06216487]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 43:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.5491725 -0.835544 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 44:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9790523   0.20344272]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 45:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9925282   0.12170982]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 46:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99994075 -0.005143  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 47:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9854885   0.16948436]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 48:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.3477226 0.9374604]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 49:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9842384  -0.17662318]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 50:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99504036 -0.09909464]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 51:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.97840446  0.20450167]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 52:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.97588366 -0.21803549]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 53:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.94807404 -0.31790307]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 54:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99577445  0.09132887]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 55:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9234515 -0.3833715]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 56:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.7188009  0.6949692]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 57:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9826959  0.18495208]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 58:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99951625 -0.03002349]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 59:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.98422915 -0.17661057]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 60:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9955026  -0.09437244]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 61:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9990925  -0.04197469]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 62:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.999934   0.00974483]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 63:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9992237   0.03755298]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "\n",
            "Info-energy Output (all qubits):\n",
            " [ 9.092629   5.293044   8.32954    6.720595   5.942907   7.071164\n",
            "  8.062402   9.900666  11.753969   7.4687233  7.922216   6.865246\n",
            "  6.353934   4.8287425  6.590342   7.1021895  8.493172  11.77414\n",
            "  6.3403873  8.627653  10.0155945  7.940031   6.8500733  4.873583\n",
            " 10.468583   4.5809126  7.431211   5.725212   8.64826    8.860287\n",
            " 13.281279   4.390598  16.08764   12.076212   7.059799   6.9651175\n",
            "  8.829386  11.024874   7.847007   5.918664  10.462877   2.9740098\n",
            " 11.024635   4.8496957  9.871372   5.3837485  8.3960705  7.038787\n",
            "  9.199932  11.660518   5.247177  11.696674   2.7625215 12.5483465\n",
            "  8.372878   4.871544   5.3504353 10.72646   12.988567   3.8894632\n",
            "  3.0953417 17.577503  14.871183   3.7237785]\n",
            "\n",
            "Resonance Keys (all qubits):\n",
            " ['00a659450010d9c1fe3b45d3754283108d8d1c866f3d34baeae9930b673d3234', '81a8c4bdd86204ff9ce80b0a53888da564a39213c641e24661a238438411de39', 'a2f409e798c50a43af0fcfa58af1bc8a71b1bbeeb62f9df8894720c042c15e5b', '66fe83faaf5680d79225711d108d35943c43f115e8cc0a9855df7ee799361056', '286921d6788c4088eeb397bc8375a7dc6069412dd099eed1c37f6d5c47a002b4', 'd58f70c72a031d85e9bbeb29b806ad897e4dc61a27f1c75cbf45662036a0e707', '3ba962c9c51b910a39d6ce544df25485e56796839b30c2b8a23cf1fc4195c637', 'ef1b0df388eddc144e9671007f1f3e5ac6da9aea9d21b4e86f4d087e1ba0e9b1', 'bccd119de0086172be44c71c64949a7721d25117ec9716f321450c1cc9a1d8d3', '8f48d3fae88cc86199db25254c2142046067c39c23006d1114867059e6037be8', '0b6b275313a9df6a8480cf726f0c795dc949bfd46e447299b239e87e4c242be6', 'd881d870c3e0ad1020ad7e156a8b0f60601f7c9203e5cb2daf0fef860ef6a554', 'b024f6d05873165986fb38ac7c0af303e581a08df9360018d183b08b9402276c', 'e6e8d9f4c8c27a915b699c3001fe5fe690cdef1123631ba9d2fbdefe398cbeb1', 'f53bf68b354a0947ffcf62c00ba227e84bdb1e3610405cf6ed2ac435878adb95', '2c75402c954f3d32109a10a371378efba0ab9e1a239c8885a7c53c91962ade24', 'b02014c0829fda624f57bac74008324125121ac011f952c9f5f7103a5fd96817', '1901a512b2cfbec1173a331739c2b3d76d1c96c8a6ec6364e7e7e27fba85ef49', 'cee4b066ced81e48fd27eddaeec791327c0fdda1d7b12d141b6e38fe1a2db5ec', '477f7e573ae8f84766d3a8fbfa83d945b25174133a50973f494f014c16ce60b8', '9637986ef34caca21452d68dc14e0d97b54f8cae85272f1ee3a8c49728401b32', '72da45e5c6fb64d9e239708b50a8835b6fd30f16a364d23606acd96d06e002e2', 'feca923fde6a9609bc125a8e57c10e4b5a915a885a0be280070384de68e7b783', '5dcc2df93b640eaaca5f4b56d82e7cc2d8dde9a5c8582ccd5dc153a6c0952595', '188b245f570e5cc6c66bef3c02502fec1e2ceba3062a6a7f273ed007e53d385a', '4edaab4ae25fd9ca612dc09f55c2a354ae4e403646a8ade6cc2407ac34d60824', 'cd713eca5728613aae7ef6b1dd72379217af76fa8a71951117b0bf9cd6ce0fbe', '9ed54251624b63b9cf2ef75cd1fd276587450c9c6b3633dcc63ec24e7c92500e', '6e30654138b2aa3c8aee93f575d534b92b02b358b2d2d54395ee08f826e3122c', '0325927eba95f508eb58eff9319b749b3daa58d622cdae28b02f3cc9a2527817', '3fba018d4980e0bd9522978739d676ff5fff0fdeb7f467ba2b6865515689b341', '98b37001165631163f6c71d1465cf93a7a74969c14c5eddefd1c6f05e717b70c', '84741eaf0d28c1a0cd61270a0f6d8be65be685f46108addde626861b0ed0db1e', '5573186698054a2b926cd65da79c5cfbedd2b0737544eb88eb1f80872f81fdf7', '5fb74ea3254acf9351a438411260e55e3d3df640f9fdbb0aad0061915856c151', '10de4197b537c41b17b30251485fb8bfafe802edb22610e2e56838ef336d7f56', '5e3cc0545add485330d0122558e9ca2de770ab1b1eedec7c9d3dc4278b981df0', '6dec9330f68c23c7f64cdfea6fcdb6a488041c4f636e30828b50ca97301d61b4', '9c21dd742825e5f37114f7708eb8f6d04ab152fae46266434664c3881f7989dd', '9ef12def92ad035707134b537bcaf8d3ecb7659fa38aa9e632c01ec1ece7e5d0', '8d97a4b6c9e60f3c2a15162a94125574386b0d39b6d1bfee3de1b93f010a4a9a', 'c7438d77dbac834436fe780ffc9eb41c7df21b109bc94b3394f380fe53fbd694', '6dd5b935a518ba7cd4cc0142b44a0c10928398f6dbf0a061f361d97c04a00d40', '0ed83a9faf1635ddb972330d693ded9bf4e53fc6a852f830e3fdaf79a40c8ae9', '043d08f74b1faf7d9016d6755d1b7e3b08fcc20451f863c387e80f9bc25af004', '7bf5c7237ad12ef1c501b449c8816cf65718abfaf9409761e5325b8d3a635789', 'caaa4a86e4794a78d2b04e4a99dbd3d7394ecc3c2773d7556cbf3ae7a0331fe7', '14f94b00dd14e9a15b0f4d805722f745b19fec6ac6ee6f501595fc5cac35c428', '32eb73e4d6435178a48de32481ae93eb976034c36f94b19c350d5e9ad79aa652', 'f87d505c8f6c21b5c5921e80b086e0590c9ccd62512a8a3ecf3dbbf0b2e0bddf', '94e55888f25cc0fddebafa6220a89b1cab25d20c69ca37f1f0910a04c7ab413e', '209ecdc91eec7630d35dad855029255f9acedbd2e8bb5e1e66a942fe35099375', '9722c34199e858bc3032858f16d9ac6660c2ee0d5a5e9aa647b5e262dc2ac3b1', '222ca8b1b36b6241022f8cf2fa4890aa69627266f9a6042c0ed487c6cbcddfc7', '34b792389c4546c69bf39af614cf0f7fd11a4086f404859459d0e2ad2aa11b0e', '4b7a7b6f0b27cf6956bf66f9e203379243f5fba9d2c42d003858664369aab81c', '8776f86aaf3a55899b5a8e290f8c9bc9065db166c53f04c25c8ffe9880636bde', '18bb7ee8567f1c39e1b1946ff8887aacbfc3991aee22473c44d8af1406fc0ef8', '26cb2b288a0385c55d638eef70ca6886f43c3817bafe7bc5b3927c73dd1b0e47', 'dbdd551b9317b6420bcb7e583cb78698e047dbcf9a44d4d3c09d9dd06ce7d276', 'ec72c499d537a9869541fe047fa85c301aebf45967b9e6b69383de3ea8dbd00c', 'ea0aa801d918159fec9fbc8d6399d0630b8c3faf462ea93763ba83cf743f6783', '06ec7d54c41cd82ae776f503c59ec9f510a33bea8860d9c6a1dd247aa5422f0e', 'b03dce7828917707a02398943a0d1d0e0e7162fdc360406a50d8952bfb4bb6d0']\n",
            "\n",
            "Spin (all qubits, conceptual):\n",
            " [[[-0.08213061 -0.9935096  -0.07869753]\n",
            "  [ 0.5498306   0.83156055 -0.07869753]]\n",
            "\n",
            " [[-0.07730456 -0.5624438  -0.8232138 ]\n",
            "  [ 0.42904735 -0.37180287 -0.8232138 ]]\n",
            "\n",
            " [[-0.6689119   0.34994537  0.6558164 ]\n",
            "  [-0.7546795  -0.01907163  0.6558164 ]]\n",
            "\n",
            " [[ 0.21040262 -0.07820822  0.9744815 ]\n",
            "  [-0.20973012 -0.07999418  0.9744815 ]]\n",
            "\n",
            " [[ 0.34853986  0.18637729 -0.9185769 ]\n",
            "  [-0.3031691  -0.25358436 -0.9185769 ]]\n",
            "\n",
            " [[-0.12025477  0.38219377 -0.9162242 ]\n",
            "  [ 0.36139637 -0.1729912  -0.9162242 ]]\n",
            "\n",
            " [[-0.09201008 -0.17910698 -0.97951764]\n",
            "  [ 0.0038148   0.20132217 -0.97951764]]\n",
            "\n",
            " [[ 0.5206956   0.8537304  -0.00452027]\n",
            "  [-0.7377294   0.67508143 -0.00452027]]\n",
            "\n",
            " [[-0.21642539  0.01130416 -0.9762337 ]\n",
            "  [-0.17121774 -0.13286166 -0.9762337 ]]\n",
            "\n",
            " [[-0.9286617   0.19431975  0.3159545 ]\n",
            "  [-0.4721488  -0.82295096  0.3159545 ]]\n",
            "\n",
            " [[ 0.24982268 -0.25946075 -0.93288195]\n",
            "  [ 0.34912246 -0.08857065 -0.93288195]]\n",
            "\n",
            " [[ 0.0991297  -0.27273014 -0.95697   ]\n",
            "  [-0.28119937 -0.07166128 -0.95697   ]]\n",
            "\n",
            " [[-0.02448832  0.9844654  -0.17386231]\n",
            "  [ 0.8953299   0.41006863 -0.17386231]]\n",
            "\n",
            " [[-0.03146019 -0.6357572   0.77124774]\n",
            "  [ 0.6360615   0.02454983  0.77124774]]\n",
            "\n",
            " [[-0.9442509   0.22511928 -0.24023236]\n",
            "  [-0.96469647  0.10793131 -0.24023236]]\n",
            "\n",
            " [[ 0.84282094 -0.07486396 -0.5329617 ]\n",
            "  [ 0.3189154   0.78373766 -0.5329617 ]]\n",
            "\n",
            " [[ 0.67297244 -0.18660821  0.7157412 ]\n",
            "  [-0.68797225  0.12003613  0.7157412 ]]\n",
            "\n",
            " [[-0.21482988  0.38686144  0.8967644 ]\n",
            "  [-0.38775527 -0.21321236  0.8967644 ]]\n",
            "\n",
            " [[-0.2619816   0.7936218   0.54911757]\n",
            "  [-0.13406067  0.8249228   0.54911757]]\n",
            "\n",
            " [[-0.39847472  0.2569239  -0.88045895]\n",
            "  [ 0.22550264  0.41706184 -0.88045895]]\n",
            "\n",
            " [[ 0.65912944 -0.02847062  0.7514904 ]\n",
            "  [ 0.49158114 -0.44001153  0.7514904 ]]\n",
            "\n",
            " [[-0.08767645  0.0605924  -0.9943045 ]\n",
            "  [ 0.10369501  0.02461591 -0.9943045 ]]\n",
            "\n",
            " [[ 0.20797338  0.7098293   0.67297065]\n",
            "  [ 0.63107944 -0.38580984  0.67297065]]\n",
            "\n",
            " [[ 0.00380135 -0.81779397 -0.5754985 ]\n",
            "  [ 0.4741015  -0.66635513 -0.5754985 ]]\n",
            "\n",
            " [[ 0.6753753  -0.46841875 -0.569607  ]\n",
            "  [ 0.42670006  0.7024777  -0.569607  ]]\n",
            "\n",
            " [[ 0.8053285   0.58218706 -0.11182245]\n",
            "  [ 0.5001695  -0.85867697 -0.11182245]]\n",
            "\n",
            " [[-0.02137562  0.06847066 -0.9974241 ]\n",
            "  [-0.06212014 -0.03586416 -0.9974241 ]]\n",
            "\n",
            " [[-0.05881027 -0.757844    0.64977986]\n",
            "  [ 0.22779578 -0.72518635  0.64977986]]\n",
            "\n",
            " [[-0.9473476   0.31452844 -0.0600373 ]\n",
            "  [ 0.86783296 -0.4932154  -0.0600373 ]]\n",
            "\n",
            " [[ 0.2503195  -0.05759706  0.9664485 ]\n",
            "  [ 0.22219126 -0.12887326  0.9664485 ]]\n",
            "\n",
            " [[-0.84577703 -0.08867363  0.52611613]\n",
            "  [-0.16357417  0.834533    0.52611613]]\n",
            "\n",
            " [[-0.89761597  0.17708436 -0.40364173]\n",
            "  [-0.1952403  -0.8938426  -0.40364173]]\n",
            "\n",
            " [[ 0.5047882  -0.85115343  0.1439676 ]\n",
            "  [-0.13487506  0.98034793  0.1439676 ]]\n",
            "\n",
            " [[-0.47180793  0.03592123 -0.88096935]\n",
            "  [ 0.18715563 -0.43458697 -0.88096935]]\n",
            "\n",
            " [[-0.74504167  0.55007803 -0.37726262]\n",
            "  [ 0.6974079   0.6093399  -0.37726262]]\n",
            "\n",
            " [[-0.03352628  0.6531007  -0.7565285 ]\n",
            "  [ 0.6057582  -0.24641754 -0.7565285 ]]\n",
            "\n",
            " [[-0.32198843  0.4716367  -0.8209033 ]\n",
            "  [ 0.13101827 -0.5558345  -0.8209033 ]]\n",
            "\n",
            " [[-0.5410025   0.08820581 -0.8363827 ]\n",
            "  [-0.35875902 -0.41443446 -0.8363827 ]]\n",
            "\n",
            " [[ 0.3811417   0.21370748 -0.8994777 ]\n",
            "  [ 0.2915567   0.32547593 -0.8994777 ]]\n",
            "\n",
            " [[-0.13022867 -0.31098998  0.94144875]\n",
            "  [ 0.31904823  0.10900696  0.94144875]]\n",
            "\n",
            " [[ 0.45975953  0.71539235  0.52615106]\n",
            "  [ 0.53121835  0.6640573   0.52615106]]\n",
            "\n",
            " [[ 0.19186525  0.9307194  -0.31136668]\n",
            "  [ 0.90029705  0.30416438 -0.31136668]]\n",
            "\n",
            " [[ 0.83844167 -0.2102135   0.5028179 ]\n",
            "  [ 0.41131732 -0.760258    0.5028179 ]]\n",
            "\n",
            " [[-0.614137    0.78837734 -0.03601205]\n",
            "  [-0.18905663 -0.9813056  -0.03601205]]\n",
            "\n",
            " [[-0.32016507  0.8743724  -0.3646466 ]\n",
            "  [ 0.63489264 -0.6811345  -0.3646466 ]]\n",
            "\n",
            " [[ 0.9662431   0.04205205 -0.25417697]\n",
            "  [-0.43120164 -0.8657131  -0.25417697]]\n",
            "\n",
            " [[-0.06102535  0.51358396  0.85586643]\n",
            "  [-0.18550453 -0.4827843   0.85586643]]\n",
            "\n",
            " [[ 0.06142407  0.11666884  0.99126965]\n",
            "  [ 0.06925922  0.11219489  0.99126965]]\n",
            "\n",
            " [[-0.91454613 -0.15314382  0.37436932]\n",
            "  [ 0.07373192  0.92434365  0.37436932]]\n",
            "\n",
            " [[ 0.3271596   0.39745963 -0.85731703]\n",
            "  [ 0.41389105  0.30610743 -0.85731703]]\n",
            "\n",
            " [[ 0.94433093  0.30787352  0.11598697]\n",
            "  [-0.9809686  -0.15571666  0.11598697]]\n",
            "\n",
            " [[ 0.21547987 -0.8922662   0.39677376]\n",
            "  [-0.9092182   0.126067    0.39677376]]\n",
            "\n",
            " [[-0.0730489   0.03833859  0.9965912 ]\n",
            "  [-0.04002082 -0.072141    0.9965912 ]]\n",
            "\n",
            " [[-0.21623804  0.05494587  0.9747933 ]\n",
            "  [ 0.06882179  0.21222983  0.9747933 ]]\n",
            "\n",
            " [[ 0.82644665 -0.13890779  0.54561025]\n",
            "  [ 0.6028196  -0.5821666   0.54561025]]\n",
            "\n",
            " [[ 0.15253292 -0.05514371 -0.98675877]\n",
            "  [ 0.08170886 -0.14010988 -0.98675877]]\n",
            "\n",
            " [[ 0.35469773  0.74972147 -0.5586656 ]\n",
            "  [-0.26478234  0.7859918  -0.5586656 ]]\n",
            "\n",
            " [[ 0.9848877   0.12992191 -0.1145274 ]\n",
            "  [-0.3417986   0.9327686  -0.1145274 ]]\n",
            "\n",
            " [[-0.0792864  -0.81972086 -0.56724894]\n",
            "  [-0.25512752  0.78303164 -0.56724894]]\n",
            "\n",
            " [[ 0.49034634  0.03218875 -0.87093306]\n",
            "  [-0.10600689 -0.47983143 -0.87093306]]\n",
            "\n",
            " [[ 0.06405592  0.17405759  0.98264986]\n",
            "  [-0.17065422  0.07263841  0.98264986]]\n",
            "\n",
            " [[-0.07930178  0.17079142 -0.98211074]\n",
            "  [ 0.13218932  0.13410617 -0.98211074]]\n",
            "\n",
            " [[ 0.04804776 -0.02404072  0.99855566]\n",
            "  [-0.05334742 -0.00637151  0.99855566]]\n",
            "\n",
            " [[-0.6459098  -0.4867865  -0.5880812 ]\n",
            "  [ 0.7555211   0.28870118 -0.5880812 ]]]\n",
            "\n",
            "I_vec (all qubits, conceptual):\n",
            " [[0.3210323  0.32547286 0.13725594 ... 0.19108784 0.36432776 0.29060498]\n",
            " [0.39430338 0.41578686 0.11900736 ... 0.07932527 0.01376741 0.22818752]\n",
            " [0.03096907 0.01993184 0.3365387  ... 0.02484651 0.43708906 0.4151305 ]\n",
            " ...\n",
            " [0.0329495  0.300251   0.3236476  ... 0.283059   0.2960648  0.27257904]\n",
            " [0.02016222 0.31858623 0.37226462 ... 0.43556002 0.02649771 0.3121081 ]\n",
            " [0.20896707 0.01689762 0.390031   ... 0.1656124  0.29689184 0.25711957]]\n",
            "\n",
            "NECL Manifest Checksums (per qubit, conceptual):\n",
            " ['d474eabd5150d3a4c81d31c3f956ca686248841021ecf3a711453901d988e39e', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945']\n",
            "\n",
            "TRACE Log (Conceptual - detailed lineage for error correction):\n",
            " [{'qubit': 0, 'reason': 'binary_refactor', 'source': 'tuplets', 'r_metric': 0.9813550114631653, 'u_metric': 0.9767228364944458, 'dv_metric': -0.023175358772277832, 'invariant_pass': False, 'degenerate_check': False, 'correction_threshold_r': 1.02, 'correction_threshold_u': 1.02, 'correction_threshold_d': 0.765, 'corrected_bits': [1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'old_key': '89f043fafc099c17f26cc9a3546c29ec422f0ad06d5095a0254cfb6eb1be9afb', 'new_key': '00a659450010d9c1fe3b45d3754283108d8d1c866f3d34baeae9930b673d3234'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9272e460"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires updating the `R_FOR_RATIO` constant and refactoring the `detect_collapse` function to implement the new triplet-level predicate for collapse detection, removing the nested helper function, and applying the specified logic for marking collapsed indices. I will update the code to reflect these changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3301a166",
        "outputId": "987786fa-eee4-4c52-b211-3dbc4721ad3f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "R_FOR_RATIO = 64.0 # NEW: Ratio threshold constant for collapse detection, updated to 64.0 as per instructions\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| + n_|y, η| = n_|x+y, ξ+η|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| · n_|y, η| = n_|x·y, ξ·η|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ξ| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ξ_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW, r_for_ratio=R_FOR_RATIO):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register.\n",
        "    A triplet block collapses if, for any index 'p' within the triplet,\n",
        "    the condition [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO] is met.\n",
        "    If this condition is true for *any* index within the triplet, all indices i,j,k\n",
        "    of that triplet are marked as collapsed.\n",
        "    COLL(x, χ) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for unreal component (should be negative).\n",
        "        r_for_ratio (float): Ratio threshold for collapse detection.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    # Initialize a collapse mask filled with zeros\n",
        "    collapse_mask = tf.zeros(tf.shape(real_parts), dtype=tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Iterate over each triplet block and apply collapse detection\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # Extract real and unreal parts for the current triplet across all Q qubits\n",
        "        # shape [Q, 3]\n",
        "        triplet_real_block = tf.gather(real_parts, current_triplet_indices, axis=1)\n",
        "        triplet_unreal_block = tf.gather(unreal_parts, current_triplet_indices, axis=1)\n",
        "\n",
        "        # Evaluate the new triplet-level predicate for each index 'p' within the triplet block\n",
        "        # The condition: [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO]\n",
        "        # high(real_p): triplet_real_block >= tau_hi\n",
        "        # low(unreal_p): triplet_unreal_block <= tau_low (using TAU_LOW for unreal too)\n",
        "\n",
        "        # Condition 1: high(real_p) AND low(unreal_p)\n",
        "        cond1 = tf.logical_and(triplet_real_block >= tau_hi, triplet_unreal_block <= tau_low) # [Q, 3]\n",
        "\n",
        "        # Condition 2: ratio(real_p / unreal_p) > r_for_ratio\n",
        "        # Handle potential division by zero for unreal_p\n",
        "        # If unreal_p is near zero, the ratio might be undefined or very large.\n",
        "        # Set ratio to 0 if unreal_p is ~0 to avoid NaNs and make the condition false.\n",
        "        ratio_term = tf.where(tf.abs(triplet_unreal_block) > EPS, triplet_real_block / triplet_unreal_block, tf.zeros_like(triplet_real_block))\n",
        "        cond2 = ratio_term > r_for_ratio # [Q, 3]\n",
        "\n",
        "        # Triplet collapse if (cond1 OR cond2) is true for *any* index within the triplet\n",
        "        # tf.reduce_any along the triplet dimension (axis=1) for each qubit\n",
        "        triplet_collapse_per_qubit = tf.reduce_any(tf.logical_or(cond1, cond2), axis=1) # [Q]\n",
        "\n",
        "        # Mark all 3 indices of the triplet as collapsed if triplet_collapse_per_qubit is true for that qubit\n",
        "        unit_collapse_flag_int = tf.cast(triplet_collapse_per_qubit, tf.int32) # [Q]\n",
        "        marked_triplet_block = tf.broadcast_to(tf.expand_dims(unit_collapse_flag_int, axis=1), tf.shape(triplet_real_block)) # [Q, 3]\n",
        "\n",
        "        # Construct indices for scatter_nd_max to update the global collapse_mask\n",
        "        # indices_to_update will be [Q*3, 2]\n",
        "        # First column is qubit index, second is original 30-index\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1)\n",
        "\n",
        "        # Flatten marked_triplet_block to [Q*3] for updates\n",
        "        updates = tf.reshape(marked_triplet_block, [-1])\n",
        "\n",
        "        # Use tf.tensor_scatter_nd_max to update the collapse_mask.\n",
        "        # This ensures that if any triplet marks an index as collapsed, it remains marked.\n",
        "        collapse_mask = tf.tensor_scatter_nd_max(collapse_mask, indices_to_update, updates)\n",
        "\n",
        "    return collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components. Implements ASSOC(A, B, α) logic.\n",
        "\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`).\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode('utf-8')).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    for b_idx_triplet in tf.range(10):\n",
        "        current_triplet_indices = idx[b_idx_triplet, :] # Shape [3]\n",
        "        s = tf.gather(signs, current_triplet_indices) # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        # Ensure the list extension is compatible with TF operations if trip_mix is later converted to Tensor\n",
        "        # Here, it's converted to Python list and then to Tensor once.\n",
        "        trip_mix.extend([has_mix.numpy().item()]*3)\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook for a single qubit (q_idx). This function performs a local\n",
        "    re-evaluation of the bit pattern for the current qubit if the initial derivation\n",
        "    is deemed 'inconsistent'.\n",
        "\n",
        "    This function is designed to:\n",
        "    - Advance *only* within the same triplet (or within the primaries 6-set) for local re-evaluation.\n",
        "      It uses the `pairs_q` and `triplets_q` already derived for this specific qubit `q_idx`.\n",
        "      It does not implicitly advance to other qubits or triplets; its scope is limited to the\n",
        "      current qubit's local tuplet structure.\n",
        "    - Record lineage for any local adjustments made. If a correction occurs, a specific\n",
        "      entry is added to the `TRACE` log, detailing the reason, source, metrics, and new key.\n",
        "    - *Not* advance across different units (triplets or qubits) unless the current local unit\n",
        "      has been exhausted. The `derive_bits_advanced` function, called internally,\n",
        "      operates solely on the provided `pairs_q` and `triplets_q` for the current qubit.\n",
        "\n",
        "    Args:\n",
        "        q_idx (int): The index of the current qubit being processed.\n",
        "        pairs_q (tf.Tensor): The 30-index phase-dual pair register for the current qubit [30, 2].\n",
        "        triplets_q (tf.Tensor): The 10 triplets for the current qubit [10, 3, 2].\n",
        "        current_bits_q (tf.Tensor): The initially derived 30-bit pattern for the current qubit [30].\n",
        "        resonance_key_q (str): The current resonance key string for the qubit.\n",
        "        TRACE (list): A list to append lineage information if corrections are made.\n",
        "        invariants (dict): Dictionary of invariant constants.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, str]:\n",
        "            - new_bits_q (tf.Tensor): The potentially corrected 30-bit pattern.\n",
        "            - updated_resonance_key_q (str): The updated resonance key string (with lineage if corrected).\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        # The updated key incorporates the correction lineage.\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs) # Pass R_FOR_RATIO implicitly from constants\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primaries In:\n",
            " [[[-0.5303898   0.97767615]\n",
            "  [ 0.5303898  -0.97767615]\n",
            "  [-0.14960694 -0.28227234]\n",
            "  [ 0.14960694  0.28227234]\n",
            "  [ 0.62253284 -0.69853115]\n",
            "  [-0.62253284  0.69853115]]\n",
            "\n",
            " [[-0.8621762  -0.98005486]\n",
            "  [ 0.8621762   0.98005486]\n",
            "  [-0.43148446  0.30608058]\n",
            "  [ 0.43148446 -0.30608058]\n",
            "  [ 0.6449883   0.6924815 ]\n",
            "  [-0.6449883  -0.6924815 ]]\n",
            "\n",
            " [[ 0.13599253  0.17977476]\n",
            "  [-0.13599253 -0.17977476]\n",
            "  [-0.05618954 -0.18951511]\n",
            "  [ 0.05618954  0.18951511]\n",
            "  [-0.34906554 -0.61202264]\n",
            "  [ 0.34906554  0.61202264]]\n",
            "\n",
            " [[-0.2563963  -0.51245975]\n",
            "  [ 0.2563963   0.51245975]\n",
            "  [ 0.0891223  -0.83596015]\n",
            "  [-0.0891223   0.83596015]\n",
            "  [-0.94762063 -0.7429695 ]\n",
            "  [ 0.94762063  0.7429695 ]]\n",
            "\n",
            " [[-0.41530132 -0.10287023]\n",
            "  [ 0.41530132  0.10287023]\n",
            "  [ 0.99464726  0.91437817]\n",
            "  [-0.99464726 -0.91437817]\n",
            "  [-0.31025314  0.2120173 ]\n",
            "  [ 0.31025314 -0.2120173 ]]\n",
            "\n",
            " [[ 0.16973257  0.9585984 ]\n",
            "  [-0.16973257 -0.9585984 ]\n",
            "  [-0.7913661   0.09617186]\n",
            "  [ 0.7913661  -0.09617186]\n",
            "  [ 0.71075034  0.53398967]\n",
            "  [-0.71075034 -0.53398967]]\n",
            "\n",
            " [[-0.1257937   0.09393096]\n",
            "  [ 0.1257937  -0.09393096]\n",
            "  [ 0.12947392 -0.7984481 ]\n",
            "  [-0.12947392  0.7984481 ]\n",
            "  [ 0.902313    0.90424657]\n",
            "  [-0.902313   -0.90424657]]\n",
            "\n",
            " [[ 0.12992024  0.11653161]\n",
            "  [-0.12992024 -0.11653161]\n",
            "  [ 0.8851392  -0.18728924]\n",
            "  [-0.8851392   0.18728924]\n",
            "  [ 0.7368648   0.44100404]\n",
            "  [-0.7368648  -0.44100404]]\n",
            "\n",
            " [[ 0.6780586  -0.80004025]\n",
            "  [-0.6780586   0.80004025]\n",
            "  [ 0.4362173   0.2727399 ]\n",
            "  [-0.4362173  -0.2727399 ]\n",
            "  [-0.46546435  0.9122131 ]\n",
            "  [ 0.46546435 -0.9122131 ]]\n",
            "\n",
            " [[-0.19117403  0.6860676 ]\n",
            "  [ 0.19117403 -0.6860676 ]\n",
            "  [ 0.7539449   0.11418843]\n",
            "  [-0.7539449  -0.11418843]\n",
            "  [-0.24047732  0.25401044]\n",
            "  [ 0.24047732 -0.25401044]]\n",
            "\n",
            " [[ 0.9070239   0.3873849 ]\n",
            "  [-0.9070239  -0.3873849 ]\n",
            "  [-0.33961272  0.4653349 ]\n",
            "  [ 0.33961272 -0.4653349 ]\n",
            "  [-0.33490562 -0.22124839]\n",
            "  [ 0.33490562  0.22124839]]\n",
            "\n",
            " [[ 0.48614454 -0.5426924 ]\n",
            "  [-0.48614454  0.5426924 ]\n",
            "  [-0.6238766  -0.4053278 ]\n",
            "  [ 0.6238766   0.4053278 ]\n",
            "  [ 0.30439115  0.7984438 ]\n",
            "  [-0.30439115 -0.7984438 ]]\n",
            "\n",
            " [[-0.674392   -0.5699341 ]\n",
            "  [ 0.674392    0.5699341 ]\n",
            "  [-0.8687289  -0.5265112 ]\n",
            "  [ 0.8687289   0.5265112 ]\n",
            "  [-0.93150306  0.2523737 ]\n",
            "  [ 0.93150306 -0.2523737 ]]\n",
            "\n",
            " [[-0.97757506  0.22653699]\n",
            "  [ 0.97757506 -0.22653699]\n",
            "  [ 0.12204075  0.3396082 ]\n",
            "  [-0.12204075 -0.3396082 ]\n",
            "  [ 0.1608777   0.17684174]\n",
            "  [-0.1608777  -0.17684174]]\n",
            "\n",
            " [[-0.9344516   0.62400746]\n",
            "  [ 0.9344516  -0.62400746]\n",
            "  [ 0.88527393 -0.42233896]\n",
            "  [-0.88527393  0.42233896]\n",
            "  [-0.5235653   0.821506  ]\n",
            "  [ 0.5235653  -0.821506  ]]\n",
            "\n",
            " [[ 0.55772567 -0.62359405]\n",
            "  [-0.55772567  0.62359405]\n",
            "  [ 0.30953145 -0.03350043]\n",
            "  [-0.30953145  0.03350043]\n",
            "  [ 0.99462795 -0.4482298 ]\n",
            "  [-0.99462795  0.4482298 ]]\n",
            "\n",
            " [[-0.54987407  0.8403053 ]\n",
            "  [ 0.54987407 -0.8403053 ]\n",
            "  [-0.21357656  0.4162798 ]\n",
            "  [ 0.21357656 -0.4162798 ]\n",
            "  [-0.80293775 -0.26336312]\n",
            "  [ 0.80293775  0.26336312]]\n",
            "\n",
            " [[-0.40612173 -0.94343686]\n",
            "  [ 0.40612173  0.94343686]\n",
            "  [ 0.67533016 -0.47231126]\n",
            "  [-0.67533016  0.47231126]\n",
            "  [ 0.4749844   0.48309445]\n",
            "  [-0.4749844  -0.48309445]]\n",
            "\n",
            " [[-0.4337082   0.3608079 ]\n",
            "  [ 0.4337082  -0.3608079 ]\n",
            "  [-0.43320918  0.23292685]\n",
            "  [ 0.43320918 -0.23292685]\n",
            "  [ 0.48016095 -0.24541688]\n",
            "  [-0.48016095  0.24541688]]\n",
            "\n",
            " [[ 0.50927687  0.4619112 ]\n",
            "  [-0.50927687 -0.4619112 ]\n",
            "  [-0.44816923 -0.46246767]\n",
            "  [ 0.44816923  0.46246767]\n",
            "  [-0.96054363  0.8751352 ]\n",
            "  [ 0.96054363 -0.8751352 ]]\n",
            "\n",
            " [[-0.80320334 -0.29131246]\n",
            "  [ 0.80320334  0.29131246]\n",
            "  [ 0.9390192   0.9709625 ]\n",
            "  [-0.9390192  -0.9709625 ]\n",
            "  [-0.734426    0.874053  ]\n",
            "  [ 0.734426   -0.874053  ]]\n",
            "\n",
            " [[-0.54246306 -0.9954102 ]\n",
            "  [ 0.54246306  0.9954102 ]\n",
            "  [-0.11421275  0.24656081]\n",
            "  [ 0.11421275 -0.24656081]\n",
            "  [ 0.7951422  -0.96814895]\n",
            "  [-0.7951422   0.96814895]]\n",
            "\n",
            " [[ 0.3010986  -0.9322138 ]\n",
            "  [-0.3010986   0.9322138 ]\n",
            "  [ 0.12942672  0.69436836]\n",
            "  [-0.12942672 -0.69436836]\n",
            "  [ 0.10547733 -0.11859775]\n",
            "  [-0.10547733  0.11859775]]\n",
            "\n",
            " [[-0.19649863 -0.38082743]\n",
            "  [ 0.19649863  0.38082743]\n",
            "  [-0.76723075  0.95587444]\n",
            "  [ 0.76723075 -0.95587444]\n",
            "  [-0.78713965  0.01947808]\n",
            "  [ 0.78713965 -0.01947808]]\n",
            "\n",
            " [[-0.34576988 -0.34145093]\n",
            "  [ 0.34576988  0.34145093]\n",
            "  [-0.30488992  0.86475253]\n",
            "  [ 0.30488992 -0.86475253]\n",
            "  [ 0.30827785 -0.45158505]\n",
            "  [-0.30827785  0.45158505]]\n",
            "\n",
            " [[-0.7584386  -0.05352259]\n",
            "  [ 0.7584386   0.05352259]\n",
            "  [ 0.89969206 -0.5600598 ]\n",
            "  [-0.89969206  0.5600598 ]\n",
            "  [-0.07442307  0.65260124]\n",
            "  [ 0.07442307 -0.65260124]]\n",
            "\n",
            " [[ 0.8361945  -0.38220572]\n",
            "  [-0.8361945   0.38220572]\n",
            "  [-0.56719923 -0.13848901]\n",
            "  [ 0.56719923  0.13848901]\n",
            "  [ 0.31094646 -0.11961794]\n",
            "  [-0.31094646  0.11961794]]\n",
            "\n",
            " [[ 0.2212255   0.0946424 ]\n",
            "  [-0.2212255  -0.0946424 ]\n",
            "  [ 0.8470502  -0.8164234 ]\n",
            "  [-0.8470502   0.8164234 ]\n",
            "  [ 0.30128574 -0.20502234]\n",
            "  [-0.30128574  0.20502234]]\n",
            "\n",
            " [[ 0.5782893   0.17621636]\n",
            "  [-0.5782893  -0.17621636]\n",
            "  [-0.24521947 -0.8637936 ]\n",
            "  [ 0.24521947  0.8637936 ]\n",
            "  [ 0.3539393  -0.7815697 ]\n",
            "  [-0.3539393   0.7815697 ]]\n",
            "\n",
            " [[-0.5271387  -0.13127351]\n",
            "  [ 0.5271387   0.13127351]\n",
            "  [ 0.75791645  0.8967531 ]\n",
            "  [-0.75791645 -0.8967531 ]\n",
            "  [ 0.6817839  -0.8809869 ]\n",
            "  [-0.6817839   0.8809869 ]]\n",
            "\n",
            " [[ 0.19498253 -0.8337891 ]\n",
            "  [-0.19498253  0.8337891 ]\n",
            "  [-0.7531333   0.40833616]\n",
            "  [ 0.7531333  -0.40833616]\n",
            "  [-0.82385015 -0.6178665 ]\n",
            "  [ 0.82385015  0.6178665 ]]\n",
            "\n",
            " [[ 0.45467997  0.73666835]\n",
            "  [-0.45467997 -0.73666835]\n",
            "  [-0.11380792  0.9290538 ]\n",
            "  [ 0.11380792 -0.9290538 ]\n",
            "  [ 0.69485784 -0.83136296]\n",
            "  [-0.69485784  0.83136296]]\n",
            "\n",
            " [[-0.9838567  -0.55792475]\n",
            "  [ 0.9838567   0.55792475]\n",
            "  [-0.60250735  0.7738168 ]\n",
            "  [ 0.60250735 -0.7738168 ]\n",
            "  [-0.48133755  0.37916112]\n",
            "  [ 0.48133755 -0.37916112]]\n",
            "\n",
            " [[-0.27690887  0.5588665 ]\n",
            "  [ 0.27690887 -0.5588665 ]\n",
            "  [ 0.69634914  0.81573606]\n",
            "  [-0.69634914 -0.81573606]\n",
            "  [-0.750942    0.46361494]\n",
            "  [ 0.750942   -0.46361494]]\n",
            "\n",
            " [[ 0.6171844  -0.09680128]\n",
            "  [-0.6171844   0.09680128]\n",
            "  [-0.47387695 -0.82026863]\n",
            "  [ 0.47387695  0.82026863]\n",
            "  [ 0.66308975  0.30825496]\n",
            "  [-0.66308975 -0.30825496]]\n",
            "\n",
            " [[-0.0685668   0.3310771 ]\n",
            "  [ 0.0685668  -0.3310771 ]\n",
            "  [-0.1706276  -0.02509308]\n",
            "  [ 0.1706276   0.02509308]\n",
            "  [-0.6459336  -0.997947  ]\n",
            "  [ 0.6459336   0.997947  ]]\n",
            "\n",
            " [[-0.25179768  0.3818655 ]\n",
            "  [ 0.25179768 -0.3818655 ]\n",
            "  [ 0.69136024  0.28186035]\n",
            "  [-0.69136024 -0.28186035]\n",
            "  [-0.7881174  -0.42740107]\n",
            "  [ 0.7881174   0.42740107]]\n",
            "\n",
            " [[-0.65997195 -0.9633672 ]\n",
            "  [ 0.65997195  0.9633672 ]\n",
            "  [ 0.12812018  0.99143696]\n",
            "  [-0.12812018 -0.99143696]\n",
            "  [-0.12649989  0.37894964]\n",
            "  [ 0.12649989 -0.37894964]]\n",
            "\n",
            " [[-0.63837934 -0.37983298]\n",
            "  [ 0.63837934  0.37983298]\n",
            "  [ 0.6171603   0.8704848 ]\n",
            "  [-0.6171603  -0.8704848 ]\n",
            "  [-0.537796    0.96386576]\n",
            "  [ 0.537796   -0.96386576]]\n",
            "\n",
            " [[-0.35103297 -0.44808197]\n",
            "  [ 0.35103297  0.44808197]\n",
            "  [ 0.75688624 -0.26015043]\n",
            "  [-0.75688624  0.26015043]\n",
            "  [ 0.15088725  0.7295222 ]\n",
            "  [-0.15088725 -0.7295222 ]]\n",
            "\n",
            " [[-0.4669025  -0.15041542]\n",
            "  [ 0.4669025   0.15041542]\n",
            "  [ 0.49468398  0.7362442 ]\n",
            "  [-0.49468398 -0.7362442 ]\n",
            "  [-0.3354497   0.76749325]\n",
            "  [ 0.3354497  -0.76749325]]\n",
            "\n",
            " [[ 0.06816387  0.9056699 ]\n",
            "  [-0.06816387 -0.9056699 ]\n",
            "  [ 0.4101529  -0.9937713 ]\n",
            "  [-0.4101529   0.9937713 ]\n",
            "  [ 0.4618399  -0.2526579 ]\n",
            "  [-0.4618399   0.2526579 ]]\n",
            "\n",
            " [[ 0.42598414 -0.9463253 ]\n",
            "  [-0.42598414  0.9463253 ]\n",
            "  [-0.19656157 -0.35879922]\n",
            "  [ 0.19656157  0.35879922]\n",
            "  [ 0.8138261  -0.23033714]\n",
            "  [-0.8138261   0.23033714]]\n",
            "\n",
            " [[ 0.5036137   0.4391601 ]\n",
            "  [-0.5036137  -0.4391601 ]\n",
            "  [-0.5936756  -0.1897924 ]\n",
            "  [ 0.5936756   0.1897924 ]\n",
            "  [-0.87906003 -0.09211063]\n",
            "  [ 0.87906003  0.09211063]]\n",
            "\n",
            " [[ 0.91509056  0.73692775]\n",
            "  [-0.91509056 -0.73692775]\n",
            "  [ 0.09919262 -0.88407946]\n",
            "  [-0.09919262  0.88407946]\n",
            "  [ 0.86757517  0.7557664 ]\n",
            "  [-0.86757517 -0.7557664 ]]\n",
            "\n",
            " [[ 0.5544934   0.99091935]\n",
            "  [-0.5544934  -0.99091935]\n",
            "  [ 0.2274437  -0.89467144]\n",
            "  [-0.2274437   0.89467144]\n",
            "  [ 0.7361989  -0.03783703]\n",
            "  [-0.7361989   0.03783703]]\n",
            "\n",
            " [[-0.59148717  0.07578683]\n",
            "  [ 0.59148717 -0.07578683]\n",
            "  [ 0.83758664 -0.26262212]\n",
            "  [-0.83758664  0.26262212]\n",
            "  [-0.54394126 -0.5048399 ]\n",
            "  [ 0.54394126  0.5048399 ]]\n",
            "\n",
            " [[ 0.21405315 -0.74768806]\n",
            "  [-0.21405315  0.74768806]\n",
            "  [ 0.44022417 -0.9144311 ]\n",
            "  [-0.44022417  0.9144311 ]\n",
            "  [-0.31551695 -0.494215  ]\n",
            "  [ 0.31551695  0.494215  ]]\n",
            "\n",
            " [[ 0.47835755  0.00632286]\n",
            "  [-0.47835755 -0.00632286]\n",
            "  [-0.73165536  0.27118397]\n",
            "  [ 0.73165536 -0.27118397]\n",
            "  [ 0.42211604  0.22315264]\n",
            "  [-0.42211604 -0.22315264]]\n",
            "\n",
            " [[ 0.199054    0.87681365]\n",
            "  [-0.199054   -0.87681365]\n",
            "  [ 0.22598195 -0.8949983 ]\n",
            "  [-0.22598195  0.8949983 ]\n",
            "  [-0.14189339 -0.11591554]\n",
            "  [ 0.14189339  0.11591554]]\n",
            "\n",
            " [[-0.6194637   0.6095133 ]\n",
            "  [ 0.6194637  -0.6095133 ]\n",
            "  [ 0.96703005 -0.2882352 ]\n",
            "  [-0.96703005  0.2882352 ]\n",
            "  [ 0.7548158  -0.9588876 ]\n",
            "  [-0.7548158   0.9588876 ]]\n",
            "\n",
            " [[ 0.35802865  0.10155582]\n",
            "  [-0.35802865 -0.10155582]\n",
            "  [-0.8802285  -0.88413286]\n",
            "  [ 0.8802285   0.88413286]\n",
            "  [-0.91973376  0.16131473]\n",
            "  [ 0.91973376 -0.16131473]]\n",
            "\n",
            " [[-0.8353367   0.77902293]\n",
            "  [ 0.8353367  -0.77902293]\n",
            "  [ 0.26068306  0.49625587]\n",
            "  [-0.26068306 -0.49625587]\n",
            "  [ 0.36047578  0.70534825]\n",
            "  [-0.36047578 -0.70534825]]\n",
            "\n",
            " [[-0.5751822   0.57129455]\n",
            "  [ 0.5751822  -0.57129455]\n",
            "  [ 0.08083868 -0.37235165]\n",
            "  [-0.08083868  0.37235165]\n",
            "  [-0.698962   -0.02412939]\n",
            "  [ 0.698962    0.02412939]]\n",
            "\n",
            " [[ 0.3739295  -0.74870086]\n",
            "  [-0.3739295   0.74870086]\n",
            "  [ 0.22688127 -0.2815001 ]\n",
            "  [-0.22688127  0.2815001 ]\n",
            "  [-0.56236005  0.42330623]\n",
            "  [ 0.56236005 -0.42330623]]\n",
            "\n",
            " [[-0.9297924  -0.99221635]\n",
            "  [ 0.9297924   0.99221635]\n",
            "  [-0.9901519  -0.94187665]\n",
            "  [ 0.9901519   0.94187665]\n",
            "  [-0.5621686   0.50375915]\n",
            "  [ 0.5621686  -0.50375915]]\n",
            "\n",
            " [[-0.5270846   0.5586853 ]\n",
            "  [ 0.5270846  -0.5586853 ]\n",
            "  [ 0.43767047 -0.42542696]\n",
            "  [-0.43767047  0.42542696]\n",
            "  [-0.04639721  0.6159518 ]\n",
            "  [ 0.04639721 -0.6159518 ]]\n",
            "\n",
            " [[ 0.9212229   0.51150846]\n",
            "  [-0.9212229  -0.51150846]\n",
            "  [-0.4997759   0.38782907]\n",
            "  [ 0.4997759  -0.38782907]\n",
            "  [-0.7609501   0.7176254 ]\n",
            "  [ 0.7609501  -0.7176254 ]]\n",
            "\n",
            " [[ 0.3607669   0.8954637 ]\n",
            "  [-0.3607669  -0.8954637 ]\n",
            "  [ 0.826637    0.9781854 ]\n",
            "  [-0.826637   -0.9781854 ]\n",
            "  [ 0.4420483  -0.885164  ]\n",
            "  [-0.4420483   0.885164  ]]\n",
            "\n",
            " [[ 0.41129994  0.8592386 ]\n",
            "  [-0.41129994 -0.8592386 ]\n",
            "  [-0.1264131   0.47711372]\n",
            "  [ 0.1264131  -0.47711372]\n",
            "  [ 0.21082878 -0.75665903]\n",
            "  [-0.21082878  0.75665903]]\n",
            "\n",
            " [[ 0.25308013 -0.8345022 ]\n",
            "  [-0.25308013  0.8345022 ]\n",
            "  [ 0.9158988   0.9569135 ]\n",
            "  [-0.9158988  -0.9569135 ]\n",
            "  [ 0.9590049  -0.40745592]\n",
            "  [-0.9590049   0.40745592]]\n",
            "\n",
            " [[-0.83803606 -0.3009193 ]\n",
            "  [ 0.83803606  0.3009193 ]\n",
            "  [ 0.4208665  -0.6283672 ]\n",
            "  [-0.4208665   0.6283672 ]\n",
            "  [-0.1007812  -0.674098  ]\n",
            "  [ 0.1007812   0.674098  ]]\n",
            "\n",
            " [[-0.32506394 -0.70591974]\n",
            "  [ 0.32506394  0.70591974]\n",
            "  [ 0.68807364  0.54829   ]\n",
            "  [-0.68807364 -0.54829   ]\n",
            "  [-0.13508844  0.76741743]\n",
            "  [ 0.13508844 -0.76741743]]\n",
            "\n",
            " [[-0.14456272 -0.34380126]\n",
            "  [ 0.14456272  0.34380126]\n",
            "  [ 0.16498494  0.2074449 ]\n",
            "  [-0.16498494 -0.2074449 ]\n",
            "  [ 0.596673    0.68716574]\n",
            "  [-0.596673   -0.68716574]]]\n",
            "\n",
            "Primaries After NECL:\n",
            " [[[-0.11740313  0.15302578]\n",
            "  [ 0.11740313 -0.15302578]\n",
            "  [ 0.03315935  0.04423924]\n",
            "  [-0.03315935 -0.04423924]\n",
            "  [ 0.13782151 -0.10935169]\n",
            "  [ 0.13782151 -0.10935169]]\n",
            "\n",
            " [[-0.16245864 -0.13058165]\n",
            "  [ 0.16245864  0.13058165]\n",
            "  [ 0.08139507 -0.04082758]\n",
            "  [-0.08139507  0.04082758]\n",
            "  [ 0.12159889  0.09231472]\n",
            "  [ 0.12159889  0.09231472]]\n",
            "\n",
            " [[ 0.06326143  0.05913406]\n",
            "  [-0.06326143 -0.05913406]\n",
            "  [ 0.02614316  0.06234927]\n",
            "  [-0.02614316 -0.06234927]\n",
            "  [-0.16211379 -0.20098583]\n",
            "  [-0.16211379 -0.20098583]]\n",
            "\n",
            " [[-0.05137527 -0.07260844]\n",
            "  [ 0.05137527  0.07260844]\n",
            "  [-0.01785259  0.11840919]\n",
            "  [ 0.01785259 -0.11840919]\n",
            "  [-0.1896475  -0.10514016]\n",
            "  [-0.1896475  -0.10514016]]\n",
            "\n",
            " [[-0.10109034 -0.01770602]\n",
            "  [ 0.10109034  0.01770602]\n",
            "  [-0.24168305 -0.15710425]\n",
            "  [ 0.24168305  0.15710425]\n",
            "  [-0.07553358  0.03649893]\n",
            "  [-0.07553358  0.03649893]]\n",
            "\n",
            " [[ 0.03345978  0.13362247]\n",
            "  [-0.03345978 -0.13362247]\n",
            "  [ 0.15597583 -0.01340333]\n",
            "  [-0.15597583  0.01340333]\n",
            "  [ 0.14008395  0.07441992]\n",
            "  [ 0.14008395  0.07441992]]\n",
            "\n",
            " [[-0.02943015  0.01553915]\n",
            "  [ 0.02943015 -0.01553915]\n",
            "  [-0.0302617   0.1319601 ]\n",
            "  [ 0.0302617  -0.1319601 ]\n",
            "  [ 0.21064897  0.14927049]\n",
            "  [ 0.21064897  0.14927049]]\n",
            "\n",
            " [[ 0.0351809   0.02231305]\n",
            "  [-0.0351809  -0.02231305]\n",
            "  [-0.2392282   0.03579304]\n",
            "  [ 0.2392282  -0.03579304]\n",
            "  [ 0.19920245  0.08430133]\n",
            "  [ 0.19920245  0.08430133]]\n",
            "\n",
            " [[ 0.13735361 -0.11459605]\n",
            "  [-0.13735361  0.11459605]\n",
            "  [-0.08843336 -0.03909731]\n",
            "  [ 0.08843336  0.03909731]\n",
            "  [-0.09430455  0.13068554]\n",
            "  [-0.09430455  0.13068554]]\n",
            "\n",
            " [[-0.05493079  0.1393923 ]\n",
            "  [ 0.05493079 -0.1393923 ]\n",
            "  [-0.21649364 -0.0231853 ]\n",
            "  [ 0.21649364  0.0231853 ]\n",
            "  [-0.06913916  0.05164004]\n",
            "  [-0.06913916  0.05164004]]\n",
            "\n",
            " [[ 0.24190417  0.0730554 ]\n",
            "  [-0.24190417 -0.0730554 ]\n",
            "  [ 0.09068436 -0.0878616 ]\n",
            "  [-0.09068436  0.0878616 ]\n",
            "  [-0.08945095 -0.04178569]\n",
            "  [-0.08945095 -0.04178569]]\n",
            "\n",
            " [[ 0.10953078 -0.08645887]\n",
            "  [-0.10953078  0.08645887]\n",
            "  [ 0.14054222  0.06456535]\n",
            "  [-0.14054222 -0.06456535]\n",
            "  [ 0.06857759  0.12719779]\n",
            "  [ 0.06857759  0.12719779]]\n",
            "\n",
            " [[-0.12345871 -0.07377667]\n",
            "  [ 0.12345871  0.07377667]\n",
            "  [ 0.1589911   0.06813671]\n",
            "  [-0.1589911  -0.06813671]\n",
            "  [-0.1704788   0.03265993]\n",
            "  [-0.1704788   0.03265993]]\n",
            "\n",
            " [[-0.3190966   0.05228729]\n",
            "  [ 0.3190966  -0.05228729]\n",
            "  [-0.03992563 -0.07856155]\n",
            "  [ 0.03992563  0.07856155]\n",
            "  [ 0.0526419   0.04091715]\n",
            "  [ 0.0526419   0.04091715]]\n",
            "\n",
            " [[-0.15908343  0.07511781]\n",
            "  [ 0.15908343 -0.07511781]\n",
            "  [-0.15073551  0.05084919]\n",
            "  [ 0.15073551 -0.05084919]\n",
            "  [-0.08916945  0.09893295]\n",
            "  [-0.08916945  0.09893295]]\n",
            "\n",
            " [[ 0.13057287 -0.10323317]\n",
            "  [-0.13057287  0.10323317]\n",
            "  [-0.07253124  0.0055508 ]\n",
            "  [ 0.07253124 -0.0055508 ]\n",
            "  [ 0.23268624 -0.07414737]\n",
            "  [ 0.23268624 -0.07414737]]\n",
            "\n",
            " [[-0.12436975  0.13439207]\n",
            "  [ 0.12436975 -0.13439207]\n",
            "  [ 0.04835289 -0.06664065]\n",
            "  [-0.04835289  0.06664065]\n",
            "  [-0.18160158 -0.04211897]\n",
            "  [-0.18160158 -0.04211897]]\n",
            "\n",
            " [[-0.08418661 -0.13828804]\n",
            "  [ 0.08418661  0.13828804]\n",
            "  [-0.13999954  0.0692347 ]\n",
            "  [ 0.13999954 -0.0692347 ]\n",
            "  [ 0.09849953  0.07083891]\n",
            "  [ 0.09849953  0.07083891]]\n",
            "\n",
            " [[-0.1425076   0.08383039]\n",
            "  [ 0.1425076  -0.08383039]\n",
            "  [ 0.14236134 -0.05412514]\n",
            "  [-0.14236134  0.05412514]\n",
            "  [ 0.1577674  -0.05701903]\n",
            "  [ 0.1577674  -0.05701903]]\n",
            "\n",
            " [[ 0.10150744  0.06510096]\n",
            "  [-0.10150744 -0.06510096]\n",
            "  [ 0.08933618  0.0651856 ]\n",
            "  [-0.08933618 -0.0651856 ]\n",
            "  [-0.19125731  0.12321429]\n",
            "  [-0.19125731  0.12321429]]\n",
            "\n",
            " [[-0.12583984 -0.0322728 ]\n",
            "  [ 0.12583984  0.0322728 ]\n",
            "  [-0.14704517 -0.10751368]\n",
            "  [ 0.14704517  0.10751368]\n",
            "  [-0.11504191  0.09681235]\n",
            "  [-0.11504191  0.09681235]]\n",
            "\n",
            " [[-0.10695968 -0.13878323]\n",
            "  [ 0.10695968  0.13878323]\n",
            "  [ 0.0225486  -0.03442025]\n",
            "  [-0.0225486   0.03442025]\n",
            "  [ 0.15673418 -0.13494167]\n",
            "  [ 0.15673418 -0.13494167]]\n",
            "\n",
            " [[ 0.08552539 -0.18723495]\n",
            "  [-0.08552539  0.18723495]\n",
            "  [-0.03678453 -0.1395456 ]\n",
            "  [ 0.03678453  0.1395456 ]\n",
            "  [ 0.03000814 -0.0238584 ]\n",
            "  [ 0.03000814 -0.0238584 ]]\n",
            "\n",
            " [[-0.04222264 -0.05786274]\n",
            "  [ 0.04222264  0.05786274]\n",
            "  [ 0.16462651 -0.14503059]\n",
            "  [-0.16462651  0.14503059]\n",
            "  [-0.16897964  0.00295674]\n",
            "  [-0.16897964  0.00295674]]\n",
            "\n",
            " [[-0.09300792 -0.06494505]\n",
            "  [ 0.09300792  0.06494505]\n",
            "  [ 0.0819568  -0.16436857]\n",
            "  [-0.0819568   0.16436857]\n",
            "  [ 0.08291832 -0.08588805]\n",
            "  [ 0.08291832 -0.08588805]]\n",
            "\n",
            " [[-0.16050972 -0.00800946]\n",
            "  [ 0.16050972  0.00800946]\n",
            "  [-0.19031768  0.0837731 ]\n",
            "  [ 0.19031768 -0.0837731 ]\n",
            "  [-0.01575956  0.09771685]\n",
            "  [-0.01575956  0.09771685]]\n",
            "\n",
            " [[ 0.23848182 -0.07707795]\n",
            "  [-0.23848182  0.07707795]\n",
            "  [ 0.16189796  0.02795156]\n",
            "  [-0.16189796 -0.02795156]\n",
            "  [ 0.08881588 -0.02415941]\n",
            "  [ 0.08881588 -0.02415941]]\n",
            "\n",
            " [[ 0.06515187  0.0197089 ]\n",
            "  [-0.06515187 -0.0197089 ]\n",
            "  [-0.2489057   0.16963919]\n",
            "  [ 0.2489057  -0.16963919]\n",
            "  [ 0.08870429 -0.04268273]\n",
            "  [ 0.08870429 -0.04268273]]\n",
            "\n",
            " [[ 0.1284596   0.02767914]\n",
            "  [-0.1284596  -0.02767914]\n",
            "  [ 0.05446471  0.13566107]\n",
            "  [-0.05446471 -0.13566107]\n",
            "  [ 0.07861235 -0.12274809]\n",
            "  [ 0.07861235 -0.12274809]]\n",
            "\n",
            " [[-0.09765128 -0.01719552]\n",
            "  [ 0.09765128  0.01719552]\n",
            "  [-0.14029026 -0.11737187]\n",
            "  [ 0.14029026  0.11737187]\n",
            "  [ 0.12621251 -0.11532146]\n",
            "  [ 0.12621251 -0.11532146]]\n",
            "\n",
            " [[ 0.03727955 -0.11272395]\n",
            "  [-0.03727955  0.11272395]\n",
            "  [ 0.14394617 -0.05518628]\n",
            "  [-0.14394617  0.05518628]\n",
            "  [-0.15742618 -0.08348498]\n",
            "  [-0.15742618 -0.08348498]]\n",
            "\n",
            " [[ 0.0826361   0.09467188]\n",
            "  [-0.0826361  -0.09467188]\n",
            "  [ 0.02068498 -0.11940113]\n",
            "  [-0.02068498  0.11940113]\n",
            "  [ 0.1262396  -0.106801  ]\n",
            "  [ 0.1262396  -0.106801  ]]\n",
            "\n",
            " [[-0.18921715 -0.07587335]\n",
            "  [ 0.18921715  0.07587335]\n",
            "  [ 0.11592761 -0.10528042]\n",
            "  [-0.11592761  0.10528042]\n",
            "  [-0.09265813  0.05161104]\n",
            "  [-0.09265813  0.05161104]]\n",
            "\n",
            " [[-0.05632199  0.08037744]\n",
            "  [ 0.05632199 -0.08037744]\n",
            "  [-0.1415186  -0.11722523]\n",
            "  [ 0.1415186   0.11722523]\n",
            "  [-0.15263852  0.06663466]\n",
            "  [-0.15263852  0.06663466]]\n",
            "\n",
            " [[ 0.14048904 -0.01558094]\n",
            "  [-0.14048904  0.01558094]\n",
            "  [ 0.10783819  0.13199215]\n",
            "  [-0.10783819 -0.13199215]\n",
            "  [ 0.15091322  0.04960781]\n",
            "  [ 0.15091322  0.04960781]]\n",
            "\n",
            " [[-0.02116836  0.0722749 ]\n",
            "  [ 0.02116836 -0.0722749 ]\n",
            "  [ 0.0526884   0.00547904]\n",
            "  [-0.0526884  -0.00547904]\n",
            "  [-0.19899955 -0.21739857]\n",
            "  [-0.19899955 -0.21739857]]\n",
            "\n",
            " [[-0.06287715  0.06742743]\n",
            "  [ 0.06287715 -0.06742743]\n",
            "  [-0.17249791 -0.04972771]\n",
            "  [ 0.17249791  0.04972771]\n",
            "  [-0.19658116 -0.07538267]\n",
            "  [-0.19658116 -0.07538267]]\n",
            "\n",
            " [[-0.13473111 -0.13906546]\n",
            "  [ 0.13473111  0.13906546]\n",
            "  [-0.02616731 -0.14318307]\n",
            "  [ 0.02616731  0.14318307]\n",
            "  [-0.02585732  0.05477217]\n",
            "  [-0.02585732  0.05477217]]\n",
            "\n",
            " [[-0.11489074 -0.04833747]\n",
            "  [ 0.11489074  0.04833747]\n",
            "  [-0.11103782 -0.11074372]\n",
            "  [ 0.11103782  0.11074372]\n",
            "  [-0.09675939  0.12262445]\n",
            "  [-0.09675939  0.12262445]]\n",
            "\n",
            " [[-0.0870582  -0.0785786 ]\n",
            "  [ 0.0870582   0.0785786 ]\n",
            "  [-0.1875766   0.04558874]\n",
            "  [ 0.1875766  -0.04558874]\n",
            "  [ 0.03741521  0.1279143 ]\n",
            "  [ 0.03741521  0.1279143 ]]\n",
            "\n",
            " [[-0.11053928 -0.0251807 ]\n",
            "  [ 0.11053928  0.0251807 ]\n",
            "  [-0.1170534  -0.12318649]\n",
            "  [ 0.1170534   0.12318649]\n",
            "  [-0.07938932  0.1284382 ]\n",
            "  [-0.07938932  0.1284382 ]]\n",
            "\n",
            " [[ 0.01424053  0.133791  ]\n",
            "  [-0.01424053 -0.133791  ]\n",
            "  [-0.08565865  0.14675634]\n",
            "  [ 0.08565865 -0.14675634]\n",
            "  [ 0.09651439 -0.03733519]\n",
            "  [ 0.09651439 -0.03733519]]\n",
            "\n",
            " [[ 0.09737703 -0.15296376]\n",
            "  [-0.09737703  0.15296376]\n",
            "  [ 0.04497887  0.0580559 ]\n",
            "  [-0.04497887 -0.0580559 ]\n",
            "  [ 0.18602015 -0.03722865]\n",
            "  [ 0.18602015 -0.03722865]]\n",
            "\n",
            " [[ 0.12137751  0.07484255]\n",
            "  [-0.12137751 -0.07484255]\n",
            "  [ 0.14307801  0.03234354]\n",
            "  [-0.14307801 -0.03234354]\n",
            "  [-0.21172416 -0.01568724]\n",
            "  [-0.21172416 -0.01568724]]\n",
            "\n",
            " [[ 0.14918032  0.08494883]\n",
            "  [-0.14918032 -0.08494883]\n",
            "  [-0.01618118  0.10197815]\n",
            "  [ 0.01618118 -0.10197815]\n",
            "  [ 0.14144175  0.08712506]\n",
            "  [ 0.14144175  0.08712506]]\n",
            "\n",
            " [[ 0.10395717  0.1313655 ]\n",
            "  [-0.10395717 -0.1313655 ]\n",
            "  [-0.0426583   0.11865288]\n",
            "  [ 0.0426583  -0.11865288]\n",
            "  [ 0.13806222 -0.00501743]\n",
            "  [ 0.13806222 -0.00501743]]\n",
            "\n",
            " [[-0.13992903  0.01267772]\n",
            "  [ 0.13992903 -0.01267772]\n",
            "  [-0.19803134  0.04390566]\n",
            "  [ 0.19803134 -0.04390566]\n",
            "  [-0.12866458 -0.0844395 ]\n",
            "  [-0.12866458 -0.0844395 ]]\n",
            "\n",
            " [[ 0.04718189 -0.11653575]\n",
            "  [-0.04718189  0.11653575]\n",
            "  [-0.09699167  0.14246118]\n",
            "  [ 0.09699167 -0.14246118]\n",
            "  [-0.06956121 -0.07704516]\n",
            "  [-0.06956121 -0.07704516]]\n",
            "\n",
            " [[ 0.          0.        ]\n",
            "  [ 0.          0.        ]\n",
            "  [ 0.          0.        ]\n",
            "  [-0.22076462  0.05785913]\n",
            "  [ 0.12747838  0.04765315]\n",
            "  [ 0.12747838  0.04765315]]\n",
            "\n",
            " [[ 0.05202563  0.16204616]\n",
            "  [-0.05202563 -0.16204616]\n",
            "  [-0.05906058  0.16539834]\n",
            "  [ 0.05906058 -0.16539834]\n",
            "  [-0.03713093 -0.02144867]\n",
            "  [-0.03713093 -0.02144867]]\n",
            "\n",
            " [[-0.10483392  0.07293805]\n",
            "  [ 0.10483392 -0.07293805]\n",
            "  [-0.16359212  0.03447898]\n",
            "  [ 0.16359212 -0.03447898]\n",
            "  [ 0.1276865  -0.11469822]\n",
            "  [ 0.1276865  -0.11469822]]\n",
            "\n",
            " [[ 0.0735575   0.01475364]\n",
            "  [-0.0735575  -0.01475364]\n",
            "  [ 0.18059175  0.12826405]\n",
            "  [-0.18059175 -0.12826405]\n",
            "  [-0.18875322  0.02340945]\n",
            "  [-0.18875322  0.02340945]]\n",
            "\n",
            " [[-0.17542745  0.11568344]\n",
            "  [ 0.17542745 -0.11568344]\n",
            "  [-0.05480732 -0.07377621]\n",
            "  [ 0.05480732  0.07377621]\n",
            "  [ 0.0757612   0.10482366]\n",
            "  [ 0.0757612   0.10482366]]\n",
            "\n",
            " [[-0.15938447  0.11194009]\n",
            "  [ 0.15938447 -0.11194009]\n",
            "  [-0.02242591  0.0730414 ]\n",
            "  [ 0.02242591 -0.0730414 ]\n",
            "  [-0.19368607 -0.00472799]\n",
            "  [-0.19368607 -0.00472799]]\n",
            "\n",
            " [[ 0.10302182 -0.14585885]\n",
            "  [-0.10302182  0.14585885]\n",
            "  [-0.06256521  0.05489059]\n",
            "  [ 0.06256521 -0.05489059]\n",
            "  [-0.1549411   0.08246921]\n",
            "  [-0.1549411   0.08246921]]\n",
            "\n",
            " [[-0.13998725 -0.1056316 ]\n",
            "  [ 0.13998725  0.1056316 ]\n",
            "  [ 0.14906874  0.10026833]\n",
            "  [-0.14906874 -0.10026833]\n",
            "  [-0.08469936  0.05366875]\n",
            "  [-0.08469936  0.05366875]]\n",
            "\n",
            " [[-0.13839881  0.10372998]\n",
            "  [ 0.13839881 -0.10372998]\n",
            "  [-0.11495767  0.07901338]\n",
            "  [ 0.11495767 -0.07901338]\n",
            "  [-0.01218944  0.1144257 ]\n",
            "  [-0.01218944  0.1144257 ]]\n",
            "\n",
            " [[ 0.17669117  0.06937259]\n",
            "  [-0.17669117 -0.06937259]\n",
            "  [ 0.0959309  -0.0526391 ]\n",
            "  [-0.0959309   0.0526391 ]\n",
            "  [-0.14597078  0.09734026]\n",
            "  [-0.14597078  0.09734026]]\n",
            "\n",
            " [[ 0.05847297  0.10262696]\n",
            "  [-0.05847297 -0.10262696]\n",
            "  [-0.13390888 -0.11204711]\n",
            "  [ 0.13390888  0.11204711]\n",
            "  [ 0.07164289 -0.10144068]\n",
            "  [ 0.07164289 -0.10144068]]\n",
            "\n",
            " [[ 0.09659967  0.14269729]\n",
            "  [-0.09659967 -0.14269729]\n",
            "  [ 0.02971474 -0.07930248]\n",
            "  [-0.02971474  0.07930248]\n",
            "  [ 0.04953372 -0.12570608]\n",
            "  [ 0.04953372 -0.12570608]]\n",
            "\n",
            " [[ 0.04098539 -0.09556162]\n",
            "  [-0.04098539  0.09556162]\n",
            "  [-0.14821288 -0.10949546]\n",
            "  [ 0.14821288  0.10949546]\n",
            "  [ 0.15522128 -0.04663329]\n",
            "  [ 0.15522128 -0.04663329]]\n",
            "\n",
            " [[-0.18861508 -0.04789044]\n",
            "  [ 0.18861508  0.04789044]\n",
            "  [-0.09477489  0.10005699]\n",
            "  [ 0.09477489 -0.10005699]\n",
            "  [-0.02270099 -0.1073676 ]\n",
            "  [-0.02270099 -0.1073676 ]]\n",
            "\n",
            " [[-0.06996573 -0.10743773]\n",
            "  [ 0.06996573  0.10743773]\n",
            "  [-0.14803988 -0.08341402]\n",
            "  [ 0.14803988  0.08341402]\n",
            "  [-0.02907817  0.11680613]\n",
            "  [-0.02907817  0.11680613]]\n",
            "\n",
            " [[-0.04898091 -0.08236886]\n",
            "  [ 0.04898091  0.08236886]\n",
            "  [-0.0559116  -0.04971018]\n",
            "  [ 0.0559116   0.04971018]\n",
            "  [ 0.2018485   0.16437493]\n",
            "  [ 0.2018485   0.16437493]]]\n",
            "\n",
            "Pairs[0]:\n",
            " [[-0.11740313  0.15302578]\n",
            " [ 0.11740313 -0.15302578]\n",
            " [ 0.03315935  0.04423924]\n",
            " [-0.03315935 -0.04423924]\n",
            " [ 0.13782151 -0.10935169]\n",
            " [ 0.13782151 -0.10935169]\n",
            " [-0.08424378  0.19726501]\n",
            " [-0.00389301  0.00676974]\n",
            " [-0.1505625   0.10878654]\n",
            " [ 0.00389301 -0.00676974]\n",
            " [ 0.1505625  -0.10878654]\n",
            " [ 0.00389301 -0.00676974]\n",
            " [ 0.08424378 -0.19726501]\n",
            " [-0.00389301  0.00676974]\n",
            " [ 0.02041838  0.04367408]\n",
            " [-0.01618068 -0.01673363]\n",
            " [ 0.02041838  0.04367408]\n",
            " [-0.01618068 -0.01673363]\n",
            " [ 0.25522465 -0.26237747]\n",
            " [ 0.01618068  0.01673363]\n",
            " [ 0.25522465 -0.26237747]\n",
            " [ 0.01618068  0.01673363]\n",
            " [ 0.17098087 -0.06511246]\n",
            " [ 0.00457007 -0.00483764]\n",
            " [ 0.17098087 -0.06511246]\n",
            " [ 0.00457007 -0.00483764]\n",
            " [ 0.10466216 -0.15359093]\n",
            " [-0.00457007  0.00483764]\n",
            " [ 0.10466216 -0.15359093]\n",
            " [-0.00457007  0.00483764]]\n",
            "\n",
            "Triplets[0]:\n",
            " [[[-0.11740313  0.15302578]\n",
            "  [ 0.11740313 -0.15302578]\n",
            "  [ 0.03315935  0.04423924]]\n",
            "\n",
            " [[-0.03315935 -0.04423924]\n",
            "  [ 0.13782151 -0.10935169]\n",
            "  [ 0.13782151 -0.10935169]]\n",
            "\n",
            " [[-0.08424378  0.19726501]\n",
            "  [-0.00389301  0.00676974]\n",
            "  [-0.1505625   0.10878654]]\n",
            "\n",
            " [[ 0.00389301 -0.00676974]\n",
            "  [ 0.1505625  -0.10878654]\n",
            "  [ 0.00389301 -0.00676974]]\n",
            "\n",
            " [[ 0.08424378 -0.19726501]\n",
            "  [-0.00389301  0.00676974]\n",
            "  [ 0.02041838  0.04367408]]\n",
            "\n",
            " [[-0.01618068 -0.01673363]\n",
            "  [ 0.02041838  0.04367408]\n",
            "  [-0.01618068 -0.01673363]]\n",
            "\n",
            " [[ 0.25522465 -0.26237747]\n",
            "  [ 0.01618068  0.01673363]\n",
            "  [ 0.25522465 -0.26237747]]\n",
            "\n",
            " [[ 0.01618068  0.01673363]\n",
            "  [ 0.17098087 -0.06511246]\n",
            "  [ 0.00457007 -0.00483764]]\n",
            "\n",
            " [[ 0.17098087 -0.06511246]\n",
            "  [ 0.00457007 -0.00483764]\n",
            "  [ 0.10466216 -0.15359093]]\n",
            "\n",
            " [[-0.00457007  0.00483764]\n",
            "  [ 0.10466216 -0.15359093]\n",
            "  [-0.00457007  0.00483764]]]\n",
            "\n",
            "Bits (all qubits):\n",
            " [[1 1 1 ... 1 1 1]\n",
            " [0 1 0 ... 0 1 1]\n",
            " [1 0 0 ... 1 0 0]\n",
            " ...\n",
            " [0 1 1 ... 0 1 1]\n",
            " [0 1 1 ... 0 1 1]\n",
            " [0 1 1 ... 1 1 0]]\n",
            "\n",
            "Primaries Out (promoted):\n",
            " [[[-4.57007205e-03  4.83763544e-03]\n",
            "  [ 4.57007205e-03 -4.83763544e-03]\n",
            "  [ 1.04662158e-01 -1.53590932e-01]\n",
            "  [-1.04662158e-01  1.53590932e-01]\n",
            "  [-4.57007205e-03  4.83763544e-03]\n",
            "  [ 4.57007205e-03 -4.83763544e-03]]\n",
            "\n",
            " [[-9.89755057e-03  3.76898702e-03]\n",
            "  [ 9.89755057e-03 -3.76898702e-03]\n",
            "  [ 4.02038172e-02  1.33142307e-01]\n",
            "  [-4.02038172e-02 -1.33142307e-01]\n",
            "  [-9.89755057e-03  3.76898702e-03]\n",
            "  [ 9.89755057e-03 -3.76898702e-03]]\n",
            "\n",
            " [[ 4.23816592e-03  1.25313206e-02]\n",
            "  [-4.23816592e-03 -1.25313206e-02]\n",
            "  [-1.88256949e-01 -2.63335109e-01]\n",
            "  [ 1.88256949e-01  2.63335109e-01]\n",
            "  [ 4.23816592e-03  1.25313206e-02]\n",
            "  [-4.23816592e-03 -1.25313206e-02]]\n",
            "\n",
            " [[-3.38569889e-03  1.24495607e-02]\n",
            "  [ 3.38569889e-03 -1.24495607e-02]\n",
            "  [-1.71794906e-01 -2.23549336e-01]\n",
            "  [ 1.71794906e-01  2.23549336e-01]\n",
            "  [-3.38569889e-03  1.24495607e-02]\n",
            "  [ 3.38569889e-03 -1.24495607e-02]]\n",
            "\n",
            " [[-1.82551872e-02  5.73413773e-03]\n",
            "  [ 1.82551872e-02 -5.73413773e-03]\n",
            "  [ 1.66149467e-01  1.93603188e-01]\n",
            "  [-1.66149467e-01 -1.93603188e-01]\n",
            "  [-1.82551872e-02  5.73413773e-03]\n",
            "  [ 1.82551872e-02 -5.73413773e-03]]\n",
            "\n",
            " [[-2.18497124e-02  9.97474999e-04]\n",
            "  [ 2.18497124e-02 -9.97474999e-04]\n",
            "  [-1.58918798e-02  8.78232494e-02]\n",
            "  [ 1.58918798e-02 -8.78232494e-02]\n",
            "  [-2.18497124e-02  9.97474999e-04]\n",
            "  [ 2.18497124e-02 -9.97474999e-04]]\n",
            "\n",
            " [[ 6.37459522e-03 -1.96977481e-02]\n",
            "  [-6.37459522e-03  1.96977481e-02]\n",
            "  [ 2.40910664e-01  1.73103958e-02]\n",
            "  [-2.40910664e-01 -1.73103958e-02]\n",
            "  [ 6.37459522e-03 -1.96977481e-02]\n",
            "  [-6.37459522e-03  1.96977481e-02]]\n",
            "\n",
            " [[ 4.76548448e-02 -3.01740109e-03]\n",
            "  [-4.76548448e-02  3.01740109e-03]\n",
            "  [ 4.38430667e-01  4.85082865e-02]\n",
            "  [-4.38430667e-01 -4.85082865e-02]\n",
            "  [ 4.76548448e-02 -3.01740109e-03]\n",
            "  [-4.76548448e-02  3.01740109e-03]]\n",
            "\n",
            " [[-8.33966769e-03  5.10945218e-03]\n",
            "  [ 8.33966769e-03 -5.10945218e-03]\n",
            "  [-5.87119907e-03  1.69782847e-01]\n",
            "  [ 5.87119907e-03 -1.69782847e-01]\n",
            "  [-8.33966769e-03  5.10945218e-03]\n",
            "  [ 8.33966769e-03 -5.10945218e-03]]\n",
            "\n",
            " [[-1.49681885e-02  1.19728956e-03]\n",
            "  [ 1.49681885e-02 -1.19728956e-03]\n",
            "  [ 1.47354484e-01  7.48253316e-02]\n",
            "  [-1.47354484e-01 -7.48253316e-02]\n",
            "  [-1.49681885e-02  1.19728956e-03]\n",
            "  [ 1.49681885e-02 -1.19728956e-03]]\n",
            "\n",
            " [[ 8.11180193e-03 -3.67135787e-03]\n",
            "  [-8.11180193e-03  3.67135787e-03]\n",
            "  [-1.80135310e-01  4.60759029e-02]\n",
            "  [ 1.80135310e-01 -4.60759029e-02]\n",
            "  [ 8.11180193e-03 -3.67135787e-03]\n",
            "  [-8.11180193e-03  3.67135787e-03]]\n",
            "\n",
            " [[-9.63804685e-03 -8.21256917e-03]\n",
            "  [ 9.63804685e-03  8.21256917e-03]\n",
            "  [-7.19646364e-02  6.26324415e-02]\n",
            "  [ 7.19646364e-02 -6.26324415e-02]\n",
            "  [-9.63804685e-03 -8.21256917e-03]\n",
            "  [ 9.63804685e-03  8.21256917e-03]]\n",
            "\n",
            " [[ 2.71046124e-02 -2.22534011e-03]\n",
            "  [-2.71046124e-02  2.22534011e-03]\n",
            "  [-3.29469919e-01 -3.54767889e-02]\n",
            "  [ 3.29469919e-01  3.54767889e-02]\n",
            "  [ 2.71046124e-02 -2.22534011e-03]\n",
            "  [-2.71046124e-02  2.22534011e-03]]\n",
            "\n",
            " [[ 2.10176106e-03  3.21451505e-03]\n",
            "  [-2.10176106e-03 -3.21451505e-03]\n",
            "  [ 9.25675333e-02  1.19478703e-01]\n",
            "  [-9.25675333e-02 -1.19478703e-01]\n",
            "  [ 2.10176106e-03  3.21451505e-03]\n",
            "  [-2.10176106e-03 -3.21451505e-03]]\n",
            "\n",
            " [[-1.34410029e-02 -5.03066042e-03]\n",
            "  [ 1.34410029e-02  5.03066042e-03]\n",
            "  [ 6.15660623e-02  4.80837598e-02]\n",
            "  [-6.15660623e-02 -4.80837598e-02]\n",
            "  [-1.34410029e-02 -5.03066042e-03]\n",
            "  [ 1.34410029e-02  5.03066042e-03]]\n",
            "\n",
            " [[ 1.68770216e-02  4.11577377e-04]\n",
            "  [-1.68770216e-02 -4.11577377e-04]\n",
            "  [ 3.05217475e-01 -7.96981677e-02]\n",
            "  [-3.05217475e-01  7.96981677e-02]\n",
            "  [ 1.68770216e-02  4.11577377e-04]\n",
            "  [-1.68770216e-02 -4.11577377e-04]]\n",
            "\n",
            " [[ 8.78096092e-03 -2.80683511e-03]\n",
            "  [-8.78096092e-03  2.80683511e-03]\n",
            "  [-2.29954481e-01  2.45216787e-02]\n",
            "  [ 2.29954481e-01 -2.45216787e-02]\n",
            "  [ 8.78096092e-03 -2.80683511e-03]\n",
            "  [-8.78096092e-03  2.80683511e-03]]\n",
            "\n",
            " [[ 1.37898885e-02 -4.90451045e-03]\n",
            "  [-1.37898885e-02  4.90451045e-03]\n",
            "  [ 2.38499075e-01  1.60420686e-03]\n",
            "  [-2.38499075e-01 -1.60420686e-03]\n",
            "  [ 1.37898885e-02 -4.90451045e-03]\n",
            "  [-1.37898885e-02  4.90451045e-03]]\n",
            "\n",
            " [[-2.24599782e-02 -3.08616320e-03]\n",
            "  [ 2.24599782e-02  3.08616320e-03]\n",
            "  [ 1.54060572e-02 -2.89389119e-03]\n",
            "  [-1.54060572e-02  2.89389119e-03]\n",
            "  [-2.24599782e-02 -3.08616320e-03]\n",
            "  [ 2.24599782e-02  3.08616320e-03]]\n",
            "\n",
            " [[ 1.70861967e-02 -8.03179760e-03]\n",
            "  [-1.70861967e-02  8.03179760e-03]\n",
            "  [-2.80593485e-01  5.80286905e-02]\n",
            "  [ 2.80593485e-01 -5.80286905e-02]\n",
            "  [ 1.70861967e-02 -8.03179760e-03]\n",
            "  [-1.70861967e-02  8.03179760e-03]]\n",
            "\n",
            " [[-1.69163570e-02  1.04086520e-02]\n",
            "  [ 1.69163570e-02 -1.04086520e-02]\n",
            "  [ 3.20032537e-02  2.04326034e-01]\n",
            "  [-3.20032537e-02 -2.04326034e-01]\n",
            "  [-1.69163570e-02  1.04086520e-02]\n",
            "  [ 1.69163570e-02 -1.04086520e-02]]\n",
            "\n",
            " [[-3.53413657e-03 -4.64472640e-03]\n",
            "  [ 3.53413657e-03  4.64472640e-03]\n",
            "  [ 1.34185582e-01 -1.00521415e-01]\n",
            "  [-1.34185582e-01  1.00521415e-01]\n",
            "  [-3.53413657e-03 -4.64472640e-03]\n",
            "  [ 3.53413657e-03  4.64472640e-03]]\n",
            "\n",
            " [[ 1.10383541e-03 -3.32933548e-03]\n",
            "  [-1.10383541e-03  3.32933548e-03]\n",
            "  [ 6.67926744e-02  1.15687199e-01]\n",
            "  [-6.67926744e-02 -1.15687199e-01]\n",
            "  [ 1.10383541e-03 -3.32933548e-03]\n",
            "  [-1.10383541e-03  3.32933548e-03]]\n",
            "\n",
            " [[ 2.78185289e-02  4.28818428e-04]\n",
            "  [-2.78185289e-02 -4.28818428e-04]\n",
            "  [-3.33606154e-01  1.47987336e-01]\n",
            "  [ 3.33606154e-01 -1.47987336e-01]\n",
            "  [ 2.78185289e-02  4.28818428e-04]\n",
            "  [-2.78185289e-02 -4.28818428e-04]]\n",
            "\n",
            " [[-6.79572020e-03 -1.41172959e-02]\n",
            "  [ 6.79572020e-03  1.41172959e-02]\n",
            "  [ 9.61512327e-04  7.84805194e-02]\n",
            "  [-9.61512327e-04 -7.84805194e-02]\n",
            "  [-6.79572020e-03 -1.41172959e-02]\n",
            "  [ 6.79572020e-03  1.41172959e-02]]\n",
            "\n",
            " [[-2.99932342e-03 -8.18604324e-03]\n",
            "  [ 2.99932342e-03  8.18604324e-03]\n",
            "  [ 1.74558118e-01  1.39437467e-02]\n",
            "  [-1.74558118e-01 -1.39437467e-02]\n",
            "  [-2.99932342e-03 -8.18604324e-03]\n",
            "  [ 2.99932342e-03  8.18604324e-03]]\n",
            "\n",
            " [[-1.43791093e-02  6.75293268e-04]\n",
            "  [ 1.43791093e-02 -6.75293268e-04]\n",
            "  [-7.30820820e-02 -5.21109700e-02]\n",
            "  [ 7.30820820e-02  5.21109700e-02]\n",
            "  [-1.43791093e-02  6.75293268e-04]\n",
            "  [ 1.43791093e-02 -6.75293268e-04]]\n",
            "\n",
            " [[ 2.20790040e-02  7.24066282e-03]\n",
            "  [-2.20790040e-02 -7.24066282e-03]\n",
            "  [ 3.37610006e-01 -2.12321907e-01]\n",
            "  [-3.37610006e-01  2.12321907e-01]\n",
            "  [ 2.20790040e-02  7.24066282e-03]\n",
            "  [-2.20790040e-02 -7.24066282e-03]]\n",
            "\n",
            " [[-4.28159907e-03  1.66521370e-02]\n",
            "  [ 4.28159907e-03 -1.66521370e-02]\n",
            "  [ 2.41476372e-02 -2.58409142e-01]\n",
            "  [-2.41476372e-02  2.58409142e-01]\n",
            "  [-4.28159907e-03  1.66521370e-02]\n",
            "  [ 4.28159907e-03 -1.66521370e-02]]\n",
            "\n",
            " [[ 1.77063849e-02 -1.35354958e-02]\n",
            "  [-1.77063849e-02  1.35354958e-02]\n",
            "  [ 2.66502768e-01  2.05040723e-03]\n",
            "  [-2.66502768e-01 -2.05040723e-03]\n",
            "  [ 1.77063849e-02 -1.35354958e-02]\n",
            "  [-1.77063849e-02  1.35354958e-02]]\n",
            "\n",
            " [[ 2.26608962e-02 -4.60722577e-03]\n",
            "  [-2.26608962e-02  4.60722577e-03]\n",
            "  [-3.01372349e-01 -2.82987058e-02]\n",
            "  [ 3.01372349e-01  2.82987058e-02]\n",
            "  [ 2.26608962e-02 -4.60722577e-03]\n",
            "  [-2.26608962e-02  4.60722577e-03]]\n",
            "\n",
            " [[-2.61126342e-03 -1.27521614e-02]\n",
            "  [ 2.61126342e-03  1.27521614e-02]\n",
            "  [ 1.05554618e-01  1.26001313e-02]\n",
            "  [-1.05554618e-01 -1.26001313e-02]\n",
            "  [-2.61126342e-03 -1.27521614e-02]\n",
            "  [ 2.61126342e-03  1.27521614e-02]]\n",
            "\n",
            " [[ 1.07416352e-02  5.43363206e-03]\n",
            "  [-1.07416352e-02 -5.43363206e-03]\n",
            "  [-2.08585739e-01  1.56891465e-01]\n",
            "  [ 2.08585739e-01 -1.56891465e-01]\n",
            "  [ 1.07416352e-02  5.43363206e-03]\n",
            "  [-1.07416352e-02 -5.43363206e-03]]\n",
            "\n",
            " [[-2.16011889e-02  7.81126367e-03]\n",
            "  [ 2.16011889e-02 -7.81126367e-03]\n",
            "  [-1.11199319e-02  1.83859885e-01]\n",
            "  [ 1.11199319e-02 -1.83859885e-01]\n",
            "  [-2.16011889e-02  7.81126367e-03]\n",
            "  [ 2.16011889e-02 -7.81126367e-03]]\n",
            "\n",
            " [[-1.62742082e-02 -6.54784078e-03]\n",
            "  [ 1.62742082e-02  6.54784078e-03]\n",
            "  [ 4.30750325e-02 -8.23843405e-02]\n",
            "  [-4.30750325e-02  8.23843405e-02]\n",
            "  [-1.62742082e-02 -6.54784078e-03]\n",
            "  [ 1.62742082e-02  6.54784078e-03]]\n",
            "\n",
            " [[ 1.04849692e-02  1.19113619e-03]\n",
            "  [-1.04849692e-02 -1.19113619e-03]\n",
            "  [-2.51687944e-01 -2.22877607e-01]\n",
            "  [ 2.51687944e-01  2.22877607e-01]\n",
            "  [ 1.04849692e-02  1.19113619e-03]\n",
            "  [-1.04849692e-02 -1.19113619e-03]]\n",
            "\n",
            " [[-3.39098386e-02 -3.74860759e-03]\n",
            "  [ 3.39098386e-02  3.74860759e-03]\n",
            "  [-2.40832418e-02 -2.56549641e-02]\n",
            "  [ 2.40832418e-02  2.56549641e-02]\n",
            "  [-3.39098386e-02 -3.74860759e-03]\n",
            "  [ 3.39098386e-02  3.74860759e-03]]\n",
            "\n",
            " [[-6.76616677e-04  7.84244668e-03]\n",
            "  [ 6.76616677e-04 -7.84244668e-03]\n",
            "  [ 3.09988856e-04  1.97955236e-01]\n",
            "  [-3.09988856e-04 -1.97955236e-01]\n",
            "  [-6.76616677e-04  7.84244668e-03]\n",
            "  [ 6.76616677e-04 -7.84244668e-03]]\n",
            "\n",
            " [[-1.07439514e-02  1.35798883e-02]\n",
            "  [ 1.07439514e-02 -1.35798883e-02]\n",
            "  [ 1.42784342e-02  2.33368173e-01]\n",
            "  [-1.42784342e-02 -2.33368173e-01]\n",
            "  [-1.07439514e-02  1.35798883e-02]\n",
            "  [ 1.07439514e-02 -1.35798883e-02]]\n",
            "\n",
            " [[ 7.01821735e-03 -5.83145162e-03]\n",
            "  [-7.01821735e-03  5.83145162e-03]\n",
            "  [ 2.24991813e-01  8.23255554e-02]\n",
            "  [-2.24991813e-01 -8.23255554e-02]\n",
            "  [ 7.01821735e-03 -5.83145162e-03]\n",
            "  [-7.01821735e-03  5.83145162e-03]]\n",
            "\n",
            " [[-9.29278973e-03  1.58218518e-02]\n",
            "  [ 9.29278973e-03 -1.58218518e-02]\n",
            "  [ 3.76640856e-02  2.51624703e-01]\n",
            "  [-3.76640856e-02 -2.51624703e-01]\n",
            "  [-9.29278973e-03  1.58218518e-02]\n",
            "  [ 9.29278973e-03 -1.58218518e-02]]\n",
            "\n",
            " [[ 8.26729182e-03  5.47917653e-03]\n",
            "  [-8.26729182e-03 -5.47917653e-03]\n",
            "  [ 1.82173043e-01 -1.84091538e-01]\n",
            "  [-1.82173043e-01  1.84091538e-01]\n",
            "  [ 8.26729182e-03  5.47917653e-03]\n",
            "  [-8.26729182e-03 -5.47917653e-03]]\n",
            "\n",
            " [[-8.36697593e-03  2.16134288e-03]\n",
            "  [ 8.36697593e-03 -2.16134288e-03]\n",
            "  [ 1.41041279e-01 -9.52845514e-02]\n",
            "  [-1.41041279e-01  9.52845514e-02]\n",
            "  [-8.36697593e-03  2.16134288e-03]\n",
            "  [ 8.36697593e-03 -2.16134288e-03]]\n",
            "\n",
            " [[ 3.02930735e-02  5.07380930e-04]\n",
            "  [-3.02930735e-02 -5.07380930e-04]\n",
            "  [-3.54802191e-01 -4.80307788e-02]\n",
            "  [ 3.54802191e-01  4.80307788e-02]\n",
            "  [ 3.02930735e-02  5.07380930e-04]\n",
            "  [-3.02930735e-02 -5.07380930e-04]]\n",
            "\n",
            " [[ 2.28869473e-03 -8.88485275e-03]\n",
            "  [-2.28869473e-03  8.88485275e-03]\n",
            "  [ 1.57622933e-01 -1.48530900e-02]\n",
            "  [-1.57622933e-01  1.48530900e-02]\n",
            "  [ 2.28869473e-03 -8.88485275e-03]\n",
            "  [-2.28869473e-03  8.88485275e-03]]\n",
            "\n",
            " [[ 5.88950003e-03  5.95332996e-04]\n",
            "  [-5.88950003e-03 -5.95332996e-04]\n",
            "  [ 1.80720523e-01 -1.23670317e-01]\n",
            "  [-1.80720523e-01  1.23670317e-01]\n",
            "  [ 5.88950003e-03  5.95332996e-04]\n",
            "  [-5.88950003e-03 -5.95332996e-04]]\n",
            "\n",
            " [[-2.54796185e-02  3.70737212e-03]\n",
            "  [ 2.54796185e-02 -3.70737212e-03]\n",
            "  [ 6.93667531e-02 -1.28345162e-01]\n",
            "  [-6.93667531e-02  1.28345162e-01]\n",
            "  [-2.54796185e-02  3.70737212e-03]\n",
            "  [ 2.54796185e-02 -3.70737212e-03]]\n",
            "\n",
            " [[-6.74685836e-03  1.09759439e-02]\n",
            "  [ 6.74685836e-03 -1.09759439e-02]\n",
            "  [ 2.74304599e-02 -2.19506338e-01]\n",
            "  [-2.74304599e-02  2.19506338e-01]\n",
            "  [-6.74685836e-03  1.09759439e-02]\n",
            "  [ 6.74685836e-03 -1.09759439e-02]]\n",
            "\n",
            " [[-2.81427149e-02  2.75717024e-03]\n",
            "  [ 2.81427149e-02 -2.75717024e-03]\n",
            "  [-9.32862461e-02  1.05512291e-01]\n",
            "  [ 9.32862461e-02 -1.05512291e-01]\n",
            "  [-2.81427149e-02  2.75717024e-03]\n",
            "  [ 2.81427149e-02 -2.75717024e-03]]\n",
            "\n",
            " [[-2.19297409e-03  3.54757393e-03]\n",
            "  [ 2.19297409e-03 -3.54757393e-03]\n",
            "  [ 2.19296589e-02 -1.86847016e-01]\n",
            "  [-2.19296589e-02  1.86847016e-01]\n",
            "  [-2.19297409e-03  3.54757393e-03]\n",
            "  [ 2.19297409e-03 -3.54757393e-03]]\n",
            "\n",
            " [[ 2.08885055e-02  3.95467784e-03]\n",
            "  [-2.08885055e-02 -3.95467784e-03]\n",
            "  [ 2.91278601e-01 -1.49177194e-01]\n",
            "  [-2.91278601e-01  1.49177194e-01]\n",
            "  [ 2.08885055e-02  3.95467784e-03]\n",
            "  [-2.08885055e-02 -3.95467784e-03]]\n",
            "\n",
            " [[ 3.40872742e-02 -3.00259097e-03]\n",
            "  [-3.40872742e-02  3.00259097e-03]\n",
            "  [-3.69344950e-01 -1.04854606e-01]\n",
            "  [ 3.69344950e-01  1.04854606e-01]\n",
            "  [ 3.40872742e-02 -3.00259097e-03]\n",
            "  [-3.40872742e-02  3.00259097e-03]]\n",
            "\n",
            " [[ 4.15226817e-03  7.73349218e-03]\n",
            "  [-4.15226817e-03 -7.73349218e-03]\n",
            "  [ 1.30568519e-01  1.78599864e-01]\n",
            "  [-1.30568519e-01 -1.78599864e-01]\n",
            "  [ 4.15226817e-03  7.73349218e-03]\n",
            "  [-4.15226817e-03 -7.73349218e-03]]\n",
            "\n",
            " [[-4.34358558e-03  3.45338776e-04]\n",
            "  [ 4.34358558e-03 -3.45338776e-04]\n",
            "  [-1.71260163e-01 -7.77693912e-02]\n",
            "  [ 1.71260163e-01  7.77693912e-02]\n",
            "  [-4.34358558e-03  3.45338776e-04]\n",
            "  [ 4.34358558e-03 -3.45338776e-04]]\n",
            "\n",
            " [[-9.69392341e-03 -4.52678325e-03]\n",
            "  [ 9.69392341e-03  4.52678325e-03]\n",
            "  [-9.23758820e-02  2.75786221e-02]\n",
            "  [ 9.23758820e-02 -2.75786221e-02]\n",
            "  [-9.69392341e-03 -4.52678325e-03]\n",
            "  [ 9.69392341e-03  4.52678325e-03]]\n",
            "\n",
            " [[ 1.26260268e-02 -5.38127590e-03]\n",
            "  [-1.26260268e-02  5.38127590e-03]\n",
            "  [-2.33768106e-01 -4.65995744e-02]\n",
            "  [ 2.33768106e-01  4.65995744e-02]\n",
            "  [ 1.26260268e-02 -5.38127590e-03]\n",
            "  [-1.26260268e-02  5.38127590e-03]]\n",
            "\n",
            " [[-1.40126946e-03 -9.04116221e-03]\n",
            "  [ 1.40126946e-03  9.04116221e-03]\n",
            "  [ 1.02768227e-01  3.54123190e-02]\n",
            "  [-1.02768227e-01 -3.54123190e-02]\n",
            "  [-1.40126946e-03 -9.04116221e-03]\n",
            "  [ 1.40126946e-03  9.04116221e-03]]\n",
            "\n",
            " [[ 1.40031073e-02  5.12390444e-03]\n",
            "  [-1.40031073e-02 -5.12390444e-03]\n",
            "  [-2.41901666e-01  1.49979368e-01]\n",
            "  [ 2.41901666e-01 -1.49979368e-01]\n",
            "  [ 1.40031073e-02  5.12390444e-03]\n",
            "  [-1.40031073e-02 -5.12390444e-03]]\n",
            "\n",
            " [[ 9.59361903e-03 -1.13661345e-02]\n",
            "  [-9.59361903e-03  1.13661345e-02]\n",
            "  [ 2.05551773e-01  1.06064379e-02]\n",
            "  [-2.05551773e-01 -1.06064379e-02]\n",
            "  [ 9.59361903e-03 -1.13661345e-02]\n",
            "  [-9.59361903e-03  1.13661345e-02]]\n",
            "\n",
            " [[-1.47188164e-03 -9.96880420e-03]\n",
            "  [ 1.47188164e-03  9.96880420e-03]\n",
            "  [ 1.98189802e-02 -4.64035943e-02]\n",
            "  [-1.98189802e-02  4.64035943e-02]\n",
            "  [-1.47188164e-03 -9.96880420e-03]\n",
            "  [ 1.47188164e-03  9.96880420e-03]]\n",
            "\n",
            " [[ 2.30057929e-02 -5.10613387e-03]\n",
            "  [-2.30057929e-02  5.10613387e-03]\n",
            "  [ 3.03434163e-01  6.28621727e-02]\n",
            "  [-3.03434163e-01 -6.28621727e-02]\n",
            "  [ 2.30057929e-02 -5.10613387e-03]\n",
            "  [-2.30057929e-02  5.10613387e-03]]\n",
            "\n",
            " [[-2.15148344e-03  1.07428785e-02]\n",
            "  [ 2.15148344e-03 -1.07428785e-02]\n",
            "  [ 7.20739067e-02 -2.07424581e-01]\n",
            "  [-7.20739067e-02  2.07424581e-01]\n",
            "  [-2.15148344e-03  1.07428785e-02]\n",
            "  [ 2.15148344e-03 -1.07428785e-02]]\n",
            "\n",
            " [[-4.30472940e-03  9.74326860e-03]\n",
            "  [ 4.30472940e-03 -9.74326860e-03]\n",
            "  [ 1.18961707e-01  2.00220138e-01]\n",
            "  [-1.18961707e-01 -2.00220138e-01]\n",
            "  [-4.30472940e-03  9.74326860e-03]\n",
            "  [ 4.30472940e-03 -9.74326860e-03]]\n",
            "\n",
            " [[ 1.12856720e-02  8.17110762e-03]\n",
            "  [-1.12856720e-02 -8.17110762e-03]\n",
            "  [ 2.57760108e-01  2.14085117e-01]\n",
            "  [-2.57760108e-01 -2.14085117e-01]\n",
            "  [ 1.12856720e-02  8.17110762e-03]\n",
            "  [-1.12856720e-02 -8.17110762e-03]]]\n",
            "\n",
            "Nth Identities (Conceptual, per qubit):\n",
            "\n",
            "  Qubit 0:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.6866152   0.72681445]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 1:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9344468   0.35583732]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 2:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.3203546 0.9472179]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 3:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.26240185  0.9648784 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 4:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9539918  0.2996584]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 5:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99891394  0.04560205]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 6:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.30788386 -0.95137316]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 7:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9979806  -0.06318996]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 8:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8526032  0.5223632]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 9:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9967497   0.07972895]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 10:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9109325  -0.41228312]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 11:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.7610903  -0.64852417]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 12:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9966099  -0.08182357]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 13:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.5471001  0.83675617]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 14:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9364863  -0.35050544]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 15:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99964356 0.02437816]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 16:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.95241755 -0.30444038]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 17:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9421193  -0.33507407]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 18:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9906475  -0.13612212]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 19:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.90494955 -0.42539436]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 20:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8516472  0.5240194]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 21:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.6054296 -0.7956837]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 22:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.31461272 -0.94891983]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 23:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99984527 0.01541246]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 24:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.43371037 -0.9009814 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 25:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.34399015 -0.9388511 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 26:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9988296   0.04690854]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 27:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9501677 0.3116012]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 28:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.24900587  0.96844184]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 29:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.7944235 -0.6072903]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 30:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.97990924 -0.19922704]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 31:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.2005922 -0.9795964]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 32:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.8922561  0.45134574]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 33:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9403622   0.34004688]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 34:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9276718 -0.3732438]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 35:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9935146 0.1128674]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 36:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99391615 -0.10987376]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 37:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.08594599  0.9961723 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 38:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.6204259   0.78419137]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 39:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.76905584 -0.63901013]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 40:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.50641817  0.8622248 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 41:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.8334687  0.55238426]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 42:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96810573  0.25007942]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 43:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9998267  0.01674617]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 44:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.24942462 -0.96828157]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 45:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9947618 0.1005543]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 46:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9895411   0.14398164]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 47:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.5236306   0.85185426]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 48:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9951999   0.09750074]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 49:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.52568364  0.8503984 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 50:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9825  0.18601]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 51:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99611384 -0.08774308]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 52:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.47299284 0.8809369 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 53:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9966256   0.07923718]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 54:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9059926 -0.4230725]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 55:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.91986436 -0.3920508 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 56:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.15314241 -0.98809355]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 57:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9390422  0.34360677]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 58:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.6449628 -0.764126 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 59:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.14605072 -0.98917675]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 60:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9762019  -0.21666794]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 61:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.19635338  0.98044   ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 62:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.4040917   0.91461587]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 63:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.80992746 0.58640766]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "\n",
            "Info-energy Output (all qubits):\n",
            " [ 5.664113   3.2414432 12.380252   7.318507   9.367604   3.2668586\n",
            " 10.99574   21.216152   5.3159895  6.494157   8.1107435  4.7431717\n",
            " 12.191927   5.158268   4.107117   7.445465   8.29923    7.4901276\n",
            "  1.9877886 10.840014   6.3172493  4.5045786  4.1863666 10.828876\n",
            "  2.844001   4.988294   2.5307274 17.786753   6.1920576  7.040386\n",
            " 10.4110775  2.767186   7.305361   7.5815134  3.393347   9.230713\n",
            "  2.9982412  6.1848526 10.463778   8.187122   9.743383   7.0623493\n",
            "  5.1959324 16.567787   4.728344   4.867386   5.0672617  7.7600117\n",
            "  6.1420274  3.9471936  9.81737   11.186071   5.493405   6.2691784\n",
            "  3.5954463  7.464301   2.8724086  7.391033   5.1909485  1.5872048\n",
            " 11.850666   6.3803663  9.461951   9.440656 ]\n",
            "\n",
            "Resonance Keys (all qubits):\n",
            " ['06daad34881e65f03f036eb4864ab1a75e0b348dc0fd499e3897f547767881d5', '9d21c98ea6723ca531ef84e2e77fbd3e5bc6eb4930e94a77ceb13e6cc4ef8c69', '190923e1f67a7d33ce92827d2bfddaa05372882e0bfb968a9c22ce7fdc2a0d12', '734534c821c2d3fba1f1d5e5c50477d4221b291cb79bc8159160b9411c17e116', '286921d6788c4088eeb397bc8375a7dc6069412dd099eed1c37f6d5c47a002b4', '36f0b84ec2c7ae7736a11fc1bf38b238008eaf0e2a323d751cf3013856dc1dc2', '9196b4e468b167cb82cba45b0f6c9e37dc38c50bb455339bb3c2b0daa6a23748', '8e9e7177fc910583771bc57693a97680be8edced59c7061284de1cce2efb6157', '98a03a27d21e309d3c8493db8ac4b79788e6b25fbe5b3eff34ecce152a6e8e16', '9d39475e89532a12ef44afd9f8f37e4a0407958dea98adaf0b6482f0ee80fcc3', 'c17d9cdf54e72522ae038cc83349518ce5da0c2c32c960783086c67f87dec7f1', 'a7fb5aad7d5efb483329607831d52006b3d51ee74eab3e180f4140ef6124f34d', 'c5ebabae2b76eaf149d8df7bd663f4ed38b8b9b401123a5fc0308d0e67834932', '40fe2a56bfe788394f1e9616b189718de8cce9b8bce51719d7f4ad7fb94752be', 'b7b37d4159ead6348f8e96e83b4193ca692429a7104369d2ca477d80148da644', 'eefed60ad928d13aa0d4b0f9109b136acddccff70dcd0ff4482f0c75c3424f1d', '2a094a48bcb4efb8354ce73b518601c4f1dc2ab951fc006caab148c45b2c20c0', '5b543c592fde0f42060466750b11124b46a794369fdc0135982ac038f8db8c93', '6bba14cf7d1d20f3ac11a8ab45abd5f30a88b2611332b56f995e8da13992fdc2', 'f9b1cae693e81366e64b6dc4dd62b66f16e542c3d97c48587c68710dd86dd48e', '96166f7925e70af446a8fac4290d1826ecade38ce13087d8bce9692fa63469f3', 'f5b446674ab5e09cc21967eef4915b368d235491f8bc15278e38cf79ad58fdd4', '65562bc9b3dedc5b906bf9284b3f0c2ab60694da94fab3be421d5f6f965657cd', 'f98e0fb7f9f804fbd8ff533c99601eab7936292664610ecd0fe3ef1928d13995', 'd7b69334c0077004576de0b28c86e69725be15472f13898c14383c0bc20b0ba0', 'b563082bae20795cbcbd77f4a8de06bf0d9eaa4039a67534c3827906d62305ec', 'de098fdd2a5f90e87f308fadad146f009327ea9bd0241921416296bf87dd09b2', '500d48f9fec3001bca79fde1591c52665003208e46704a41ae731aa79967e3e6', 'f9014d786749c70e46cee49e4e93bfe14470a74d89cba30c8a472839f2c0d1bb', '735c5ad96895bd31793a59f48f3627cac1f6566ceb6090dc0cba23bb6ec89da3', '3bc24e5ba13fe6e58d55ab96aedec2182e78011fd7d165895c8eaf8a983db6d1', 'ce16906c83fa4aba4f778a454985da7ee90d0c702764f8f67505165fe7fe1d04', 'ab428418ea48f71782eda727594fe77a2266302d677047fb58c794520b9b5b07', '048280927a7bc5fa3bfdc3f950bac85b007114886ed1d66b80088a32e26555ac', 'e30557a99bdd2995c5c2a1a176d2637fbae0cecbbc798ec7d39249c4ff3c4d3d', 'aed04981a4d97f5e28445135b9e0a182035e93c190b89c59ce6bcfd12d6d60fb', 'e3a777cbdee51acd5d6bc14d973d8732660704f30ecebcca894c6b4bf84d51b5', '80a557221845d54b3836c4b13fcb3bd0bf12ab3054725b391472b110f4bd3d62', '875a407160906d8178c7c7f9ba36dc1e20b71d9231ebc74173e7b0d2009a11c2', '7372297beabf8f3f2f20d308461afa59c2ade4396e23eac1534a8b15bd472d72', 'dfba2bf65ef801147607fed99695b40030e155bfd4c7a9c2a82f6cca6abd0335', '237b6a28f06c3abb52acdbd713836d1f646e80e69fa6d8515f5bcb1e16210882', 'c26bcd8f6431e975265de2d927f37ac1e2f8d1437115c30e4ba70ffe98ad0293', 'd0f6f826fc8d3128aaf0ed89af769d8718fc2ef61ee07dfac71399a5daa1dc5d', '51bc7950c79f8dbb136b568a496c3aa30868995367fea8e929e1395fc028d292', 'f7cb741be3ea76e312017a091e36aa6d377162d9d298972aacb411ea7438edaf', 'a77b5a7153a1507dfa45fb3ad7c7a29a8fab31e511df9b0590012d7ba0cb12c3', 'ea0c8b6f382d72f1f2cfdb4eedec436c36d5326691f104ad5349f03a8feee52b', '3ae2f68af56fe8d0130428a6acf9e076f2a005a198252e0c9e1294c1776ebb57', '220702db5a1d384600617364fef28a54a9843c3a2f4cd200a280a9e8b337b65f', 'ce6fee2ca3e045be7ece84905ef1468e64b68854906909ca5894c19df6d91259', '92c6e0754bb0b71a4bc3b00fb9e20026e405c45e23279b55d925ac84781a2755', 'a20c97665a7caaad54bced7e186be4aff15e5a8d5469e4fa65600c8de3f378a2', 'd5e86c27471cdef329de7ade03e1b70bced1aee61d6c27a75e21e71f42e6102f', '39482f29089cc04145d7389959690fc48637b92d04bd6da8b0daaa8dea7f12b1', 'a1fb299cbcde26ab7fa109f6bb343c6601703267736d1e64b3b541c5614fa442', 'a977063a0093c57d5435fe1bdb3c6155e4ceabc6157c2a1d1916325fd94bb40b', '700125470aa799ea08fd88760e343d0e5014b527d12b18a28fec71b90ff5c606', 'ab839eeb44ffd19cfb801f23bb35512ade89d0266cd2321183bf20221ebec451', 'd1b2b25caaa320fcb9b0d824e665982308b4ab554dd1bd97c9f97e99e6a649d3', '641ea96f3a28401e3cf69e298484817795ffa29a45db89ced15a81b4086220f8', '93c776f343aeb7ec6ea72b988ca4696fbd46e91dc3a267d6e4135cc4b8fbf94a', 'bb5a9d0529e000d1aae556ab188a4efe5c998b0d42092dc1d8e0100d97df311d', '24270b59705b61e5e70093d9c98ad7f249e1d4563f3d03ad476cdeeb3e575206']\n",
            "\n",
            "Spin (all qubits, conceptual):\n",
            " [[[-0.83662593  0.30517218 -0.45489222]\n",
            "  [-0.81854826 -0.35078746 -0.45489222]]\n",
            "\n",
            " [[-0.1716074  -0.4889917   0.8552415 ]\n",
            "  [-0.2199969  -0.4692157   0.8552415 ]]\n",
            "\n",
            " [[ 0.95872205  0.04329533 -0.28102937]\n",
            "  [-0.3374578  -0.89841235 -0.28102937]]\n",
            "\n",
            " [[-0.8314095   0.236782    0.5026853 ]\n",
            "  [-0.77813834  0.37657428  0.5026853 ]]\n",
            "\n",
            " [[ 0.34853986  0.18637729 -0.9185769 ]\n",
            "  [-0.3031691  -0.25358436 -0.9185769 ]]\n",
            "\n",
            " [[-0.7328247   0.6431754  -0.22202097]\n",
            "  [ 0.97499835  0.00921603 -0.22202097]]\n",
            "\n",
            " [[ 0.9898262   0.0828657  -0.1156608 ]\n",
            "  [ 0.35760874  0.92668146 -0.1156608 ]]\n",
            "\n",
            " [[ 0.20139286 -0.23098524  0.9518859 ]\n",
            "  [-0.22934543 -0.20325832  0.9518859 ]]\n",
            "\n",
            " [[ 0.39483362  0.8743348   0.2822145 ]\n",
            "  [ 0.79877365 -0.53133386  0.2822145 ]]\n",
            "\n",
            " [[ 0.28819612 -0.86280674 -0.41534021]\n",
            "  [-0.8596153   0.29758027 -0.41534021]]\n",
            "\n",
            " [[ 0.33763832  0.8648598   0.3715075 ]\n",
            "  [ 0.8812867   0.2920889   0.3715075 ]]\n",
            "\n",
            " [[ 0.02327821  0.04114883  0.9988818 ]\n",
            "  [-0.01101217 -0.04597644  0.9988818 ]]\n",
            "\n",
            " [[-0.09712469  0.00996531 -0.99522233]\n",
            "  [-0.08449221 -0.04892423 -0.99522233]]\n",
            "\n",
            " [[-0.2166256  -0.90070415  0.3765705 ]\n",
            "  [-0.925449   -0.04169825  0.3765705 ]]\n",
            "\n",
            " [[-0.9749813  -0.2003732   0.09623965]\n",
            "  [-0.37310678  0.92278343  0.09623965]]\n",
            "\n",
            " [[-0.14493623 -0.08282903  0.985968  ]\n",
            "  [-0.13436896  0.09905625  0.985968  ]]\n",
            "\n",
            " [[ 0.4481839   0.76464516  0.4630864 ]\n",
            "  [-0.38392437  0.7988448   0.4630864 ]]\n",
            "\n",
            " [[-0.77573395  0.01169229  0.63095176]\n",
            "  [-0.6193062   0.46728966  0.63095176]]\n",
            "\n",
            " [[-0.5583341   0.24395496 -0.7929369 ]\n",
            "  [-0.44285494 -0.418486   -0.7929369 ]]\n",
            "\n",
            " [[ 0.5596196   0.64159423  0.52457863]\n",
            "  [ 0.07204428 -0.84830827  0.52457863]]\n",
            "\n",
            " [[ 0.17571121 -0.05056676  0.9831422 ]\n",
            "  [ 0.00356271  0.18280792  0.9831422 ]]\n",
            "\n",
            " [[-0.3923038  -0.8472112  -0.35823312]\n",
            "  [ 0.81417227 -0.45693824 -0.35823312]]\n",
            "\n",
            " [[ 0.06919616 -0.31300133  0.9472286 ]\n",
            "  [ 0.29528993 -0.12474695  0.9472286 ]]\n",
            "\n",
            " [[-0.81769323  0.02192249  0.5752366 ]\n",
            "  [ 0.7202622   0.38771784  0.5752366 ]]\n",
            "\n",
            " [[ 0.3293933   0.7693366  -0.5473767 ]\n",
            "  [ 0.83366895  0.07331339 -0.5473767 ]]\n",
            "\n",
            " [[ 0.14564587  0.15384753  0.9773015 ]\n",
            "  [ 0.03130799 -0.20952706  0.9773015 ]]\n",
            "\n",
            " [[-0.19702184 -0.91807306  0.34398288]\n",
            "  [-0.45133322  0.82339185  0.34398288]]\n",
            "\n",
            " [[ 0.47910815 -0.7561683  -0.4457184 ]\n",
            "  [ 0.21752842 -0.8683412  -0.4457184 ]]\n",
            "\n",
            " [[-0.09874654 -0.6559845   0.748287  ]\n",
            "  [-0.6323971  -0.20035075  0.748287  ]]\n",
            "\n",
            " [[-0.23128963 -0.09168185  0.9685554 ]\n",
            "  [-0.23723346 -0.07497157  0.9685554 ]]\n",
            "\n",
            " [[-0.4574572  -0.05869719  0.88729227]\n",
            "  [-0.17981608 -0.42471007  0.88729227]]\n",
            "\n",
            " [[ 0.9502384   0.11660914 -0.28887588]\n",
            "  [-0.9567575   0.03414436 -0.28887588]]\n",
            "\n",
            " [[-0.5394531   0.6885281   0.4846848 ]\n",
            "  [-0.50835216 -0.7117996   0.4846848 ]]\n",
            "\n",
            " [[-0.7282389   0.23298994 -0.64450276]\n",
            "  [-0.5558661  -0.52500385 -0.64450276]]\n",
            "\n",
            " [[ 0.32400623 -0.58823806 -0.74094266]\n",
            "  [ 0.52143127 -0.42321798 -0.74094266]]\n",
            "\n",
            " [[ 0.06895421  0.8113707  -0.5804506 ]\n",
            "  [ 0.81385046 -0.02691765 -0.5804506 ]]\n",
            "\n",
            " [[-0.8335473  -0.06981163  0.5480194 ]\n",
            "  [ 0.801766    0.23842406  0.5480194 ]]\n",
            "\n",
            " [[ 0.7240433   0.3829075  -0.57371   ]\n",
            "  [-0.7189951   0.39230457 -0.57371   ]]\n",
            "\n",
            " [[ 0.46895066 -0.8624172   0.19058289]\n",
            "  [ 0.38112432  0.904667    0.19058289]]\n",
            "\n",
            " [[-0.40426105 -0.5168455   0.75461495]\n",
            "  [ 0.6350377  -0.16517684  0.75461495]]\n",
            "\n",
            " [[-0.2718389  -0.87197816 -0.40713352]\n",
            "  [-0.8841142  -0.22931293 -0.40713352]]\n",
            "\n",
            " [[-0.04243881 -0.02324174 -0.9988287 ]\n",
            "  [-0.00150853  0.04836275 -0.9988287 ]]\n",
            "\n",
            " [[ 0.10415483 -0.8370307  -0.5371511 ]\n",
            "  [ 0.8243708   0.17855366 -0.5371511 ]]\n",
            "\n",
            " [[ 0.33203956 -0.3064816   0.89208674]\n",
            "  [ 0.39608887 -0.2174738   0.89208674]]\n",
            "\n",
            " [[-0.08738618  0.12429693 -0.98838955]\n",
            "  [-0.12005679 -0.09312592 -0.98838955]]\n",
            "\n",
            " [[ 0.6846878   0.6771842   0.2694887 ]\n",
            "  [ 0.6387201   0.72070277  0.2694887 ]]\n",
            "\n",
            " [[-0.4517746   0.7336504   0.5075991 ]\n",
            "  [-0.63445383  0.5829335   0.5075991 ]]\n",
            "\n",
            " [[-0.23157562 -0.90215087  0.3640008 ]\n",
            "  [-0.29397625  0.8837881   0.3640008 ]]\n",
            "\n",
            " [[ 0.3009606  -0.13304266  0.94431055]\n",
            "  [-0.08625702  0.31754896  0.94431055]]\n",
            "\n",
            " [[ 0.04872276 -0.03340367 -0.99825364]\n",
            "  [-0.05542241  0.02044673 -0.99825364]]\n",
            "\n",
            " [[-0.7495846  -0.5818402   0.31557065]\n",
            "  [ 0.5013191   0.8056639   0.31557065]]\n",
            "\n",
            " [[-0.73656887  0.04011533  0.6751719 ]\n",
            "  [ 0.18401445 -0.71434     0.6751719 ]]\n",
            "\n",
            " [[ 0.7165131  -0.31492573  0.6224393 ]\n",
            "  [ 0.74813575 -0.22991765  0.6224393 ]]\n",
            "\n",
            " [[ 0.9037153   0.1781131   0.3893255 ]\n",
            "  [-0.89654505  0.21126424  0.3893255 ]]\n",
            "\n",
            " [[ 0.35774878 -0.4399531   0.82368505]\n",
            "  [ 0.56696194  0.00985336  0.82368505]]\n",
            "\n",
            " [[-0.13145015  0.6905597  -0.71123004]\n",
            "  [ 0.4470054   0.5425293  -0.71123004]]\n",
            "\n",
            " [[ 0.38901708 -0.9070346  -0.1611025 ]\n",
            "  [-0.6599192   0.73386145 -0.1611025 ]]\n",
            "\n",
            " [[-0.6485249  -0.24377969 -0.72110116]\n",
            "  [ 0.23634179 -0.6512723  -0.72110116]]\n",
            "\n",
            " [[ 0.06046719  0.11013415 -0.9920757 ]\n",
            "  [-0.04371057  0.11779303 -0.9920757 ]]\n",
            "\n",
            " [[ 0.30427945 -0.3234322  -0.8959942 ]\n",
            "  [-0.18708856 -0.402731   -0.8959942 ]]\n",
            "\n",
            " [[-0.08317293  0.75306445 -0.6526685 ]\n",
            "  [ 0.29837212  0.6964179  -0.6526685 ]]\n",
            "\n",
            " [[-0.5339166   0.5042628  -0.67871356]\n",
            "  [ 0.6418077   0.3569745  -0.67871356]]\n",
            "\n",
            " [[ 0.63669986 -0.77024066  0.03664173]\n",
            "  [-0.629127    0.7764384   0.03664173]]\n",
            "\n",
            " [[-0.4538627  -0.83774525  0.3036306 ]\n",
            "  [ 0.28616372  0.9088007   0.3036306 ]]]\n",
            "\n",
            "I_vec (all qubits, conceptual):\n",
            " [[0.09151357 0.08491848 0.3875682  ... 0.25376046 0.5478712  0.08435702]\n",
            " [0.3416604  0.32065162 0.04422504 ... 0.06951191 0.32640338 0.216015  ]\n",
            " [0.33681786 0.08505451 0.03513383 ... 0.09742806 0.37043563 0.21049112]\n",
            " ...\n",
            " [0.23686737 0.18835355 0.18726945 ... 0.02961628 0.24591473 0.20650853]\n",
            " [0.11722361 0.40208167 0.05992839 ... 0.3903746  0.33998403 0.05063025]\n",
            " [0.24254632 0.23123011 0.37595373 ... 0.13327092 0.11875174 0.17055963]]\n",
            "\n",
            "NECL Manifest Checksums (per qubit, conceptual):\n",
            " ['718184d54a0eaef5045d5e09708815231467f1702346324dcb4dc63efb89fbcd', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945']\n",
            "\n",
            "TRACE Log (Conceptual - detailed lineage for error correction):\n",
            " [{'qubit': 0, 'reason': 'binary_refactor', 'source': 'tuplets', 'r_metric': 0.9772743582725525, 'u_metric': 0.9757162928581238, 'dv_metric': -0.05980956554412842, 'invariant_pass': False, 'degenerate_check': False, 'correction_threshold_r': 1.02, 'correction_threshold_u': 1.02, 'correction_threshold_d': 0.765, 'corrected_bits': [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1], 'old_key': '423aebcd46355e5135c4d7691b7471038bf9de79b84409e3068e18442db8fca2', 'new_key': '06daad34881e65f03f036eb4864ab1a75e0b348dc0fd499e3897f547767881d5'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "503b43dd"
      },
      "source": [
        "**Reasoning**:\n",
        "The provided code block already incorporates the requested changes for `R_FOR_RATIO` and `detect_collapse` function. I will re-execute the code to confirm its correct implementation and ensure all instructions have been met.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "555f25d7",
        "outputId": "598c2e82-8eb8-47ce-b687-bdfd99fed63f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "R_FOR_RATIO = 64.0 # NEW: Ratio threshold constant for collapse detection, updated to 64.0 as per instructions\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| + n_|y, η| = n_|x+y, ξ+η|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| · n_|y, η| = n_|x·y, ξ·η|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ξ| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ξ_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW, r_for_ratio=R_FOR_RATIO):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register.\n",
        "    A triplet block collapses if, for any index 'p' within the triplet,\n",
        "    the condition [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO] is met.\n",
        "    If this condition is true for *any* index within the triplet, all indices i,j,k\n",
        "    of that triplet are marked as collapsed.\n",
        "    COLL(x, χ) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for unreal component (should be negative).\n",
        "        r_for_ratio (float): Ratio threshold for collapse detection.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    # Initialize a collapse mask filled with zeros\n",
        "    collapse_mask = tf.zeros(tf.shape(real_parts), dtype=tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Iterate over each triplet block and apply collapse detection\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # Extract real and unreal parts for the current triplet across all Q qubits\n",
        "        # shape [Q, 3]\n",
        "        triplet_real_block = tf.gather(real_parts, current_triplet_indices, axis=1)\n",
        "        triplet_unreal_block = tf.gather(unreal_parts, current_triplet_indices, axis=1)\n",
        "\n",
        "        # Evaluate the new triplet-level predicate for each index 'p' within the triplet block\n",
        "        # The condition: [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO]\n",
        "        # high(real_p): triplet_real_block >= tau_hi\n",
        "        # low(unreal_p): triplet_unreal_block <= tau_low (using TAU_LOW for unreal too)\n",
        "\n",
        "        # Condition 1: high(real_p) AND low(unreal_p)\n",
        "        cond1 = tf.logical_and(triplet_real_block >= tau_hi, triplet_unreal_block <= tau_low) # [Q, 3]\n",
        "\n",
        "        # Condition 2: ratio(real_p / unreal_p) > r_for_ratio\n",
        "        # Handle potential division by zero for unreal_p\n",
        "        # If unreal_p is near zero, the ratio might be undefined or very large.\n",
        "        # Set ratio to 0 if unreal_p is ~0 to avoid NaNs and make the condition false.\n",
        "        ratio_term = tf.where(tf.abs(triplet_unreal_block) > EPS, triplet_real_block / triplet_unreal_block, tf.zeros_like(triplet_real_block))\n",
        "        cond2 = ratio_term > r_for_ratio # [Q, 3]\n",
        "\n",
        "        # Triplet collapse if (cond1 OR cond2) is true for *any* index within the triplet\n",
        "        # tf.reduce_any along the triplet dimension (axis=1) for each qubit\n",
        "        triplet_collapse_per_qubit = tf.reduce_any(tf.logical_or(cond1, cond2), axis=1) # [Q]\n",
        "\n",
        "        # Mark all 3 indices of the triplet as collapsed if triplet_collapse_per_qubit is true for that qubit\n",
        "        unit_collapse_flag_int = tf.cast(triplet_collapse_per_qubit, tf.int32) # [Q]\n",
        "        marked_triplet_block = tf.broadcast_to(tf.expand_dims(unit_collapse_flag_int, axis=1), tf.shape(triplet_real_block)) # [Q, 3]\n",
        "\n",
        "        # Construct indices for scatter_nd_max to update the global collapse_mask\n",
        "        # indices_to_update will be [Q*3, 2]\n",
        "        # First column is qubit index, second is original 30-index\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1)\n",
        "\n",
        "        # Flatten marked_triplet_block to [Q*3] for updates\n",
        "        updates = tf.reshape(marked_triplet_block, [-1])\n",
        "\n",
        "        # Use tf.tensor_scatter_nd_max to update the collapse_mask.\n",
        "        # This ensures that if any triplet marks an index as collapsed, it remains marked.\n",
        "        collapse_mask = tf.tensor_scatter_nd_max(collapse_mask, indices_to_update, updates)\n",
        "\n",
        "    return collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`).\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode('utf-8')).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    for b_idx_triplet in tf.range(10):\n",
        "        current_triplet_indices = idx[b_idx_triplet, :] # Shape [3]\n",
        "        s = tf.gather(signs, current_triplet_indices) # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        # Ensure the list extension is compatible with TF operations if trip_mix is later converted to Tensor\n",
        "        # Here, it's converted to Python list and then to Tensor once.\n",
        "        trip_mix.extend([has_mix.numpy().item()]*3)\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook for a single qubit (q_idx). This function performs a local\n",
        "    re-evaluation of the bit pattern for the current qubit if the initial derivation\n",
        "    is deemed 'inconsistent'.\n",
        "\n",
        "    This function is designed to:\n",
        "    - Advance *only* within the same triplet (or within the primaries 6-set) for local re-evaluation.\n",
        "      It uses the `pairs_q` and `triplets_q` already derived for this specific qubit `q_idx`.\n",
        "      It does not implicitly advance to other qubits or triplets; its scope is limited to the\n",
        "      current qubit's local tuplet structure.\n",
        "    - Record lineage for any local adjustments made. If a correction occurs, a specific\n",
        "      entry is added to the `TRACE` log, detailing the reason, source, metrics, and new key.\n",
        "    - *Not* advance across different units (triplets or qubits) unless the current local unit\n",
        "      has been exhausted. The `derive_bits_advanced` function, called internally,\n",
        "      operates solely on the provided `pairs_q` and `triplets_q` for the current qubit.\n",
        "\n",
        "    Args:\n",
        "        q_idx (int): The index of the current qubit being processed.\n",
        "        pairs_q (tf.Tensor): The 30-index phase-dual pair register for the current qubit [30, 2].\n",
        "        triplets_q (tf.Tensor): The 10 triplets for the current qubit [10, 3, 2].\n",
        "        current_bits_q (tf.Tensor): The initially derived 30-bit pattern for the current qubit [30].\n",
        "        resonance_key_q (str): The current resonance key string for the qubit.\n",
        "        TRACE (list): A list to append lineage information if corrections are made.\n",
        "        invariants (dict): Dictionary of invariant constants.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, str]:\n",
        "            - new_bits_q (tf.Tensor): The potentially corrected 30-bit pattern.\n",
        "            - updated_resonance_key_q (str): The updated resonance key string (with lineage if corrected).\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        # The updated key incorporates the correction lineage.\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs) # Pass R_FOR_RATIO implicitly from constants\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primaries In:\n",
            " [[[ 0.90209603 -0.53428197]\n",
            "  [-0.90209603  0.53428197]\n",
            "  [ 0.70395136 -0.36591053]\n",
            "  [-0.70395136  0.36591053]\n",
            "  [-0.31954408  0.98262954]\n",
            "  [ 0.31954408 -0.98262954]]\n",
            "\n",
            " [[-0.8982675  -0.265064  ]\n",
            "  [ 0.8982675   0.265064  ]\n",
            "  [-0.1840229   0.80294514]\n",
            "  [ 0.1840229  -0.80294514]\n",
            "  [-0.6169443  -0.99405   ]\n",
            "  [ 0.6169443   0.99405   ]]\n",
            "\n",
            " [[-0.8802948   0.7524471 ]\n",
            "  [ 0.8802948  -0.7524471 ]\n",
            "  [-0.79389167 -0.8303001 ]\n",
            "  [ 0.79389167  0.8303001 ]\n",
            "  [-0.77415824 -0.585233  ]\n",
            "  [ 0.77415824  0.585233  ]]\n",
            "\n",
            " [[ 0.6575589   0.05274415]\n",
            "  [-0.6575589  -0.05274415]\n",
            "  [ 0.2511468   0.30640817]\n",
            "  [-0.2511468  -0.30640817]\n",
            "  [-0.12385678 -0.60668516]\n",
            "  [ 0.12385678  0.60668516]]\n",
            "\n",
            " [[-0.22904539  0.8970206 ]\n",
            "  [ 0.22904539 -0.8970206 ]\n",
            "  [ 0.04963422 -0.24383497]\n",
            "  [-0.04963422  0.24383497]\n",
            "  [-0.689733    0.71573305]\n",
            "  [ 0.689733   -0.71573305]]\n",
            "\n",
            " [[-0.61197925  0.02721548]\n",
            "  [ 0.61197925 -0.02721548]\n",
            "  [ 0.17395735 -0.85962915]\n",
            "  [-0.17395735  0.85962915]\n",
            "  [ 0.17013168 -0.2324841 ]\n",
            "  [-0.17013168  0.2324841 ]]\n",
            "\n",
            " [[ 0.8764496   0.46616673]\n",
            "  [-0.8764496  -0.46616673]\n",
            "  [ 0.51229286 -0.7488482 ]\n",
            "  [-0.51229286  0.7488482 ]\n",
            "  [-0.93452144 -0.4941244 ]\n",
            "  [ 0.93452144  0.4941244 ]]\n",
            "\n",
            " [[-0.20388198 -0.9181049 ]\n",
            "  [ 0.20388198  0.9181049 ]\n",
            "  [-0.38662982 -0.7913122 ]\n",
            "  [ 0.38662982  0.7913122 ]\n",
            "  [-0.09843874  0.31561732]\n",
            "  [ 0.09843874 -0.31561732]]\n",
            "\n",
            " [[-0.71058416  0.22072291]\n",
            "  [ 0.71058416 -0.22072291]\n",
            "  [-0.5916462  -0.24328446]\n",
            "  [ 0.5916462   0.24328446]\n",
            "  [-0.29978275 -0.79807305]\n",
            "  [ 0.29978275  0.79807305]]\n",
            "\n",
            " [[ 0.4785688  -0.52458644]\n",
            "  [-0.4785688   0.52458644]\n",
            "  [-0.8369005   0.35096097]\n",
            "  [ 0.8369005  -0.35096097]\n",
            "  [-0.71279526  0.04718637]\n",
            "  [ 0.71279526 -0.04718637]]\n",
            "\n",
            " [[ 0.13383341 -0.8407886 ]\n",
            "  [-0.13383341  0.8407886 ]\n",
            "  [ 0.31147432  0.8115854 ]\n",
            "  [-0.31147432 -0.8115854 ]\n",
            "  [ 0.3732264   0.42423964]\n",
            "  [-0.3732264  -0.42423964]]\n",
            "\n",
            " [[ 0.22497082  0.5386503 ]\n",
            "  [-0.22497082 -0.5386503 ]\n",
            "  [ 0.729079   -0.1809802 ]\n",
            "  [-0.729079    0.1809802 ]\n",
            "  [-0.39246273  0.31418967]\n",
            "  [ 0.39246273 -0.31418967]]\n",
            "\n",
            " [[ 0.05465627  0.98146963]\n",
            "  [-0.05465627 -0.98146963]\n",
            "  [-0.50486016  0.2021792 ]\n",
            "  [ 0.50486016 -0.2021792 ]\n",
            "  [-0.16645908  0.563452  ]\n",
            "  [ 0.16645908 -0.563452  ]]\n",
            "\n",
            " [[-0.15716004 -0.75601864]\n",
            "  [ 0.15716004  0.75601864]\n",
            "  [-0.15372896 -0.6791868 ]\n",
            "  [ 0.15372896  0.6791868 ]\n",
            "  [-0.11994147  0.9924991 ]\n",
            "  [ 0.11994147 -0.9924991 ]]\n",
            "\n",
            " [[ 0.64064264 -0.95319223]\n",
            "  [-0.64064264  0.95319223]\n",
            "  [-0.18294573 -0.64532137]\n",
            "  [ 0.18294573  0.64532137]\n",
            "  [ 0.8903265   0.86540127]\n",
            "  [-0.8903265  -0.86540127]]\n",
            "\n",
            " [[-0.562814   -0.654721  ]\n",
            "  [ 0.562814    0.654721  ]\n",
            "  [-0.03399587  0.09481144]\n",
            "  [ 0.03399587 -0.09481144]\n",
            "  [-0.0273428   0.69121766]\n",
            "  [ 0.0273428  -0.69121766]]\n",
            "\n",
            " [[ 0.06630731 -0.53693724]\n",
            "  [-0.06630731  0.53693724]\n",
            "  [ 0.25194025 -0.18465376]\n",
            "  [-0.25194025  0.18465376]\n",
            "  [-0.17040968 -0.82795954]\n",
            "  [ 0.17040968  0.82795954]]\n",
            "\n",
            " [[ 0.43061042 -0.2542913 ]\n",
            "  [-0.43061042  0.2542913 ]\n",
            "  [-0.31749582 -0.89433956]\n",
            "  [ 0.31749582  0.89433956]\n",
            "  [ 0.4134233  -0.3139422 ]\n",
            "  [-0.4134233   0.3139422 ]]\n",
            "\n",
            " [[-0.34206605  0.35556436]\n",
            "  [ 0.34206605 -0.35556436]\n",
            "  [ 0.22248101 -0.20108414]\n",
            "  [-0.22248101  0.20108414]\n",
            "  [ 0.45535088 -0.17201424]\n",
            "  [-0.45535088  0.17201424]]\n",
            "\n",
            " [[ 0.22603512 -0.36481452]\n",
            "  [-0.22603512  0.36481452]\n",
            "  [-0.9069717   0.843333  ]\n",
            "  [ 0.9069717  -0.843333  ]\n",
            "  [ 0.9720948   0.38812804]\n",
            "  [-0.9720948  -0.38812804]]\n",
            "\n",
            " [[-0.51322603  0.9009564 ]\n",
            "  [ 0.51322603 -0.9009564 ]\n",
            "  [ 0.57208705 -0.70875096]\n",
            "  [-0.57208705  0.70875096]\n",
            "  [ 0.77653337 -0.9490931 ]\n",
            "  [-0.77653337  0.9490931 ]]\n",
            "\n",
            " [[ 0.7187507  -0.05127263]\n",
            "  [-0.7187507   0.05127263]\n",
            "  [ 0.8867998  -0.00269794]\n",
            "  [-0.8867998   0.00269794]\n",
            "  [ 0.98481846  0.05856037]\n",
            "  [-0.98481846 -0.05856037]]\n",
            "\n",
            " [[-0.10533333 -0.19693494]\n",
            "  [ 0.10533333  0.19693494]\n",
            "  [-0.5037782  -0.9240315 ]\n",
            "  [ 0.5037782   0.9240315 ]\n",
            "  [ 0.17146468  0.11501932]\n",
            "  [-0.17146468 -0.11501932]]\n",
            "\n",
            " [[ 0.60215306  0.66104364]\n",
            "  [-0.60215306 -0.66104364]\n",
            "  [-0.44237852  0.329592  ]\n",
            "  [ 0.44237852 -0.329592  ]\n",
            "  [ 0.34658194  0.76787734]\n",
            "  [-0.34658194 -0.76787734]]\n",
            "\n",
            " [[-0.91309047  0.08150291]\n",
            "  [ 0.91309047 -0.08150291]\n",
            "  [ 0.2728982  -0.14918375]\n",
            "  [-0.2728982   0.14918375]\n",
            "  [-0.8714402  -0.93899345]\n",
            "  [ 0.8714402   0.93899345]]\n",
            "\n",
            " [[ 0.04602146 -0.26999044]\n",
            "  [-0.04602146  0.26999044]\n",
            "  [-0.02051806  0.7320335 ]\n",
            "  [ 0.02051806 -0.7320335 ]\n",
            "  [-0.06922865 -0.31789494]\n",
            "  [ 0.06922865  0.31789494]]\n",
            "\n",
            " [[ 0.8782983   0.95713115]\n",
            "  [-0.8782983  -0.95713115]\n",
            "  [ 0.30185747 -0.6164148 ]\n",
            "  [-0.30185747  0.6164148 ]\n",
            "  [-0.8954959  -0.03255963]\n",
            "  [ 0.8954959   0.03255963]]\n",
            "\n",
            " [[ 0.69266963  0.45587277]\n",
            "  [-0.69266963 -0.45587277]\n",
            "  [ 0.26290727 -0.21242237]\n",
            "  [-0.26290727  0.21242237]\n",
            "  [ 0.92924356  0.28258514]\n",
            "  [-0.92924356 -0.28258514]]\n",
            "\n",
            " [[-0.5933852   0.6235161 ]\n",
            "  [ 0.5933852  -0.6235161 ]\n",
            "  [-0.71016407  0.27481437]\n",
            "  [ 0.71016407 -0.27481437]\n",
            "  [ 0.93148565  0.811826  ]\n",
            "  [-0.93148565 -0.811826  ]]\n",
            "\n",
            " [[-0.05303526 -0.21697378]\n",
            "  [ 0.05303526  0.21697378]\n",
            "  [-0.74719596 -0.9572065 ]\n",
            "  [ 0.74719596  0.9572065 ]\n",
            "  [-0.59324145 -0.70884705]\n",
            "  [ 0.59324145  0.70884705]]\n",
            "\n",
            " [[ 0.20724773 -0.9957919 ]\n",
            "  [-0.20724773  0.9957919 ]\n",
            "  [ 0.8360288  -0.703001  ]\n",
            "  [-0.8360288   0.703001  ]\n",
            "  [-0.64391947 -0.13096857]\n",
            "  [ 0.64391947  0.13096857]]\n",
            "\n",
            " [[-0.05865693 -0.04245734]\n",
            "  [ 0.05865693  0.04245734]\n",
            "  [-0.6017864  -0.08402848]\n",
            "  [ 0.6017864   0.08402848]\n",
            "  [-0.04746604  0.5339973 ]\n",
            "  [ 0.04746604 -0.5339973 ]]\n",
            "\n",
            " [[-0.21163297 -0.17352033]\n",
            "  [ 0.21163297  0.17352033]\n",
            "  [-0.67730975  0.4129982 ]\n",
            "  [ 0.67730975 -0.4129982 ]\n",
            "  [ 0.5964029   0.56325626]\n",
            "  [-0.5964029  -0.56325626]]\n",
            "\n",
            " [[ 0.87904525  0.90636015]\n",
            "  [-0.87904525 -0.90636015]\n",
            "  [ 0.3814125  -0.13562298]\n",
            "  [-0.3814125   0.13562298]\n",
            "  [ 0.66200566 -0.68520164]\n",
            "  [-0.66200566  0.68520164]]\n",
            "\n",
            " [[-0.89825034 -0.9366455 ]\n",
            "  [ 0.89825034  0.9366455 ]\n",
            "  [ 0.18281841 -0.5917125 ]\n",
            "  [-0.18281841  0.5917125 ]\n",
            "  [-0.42684293  0.20125127]\n",
            "  [ 0.42684293 -0.20125127]]\n",
            "\n",
            " [[ 0.7000966  -0.2892294 ]\n",
            "  [-0.7000966   0.2892294 ]\n",
            "  [ 0.34802127 -0.2887392 ]\n",
            "  [-0.34802127  0.2887392 ]\n",
            "  [-0.9221916  -0.12197542]\n",
            "  [ 0.9221916   0.12197542]]\n",
            "\n",
            " [[-0.7344663  -0.04730344]\n",
            "  [ 0.7344663   0.04730344]\n",
            "  [-0.75965     0.09205508]\n",
            "  [ 0.75965    -0.09205508]\n",
            "  [ 0.33335996 -0.34826994]\n",
            "  [-0.33335996  0.34826994]]\n",
            "\n",
            " [[ 0.5601375   0.47768188]\n",
            "  [-0.5601375  -0.47768188]\n",
            "  [ 0.9176142  -0.8881018 ]\n",
            "  [-0.9176142   0.8881018 ]\n",
            "  [-0.10759068 -0.59707737]\n",
            "  [ 0.10759068  0.59707737]]\n",
            "\n",
            " [[ 0.8103745   0.48868442]\n",
            "  [-0.8103745  -0.48868442]\n",
            "  [-0.17512107 -0.15481734]\n",
            "  [ 0.17512107  0.15481734]\n",
            "  [ 0.30897903 -0.9241586 ]\n",
            "  [-0.30897903  0.9241586 ]]\n",
            "\n",
            " [[-0.18703341  0.2357502 ]\n",
            "  [ 0.18703341 -0.2357502 ]\n",
            "  [-0.34217787 -0.8568847 ]\n",
            "  [ 0.34217787  0.8568847 ]\n",
            "  [-0.9063244   0.5103848 ]\n",
            "  [ 0.9063244  -0.5103848 ]]\n",
            "\n",
            " [[-0.73236346  0.51306677]\n",
            "  [ 0.73236346 -0.51306677]\n",
            "  [-0.06194854  0.12317109]\n",
            "  [ 0.06194854 -0.12317109]\n",
            "  [ 0.8264785  -0.3341341 ]\n",
            "  [-0.8264785   0.3341341 ]]\n",
            "\n",
            " [[-0.85656023  0.14920688]\n",
            "  [ 0.85656023 -0.14920688]\n",
            "  [ 0.59719634  0.5914829 ]\n",
            "  [-0.59719634 -0.5914829 ]\n",
            "  [ 0.7625196   0.9650402 ]\n",
            "  [-0.7625196  -0.9650402 ]]\n",
            "\n",
            " [[ 0.75395656  0.03998566]\n",
            "  [-0.75395656 -0.03998566]\n",
            "  [-0.8547981  -0.38653445]\n",
            "  [ 0.8547981   0.38653445]\n",
            "  [ 0.88630915 -0.47264504]\n",
            "  [-0.88630915  0.47264504]]\n",
            "\n",
            " [[ 0.9644048  -0.3550737 ]\n",
            "  [-0.9644048   0.3550737 ]\n",
            "  [ 0.4695599   0.3210373 ]\n",
            "  [-0.4695599  -0.3210373 ]\n",
            "  [ 0.5525701  -0.2597041 ]\n",
            "  [-0.5525701   0.2597041 ]]\n",
            "\n",
            " [[ 0.8112173  -0.9459791 ]\n",
            "  [-0.8112173   0.9459791 ]\n",
            "  [ 0.61047506  0.5433037 ]\n",
            "  [-0.61047506 -0.5433037 ]\n",
            "  [ 0.3722341  -0.62800694]\n",
            "  [-0.3722341   0.62800694]]\n",
            "\n",
            " [[ 0.39128947  0.26964498]\n",
            "  [-0.39128947 -0.26964498]\n",
            "  [ 0.7895992   0.33512592]\n",
            "  [-0.7895992  -0.33512592]\n",
            "  [ 0.54247165  0.68707395]\n",
            "  [-0.54247165 -0.68707395]]\n",
            "\n",
            " [[ 0.3440132   0.36428094]\n",
            "  [-0.3440132  -0.36428094]\n",
            "  [-0.30980492 -0.14170814]\n",
            "  [ 0.30980492  0.14170814]\n",
            "  [ 0.01605916 -0.00593495]\n",
            "  [-0.01605916  0.00593495]]\n",
            "\n",
            " [[-0.61389065  0.9060497 ]\n",
            "  [ 0.61389065 -0.9060497 ]\n",
            "  [-0.82031226 -0.12075782]\n",
            "  [ 0.82031226  0.12075782]\n",
            "  [ 0.8874967   0.5848167 ]\n",
            "  [-0.8874967  -0.5848167 ]]\n",
            "\n",
            " [[-0.960109   -0.3188603 ]\n",
            "  [ 0.960109    0.3188603 ]\n",
            "  [ 0.9746809  -0.8040595 ]\n",
            "  [-0.9746809   0.8040595 ]\n",
            "  [-0.49609256 -0.5698135 ]\n",
            "  [ 0.49609256  0.5698135 ]]\n",
            "\n",
            " [[ 0.26999235 -0.472708  ]\n",
            "  [-0.26999235  0.472708  ]\n",
            "  [-0.07367325  0.12666893]\n",
            "  [ 0.07367325 -0.12666893]\n",
            "  [-0.16820621 -0.82481456]\n",
            "  [ 0.16820621  0.82481456]]\n",
            "\n",
            " [[-0.49547505  0.08281374]\n",
            "  [ 0.49547505 -0.08281374]\n",
            "  [ 0.23431897 -0.11436534]\n",
            "  [-0.23431897  0.11436534]\n",
            "  [-0.42174459 -0.47735667]\n",
            "  [ 0.42174459  0.47735667]]\n",
            "\n",
            " [[-0.5368943  -0.51251435]\n",
            "  [ 0.5368943   0.51251435]\n",
            "  [ 0.19476795  0.4761479 ]\n",
            "  [-0.19476795 -0.4761479 ]\n",
            "  [ 0.902905    0.20216942]\n",
            "  [-0.902905   -0.20216942]]\n",
            "\n",
            " [[ 0.23355055 -0.12333608]\n",
            "  [-0.23355055  0.12333608]\n",
            "  [-0.03102994  0.3621986 ]\n",
            "  [ 0.03102994 -0.3621986 ]\n",
            "  [-0.83311987 -0.8692677 ]\n",
            "  [ 0.83311987  0.8692677 ]]\n",
            "\n",
            " [[ 0.35396624  0.42046475]\n",
            "  [-0.35396624 -0.42046475]\n",
            "  [-0.7191603   0.28231263]\n",
            "  [ 0.7191603  -0.28231263]\n",
            "  [-0.97734857 -0.8558712 ]\n",
            "  [ 0.97734857  0.8558712 ]]\n",
            "\n",
            " [[ 0.15183854  0.7628641 ]\n",
            "  [-0.15183854 -0.7628641 ]\n",
            "  [-0.37198877  0.14811754]\n",
            "  [ 0.37198877 -0.14811754]\n",
            "  [ 0.3555379   0.66030884]\n",
            "  [-0.3555379  -0.66030884]]\n",
            "\n",
            " [[ 0.57232285  0.49868608]\n",
            "  [-0.57232285 -0.49868608]\n",
            "  [ 0.535743   -0.38067245]\n",
            "  [-0.535743    0.38067245]\n",
            "  [ 0.69433856  0.38687062]\n",
            "  [-0.69433856 -0.38687062]]\n",
            "\n",
            " [[-0.7738786  -0.21279168]\n",
            "  [ 0.7738786   0.21279168]\n",
            "  [-0.288213   -0.15306067]\n",
            "  [ 0.288213    0.15306067]\n",
            "  [ 0.09901738 -0.54968095]\n",
            "  [-0.09901738  0.54968095]]\n",
            "\n",
            " [[-0.00243759 -0.4640615 ]\n",
            "  [ 0.00243759  0.4640615 ]\n",
            "  [-0.8885951  -0.9564669 ]\n",
            "  [ 0.8885951   0.9564669 ]\n",
            "  [ 0.68452954 -0.47796178]\n",
            "  [-0.68452954  0.47796178]]\n",
            "\n",
            " [[-0.68050003 -0.62871075]\n",
            "  [ 0.68050003  0.62871075]\n",
            "  [ 0.25847626  0.24156475]\n",
            "  [-0.25847626 -0.24156475]\n",
            "  [-0.3558221  -0.04608393]\n",
            "  [ 0.3558221   0.04608393]]\n",
            "\n",
            " [[ 0.06498647 -0.86275125]\n",
            "  [-0.06498647  0.86275125]\n",
            "  [ 0.24936128 -0.34296012]\n",
            "  [-0.24936128  0.34296012]\n",
            "  [ 0.2502179   0.11389279]\n",
            "  [-0.2502179  -0.11389279]]\n",
            "\n",
            " [[-0.5365319   0.6007204 ]\n",
            "  [ 0.5365319  -0.6007204 ]\n",
            "  [ 0.13049579 -0.5007415 ]\n",
            "  [-0.13049579  0.5007415 ]\n",
            "  [-0.962085   -0.8767457 ]\n",
            "  [ 0.962085    0.8767457 ]]\n",
            "\n",
            " [[ 0.34232545  0.735723  ]\n",
            "  [-0.34232545 -0.735723  ]\n",
            "  [-0.4168365  -0.965719  ]\n",
            "  [ 0.4168365   0.965719  ]\n",
            "  [ 0.68851805 -0.7948141 ]\n",
            "  [-0.68851805  0.7948141 ]]\n",
            "\n",
            " [[-0.10154366  0.9282706 ]\n",
            "  [ 0.10154366 -0.9282706 ]\n",
            "  [ 0.06565523 -0.8816266 ]\n",
            "  [-0.06565523  0.8816266 ]\n",
            "  [ 0.4117012  -0.18059468]\n",
            "  [-0.4117012   0.18059468]]\n",
            "\n",
            " [[-0.2861097   0.4803729 ]\n",
            "  [ 0.2861097  -0.4803729 ]\n",
            "  [-0.33963013  0.56373906]\n",
            "  [ 0.33963013 -0.56373906]\n",
            "  [-0.58643293 -0.9982376 ]\n",
            "  [ 0.58643293  0.9982376 ]]]\n",
            "\n",
            "Primaries After NECL:\n",
            " [[[ 0.16444534 -0.06886909]\n",
            "  [-0.16444534  0.06886909]\n",
            "  [-0.12837589  0.04718465]\n",
            "  [ 0.12837589 -0.04718465]\n",
            "  [-0.05827206  0.12670812]\n",
            "  [-0.05827206  0.12670812]]\n",
            "\n",
            " [[-0.16068643 -0.03352813]\n",
            "  [ 0.16068643  0.03352813]\n",
            "  [ 0.0329369  -0.1016206 ]\n",
            "  [-0.0329369   0.1016206 ]\n",
            "  [-0.11035866 -0.12573427]\n",
            "  [-0.11035866 -0.12573427]]\n",
            "\n",
            " [[-0.14079614  0.08509883]\n",
            "  [ 0.14079614 -0.08509883]\n",
            "  [ 0.12698461  0.09390958]\n",
            "  [-0.12698461 -0.09390958]\n",
            "  [-0.12384889 -0.06620277]\n",
            "  [-0.12384889 -0.06620277]]\n",
            "\n",
            " [[ 0.20568964  0.01166641]\n",
            "  [-0.20568964 -0.01166641]\n",
            "  [-0.0786373  -0.06784008]\n",
            "  [ 0.0786373   0.06784008]\n",
            "  [-0.03876788 -0.13427669]\n",
            "  [-0.03876788 -0.13427669]]\n",
            "\n",
            " [[-0.05536335  0.15331624]\n",
            "  [ 0.05536335 -0.15331624]\n",
            "  [-0.01201094  0.04172313]\n",
            "  [ 0.01201094 -0.04172313]\n",
            "  [-0.16664827  0.12228011]\n",
            "  [-0.16664827  0.12228011]]\n",
            "\n",
            " [[-0.18041983  0.00567347]\n",
            "  [ 0.18041983 -0.00567347]\n",
            "  [-0.05128212  0.1791923 ]\n",
            "  [ 0.05128212 -0.1791923 ]\n",
            "  [ 0.0502101  -0.04851591]\n",
            "  [ 0.0502101  -0.04851591]]\n",
            "\n",
            " [[ 0.15535583  0.05842878]\n",
            "  [-0.15535583 -0.05842878]\n",
            "  [-0.09083751  0.09389137]\n",
            "  [ 0.09083751 -0.09389137]\n",
            "  [-0.16563225 -0.06192655]\n",
            "  [-0.16563225 -0.06192655]]\n",
            "\n",
            " [[-0.04966502 -0.15814267]\n",
            "  [ 0.04966502  0.15814267]\n",
            "  [ 0.0941819   0.13630287]\n",
            "  [-0.0941819  -0.13630287]\n",
            "  [-0.02400368  0.05441989]\n",
            "  [-0.02400368  0.05441989]]\n",
            "\n",
            " [[-0.16654713  0.03658088]\n",
            "  [ 0.16654713 -0.03658088]\n",
            "  [ 0.13870488  0.04033007]\n",
            "  [-0.13870488 -0.04033007]\n",
            "  [-0.07027714 -0.13229246]\n",
            "  [-0.07027714 -0.13229246]]\n",
            "\n",
            " [[ 0.10760212 -0.0834024 ]\n",
            "  [-0.10760212  0.0834024 ]\n",
            "  [ 0.18806227 -0.05576627]\n",
            "  [-0.18806227  0.05576627]\n",
            "  [-0.16022886  0.00750028]\n",
            "  [-0.16022886  0.00750028]]\n",
            "\n",
            " [[ 0.03069882 -0.13637316]\n",
            "  [-0.03069882  0.13637316]\n",
            "  [-0.07143944 -0.13162398]\n",
            "  [ 0.07143944  0.13162398]\n",
            "  [ 0.08563541  0.06882992]\n",
            "  [ 0.08563541  0.06882992]]\n",
            "\n",
            " [[ 0.06419368  0.10868209]\n",
            "  [-0.06419368 -0.10868209]\n",
            "  [-0.20786877  0.03648638]\n",
            "  [ 0.20786877 -0.03648638]\n",
            "  [-0.11198357  0.06339177]\n",
            "  [-0.11198357  0.06339177]]\n",
            "\n",
            " [[ 0.01354899  0.17203976]\n",
            "  [-0.01354899 -0.17203976]\n",
            "  [ 0.12520276 -0.03545392]\n",
            "  [-0.12520276  0.03545392]\n",
            "  [-0.04129007  0.098828  ]\n",
            "  [-0.04129007  0.098828  ]]\n",
            "\n",
            " [[-0.03339019 -0.11357804]\n",
            "  [ 0.03339019  0.11357804]\n",
            "  [ 0.03266473  0.1020464 ]\n",
            "  [-0.03266473 -0.1020464 ]\n",
            "  [-0.02547477  0.14905824]\n",
            "  [-0.02547477  0.14905824]]\n",
            "\n",
            " [[ 0.10971729 -0.11543159]\n",
            "  [-0.10971729  0.11543159]\n",
            "  [ 0.03135393  0.07820432]\n",
            "  [-0.03135393 -0.07820432]\n",
            "  [ 0.15244104  0.10477439]\n",
            "  [ 0.15244104  0.10477439]]\n",
            "\n",
            " [[-0.17805189 -0.14646134]\n",
            "  [ 0.17805189  0.14646134]\n",
            "  [ 0.01077616 -0.02125121]\n",
            "  [-0.01077616  0.02125121]\n",
            "  [-0.00865641  0.15473719]\n",
            "  [-0.00865641  0.15473719]]\n",
            "\n",
            " [[ 0.02046978 -0.11720879]\n",
            "  [-0.02046978  0.11720879]\n",
            "  [-0.0777999   0.04032038]\n",
            "  [ 0.0777999  -0.04032038]\n",
            "  [-0.05257261 -0.18061733]\n",
            "  [-0.05257261 -0.18061733]]\n",
            "\n",
            " [[ 0.11472394 -0.04790557]\n",
            "  [-0.11472394  0.04790557]\n",
            "  [ 0.08453608  0.16838036]\n",
            "  [-0.08453608 -0.16838036]\n",
            "  [ 0.11014418 -0.05914272]\n",
            "  [ 0.11014418 -0.05914272]]\n",
            "\n",
            " [[-0.14006414  0.10294853]\n",
            "  [ 0.14006414 -0.10294853]\n",
            "  [-0.09115526  0.05825747]\n",
            "  [ 0.09115526 -0.05825747]\n",
            "  [ 0.1864163  -0.04979515]\n",
            "  [ 0.1864163  -0.04979515]]\n",
            "\n",
            " [[ 0.04369133 -0.04986277]\n",
            "  [-0.04369133  0.04986277]\n",
            "  [ 0.17507327 -0.11510924]\n",
            "  [-0.17507327  0.11510924]\n",
            "  [ 0.18767002  0.05298419]\n",
            "  [ 0.18767002  0.05298419]]\n",
            "\n",
            " [[-0.08478162  0.10524023]\n",
            "  [ 0.08478162 -0.10524023]\n",
            "  [-0.09451363  0.08279631]\n",
            "  [ 0.09451363 -0.08279631]\n",
            "  [ 0.12823626 -0.11082674]\n",
            "  [ 0.12823626 -0.11082674]]\n",
            "\n",
            " [[ 0.14526992 -0.00732771]\n",
            "  [-0.14526992  0.00732771]\n",
            "  [-0.17917743  0.00038546]\n",
            "  [ 0.17917743 -0.00038546]\n",
            "  [ 0.19894418  0.00836496]\n",
            "  [ 0.19894418  0.00836496]]\n",
            "\n",
            " [[-0.03728635 -0.04929375]\n",
            "  [ 0.03728635  0.04929375]\n",
            "  [ 0.17793943  0.23078343]\n",
            "  [-0.17793943 -0.23078343]\n",
            "  [ 0.06069271  0.02878841]\n",
            "  [ 0.06069271  0.02878841]]\n",
            "\n",
            " [[ 0.13792007  0.10706209]\n",
            "  [-0.13792007 -0.10706209]\n",
            "  [ 0.10138253 -0.05341101]\n",
            "  [-0.10138253  0.05341101]\n",
            "  [ 0.07940327  0.12439683]\n",
            "  [ 0.07940327  0.12439683]]\n",
            "\n",
            " [[-0.19072898  0.01203819]\n",
            "  [ 0.19072898 -0.01203819]\n",
            "  [-0.05707443  0.02206213]\n",
            "  [ 0.05707443 -0.02206213]\n",
            "  [-0.18196356 -0.13864186]\n",
            "  [-0.18196356 -0.13864186]]\n",
            "\n",
            " [[ 0.01813182 -0.07521673]\n",
            "  [-0.01813182  0.07521673]\n",
            "  [ 0.00807409 -0.20369162]\n",
            "  [-0.00807409  0.20369162]\n",
            "  [-0.02727116 -0.08854955]\n",
            "  [-0.02727116 -0.08854955]]\n",
            "\n",
            " [[ 0.1597166   0.12307347]\n",
            "  [-0.1597166  -0.12307347]\n",
            "  [-0.05494718  0.0793417 ]\n",
            "  [ 0.05494718 -0.0793417 ]\n",
            "  [-0.16290405 -0.00418825]\n",
            "  [-0.16290405 -0.00418825]]\n",
            "\n",
            " [[ 0.16974787  0.07899631]\n",
            "  [-0.16974787 -0.07899631]\n",
            "  [-0.06449834  0.03684946]\n",
            "  [ 0.06449834 -0.03684946]\n",
            "  [ 0.2276244   0.04894672]\n",
            "  [ 0.2276244   0.04894672]]\n",
            "\n",
            " [[-0.10886735  0.08088976]\n",
            "  [ 0.10886735 -0.08088976]\n",
            "  [ 0.13029325 -0.0356523 ]\n",
            "  [-0.13029325  0.0356523 ]\n",
            "  [ 0.17079212  0.10525424]\n",
            "  [ 0.17079212  0.10525424]]\n",
            "\n",
            " [[-0.01178402 -0.03408952]\n",
            "  [ 0.01178402  0.03408952]\n",
            "  [ 0.16572443  0.15012142]\n",
            "  [-0.16572443 -0.15012142]\n",
            "  [-0.13164246 -0.1112249 ]\n",
            "  [-0.13164246 -0.1112249 ]]\n",
            "\n",
            " [[ 0.03927668 -0.13344386]\n",
            "  [-0.03927668  0.13344386]\n",
            "  [-0.15837231  0.09416705]\n",
            "  [ 0.15837231 -0.09416705]\n",
            "  [-0.12205119 -0.01755345]\n",
            "  [-0.12205119 -0.01755345]]\n",
            "\n",
            " [[-0.02531501 -0.01295676]\n",
            "  [ 0.02531501  0.01295676]\n",
            "  [ 0.25914347  0.02558642]\n",
            "  [-0.25914347 -0.02558642]\n",
            "  [-0.02045881  0.16275017]\n",
            "  [-0.02045881  0.16275017]]\n",
            "\n",
            " [[-0.05883267 -0.03410913]\n",
            "  [ 0.05883267  0.03410913]\n",
            "  [ 0.18804258 -0.08107781]\n",
            "  [-0.18804258  0.08107781]\n",
            "  [ 0.16558921  0.11058173]\n",
            "  [ 0.16558921  0.11058173]]\n",
            "\n",
            " [[ 0.175767    0.12814802]\n",
            "  [-0.175767   -0.12814802]\n",
            "  [-0.07636525  0.01920079]\n",
            "  [ 0.07636525 -0.01920079]\n",
            "  [ 0.13243692 -0.09692833]\n",
            "  [ 0.13243692 -0.09692833]]\n",
            "\n",
            " [[-0.19693941 -0.14520964]\n",
            "  [ 0.19693941  0.14520964]\n",
            "  [-0.0401378   0.09186061]\n",
            "  [ 0.0401378  -0.09186061]\n",
            "  [-0.09371471  0.03124376]\n",
            "  [-0.09371471  0.03124376]]\n",
            "\n",
            " [[ 0.1714671  -0.05008991]\n",
            "  [-0.1714671   0.05008991]\n",
            "  [-0.08530193  0.05004306]\n",
            "  [ 0.08530193 -0.05004306]\n",
            "  [-0.22575879 -0.0211145 ]\n",
            "  [-0.22575879 -0.0211145 ]]\n",
            "\n",
            " [[-0.19406147 -0.00883782]\n",
            "  [ 0.19406147  0.00883782]\n",
            "  [ 0.20070179 -0.0171977 ]\n",
            "  [-0.20070179  0.0171977 ]\n",
            "  [ 0.08815187 -0.06512071]\n",
            "  [ 0.08815187 -0.06512071]]\n",
            "\n",
            " [[ 0.11210732  0.06760255]\n",
            "  [-0.11210732 -0.06760255]\n",
            "  [-0.18349347  0.12557645]\n",
            "  [ 0.18349347 -0.12557645]\n",
            "  [-0.02154244 -0.08453485]\n",
            "  [-0.02154244 -0.08453485]]\n",
            "\n",
            " [[ 0.19706555  0.08403078]\n",
            "  [-0.19706555 -0.08403078]\n",
            "  [ 0.04265227  0.02666296]\n",
            "  [-0.04265227 -0.02666296]\n",
            "  [ 0.07516453 -0.15897012]\n",
            "  [ 0.07516453 -0.15897012]]\n",
            "\n",
            " [[-0.04335181  0.03863893]\n",
            "  [ 0.04335181 -0.03863893]\n",
            "  [ 0.07923429  0.14030357]\n",
            "  [-0.07923429 -0.14030357]\n",
            "  [-0.20973803  0.08351726]\n",
            "  [-0.20973803  0.08351726]]\n",
            "\n",
            " [[-0.19946343  0.09880877]\n",
            "  [ 0.19946343 -0.09880877]\n",
            "  [ 0.01690319 -0.02376465]\n",
            "  [-0.01690319  0.02376465]\n",
            "  [ 0.2250715  -0.06434203]\n",
            "  [ 0.2250715  -0.06434203]]\n",
            "\n",
            " [[-0.15273683  0.01881307]\n",
            "  [ 0.15273683 -0.01881307]\n",
            "  [-0.1065128  -0.07459536]\n",
            "  [ 0.1065128   0.07459536]\n",
            "  [ 0.13593106  0.12164607]\n",
            "  [ 0.13593106  0.12164607]]\n",
            "\n",
            " [[ 0.14652787  0.00549494]\n",
            "  [-0.14652787 -0.00549494]\n",
            "  [ 0.16608201  0.05310461]\n",
            "  [-0.16608201 -0.05310461]\n",
            "  [ 0.17218854 -0.06492905]\n",
            "  [ 0.17218854 -0.06492905]]\n",
            "\n",
            " [[ 0.22888842 -0.05958926]\n",
            "  [-0.22888842  0.05958926]\n",
            "  [-0.11156345 -0.05393509]\n",
            "  [ 0.11156345  0.05393509]\n",
            "  [ 0.13126792 -0.04362497]\n",
            "  [ 0.13126792 -0.04362497]]\n",
            "\n",
            " [[ 0.1521743  -0.12547886]\n",
            "  [-0.1521743   0.12547886]\n",
            "  [-0.11458512 -0.07210875]\n",
            "  [ 0.11458512  0.07210875]\n",
            "  [ 0.06988543 -0.08337193]\n",
            "  [ 0.06988543 -0.08337193]]\n",
            "\n",
            " [[ 0.09292967  0.04528283]\n",
            "  [-0.09292967 -0.04528283]\n",
            "  [-0.18736172 -0.05622989]\n",
            "  [ 0.18736172  0.05622989]\n",
            "  [ 0.12874952  0.11530736]\n",
            "  [ 0.12874952  0.11530736]]\n",
            "\n",
            " [[ 0.2097664   0.157066  ]\n",
            "  [-0.2097664  -0.157066  ]\n",
            "  [ 0.18902177  0.06113688]\n",
            "  [-0.18902177 -0.06113688]\n",
            "  [ 0.00981583 -0.00256511]\n",
            "  [ 0.00981583 -0.00256511]]\n",
            "\n",
            " [[-0.10775843  0.11245979]\n",
            "  [ 0.10775843 -0.11245979]\n",
            "  [ 0.14400741  0.01499015]\n",
            "  [-0.14400741 -0.01499015]\n",
            "  [ 0.1557616   0.07257689]\n",
            "  [ 0.1557616   0.07257689]]\n",
            "\n",
            " [[-0.16604605 -0.03899362]\n",
            "  [ 0.16604605  0.03899362]\n",
            "  [-0.16852675  0.0983059 ]\n",
            "  [ 0.16852675 -0.0983059 ]\n",
            "  [-0.08584583 -0.0697227 ]\n",
            "  [-0.08584583 -0.0697227 ]]\n",
            "\n",
            " [[ 0.09235138 -0.11433254]\n",
            "  [-0.09235138  0.11433254]\n",
            "  [ 0.02522585 -0.03066839]\n",
            "  [-0.02522585  0.03066839]\n",
            "  [-0.05750202 -0.19938035]\n",
            "  [-0.05750202 -0.19938035]]\n",
            "\n",
            " [[-0.1854643   0.02191926]\n",
            "  [ 0.1854643  -0.02191926]\n",
            "  [-0.08778793  0.0302975 ]\n",
            "  [ 0.08778793 -0.0302975 ]\n",
            "  [-0.15784258 -0.12632889]\n",
            "  [-0.15784258 -0.12632889]]\n",
            "\n",
            " [[-0.12899095 -0.08706858]\n",
            "  [ 0.12899095  0.08706858]\n",
            "  [-0.04682149 -0.08093838]\n",
            "  [ 0.04682149  0.08093838]\n",
            "  [ 0.2167943   0.03432466]\n",
            "  [ 0.2167943   0.03432466]]\n",
            "\n",
            " [[ 0.0668951  -0.02497977]\n",
            "  [-0.0668951   0.02497977]\n",
            "  [ 0.00888759 -0.07335586]\n",
            "  [-0.00888759  0.07335586]\n",
            "  [-0.23811713 -0.17567974]\n",
            "  [-0.23811713 -0.17567974]]\n",
            "\n",
            " [[ 0.0708298   0.0594934 ]\n",
            "  [-0.0708298  -0.0594934 ]\n",
            "  [ 0.1438285  -0.03992404]\n",
            "  [-0.1438285   0.03992404]\n",
            "  [-0.19531482 -0.12094256]\n",
            "  [-0.19531482 -0.12094256]]\n",
            "\n",
            " [[ 0.04128255  0.1466617 ]\n",
            "  [-0.04128255 -0.1466617 ]\n",
            "  [ 0.10118357 -0.02848863]\n",
            "  [-0.10118357  0.02848863]\n",
            "  [ 0.09665863  0.1269366 ]\n",
            "  [ 0.09665863  0.1269366 ]]\n",
            "\n",
            " [[ 0.13568124  0.08359705]\n",
            "  [-0.13568124 -0.08359705]\n",
            "  [-0.12703003  0.06382434]\n",
            "  [ 0.12703003 -0.06382434]\n",
            "  [ 0.1645801   0.06484207]\n",
            "  [ 0.1645801   0.06484207]]\n",
            "\n",
            " [[-0.24020621 -0.04670367]\n",
            "  [ 0.24020621  0.04670367]\n",
            "  [ 0.08958644  0.03364166]\n",
            "  [-0.08958644 -0.03364166]\n",
            "  [ 0.03076949 -0.12078264]\n",
            "  [ 0.03076949 -0.12078264]]\n",
            "\n",
            " [[-0.00049105 -0.0661034 ]\n",
            "  [ 0.00049105  0.0661034 ]\n",
            "  [ 0.17873544  0.13603845]\n",
            "  [-0.17873544 -0.13603845]\n",
            "  [ 0.13778216 -0.06802663]\n",
            "  [ 0.13778216 -0.06802663]]\n",
            "\n",
            " [[-0.21742946 -0.14204505]\n",
            "  [ 0.21742946  0.14204505]\n",
            "  [-0.08271347 -0.05466057]\n",
            "  [ 0.08271347  0.05466057]\n",
            "  [-0.11384805 -0.01042623]\n",
            "  [-0.11384805 -0.01042623]]\n",
            "\n",
            " [[ 0.02176978 -0.20436266]\n",
            "  [-0.02176978  0.20436266]\n",
            "  [-0.08360423  0.08130699]\n",
            "  [ 0.08360423 -0.08130699]\n",
            "  [ 0.0839142   0.02700837]\n",
            "  [ 0.0839142   0.02700837]]\n",
            "\n",
            " [[-0.10718486  0.08485848]\n",
            "  [ 0.10718486 -0.08485848]\n",
            "  [-0.02608483  0.07077667]\n",
            "  [ 0.02608483 -0.07077667]\n",
            "  [-0.19203095 -0.1237418 ]\n",
            "  [-0.19203095 -0.1237418 ]]\n",
            "\n",
            " [[ 0.0615908   0.09360003]\n",
            "  [-0.0615908  -0.09360003]\n",
            "  [ 0.07497396  0.12282322]\n",
            "  [-0.07497396 -0.12282322]\n",
            "  [ 0.12382094 -0.10107163]\n",
            "  [ 0.12382094 -0.10107163]]\n",
            "\n",
            " [[-0.02347684  0.15175618]\n",
            "  [ 0.02347684 -0.15175618]\n",
            "  [-0.0151807   0.14414255]\n",
            "  [ 0.0151807  -0.14414255]\n",
            "  [ 0.09523397 -0.02953927]\n",
            "  [ 0.09523397 -0.02953927]]\n",
            "\n",
            " [[-0.06318589  0.07501552]\n",
            "  [ 0.06318589 -0.07501552]\n",
            "  [ 0.07499306 -0.08801932]\n",
            "  [-0.07499306  0.08801932]\n",
            "  [-0.12938191 -0.15573066]\n",
            "  [-0.12938191 -0.15573066]]]\n",
            "\n",
            "Pairs[0]:\n",
            " [[ 0.16444534 -0.06886909]\n",
            " [-0.16444534  0.06886909]\n",
            " [-0.12837589  0.04718465]\n",
            " [ 0.12837589 -0.04718465]\n",
            " [-0.05827206  0.12670812]\n",
            " [-0.05827206  0.12670812]\n",
            " [ 0.03606945 -0.02168444]\n",
            " [-0.02111082 -0.00324956]\n",
            " [ 0.29282123 -0.11605375]\n",
            " [ 0.02111082  0.00324956]\n",
            " [-0.29282123  0.11605375]\n",
            " [ 0.02111082  0.00324956]\n",
            " [-0.03606945  0.02168444]\n",
            " [-0.02111082 -0.00324956]\n",
            " [ 0.10617328  0.05783903]\n",
            " [-0.00958257 -0.00872627]\n",
            " [ 0.10617328  0.05783903]\n",
            " [-0.00958257 -0.00872627]\n",
            " [-0.2227174   0.1955772 ]\n",
            " [ 0.00958257  0.00872627]\n",
            " [-0.2227174   0.1955772 ]\n",
            " [ 0.00958257  0.00872627]\n",
            " [-0.18664795  0.17389277]\n",
            " [ 0.00748073  0.00597868]\n",
            " [-0.18664795  0.17389277]\n",
            " [ 0.00748073  0.00597868]\n",
            " [ 0.07010382  0.07952347]\n",
            " [-0.00748073 -0.00597868]\n",
            " [ 0.07010382  0.07952347]\n",
            " [-0.00748073 -0.00597868]]\n",
            "\n",
            "Triplets[0]:\n",
            " [[[ 0.16444534 -0.06886909]\n",
            "  [-0.16444534  0.06886909]\n",
            "  [-0.12837589  0.04718465]]\n",
            "\n",
            " [[ 0.12837589 -0.04718465]\n",
            "  [-0.05827206  0.12670812]\n",
            "  [-0.05827206  0.12670812]]\n",
            "\n",
            " [[ 0.03606945 -0.02168444]\n",
            "  [-0.02111082 -0.00324956]\n",
            "  [ 0.29282123 -0.11605375]]\n",
            "\n",
            " [[ 0.02111082  0.00324956]\n",
            "  [-0.29282123  0.11605375]\n",
            "  [ 0.02111082  0.00324956]]\n",
            "\n",
            " [[-0.03606945  0.02168444]\n",
            "  [-0.02111082 -0.00324956]\n",
            "  [ 0.10617328  0.05783903]]\n",
            "\n",
            " [[-0.00958257 -0.00872627]\n",
            "  [ 0.10617328  0.05783903]\n",
            "  [-0.00958257 -0.00872627]]\n",
            "\n",
            " [[-0.2227174   0.1955772 ]\n",
            "  [ 0.00958257  0.00872627]\n",
            "  [-0.2227174   0.1955772 ]]\n",
            "\n",
            " [[ 0.00958257  0.00872627]\n",
            "  [-0.18664795  0.17389277]\n",
            "  [ 0.00748073  0.00597868]]\n",
            "\n",
            " [[-0.18664795  0.17389277]\n",
            "  [ 0.00748073  0.00597868]\n",
            "  [ 0.07010382  0.07952347]]\n",
            "\n",
            " [[-0.00748073 -0.00597868]\n",
            "  [ 0.07010382  0.07952347]\n",
            "  [-0.00748073 -0.00597868]]]\n",
            "\n",
            "Bits (all qubits):\n",
            " [[1 1 1 ... 1 1 1]\n",
            " [0 1 0 ... 1 0 0]\n",
            " [0 1 0 ... 1 0 0]\n",
            " ...\n",
            " [1 0 0 ... 0 1 1]\n",
            " [0 1 1 ... 1 1 0]\n",
            " [0 1 0 ... 1 0 0]]\n",
            "\n",
            "Primaries Out (promoted):\n",
            " [[[-7.48072797e-03 -5.97867835e-03]\n",
            "  [ 7.48072797e-03  5.97867835e-03]\n",
            "  [ 7.01038241e-02  7.95234740e-02]\n",
            "  [-7.01038241e-02 -7.95234740e-02]\n",
            "  [-7.48072797e-03 -5.97867835e-03]\n",
            "  [ 7.48072797e-03  5.97867835e-03]]\n",
            "\n",
            " [[ 3.63487285e-03 -1.27771916e-02]\n",
            "  [-3.63487285e-03  1.27771916e-02]\n",
            "  [-1.43295571e-01 -2.41136700e-02]\n",
            "  [ 1.43295571e-01  2.41136700e-02]\n",
            "  [ 3.63487285e-03 -1.27771916e-02]\n",
            "  [-3.63487285e-03  1.27771916e-02]]\n",
            "\n",
            " [[ 1.57269035e-02  6.21707505e-03]\n",
            "  [-1.57269035e-02 -6.21707505e-03]\n",
            "  [-2.50833511e-01 -1.60112351e-01]\n",
            "  [ 2.50833511e-01  1.60112351e-01]\n",
            "  [ 1.57269035e-02  6.21707505e-03]\n",
            "  [-1.57269035e-02 -6.21707505e-03]]\n",
            "\n",
            " [[-3.04860133e-03 -9.10934061e-03]\n",
            "  [ 3.04860133e-03  9.10934061e-03]\n",
            "  [ 3.98694240e-02 -6.64366111e-02]\n",
            "  [-3.98694240e-02  6.64366111e-02]\n",
            "  [-3.04860133e-03 -9.10934061e-03]\n",
            "  [ 3.04860133e-03  9.10934061e-03]]\n",
            "\n",
            " [[-2.00160267e-03 -5.10190940e-03]\n",
            "  [ 2.00160267e-03  5.10190940e-03]\n",
            "  [-1.54637322e-01  8.05569813e-02]\n",
            "  [ 1.54637322e-01 -8.05569813e-02]\n",
            "  [-2.00160267e-03 -5.10190940e-03]\n",
            "  [ 2.00160267e-03  5.10190940e-03]]\n",
            "\n",
            " [[ 2.57488061e-03  8.69367830e-03]\n",
            "  [-2.57488061e-03 -8.69367830e-03]\n",
            "  [ 1.01492226e-01 -2.27708220e-01]\n",
            "  [-1.01492226e-01  2.27708220e-01]\n",
            "  [ 2.57488061e-03  8.69367830e-03]\n",
            "  [-2.57488061e-03 -8.69367830e-03]]\n",
            "\n",
            " [[-1.50456205e-02  5.81436884e-03]\n",
            "  [ 1.50456205e-02 -5.81436884e-03]\n",
            "  [-7.47947395e-02 -1.55817926e-01]\n",
            "  [ 7.47947395e-02  1.55817926e-01]\n",
            "  [-1.50456205e-02  5.81436884e-03]\n",
            "  [ 1.50456205e-02 -5.81436884e-03]]\n",
            "\n",
            " [[ 2.26071244e-03 -7.41758710e-03]\n",
            "  [-2.26071244e-03  7.41758710e-03]\n",
            "  [-1.18185580e-01 -8.18829834e-02]\n",
            "  [ 1.18185580e-01  8.18829834e-02]\n",
            "  [ 2.26071244e-03 -7.41758710e-03]\n",
            "  [-2.26071244e-03  7.41758710e-03]]\n",
            "\n",
            " [[ 9.74778272e-03  5.33536449e-03]\n",
            "  [-9.74778272e-03 -5.33536449e-03]\n",
            "  [-2.08982021e-01 -1.72622532e-01]\n",
            "  [ 2.08982021e-01  1.72622532e-01]\n",
            "  [ 9.74778272e-03  5.33536449e-03]\n",
            "  [-9.74778272e-03 -5.33536449e-03]]\n",
            "\n",
            " [[ 3.01330034e-02  4.18262702e-04]\n",
            "  [-3.01330034e-02 -4.18262702e-04]\n",
            "  [-3.48291129e-01  6.32665530e-02]\n",
            "  [ 3.48291129e-01 -6.32665530e-02]\n",
            "  [ 3.01330034e-02  4.18262702e-04]\n",
            "  [-3.01330034e-02 -4.18262702e-04]]\n",
            "\n",
            " [[ 6.11774530e-03  9.05966852e-03]\n",
            "  [-6.11774530e-03 -9.05966852e-03]\n",
            "  [ 1.57074839e-01  2.00453907e-01]\n",
            "  [-1.57074839e-01 -2.00453907e-01]\n",
            "  [ 6.11774530e-03  9.05966852e-03]\n",
            "  [-6.11774530e-03 -9.05966852e-03]]\n",
            "\n",
            " [[-2.32778881e-02 -2.31293589e-03]\n",
            "  [ 2.32778881e-02  2.31293589e-03]\n",
            "  [ 9.58851948e-02  2.69053914e-02]\n",
            "  [-9.58851948e-02 -2.69053914e-02]\n",
            "  [-2.32778881e-02 -2.31293589e-03]\n",
            "  [ 2.32778881e-02  2.31293589e-03]]\n",
            "\n",
            " [[ 5.16963098e-03  3.50383995e-03]\n",
            "  [-5.16963098e-03 -3.50383995e-03]\n",
            "  [-1.66492835e-01  1.34281918e-01]\n",
            "  [ 1.66492835e-01 -1.34281918e-01]\n",
            "  [ 5.16963098e-03  3.50383995e-03]\n",
            "  [-5.16963098e-03 -3.50383995e-03]]\n",
            "\n",
            " [[ 8.32126476e-04 -1.52108567e-02]\n",
            "  [-8.32126476e-04  1.52108567e-02]\n",
            "  [-5.81394993e-02  4.70118374e-02]\n",
            "  [ 5.81394993e-02 -4.70118374e-02]\n",
            "  [ 8.32126476e-04 -1.52108567e-02]\n",
            "  [-8.32126476e-04  1.52108567e-02]]\n",
            "\n",
            " [[-4.77962615e-03 -8.19380954e-03]\n",
            "  [ 4.77962615e-03  8.19380954e-03]\n",
            "  [ 1.21087104e-01  2.65700668e-02]\n",
            "  [-1.21087104e-01 -2.65700668e-02]\n",
            "  [-4.77962615e-03 -8.19380954e-03]\n",
            "  [ 4.77962615e-03  8.19380954e-03]]\n",
            "\n",
            " [[ 9.32828480e-05  3.28835170e-03]\n",
            "  [-9.32828480e-05 -3.28835170e-03]\n",
            "  [-1.94325689e-02  1.75988391e-01]\n",
            "  [ 1.94325689e-02 -1.75988391e-01]\n",
            "  [ 9.32828480e-05  3.28835170e-03]\n",
            "  [-9.32828480e-05 -3.28835170e-03]]\n",
            "\n",
            " [[-4.09014383e-03  7.28255929e-03]\n",
            "  [ 4.09014383e-03 -7.28255929e-03]\n",
            "  [ 2.52272896e-02 -2.20937714e-01]\n",
            "  [-2.52272896e-02  2.20937714e-01]\n",
            "  [-4.09014383e-03  7.28255929e-03]\n",
            "  [ 4.09014383e-03 -7.28255929e-03]]\n",
            "\n",
            " [[-9.31115635e-03  9.95847210e-03]\n",
            "  [ 9.31115635e-03 -9.95847210e-03]\n",
            "  [ 2.56081000e-02 -2.27523088e-01]\n",
            "  [-2.56081000e-02  2.27523088e-01]\n",
            "  [-9.31115635e-03  9.95847210e-03]\n",
            "  [ 9.31115635e-03 -9.95847210e-03]]\n",
            "\n",
            " [[ 1.69928260e-02  2.90093990e-03]\n",
            "  [-1.69928260e-02 -2.90093990e-03]\n",
            "  [ 2.77571559e-01 -1.08052626e-01]\n",
            "  [-2.77571559e-01  1.08052626e-01]\n",
            "  [ 1.69928260e-02  2.90093990e-03]\n",
            "  [-1.69928260e-02 -2.90093990e-03]]\n",
            "\n",
            " [[-3.28560024e-02  6.09896937e-03]\n",
            "  [ 3.28560024e-02 -6.09896937e-03]\n",
            "  [ 1.25967562e-02  1.68093428e-01]\n",
            "  [-1.25967562e-02 -1.68093428e-01]\n",
            "  [-3.28560024e-02  6.09896937e-03]\n",
            "  [ 3.28560024e-02 -6.09896937e-03]]\n",
            "\n",
            " [[ 1.21200755e-02  9.17604566e-03]\n",
            "  [-1.21200755e-02 -9.17604566e-03]\n",
            "  [ 2.22749889e-01 -1.93623051e-01]\n",
            "  [-2.22749889e-01  1.93623051e-01]\n",
            "  [ 1.21200755e-02  9.17604566e-03]\n",
            "  [-1.21200755e-02 -9.17604566e-03]]\n",
            "\n",
            " [[ 3.56463082e-02 -3.22433129e-06]\n",
            "  [-3.56463082e-02  3.22433129e-06]\n",
            "  [ 3.78121614e-01  7.97950383e-03]\n",
            "  [-3.78121614e-01 -7.97950383e-03]\n",
            "  [ 3.56463082e-02 -3.22433129e-06]\n",
            "  [-3.56463082e-02  3.22433129e-06]]\n",
            "\n",
            " [[-1.07996268e-02 -6.64388807e-03]\n",
            "  [ 1.07996268e-02  6.64388807e-03]\n",
            "  [-1.17246717e-01 -2.01995015e-01]\n",
            "  [ 1.17246717e-01  2.01995015e-01]\n",
            "  [-1.07996268e-02 -6.64388807e-03]\n",
            "  [ 1.07996268e-02  6.64388807e-03]]\n",
            "\n",
            " [[-8.05010460e-03  6.64416002e-03]\n",
            "  [ 8.05010460e-03 -6.64416002e-03]\n",
            "  [-2.19792575e-02  1.77807838e-01]\n",
            "  [ 2.19792575e-02 -1.77807838e-01]\n",
            "  [-8.05010460e-03  6.64416002e-03]\n",
            "  [ 8.05010460e-03 -6.64416002e-03]]\n",
            "\n",
            " [[-1.03854667e-02  3.05873482e-03]\n",
            "  [ 1.03854667e-02 -3.05873482e-03]\n",
            "  [-1.24889135e-01 -1.60703987e-01]\n",
            "  [ 1.24889135e-01  1.60703987e-01]\n",
            "  [-1.03854667e-02  3.05873482e-03]\n",
            "  [ 1.03854667e-02 -3.05873482e-03]]\n",
            "\n",
            " [[ 2.20189788e-04 -1.80368014e-02]\n",
            "  [-2.20189788e-04  1.80368014e-02]\n",
            "  [-3.53452489e-02  1.15142062e-01]\n",
            "  [ 3.53452489e-02 -1.15142062e-01]\n",
            "  [ 2.20189788e-04 -1.80368014e-02]\n",
            "  [-2.20189788e-04  1.80368014e-02]]\n",
            "\n",
            " [[-8.95111822e-03  3.32303025e-04]\n",
            "  [ 8.95111822e-03 -3.32303025e-04]\n",
            "  [-1.07956871e-01 -8.35299566e-02]\n",
            "  [ 1.07956871e-01  8.35299566e-02]\n",
            "  [-8.95111822e-03  3.32303025e-04]\n",
            "  [ 8.95111822e-03 -3.32303025e-04]]\n",
            "\n",
            " [[ 1.46813951e-02 -1.80366007e-03]\n",
            "  [-1.46813951e-02  1.80366007e-03]\n",
            "  [ 2.92122722e-01  1.20972544e-02]\n",
            "  [-2.92122722e-01 -1.20972544e-02]\n",
            "  [ 1.46813951e-02 -1.80366007e-03]\n",
            "  [-1.46813951e-02  1.80366007e-03]]\n",
            "\n",
            " [[-2.22530607e-02  3.75255593e-03]\n",
            "  [ 2.22530607e-02 -3.75255593e-03]\n",
            "  [ 4.04988676e-02  1.40906543e-01]\n",
            "  [-4.04988676e-02 -1.40906543e-01]\n",
            "  [-2.22530607e-02  3.75255593e-03]\n",
            "  [ 2.22530607e-02 -3.75255593e-03]]\n",
            "\n",
            " [[ 2.18163710e-02  1.66972410e-02]\n",
            "  [-2.18163710e-02 -1.66972410e-02]\n",
            "  [-2.97366887e-01 -2.61346340e-01]\n",
            "  [ 2.97366887e-01  2.61346340e-01]\n",
            "  [ 2.18163710e-02  1.66972410e-02]\n",
            "  [-2.18163710e-02 -1.66972410e-02]]\n",
            "\n",
            " [[-1.93295293e-02  1.65295659e-03]\n",
            "  [ 1.93295293e-02 -1.65295659e-03]\n",
            "  [ 3.63211259e-02 -1.11720502e-01]\n",
            "  [-3.63211259e-02  1.11720502e-01]\n",
            "  [-1.93295293e-02  1.65295659e-03]\n",
            "  [ 1.93295293e-02 -1.65295659e-03]]\n",
            "\n",
            " [[ 5.30176703e-03 -4.16419329e-03]\n",
            "  [-5.30176703e-03  4.16419329e-03]\n",
            "  [-2.79602289e-01  1.37163758e-01]\n",
            "  [ 2.79602289e-01 -1.37163758e-01]\n",
            "  [ 5.30176703e-03 -4.16419329e-03]\n",
            "  [-5.30176703e-03  4.16419329e-03]]\n",
            "\n",
            " [[-3.11378222e-02  8.96572415e-03]\n",
            "  [ 3.11378222e-02 -8.96572415e-03]\n",
            "  [-2.24533677e-02  1.91659540e-01]\n",
            "  [ 2.24533677e-02 -1.91659540e-01]\n",
            "  [-3.11378222e-02  8.96572415e-03]\n",
            "  [ 3.11378222e-02 -8.96572415e-03]]\n",
            "\n",
            " [[ 1.01135792e-02  1.86110067e-03]\n",
            "  [-1.01135792e-02 -1.86110067e-03]\n",
            "  [ 2.08802164e-01 -1.16129123e-01]\n",
            "  [-2.08802164e-01  1.16129123e-01]\n",
            "  [ 1.01135792e-02  1.86110067e-03]\n",
            "  [-1.01135792e-02 -1.86110067e-03]]\n",
            "\n",
            " [[-3.76150268e-03 -2.87007098e-03]\n",
            "  [ 3.76150268e-03  2.87007098e-03]\n",
            "  [-5.35769127e-02 -6.06168546e-02]\n",
            "  [ 5.35769127e-02  6.06168546e-02]\n",
            "  [-3.76150268e-03 -2.87007098e-03]\n",
            "  [ 3.76150268e-03  2.87007098e-03]]\n",
            "\n",
            " [[-1.92576610e-02  1.05663412e-03]\n",
            "  [ 1.92576610e-02 -1.05663412e-03]\n",
            "  [-1.40456855e-01 -7.11575598e-02]\n",
            "  [ 1.40456855e-01  7.11575598e-02]\n",
            "  [-1.92576610e-02  1.05663412e-03]\n",
            "  [ 1.92576610e-02 -1.05663412e-03]]\n",
            "\n",
            " [[-1.76922381e-02 -1.11992669e-03]\n",
            "  [ 1.76922381e-02  1.11992669e-03]\n",
            "  [-1.12549916e-01 -4.79230061e-02]\n",
            "  [ 1.12549916e-01  4.79230061e-02]\n",
            "  [-1.76922381e-02 -1.11992669e-03]\n",
            "  [ 1.76922381e-02  1.11992669e-03]]\n",
            "\n",
            " [[-3.95289622e-03  1.06155872e-02]\n",
            "  [ 3.95289622e-03 -1.06155872e-02]\n",
            "  [ 1.61951035e-01 -2.10111305e-01]\n",
            "  [-1.61951035e-01  2.10111305e-01]\n",
            "  [-3.95289622e-03  1.06155872e-02]\n",
            "  [ 3.95289622e-03 -1.06155872e-02]]\n",
            "\n",
            " [[-3.20593803e-03  4.23861481e-03]\n",
            "  [ 3.20593803e-03 -4.23861481e-03]\n",
            "  [ 3.25122625e-02 -1.85633078e-01]\n",
            "  [-3.25122625e-02  1.85633078e-01]\n",
            "  [-3.20593803e-03  4.23861481e-03]\n",
            "  [ 3.20593803e-03 -4.23861481e-03]]\n",
            "\n",
            " [[ 1.66184455e-02 -1.17177693e-02]\n",
            "  [-1.66184455e-02  1.17177693e-02]\n",
            "  [-2.88972318e-01 -5.67863062e-02]\n",
            "  [ 2.88972318e-01  5.67863062e-02]\n",
            "  [ 1.66184455e-02 -1.17177693e-02]\n",
            "  [-1.66184455e-02  1.17177693e-02]]\n",
            "\n",
            " [[-3.80442594e-03 -1.52906566e-03]\n",
            "  [ 3.80442594e-03  1.52906566e-03]\n",
            "  [ 2.08168313e-01 -4.05773818e-02]\n",
            "  [-2.08168313e-01  4.05773818e-02]\n",
            "  [-3.80442594e-03 -1.52906566e-03]\n",
            "  [ 3.80442594e-03  1.52906566e-03]]\n",
            "\n",
            " [[ 1.44783976e-02  9.07423254e-03]\n",
            "  [-1.44783976e-02 -9.07423254e-03]\n",
            "  [ 2.42443860e-01  1.96241438e-01]\n",
            "  [-2.42443860e-01 -1.96241438e-01]\n",
            "  [ 1.44783976e-02  9.07423254e-03]\n",
            "  [-1.44783976e-02 -9.07423254e-03]]\n",
            "\n",
            " [[-2.85974182e-02  3.44803231e-03]\n",
            "  [ 2.85974182e-02 -3.44803231e-03]\n",
            "  [ 6.10652566e-03 -1.18033662e-01]\n",
            "  [-6.10652566e-03  1.18033662e-01]\n",
            "  [-2.85974182e-02  3.44803231e-03]\n",
            "  [ 2.85974182e-02 -3.44803231e-03]]\n",
            "\n",
            " [[ 1.46447020e-02 -2.35291664e-03]\n",
            "  [-1.46447020e-02  2.35291664e-03]\n",
            "  [ 2.42831379e-01  1.03101246e-02]\n",
            "  [-2.42831379e-01 -1.03101246e-02]\n",
            "  [ 1.46447020e-02 -2.35291664e-03]\n",
            "  [-1.46447020e-02  2.35291664e-03]]\n",
            "\n",
            " [[ 8.00783001e-03 -6.01184601e-03]\n",
            "  [-8.00783001e-03  6.01184601e-03]\n",
            "  [ 1.84470549e-01 -1.12631768e-02]\n",
            "  [-1.84470549e-01  1.12631768e-02]\n",
            "  [ 8.00783001e-03 -6.01184601e-03]\n",
            "  [-8.00783001e-03  6.01184601e-03]]\n",
            "\n",
            " [[ 2.41227318e-02  6.48372015e-03]\n",
            "  [-2.41227318e-02 -6.48372015e-03]\n",
            "  [ 3.16111237e-01  1.71537250e-01]\n",
            "  [-3.16111237e-01 -1.71537250e-01]\n",
            "  [ 2.41227318e-02  6.48372015e-03]\n",
            "  [-2.41227318e-02 -6.48372015e-03]]\n",
            "\n",
            " [[-1.85540481e-03  1.56822949e-04]\n",
            "  [ 1.85540481e-03 -1.56822949e-04]\n",
            "  [-1.79205939e-01 -6.37019947e-02]\n",
            "  [ 1.79205939e-01  6.37019947e-02]\n",
            "  [-1.85540481e-03  1.56822949e-04]\n",
            "  [ 1.85540481e-03 -1.56822949e-04]]\n",
            "\n",
            " [[-2.24308260e-02 -1.08793832e-03]\n",
            "  [ 2.24308260e-02  1.08793832e-03]\n",
            "  [ 1.17541850e-02  5.75867407e-02]\n",
            "  [-1.17541850e-02 -5.75867407e-02]\n",
            "  [-2.24308260e-02 -1.08793832e-03]\n",
            "  [ 2.24308260e-02  1.08793832e-03]]\n",
            "\n",
            " [[-1.44673185e-02  6.85415231e-03]\n",
            "  [ 1.44673185e-02 -6.85415231e-03]\n",
            "  [ 8.26809257e-02 -1.68028593e-01]\n",
            "  [-8.26809257e-02  1.68028593e-01]\n",
            "  [-1.44673185e-02  6.85415231e-03]\n",
            "  [ 1.44673185e-02 -6.85415231e-03]]\n",
            "\n",
            " [[ 1.45053712e-03 -6.11467473e-03]\n",
            "  [-1.45053712e-03  6.11467473e-03]\n",
            "  [-8.27278644e-02 -1.68711960e-01]\n",
            "  [ 8.27278644e-02  1.68711960e-01]\n",
            "  [ 1.45053712e-03 -6.11467473e-03]\n",
            "  [-1.45053712e-03  6.11467473e-03]]\n",
            "\n",
            " [[-1.38566727e-02  3.82744917e-03]\n",
            "  [ 1.38566727e-02 -3.82744917e-03]\n",
            "  [-7.00546503e-02 -1.56626388e-01]\n",
            "  [ 7.00546503e-02  1.56626388e-01]\n",
            "  [-1.38566727e-02  3.82744917e-03]\n",
            "  [ 1.38566727e-02 -3.82744917e-03]]\n",
            "\n",
            " [[ 1.01506310e-02  2.77818250e-03]\n",
            "  [-1.01506310e-02 -2.77818250e-03]\n",
            "  [ 2.63615787e-01  1.15263045e-01]\n",
            "  [-2.63615787e-01 -1.15263045e-01]\n",
            "  [ 1.01506310e-02  2.77818250e-03]\n",
            "  [-1.01506310e-02 -2.77818250e-03]]\n",
            "\n",
            " [[ 2.11628736e-03 -1.28871389e-02]\n",
            "  [-2.11628736e-03  1.28871389e-02]\n",
            "  [-2.47004718e-01 -1.02323882e-01]\n",
            "  [ 2.47004718e-01  1.02323882e-01]\n",
            "  [ 2.11628736e-03 -1.28871389e-02]\n",
            "  [-2.11628736e-03  1.28871389e-02]]\n",
            "\n",
            " [[ 2.80918367e-02 -4.82851500e-03]\n",
            "  [-2.80918367e-02  4.82851500e-03]\n",
            "  [-3.39143336e-01 -8.10185224e-02]\n",
            "  [ 3.39143336e-01  8.10185224e-02]\n",
            "  [ 2.80918367e-02 -4.82851500e-03]\n",
            "  [-2.80918367e-02  4.82851500e-03]]\n",
            "\n",
            " [[-9.78026539e-03  3.61625035e-03]\n",
            "  [ 9.78026539e-03 -3.61625035e-03]\n",
            "  [-4.52493876e-03  1.55425236e-01]\n",
            "  [ 4.52493876e-03 -1.55425236e-01]\n",
            "  [-9.78026539e-03  3.61625035e-03]\n",
            "  [ 9.78026539e-03 -3.61625035e-03]]\n",
            "\n",
            " [[ 2.09066160e-02 -4.13850229e-03]\n",
            "  [-2.09066160e-02  4.13850229e-03]\n",
            "  [ 2.91610122e-01  1.01772696e-03]\n",
            "  [-2.91610122e-01 -1.01772696e-03]\n",
            "  [ 2.09066160e-02 -4.13850229e-03]\n",
            "  [-2.09066160e-02  4.13850229e-03]]\n",
            "\n",
            " [[-2.75652925e-03  4.06332826e-03]\n",
            "  [ 2.75652925e-03 -4.06332826e-03]\n",
            "  [-5.88169545e-02 -1.54424310e-01]\n",
            "  [ 5.88169545e-02  1.54424310e-01]\n",
            "  [-2.75652925e-03  4.06332826e-03]\n",
            "  [ 2.75652925e-03 -4.06332826e-03]]\n",
            "\n",
            " [[-2.46265531e-02  9.25423764e-03]\n",
            "  [ 2.46265531e-02 -9.25423764e-03]\n",
            "  [-4.09532785e-02 -2.04065084e-01]\n",
            "  [ 4.09532785e-02  2.04065084e-01]\n",
            "  [-2.46265531e-02  9.25423764e-03]\n",
            "  [ 2.46265531e-02 -9.25423764e-03]]\n",
            "\n",
            " [[-9.41676646e-03 -5.69903466e-04]\n",
            "  [ 9.41676646e-03  5.69903466e-04]\n",
            "  [-3.11345756e-02  4.42343429e-02]\n",
            "  [ 3.11345756e-02 -4.42343429e-02]\n",
            "  [-9.41676646e-03 -5.69903466e-04]\n",
            "  [ 9.41676646e-03  5.69903466e-04]]\n",
            "\n",
            " [[ 7.01558217e-03 -2.19596876e-03]\n",
            "  [-7.01558217e-03  2.19596876e-03]\n",
            "  [ 1.67518437e-01 -5.42986207e-02]\n",
            "  [-1.67518437e-01  5.42986207e-02]\n",
            "  [ 7.01558217e-03 -2.19596876e-03]\n",
            "  [-7.01558217e-03  2.19596876e-03]]\n",
            "\n",
            " [[-5.00909565e-03  8.75803269e-03]\n",
            "  [ 5.00909565e-03 -8.75803269e-03]\n",
            "  [-1.65946111e-01 -1.94518477e-01]\n",
            "  [ 1.65946111e-01  1.94518477e-01]\n",
            "  [-5.00909565e-03  8.75803269e-03]\n",
            "  [ 5.00909565e-03 -8.75803269e-03]]\n",
            "\n",
            " [[-9.28334612e-03  1.24139441e-02]\n",
            "  [ 9.28334612e-03 -1.24139441e-02]\n",
            "  [ 4.88469750e-02 -2.23894864e-01]\n",
            "  [-4.88469750e-02  2.23894864e-01]\n",
            "  [-9.28334612e-03  1.24139441e-02]\n",
            "  [ 9.28334612e-03 -1.24139441e-02]]\n",
            "\n",
            " [[ 1.44571858e-03  4.25786572e-03]\n",
            "  [-1.44571858e-03 -4.25786572e-03]\n",
            "  [ 1.10414669e-01 -1.73681825e-01]\n",
            "  [-1.10414669e-01  1.73681825e-01]\n",
            "  [ 1.44571858e-03  4.25786572e-03]\n",
            "  [-1.44571858e-03 -4.25786572e-03]]\n",
            "\n",
            " [[ 9.70274489e-03 -1.37073072e-02]\n",
            "  [-9.70274489e-03  1.37073072e-02]\n",
            "  [-2.04374969e-01 -6.77113459e-02]\n",
            "  [ 2.04374969e-01  6.77113459e-02]\n",
            "  [ 9.70274489e-03 -1.37073072e-02]\n",
            "  [-9.70274489e-03  1.37073072e-02]]]\n",
            "\n",
            "Nth Identities (Conceptual, per qubit):\n",
            "\n",
            "  Qubit 0:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.7810879  -0.62425387]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 1:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.27360398 -0.96176416]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 2:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.92991656 0.36760962]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 3:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.31733328 -0.9482043 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 4:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.36515594 -0.9307504 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 5:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.2839532 0.9587231]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 6:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.93271345  0.36044642]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 7:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.29150003 -0.95643604]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 8:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.87711996 0.480084  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 9:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9998705  0.01387875]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 10:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.5595768 0.8286681]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 11:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9950573  -0.09887081]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 12:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.82765   0.5609594]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 13:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.05462082 -0.99844146]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 14:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.50381035 -0.8636923 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 15:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.02834764 0.9992941 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 16:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.48962992  0.87179303]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 17:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.68291795  0.7303947 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 18:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9856819  0.16827124]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 19:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9831747   0.18250401]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 20:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.7972242 0.6035743]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 21:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 9.999720e-01 -9.045091e-05]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 22:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.85166276 -0.5239396 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 23:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.77116656  0.63648295]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 24:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9591722   0.28249606]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 25:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.01220622 -0.9998701 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 26:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9992      0.03709449]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 27:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9924708  -0.12192846]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 28:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.98603433  0.16627596]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 29:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.7940806  0.60775256]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 30:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99631214  0.08519921]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 31:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.7863084 -0.6175941]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 32:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9609282   0.27668658]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 33:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.98339087 0.18096358]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 34:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.79483926 -0.6064718 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 35:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99844635  0.054783  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 36:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9979462  -0.06317045]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 37:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.34892857  0.9370551 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 38:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.6031303   0.79740685]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 39:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.81722635 -0.57623136]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 40:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.92763567 -0.37283307]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 41:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.8472843 0.5310294]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 42:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9927751   0.11970033]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 43:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.98727113 -0.15862164]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 44:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.7996337  -0.60032177]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 45:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.96568614 0.25955763]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 46:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99591213  0.08417671]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 47:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9987814  -0.04844282]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 48:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.90365213  0.42812145]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 49:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.23077992 -0.97284245]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 50:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96383774  0.2662284 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 51:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9644346  0.26396146]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 52:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.16203415 -0.9867075 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 53:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.985513   -0.16939312]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 54:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.93784827  0.34676912]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 55:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9809191 -0.1941747]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 56:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.56128544  0.8273763 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 57:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.93605244  0.3517525 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 58:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99806786 -0.06040315]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 59:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9542107 -0.2986804]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 60:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.49642634  0.8679647 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 61:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.5988414  0.8007871]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 62:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.32144138 0.9466948 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 63:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.5777213 -0.8161611]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "\n",
            "Info-energy Output (all qubits):\n",
            " [ 3.5112774  4.154546   8.724641   3.021324   4.080133   6.815491\n",
            "  7.689981   5.7584763  6.358733   9.974829   7.1090264  5.08286\n",
            "  8.966797   4.0945597  5.4768467  4.9357686  5.832301   7.4294095\n",
            " 10.184999   7.338598   9.40327   16.7481     5.2572293  6.0479393\n",
            "  6.6600776  5.598101   5.8801794  9.182624   5.6370254 10.745808\n",
            "  6.232543   9.233417   6.7908287 10.283634   2.9243681  6.9884367\n",
            "  4.127801   7.7499843  5.039712   6.9259253  7.2121577 10.14094\n",
            "  4.213546   7.665539   5.9970956 15.165544   6.8746557  2.1563084\n",
            "  4.966307   5.6488996  7.4081945  6.8707128  9.657711   9.345235\n",
            "  5.930477  10.096149   3.5028129 10.120829   2.533767   5.495206\n",
            "  9.785962   8.490058   5.5597353  8.542124 ]\n",
            "\n",
            "Resonance Keys (all qubits):\n",
            " ['5d33ed4632ec9495131f2b37c4f273ee3aac8de5bcc60fea6e728c21e360d948', 'a15bbf8e84f92096f33094df9e02c35b75aae4aa92df6f6e0bd96a64b4f5c235', '882d9b0b044e6462c6c3d103481e25e981306c95d74e0887e5745a99ddb47b30', '1cecd451ab1681a9dabe67c48ec1864744a06bc7acdf9df2ccd554732db3628d', '429951cb87b0e7da21155ed9f9ac9364a4acb03ac846e73e702a9456258d54c6', '3c07831d28f58328181d47654f95053d45d4b7d0ecf0b08941f83ead5c09b046', '52facd67e741ad23c228172c519a11af396964d2fe0cfb9e9ed81d5f6b6a9546', 'a412b46790db1d56be4f9b3b2fc5d477e3a2b2e93bbd9754594f08e7b0926fe4', '9c3c28de4ed08fc7ff10e091cbba4fe983edcd23a91afd85a3d1927cf62e532d', '31f6a82a3d0830cfa7b8a3da4c5a84cb0a31f454c75d902108e66c26ed99bfc7', '46dd6b51eee98dfacf8beeb9206e6d60b371a8dff8b36d9d93a9338edd716072', 'b798de95b7330ff95f0eb7a31a912afe4d778ebc9db3b37f953ca18a6414d006', 'b2495d414a6cff13c3d8eba97588d9a32fa91e917853ed6f09dc1c31f3dfdd91', '58636b11e03cea68c9cfd0f185d4f04c0dba51857e98d4b85de5e35dcb68dc62', '0d2ade1b49712148bcd43b4dfd33fa0fac67fbfba81b43d567d0daa994d4c611', '910bf854f16ca3b2bc0d9ed2888c8878e3ec13706a19625e66f1cf01c985c5bb', 'c9e84e5d2c038193d60b761e726507ec2652d52485521e5b2dbc1c5fba67ac0b', '755dc5894a1bdfa6102dd33246dbb6116b0c1c76613a3b008b0723c584a69c4f', '82c9aceb6946a50cd1d9141e3152eb5dd3a60a272476f10e76a03c2ba1e996bd', '9c91f3365a873733bef6bf35c6990f6b720f0cf0cfb936d67aacf2b5989e23f1', 'd30e0318fee60843e082b715b49e9fb800744a2e9cf4087dc0af0244e13e255a', '059da1596b520b9df16e40c3cbf8f6deb95e4bf88d36d17e20ded408b35c8639', '7ef9efcc2805588e98be87a7a5d427b6956ffe05e798b3c3c9b0780a8f4be62d', 'e17b21883cb0d42fafa5434dd2755a59bfb473eff924f3c09f6b3e10bdfe068f', 'aeee94687cea17d82dc3486beb3061b05fa2dbba8a81b3e820893ef216e84185', 'd6f4dbb0a895b9ffec99c989a231c3b5157030d26d1d1b6595c68988399a4bb2', '414d6cd273e44f79b83a82508852468b2043434430221424a424d1a64dbdc285', '22f0e6cc3ed5f581d0a402fc4d7f2fc94708aefdf0d146cc9c3e81fafffae434', 'bb5c51c60b4208eed4251804db31e1cb0bc0a1cff426adde7347aecd4cfa0ef9', '649a3bde7a2f7727f50b81f8307d71e5bffcdcf6ddad9ec732ed075061a8c952', '452c25ba4cb92ff94b660e374638cb756ac9840dde6a8557abc9cc975a5f3415', '4ed94540ed2fd09e5390f4b10c39c1cd70772bad4c52e11a933e569b10f0a8f4', 'c7bdeeb58eeda38ceae2d1f26956d3bccad094ae7aec0c9ffd19d125e0004246', '9b9ec53f5f0a5611f41e98a379ba4dd89ae375a1e04a0654898beb5a2eeed8e3', 'a260364c7aee8ef1d1ec228af5b6780250c9951ab302e865490dfb4a020baa02', '99dd0fc3214a9c7c1b6c65501563134677c8ff197663bd47d8dae4a78d72fd9f', '776ce05eed8e00a51932254562ef4c89511a4acbd49082f43a362d1f57f4a804', 'fadf4757b75615632d35481c10572dcecc7cf9f6ad60fa7f93e11a0c3e1b9d1d', '50e82d29325a33aba386dedadfb9245aa43073f927511702bf64e7c9d4bbe2fa', '00933157d907cea81a0f9b54c29217185a265648b6171ce1d93c08983ef4c347', '7443add3b3fda94b52e36797a7bbffb3e7f24bf93ce685879a1b05bc31c19b8b', 'da4e580c97f6100a13bcb80b2a5f13f3a04ae0260f712e10e98ee04701d61d9e', 'f23a17e4356d6b8e05a9f3c591d53515b89c88d42f932c1b26eb4272a6fdda40', '1d883d17dfcab2c7ebdcdcaf57c5e2cb9fdd3b3079f73e993f9541edd9dccab8', '584dfe4e4a588444d2c8087fab6fe011cb70b4425b9e70b7243512bf48e99d5c', '785d3f03ec02c004aa88af663091c488edddfbca04ccb1a2fc32c63da9e90054', '64cc434a81a7c76339308b063b8f0fc67082cc13a5277c1f199677fe0475f829', '3dd7a327650adb9443d906654a83099b59fcbf4fc81bd197b0b43fae6c944842', '2cf25f4dd1ee1d8f2c4f466da07217234ca16430528dabb847afa7d2e6367122', '0a73cb07f18aa3770663fb33029fb7ab043a7aa7057d2993fb0c9e94fdfc3698', '8585e1e97e9df8d1d2fe44aff13c0c30f2f9a6b7832c1c22fc1f3d9b45c7c8a0', 'e77c639fb3e4475454036361e9a3fdbc114132a24f3b678b495c467adafbc215', '2a48362985dc90411363b01d4ece699fe4269c89e2aca07b56f7b6e37f4ea73f', 'fde15256d882bfda18ec30f68a54d965e913af39a5508acae85396f173496072', '2f91ea14d6849e2a29461d405fe8c2db025b3112a6c476363b26146f0e8bcdd3', '36c288530045ef8b2d72827e14aac2547571b5c1418a9835aa8647db84976603', '7b6155a6730e87fe6719555fcaa3e84828985fefb68f503ecc020a5aa706d139', '53f4240e91c9aaf207d0441cd52442fc7c45ffd5137d0626e92a05a407799211', '56022598c7f5330dcf963ff9a7b90b10ae4b8528f8ab148a295ecd715b439ae5', '10f477ac812163929e73a92a6d283bbed84b7b656414aacea70d47fc8cccd748', 'bfc1114a69cf7c277acbd9bca60578b72b6534121c3f6dad524521d8e36f3a2f', 'c6f44687420e1e4bd3c1afe5d0193e92198d080f95ec17b1a02e035f95b59916', 'f7702e2dcd732d915bd8a679450de6623611a08815baa0770c5efee0c3c8bc95', 'b5dcaf37cc176fd40a51440afd57e14a48c95fd0634676d40c0cb1eab39ebf63']\n",
            "\n",
            "Spin (all qubits, conceptual):\n",
            " [[[-5.61106086e-01 -7.83807099e-01  2.66094744e-01]\n",
            "  [-4.18473519e-02  9.63038087e-01  2.66094744e-01]]\n",
            "\n",
            " [[ 1.30775422e-01 -1.98846236e-01  9.71266150e-01]\n",
            "  [ 1.35100618e-01  1.95933312e-01  9.71266150e-01]]\n",
            "\n",
            " [[-7.28506327e-01 -1.89798865e-02 -6.84776127e-01]\n",
            "  [ 2.25828841e-01 -6.92880213e-01 -6.84776127e-01]]\n",
            "\n",
            " [[-4.84738383e-04 -9.89996456e-03 -9.99950886e-01]\n",
            "  [-7.78036425e-03 -6.14086306e-03 -9.99950886e-01]]\n",
            "\n",
            " [[ 8.12286735e-01  5.72481453e-01  1.11603245e-01]\n",
            "  [ 1.93700045e-01 -9.74692285e-01  1.11603245e-01]]\n",
            "\n",
            " [[-7.10637718e-02  9.18719232e-01 -3.88464868e-01]\n",
            "  [-2.75358588e-01  8.79359245e-01 -3.88464868e-01]]\n",
            "\n",
            " [[-5.95044971e-01 -8.03646505e-01  8.58896598e-03]\n",
            "  [-4.37028408e-01 -8.99406672e-01  8.58896598e-03]]\n",
            "\n",
            " [[-7.07914531e-01  1.30861789e-01  6.94069266e-01]\n",
            "  [-6.89888477e-01  2.05722481e-01  6.94069266e-01]]\n",
            "\n",
            " [[ 2.70078361e-01 -1.36976048e-01 -9.53045249e-01]\n",
            "  [ 2.93768376e-01  7.35180825e-02 -9.53045249e-01]]\n",
            "\n",
            " [[-4.83890861e-01 -2.06654713e-01  8.50378454e-01]\n",
            "  [ 1.30398974e-01  5.09757459e-01  8.50378454e-01]]\n",
            "\n",
            " [[-8.15736711e-01  1.31599993e-01 -5.63253939e-01]\n",
            "  [ 1.81505010e-01 -8.06102276e-01 -5.63253939e-01]]\n",
            "\n",
            " [[-6.11555278e-01 -5.52551985e-01 -5.66291809e-01]\n",
            "  [-8.19773853e-01  8.53488147e-02 -5.66291809e-01]]\n",
            "\n",
            " [[ 1.13582104e-01  1.49810314e-01 -9.82169032e-01]\n",
            "  [ 2.11508851e-02  1.86806485e-01 -9.82169032e-01]]\n",
            "\n",
            " [[-5.39429262e-02 -8.04498196e-01 -5.91500461e-01]\n",
            "  [ 5.87476254e-01 -5.52266955e-01 -5.91500461e-01]]\n",
            "\n",
            " [[-1.97464883e-01 -8.31811905e-01  5.18745184e-01]\n",
            "  [-8.09959233e-01 -2.73622930e-01  5.18745184e-01]]\n",
            "\n",
            " [[ 5.03683314e-02  2.62206905e-02  9.98386443e-01]\n",
            "  [ 5.45587875e-02  1.57426819e-02  9.98386443e-01]]\n",
            "\n",
            " [[-1.00533828e-01  1.78852063e-02  9.94772851e-01]\n",
            "  [-7.23641440e-02  7.20441714e-02  9.94772851e-01]]\n",
            "\n",
            " [[-1.07634842e-01 -7.30802445e-03  9.94163632e-01]\n",
            "  [ 7.32834488e-02  7.91719854e-02  9.94163632e-01]]\n",
            "\n",
            " [[-1.09641522e-01  2.07687601e-01  9.72031176e-01]\n",
            "  [-1.40053943e-01 -1.88521326e-01  9.72031176e-01]]\n",
            "\n",
            " [[-9.35017645e-01  3.53780448e-01 -2.41113286e-02]\n",
            "  [ 9.91759121e-01 -1.25827193e-01 -2.41113286e-02]]\n",
            "\n",
            " [[-6.98182955e-02  3.20167631e-01  9.44784701e-01]\n",
            "  [-2.99572378e-01  1.32809237e-01  9.44784701e-01]]\n",
            "\n",
            " [[ 2.07853049e-01 -4.57094193e-01 -8.64790142e-01]\n",
            "  [-4.86083269e-01  1.25940651e-01 -8.64790142e-01]]\n",
            "\n",
            " [[-3.32578927e-01 -7.39000082e-01  5.85892558e-01]\n",
            "  [-8.09013247e-01 -4.71954197e-02  5.85892558e-01]]\n",
            "\n",
            " [[ 6.24223828e-01 -4.17450458e-01  6.60363317e-01]\n",
            "  [ 3.88981760e-01 -6.42349958e-01  6.60363317e-01]]\n",
            "\n",
            " [[ 4.75810289e-01  2.03977935e-02 -8.79311383e-01]\n",
            "  [-4.69834268e-01  7.78925121e-02 -8.79311383e-01]]\n",
            "\n",
            " [[-7.47156590e-02  7.42394403e-02 -9.94437575e-01]\n",
            "  [ 7.62981251e-02 -7.26121143e-02 -9.94437575e-01]]\n",
            "\n",
            " [[-1.83617845e-01  9.37606633e-01 -2.95259714e-01]\n",
            "  [-9.23313081e-01  2.45590419e-01 -2.95259714e-01]]\n",
            "\n",
            " [[ 8.45839620e-01  2.56590415e-02 -5.32819808e-01]\n",
            "  [ 7.88207710e-01 -3.07947487e-01 -5.32819808e-01]]\n",
            "\n",
            " [[-6.01378679e-01  7.20679581e-01 -3.44912529e-01]\n",
            "  [-8.89928699e-01  2.98433006e-01 -3.44912529e-01]]\n",
            "\n",
            " [[-7.73875535e-01 -6.07430398e-01 -1.79290131e-01]\n",
            "  [-3.08034062e-01 -9.34328675e-01 -1.79290131e-01]]\n",
            "\n",
            " [[-6.30377650e-01 -4.37276274e-01 -6.41415238e-01]\n",
            "  [-4.35986996e-01 -6.31270051e-01 -6.41415238e-01]]\n",
            "\n",
            " [[ 1.13131851e-01  1.14594005e-01  9.86949563e-01]\n",
            "  [-1.36606976e-01 -8.52592215e-02  9.86949563e-01]]\n",
            "\n",
            " [[ 9.56864581e-02 -8.98241103e-01 -4.28960413e-01]\n",
            "  [-5.54154098e-01 -7.13376582e-01 -4.28960413e-01]]\n",
            "\n",
            " [[ 5.71210980e-01  2.26575926e-01  7.88911521e-01]\n",
            "  [-4.81868237e-01  3.81341845e-01  7.88911521e-01]]\n",
            "\n",
            " [[ 1.70779094e-01 -1.86317787e-01  9.67533052e-01]\n",
            "  [ 1.19546354e-01 -2.22684726e-01  9.67533052e-01]]\n",
            "\n",
            " [[ 1.39855132e-01 -3.59722763e-01  9.22518313e-01]\n",
            "  [-2.02248946e-01 -3.28717649e-01  9.22518313e-01]]\n",
            "\n",
            " [[-9.69645917e-01  2.09023684e-01  1.26869544e-01]\n",
            "  [-9.80642200e-01  1.49147704e-01  1.26869544e-01]]\n",
            "\n",
            " [[ 4.35621619e-01  3.70258331e-01 -8.20452690e-01]\n",
            "  [ 5.28423931e-04 -5.71714222e-01 -8.20452690e-01]]\n",
            "\n",
            " [[ 4.13471311e-01  1.94410220e-01  8.89520168e-01]\n",
            "  [ 1.42784208e-01 -4.34012145e-01  8.89520168e-01]]\n",
            "\n",
            " [[ 1.62277758e-01 -1.48473933e-01 -9.75510836e-01]\n",
            "  [ 2.19938338e-01 -2.38849293e-03 -9.75510836e-01]]\n",
            "\n",
            " [[ 1.30163535e-01 -8.31615865e-01  5.39881945e-01]\n",
            "  [-7.99673796e-01 -2.62772441e-01  5.39881945e-01]]\n",
            "\n",
            " [[ 6.61743224e-01  4.15362477e-01 -6.24155402e-01]\n",
            "  [ 7.77552664e-01 -7.64326081e-02 -6.24155402e-01]]\n",
            "\n",
            " [[-2.23529041e-01 -4.50807177e-02 -9.73654211e-01]\n",
            "  [-2.21635178e-01  5.36222570e-02 -9.73654211e-01]]\n",
            "\n",
            " [[-2.08295509e-01 -4.94109206e-02 -9.76817071e-01]\n",
            "  [ 2.01136544e-01 -7.32976645e-02 -9.76817071e-01]]\n",
            "\n",
            " [[-4.16325867e-01  7.24134266e-01 -5.49820304e-01]\n",
            "  [ 2.45046958e-01  7.98529685e-01 -5.49820304e-01]]\n",
            "\n",
            " [[-4.68483716e-02  1.47618772e-02 -9.98792946e-01]\n",
            "  [ 4.54137959e-02 -1.87155046e-02 -9.98792946e-01]]\n",
            "\n",
            " [[-2.24508375e-01  9.70717549e-01  8.54604244e-02]\n",
            "  [ 9.92919087e-01  8.25116634e-02  8.54604244e-02]]\n",
            "\n",
            " [[-8.83886337e-01 -2.67785072e-01 -3.83452892e-01]\n",
            "  [ 2.61404753e-01 -8.85794222e-01 -3.83452892e-01]]\n",
            "\n",
            " [[-3.27043831e-01  6.88720107e-01 -6.47075713e-01]\n",
            "  [ 6.54563665e-01 -3.90946865e-01 -6.47075713e-01]]\n",
            "\n",
            " [[-1.87503546e-01 -6.11562192e-01  7.68657327e-01]\n",
            "  [ 6.09609187e-01 -1.93758935e-01  7.68657327e-01]]\n",
            "\n",
            " [[-4.58057433e-01  8.25567901e-01  3.29576999e-01]\n",
            "  [ 4.63424832e-01 -8.22566986e-01  3.29576999e-01]]\n",
            "\n",
            " [[ 5.70867121e-01 -1.78584114e-01  8.01385343e-01]\n",
            "  [-5.92454076e-01 -8.23391676e-02  8.01385343e-01]]\n",
            "\n",
            " [[ 7.38181949e-01  5.89548111e-01 -3.27903092e-01]\n",
            "  [ 6.54549673e-02 -9.42441106e-01 -3.27903092e-01]]\n",
            "\n",
            " [[-4.29632306e-01  7.14641809e-01  5.51999271e-01]\n",
            "  [-8.10520113e-01 -1.95841566e-01  5.51999271e-01]]\n",
            "\n",
            " [[ 9.78367925e-01  2.05727071e-01 -2.17380188e-02]\n",
            "  [ 7.00540125e-01 -7.13281870e-01 -2.17380188e-02]]\n",
            "\n",
            " [[-3.16983074e-01 -1.95922315e-01 -9.27974224e-01]\n",
            "  [ 3.71740252e-01 -2.59424206e-02 -9.27974224e-01]]\n",
            "\n",
            " [[-7.35762894e-01 -1.02203898e-01 -6.69482887e-01]\n",
            "  [-3.39694232e-01  6.60606146e-01 -6.69482887e-01]]\n",
            "\n",
            " [[-7.08547188e-03 -4.29802537e-02  9.99050796e-01]\n",
            "  [ 3.31065767e-02  2.83100791e-02  9.99050796e-01]]\n",
            "\n",
            " [[-6.96274877e-01  4.41925466e-01 -5.65599799e-01]\n",
            "  [-2.24771481e-02  8.24373484e-01 -5.65599799e-01]]\n",
            "\n",
            " [[-9.57257390e-01 -1.35880113e-01 -2.55332857e-01]\n",
            "  [-8.28602135e-01 -4.98220474e-01 -2.55332857e-01]]\n",
            "\n",
            " [[ 4.56802726e-01 -2.52048463e-01  8.53113592e-01]\n",
            "  [ 4.50550944e-01  2.63060838e-01  8.53113592e-01]]\n",
            "\n",
            " [[ 1.47485897e-01 -9.28366303e-01 -3.41150820e-01]\n",
            "  [ 1.70044638e-02 -9.39854741e-01 -3.41150820e-01]]\n",
            "\n",
            " [[ 6.42378926e-01  4.05462533e-02 -7.65313864e-01]\n",
            "  [ 1.57272145e-01  6.24147534e-01 -7.65313864e-01]]\n",
            "\n",
            " [[-7.61667788e-01  5.39642930e-01  3.58674884e-01]\n",
            "  [-6.97806597e-01 -6.20014727e-01  3.58674884e-01]]]\n",
            "\n",
            "I_vec (all qubits, conceptual):\n",
            " [[0.37532642 0.2917027  0.21963315 ... 0.3116841  0.17957906 0.31284115]\n",
            " [0.14122458 0.29501635 0.24381088 ... 0.05314886 0.34709558 0.19384167]\n",
            " [0.01349588 0.09553119 0.06149324 ... 0.2226497  0.25382343 0.25467828]\n",
            " ...\n",
            " [0.3338919  0.32540247 0.18019964 ... 0.12727617 0.09059671 0.38758916]\n",
            " [0.41018057 0.14224952 0.21184741 ... 0.18789363 0.25842392 0.34668556]\n",
            " [0.36302584 0.34823447 0.0889935  ... 0.03493283 0.11498681 0.397633  ]]\n",
            "\n",
            "NECL Manifest Checksums (per qubit, conceptual):\n",
            " ['caacde9e49ff33d7f98d01fb3c3309ed23d45924b22f43d940f388740a642151', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945']\n",
            "\n",
            "TRACE Log (Conceptual - detailed lineage for error correction):\n",
            " [{'qubit': 0, 'reason': 'binary_refactor', 'source': 'tuplets', 'r_metric': 0.9738044142723083, 'u_metric': 0.9810442924499512, 'dv_metric': 0.1986478567123413, 'invariant_pass': False, 'degenerate_check': False, 'correction_threshold_r': 1.02, 'correction_threshold_u': 1.02, 'correction_threshold_d': 0.765, 'corrected_bits': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'old_key': '68052187a26d456d18749a3c1e8714b90d512c9635673c938c085b92828b5398', 'new_key': '5d33ed4632ec9495131f2b37c4f273ee3aac8de5bcc60fea6e728c21e360d948'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ebb0dea"
      },
      "source": [
        "# Task\n",
        "The refactoring of the `detect_collapse` function with the new triplet-level predicate (including the updated `R_FOR_RATIO` constant), the confirmation of `apply_parity_rotation` and `COLLAPSE_Q` functions, and the documentation of `correct_bits` have all been successfully completed and verified. The system now incorporates the specified collapse rules, and its behavior has been confirmed to be as expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55f599b6"
      },
      "source": [
        "## Refactor Collapse Detection with New Predicate\n",
        "\n",
        "### Subtask:\n",
        "Update the global constant R_FOR_RATIO to 64.0 and modify the detect_collapse function to implement the new triplet-level predicate for collapse detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dbec165"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `detect_collapse` function to implement a new triplet-level predicate and removing a nested helper function. I need to update the `R_FOR_RATIO` constant and rewrite the logic for determining collapsed indices directly within the loop.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0003769",
        "outputId": "29af29ec-56cd-43cd-f4f3-535969fac131"
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "R_FOR_RATIO = 64.0 # NEW: Ratio threshold constant for collapse detection, updated to 64.0 as per instructions\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| + n_|y, η| = n_|x+y, ξ+η|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| · n_|y, η| = n_|x·y, ξ·η|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ξ| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ξ_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW, r_for_ratio=R_FOR_RATIO):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register.\n",
        "    A triplet block collapses if, for any index 'p' within the triplet,\n",
        "    the condition [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO] is met.\n",
        "    If this condition is true for *any* index within the triplet, all indices i,j,k\n",
        "    of that triplet are marked as collapsed.\n",
        "    COLL(x, χ) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for unreal component (should be negative).\n",
        "        r_for_ratio (float): Ratio threshold for collapse detection.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    # Initialize a collapse mask filled with zeros\n",
        "    collapse_mask = tf.zeros(tf.shape(real_parts), dtype=tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Iterate over each triplet block and apply collapse detection\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # Extract real and unreal parts for the current triplet across all Q qubits\n",
        "        # shape [Q, 3]\n",
        "        triplet_real_block = tf.gather(real_parts, current_triplet_indices, axis=1)\n",
        "        triplet_unreal_block = tf.gather(unreal_parts, current_triplet_indices, axis=1)\n",
        "\n",
        "        # Evaluate the new triplet-level predicate for each index 'p' within the triplet block\n",
        "        # The condition: [high(real_p) AND low(unreal_p)] OR [ratio(real_p / unreal_p) > R_FOR_RATIO]\n",
        "        # high(real_p): triplet_real_block >= tau_hi\n",
        "        # low(unreal_p): triplet_unreal_block <= tau_low (using TAU_LOW for unreal too)\n",
        "\n",
        "        # Condition 1: high(real_p) AND low(unreal_p)\n",
        "        cond1 = tf.logical_and(triplet_real_block >= tau_hi, triplet_unreal_block <= tau_low) # [Q, 3]\n",
        "\n",
        "        # Condition 2: ratio(real_p / unreal_p) > r_for_ratio\n",
        "        # Handle potential division by zero for unreal_p\n",
        "        # If unreal_p is near zero, the ratio might be undefined or very large.\n",
        "        # Set ratio to 0 if unreal_p is ~0 to avoid NaNs and make the condition false.\n",
        "        ratio_term = tf.where(tf.abs(triplet_unreal_block) > EPS, triplet_real_block / triplet_unreal_block, tf.zeros_like(triplet_real_block))\n",
        "        cond2 = ratio_term > r_for_ratio # [Q, 3]\n",
        "\n",
        "        # Triplet collapse if (cond1 OR cond2) is true for *any* index within the triplet\n",
        "        # tf.reduce_any along the triplet dimension (axis=1) for each qubit\n",
        "        triplet_collapse_per_qubit = tf.reduce_any(tf.logical_or(cond1, cond2), axis=1) # [Q]\n",
        "\n",
        "        # Mark all 3 indices of the triplet as collapsed if triplet_collapse_per_qubit is true for that qubit\n",
        "        unit_collapse_flag_int = tf.cast(triplet_collapse_per_qubit, tf.int32) # [Q]\n",
        "        marked_triplet_block = tf.broadcast_to(tf.expand_dims(unit_collapse_flag_int, axis=1), tf.shape(triplet_real_block)) # [Q, 3]\n",
        "\n",
        "        # Construct indices for scatter_nd_max to update the global collapse_mask\n",
        "        # indices_to_update will be [Q*3, 2]\n",
        "        # First column is qubit index, second is original 30-index\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1)\n",
        "\n",
        "        # Flatten marked_triplet_block to [Q*3] for updates\n",
        "        updates = tf.reshape(marked_triplet_block, [-1])\n",
        "\n",
        "        # Use tf.tensor_scatter_nd_max to update the collapse_mask.\n",
        "        # This ensures that if any triplet marks an index as collapsed, it remains marked.\n",
        "        collapse_mask = tf.tensor_scatter_nd_max(collapse_mask, indices_to_update, updates)\n",
        "\n",
        "    return collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`)\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode('utf-8')).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    for b_idx_triplet in tf.range(10):\n",
        "        current_triplet_indices = idx[b_idx_triplet, :] # Shape [3]\n",
        "        s = tf.gather(signs, current_triplet_indices) # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        # Ensure the list extension is compatible with TF operations if trip_mix is later converted to Tensor\n",
        "        # Here, it's converted to Python list and then to Tensor once.\n",
        "        trip_mix.extend([has_mix.numpy().item()]*3)\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook for a single qubit (q_idx). This function performs a local\n",
        "    re-evaluation of the bit pattern for the current qubit if the initial derivation\n",
        "    is deemed 'inconsistent'.\n",
        "\n",
        "    This function is designed to:\n",
        "    - Advance *only* within the same triplet (or within the primaries 6-set) for local re-evaluation.\n",
        "      It uses the `pairs_q` and `triplets_q` already derived for this specific qubit `q_idx`.\n",
        "      It does not implicitly advance to other qubits or triplets; its scope is limited to the\n",
        "      current qubit's local tuplet structure.\n",
        "    - Record lineage for any local adjustments made. If a correction occurs, a specific\n",
        "      entry is added to the `TRACE` log, detailing the reason, source, metrics, and new key.\n",
        "    - *Not* advance across different units (triplets or qubits) unless the current local unit\n",
        "      has been exhausted. The `derive_bits_advanced` function, called internally,\n",
        "      operates solely on the provided `pairs_q` and `triplets_q` for the current qubit.\n",
        "\n",
        "    Args:\n",
        "        q_idx (int): The index of the current qubit being processed.\n",
        "        pairs_q (tf.Tensor): The 30-index phase-dual pair register for the current qubit [30, 2].\n",
        "        triplets_q (tf.Tensor): The 10 triplets for the current qubit [10, 3, 2].\n",
        "        current_bits_q (tf.Tensor): The initially derived 30-bit pattern for the current qubit [30].\n",
        "        resonance_key_q (str): The current resonance key string for the qubit.\n",
        "        TRACE (list): A list to append lineage information if corrections are made.\n",
        "        invariants (dict): Dictionary of invariant constants.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, str]:\n",
        "            - new_bits_q (tf.Tensor): The potentially corrected 30-bit pattern.\n",
        "            - updated_resonance_key_q (str): The updated resonance key string (with lineage if corrected).\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        # The updated key incorporates the correction lineage.\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs) # Pass R_FOR_RATIO implicitly from constants\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primaries In:\n",
            " [[[ 1.32099867e-01  9.43567753e-01]\n",
            "  [-1.32099867e-01 -9.43567753e-01]\n",
            "  [ 4.97868061e-02 -1.29245043e-01]\n",
            "  [-4.97868061e-02  1.29245043e-01]\n",
            "  [ 6.87581539e-01  2.13343143e-01]\n",
            "  [-6.87581539e-01 -2.13343143e-01]]\n",
            "\n",
            " [[-5.09592533e-01  7.30511904e-01]\n",
            "  [ 5.09592533e-01 -7.30511904e-01]\n",
            "  [ 2.02916384e-01  3.57952833e-01]\n",
            "  [-2.02916384e-01 -3.57952833e-01]\n",
            "  [ 7.47351646e-02  7.46693373e-01]\n",
            "  [-7.47351646e-02 -7.46693373e-01]]\n",
            "\n",
            " [[ 9.43643093e-01 -2.27895021e-01]\n",
            "  [-9.43643093e-01  2.27895021e-01]\n",
            "  [ 8.66883278e-01 -3.99476528e-01]\n",
            "  [-8.66883278e-01  3.99476528e-01]\n",
            "  [-9.42517042e-01  3.47955704e-01]\n",
            "  [ 9.42517042e-01 -3.47955704e-01]]\n",
            "\n",
            " [[-6.47403955e-01 -8.47853899e-01]\n",
            "  [ 6.47403955e-01  8.47853899e-01]\n",
            "  [-9.53937531e-01  8.38187456e-01]\n",
            "  [ 9.53937531e-01 -8.38187456e-01]\n",
            "  [ 5.66698790e-01  9.02263403e-01]\n",
            "  [-5.66698790e-01 -9.02263403e-01]]\n",
            "\n",
            " [[ 7.88413048e-01 -6.12660646e-01]\n",
            "  [-7.88413048e-01  6.12660646e-01]\n",
            "  [ 7.89419174e-01 -1.11490726e-01]\n",
            "  [-7.89419174e-01  1.11490726e-01]\n",
            "  [ 4.12118196e-01 -4.47762489e-01]\n",
            "  [-4.12118196e-01  4.47762489e-01]]\n",
            "\n",
            " [[-6.60369873e-01 -7.64994621e-01]\n",
            "  [ 6.60369873e-01  7.64994621e-01]\n",
            "  [ 5.09954929e-01 -7.70990372e-01]\n",
            "  [-5.09954929e-01  7.70990372e-01]\n",
            "  [ 7.97191858e-01 -1.61449194e-01]\n",
            "  [-7.97191858e-01  1.61449194e-01]]\n",
            "\n",
            " [[-9.96034861e-01 -2.20185041e-01]\n",
            "  [ 9.96034861e-01  2.20185041e-01]\n",
            "  [-1.68973207e-01 -8.42239141e-01]\n",
            "  [ 1.68973207e-01  8.42239141e-01]\n",
            "  [ 7.25428820e-01  5.61651707e-01]\n",
            "  [-7.25428820e-01 -5.61651707e-01]]\n",
            "\n",
            " [[-5.61140537e-01  9.74541426e-01]\n",
            "  [ 5.61140537e-01 -9.74541426e-01]\n",
            "  [-1.52914286e-01 -4.61499214e-01]\n",
            "  [ 1.52914286e-01  4.61499214e-01]\n",
            "  [ 5.26412725e-01 -7.99381733e-02]\n",
            "  [-5.26412725e-01  7.99381733e-02]]\n",
            "\n",
            " [[ 8.50932360e-01  1.29487038e-01]\n",
            "  [-8.50932360e-01 -1.29487038e-01]\n",
            "  [-8.60679388e-01 -5.50857544e-01]\n",
            "  [ 8.60679388e-01  5.50857544e-01]\n",
            "  [ 5.63525915e-01  2.21583366e-01]\n",
            "  [-5.63525915e-01 -2.21583366e-01]]\n",
            "\n",
            " [[ 8.95028114e-02  8.23574305e-01]\n",
            "  [-8.95028114e-02 -8.23574305e-01]\n",
            "  [ 9.55806017e-01  5.99893093e-01]\n",
            "  [-9.55806017e-01 -5.99893093e-01]\n",
            "  [ 3.93497944e-01  3.82671833e-01]\n",
            "  [-3.93497944e-01 -3.82671833e-01]]\n",
            "\n",
            " [[ 7.05026388e-01 -8.49509478e-01]\n",
            "  [-7.05026388e-01  8.49509478e-01]\n",
            "  [-5.48769236e-01  6.00323677e-02]\n",
            "  [ 5.48769236e-01 -6.00323677e-02]\n",
            "  [-3.50538492e-01 -5.68384409e-01]\n",
            "  [ 3.50538492e-01  5.68384409e-01]]\n",
            "\n",
            " [[ 3.63729715e-01  9.89772081e-01]\n",
            "  [-3.63729715e-01 -9.89772081e-01]\n",
            "  [-3.04816961e-01 -3.59296799e-01]\n",
            "  [ 3.04816961e-01  3.59296799e-01]\n",
            "  [-2.00777054e-01  9.06017780e-01]\n",
            "  [ 2.00777054e-01 -9.06017780e-01]]\n",
            "\n",
            " [[ 6.44776106e-01 -4.04955626e-01]\n",
            "  [-6.44776106e-01  4.04955626e-01]\n",
            "  [ 3.03554296e-01  6.96329117e-01]\n",
            "  [-3.03554296e-01 -6.96329117e-01]\n",
            "  [-4.63408470e-01 -3.92026901e-02]\n",
            "  [ 4.63408470e-01  3.92026901e-02]]\n",
            "\n",
            " [[-5.67984581e-03 -7.49002934e-01]\n",
            "  [ 5.67984581e-03  7.49002934e-01]\n",
            "  [-4.85863447e-01  3.76360416e-02]\n",
            "  [ 4.85863447e-01 -3.76360416e-02]\n",
            "  [-5.12557030e-01  8.98347378e-01]\n",
            "  [ 5.12557030e-01 -8.98347378e-01]]\n",
            "\n",
            " [[ 3.63813400e-01 -2.86762476e-01]\n",
            "  [-3.63813400e-01  2.86762476e-01]\n",
            "  [ 6.17790699e-01  4.22351360e-01]\n",
            "  [-6.17790699e-01 -4.22351360e-01]\n",
            "  [-1.85638666e-01 -1.81232452e-01]\n",
            "  [ 1.85638666e-01  1.81232452e-01]]\n",
            "\n",
            " [[-9.10950422e-01  4.62071419e-01]\n",
            "  [ 9.10950422e-01 -4.62071419e-01]\n",
            "  [ 5.93576908e-01 -5.97100973e-01]\n",
            "  [-5.93576908e-01  5.97100973e-01]\n",
            "  [ 1.78632736e-01  1.15361452e-01]\n",
            "  [-1.78632736e-01 -1.15361452e-01]]\n",
            "\n",
            " [[ 7.52227545e-01  2.07793951e-01]\n",
            "  [-7.52227545e-01 -2.07793951e-01]\n",
            "  [ 8.30527544e-01 -6.80910826e-01]\n",
            "  [-8.30527544e-01  6.80910826e-01]\n",
            "  [ 5.48313856e-01  2.19948292e-01]\n",
            "  [-5.48313856e-01 -2.19948292e-01]]\n",
            "\n",
            " [[ 9.94067430e-01  4.43608284e-01]\n",
            "  [-9.94067430e-01 -4.43608284e-01]\n",
            "  [-2.13360786e-01 -6.54762983e-01]\n",
            "  [ 2.13360786e-01  6.54762983e-01]\n",
            "  [ 5.17472982e-01  9.78635311e-01]\n",
            "  [-5.17472982e-01 -9.78635311e-01]]\n",
            "\n",
            " [[-2.86427498e-01 -6.90884590e-02]\n",
            "  [ 2.86427498e-01  6.90884590e-02]\n",
            "  [ 6.00720406e-01 -6.32485628e-01]\n",
            "  [-6.00720406e-01  6.32485628e-01]\n",
            "  [-3.61919403e-04 -3.23843956e-01]\n",
            "  [ 3.61919403e-04  3.23843956e-01]]\n",
            "\n",
            " [[-6.07792377e-01 -5.48769474e-01]\n",
            "  [ 6.07792377e-01  5.48769474e-01]\n",
            "  [ 9.05523300e-01  5.19401312e-01]\n",
            "  [-9.05523300e-01 -5.19401312e-01]\n",
            "  [-5.22277832e-01  1.55933619e-01]\n",
            "  [ 5.22277832e-01 -1.55933619e-01]]\n",
            "\n",
            " [[-6.52713776e-02  2.81698465e-01]\n",
            "  [ 6.52713776e-02 -2.81698465e-01]\n",
            "  [ 6.40456438e-01 -4.77051973e-01]\n",
            "  [-6.40456438e-01  4.77051973e-01]\n",
            "  [-5.21759033e-01 -3.65323782e-01]\n",
            "  [ 5.21759033e-01  3.65323782e-01]]\n",
            "\n",
            " [[-2.43664980e-01  3.30482960e-01]\n",
            "  [ 2.43664980e-01 -3.30482960e-01]\n",
            "  [-5.66182375e-01 -3.76793861e-01]\n",
            "  [ 5.66182375e-01  3.76793861e-01]\n",
            "  [-3.57477188e-01 -9.45563316e-01]\n",
            "  [ 3.57477188e-01  9.45563316e-01]]\n",
            "\n",
            " [[-2.10402012e-02  1.81074858e-01]\n",
            "  [ 2.10402012e-02 -1.81074858e-01]\n",
            "  [ 7.49731541e-01 -3.82757425e-01]\n",
            "  [-7.49731541e-01  3.82757425e-01]\n",
            "  [ 2.22125053e-02  5.89535236e-02]\n",
            "  [-2.22125053e-02 -5.89535236e-02]]\n",
            "\n",
            " [[ 7.98693657e-01 -8.73685122e-01]\n",
            "  [-7.98693657e-01  8.73685122e-01]\n",
            "  [ 7.22815275e-01 -1.59861565e-01]\n",
            "  [-7.22815275e-01  1.59861565e-01]\n",
            "  [ 6.49106264e-01  2.61621714e-01]\n",
            "  [-6.49106264e-01 -2.61621714e-01]]\n",
            "\n",
            " [[-5.17709970e-01  8.97311687e-01]\n",
            "  [ 5.17709970e-01 -8.97311687e-01]\n",
            "  [ 9.41356659e-01 -1.01578951e-01]\n",
            "  [-9.41356659e-01  1.01578951e-01]\n",
            "  [-6.87644243e-01 -5.89871883e-01]\n",
            "  [ 6.87644243e-01  5.89871883e-01]]\n",
            "\n",
            " [[-8.21730375e-01 -3.45780849e-02]\n",
            "  [ 8.21730375e-01  3.45780849e-02]\n",
            "  [-5.14966726e-01  1.49614811e-02]\n",
            "  [ 5.14966726e-01 -1.49614811e-02]\n",
            "  [ 7.31813669e-01  1.52625561e-01]\n",
            "  [-7.31813669e-01 -1.52625561e-01]]\n",
            "\n",
            " [[-2.55627871e-01 -8.65420341e-01]\n",
            "  [ 2.55627871e-01  8.65420341e-01]\n",
            "  [-9.77937698e-01  3.35700989e-01]\n",
            "  [ 9.77937698e-01 -3.35700989e-01]\n",
            "  [ 7.95960188e-01  1.32060051e-03]\n",
            "  [-7.95960188e-01 -1.32060051e-03]]\n",
            "\n",
            " [[-8.92039299e-01  5.85481167e-01]\n",
            "  [ 8.92039299e-01 -5.85481167e-01]\n",
            "  [ 8.22642088e-01  3.70753765e-01]\n",
            "  [-8.22642088e-01 -3.70753765e-01]\n",
            "  [ 9.79634523e-01  7.01937914e-01]\n",
            "  [-9.79634523e-01 -7.01937914e-01]]\n",
            "\n",
            " [[ 9.64687586e-01 -2.93425322e-01]\n",
            "  [-9.64687586e-01  2.93425322e-01]\n",
            "  [-2.02064514e-01 -9.37514305e-02]\n",
            "  [ 2.02064514e-01  9.37514305e-02]\n",
            "  [ 8.41936350e-01 -4.25225735e-01]\n",
            "  [-8.41936350e-01  4.25225735e-01]]\n",
            "\n",
            " [[-6.85295820e-01 -2.82243013e-01]\n",
            "  [ 6.85295820e-01  2.82243013e-01]\n",
            "  [-5.63011169e-02 -5.55768013e-01]\n",
            "  [ 5.63011169e-02  5.55768013e-01]\n",
            "  [ 4.56465960e-01 -2.66252279e-01]\n",
            "  [-4.56465960e-01  2.66252279e-01]]\n",
            "\n",
            " [[-7.17498302e-01 -3.57411146e-01]\n",
            "  [ 7.17498302e-01  3.57411146e-01]\n",
            "  [-3.42397451e-01 -2.02903748e-02]\n",
            "  [ 3.42397451e-01  2.02903748e-02]\n",
            "  [-2.76262522e-01  9.20486212e-01]\n",
            "  [ 2.76262522e-01 -9.20486212e-01]]\n",
            "\n",
            " [[-8.72671127e-01  7.50366688e-01]\n",
            "  [ 8.72671127e-01 -7.50366688e-01]\n",
            "  [ 7.51308441e-01 -5.84644556e-01]\n",
            "  [-7.51308441e-01  5.84644556e-01]\n",
            "  [ 1.17479801e-01 -9.71601725e-01]\n",
            "  [-1.17479801e-01  9.71601725e-01]]\n",
            "\n",
            " [[ 2.88371325e-01  6.17189407e-01]\n",
            "  [-2.88371325e-01 -6.17189407e-01]\n",
            "  [-1.47700548e-01  2.00492382e-01]\n",
            "  [ 1.47700548e-01 -2.00492382e-01]\n",
            "  [-5.82095623e-01  5.02048016e-01]\n",
            "  [ 5.82095623e-01 -5.02048016e-01]]\n",
            "\n",
            " [[ 5.11282444e-01 -9.05280113e-01]\n",
            "  [-5.11282444e-01  9.05280113e-01]\n",
            "  [ 5.50655603e-01  6.37252331e-02]\n",
            "  [-5.50655603e-01 -6.37252331e-02]\n",
            "  [-8.44222546e-01  7.96161652e-01]\n",
            "  [ 8.44222546e-01 -7.96161652e-01]]\n",
            "\n",
            " [[-1.42316103e-01  7.79326439e-01]\n",
            "  [ 1.42316103e-01 -7.79326439e-01]\n",
            "  [-4.57086802e-01  8.63270760e-02]\n",
            "  [ 4.57086802e-01 -8.63270760e-02]\n",
            "  [-7.22197771e-01 -5.86299181e-01]\n",
            "  [ 7.22197771e-01  5.86299181e-01]]\n",
            "\n",
            " [[ 1.38393402e-01 -7.23166227e-01]\n",
            "  [-1.38393402e-01  7.23166227e-01]\n",
            "  [-9.95438576e-01  8.89419794e-01]\n",
            "  [ 9.95438576e-01 -8.89419794e-01]\n",
            "  [ 7.19079494e-01 -8.29412937e-01]\n",
            "  [-7.19079494e-01  8.29412937e-01]]\n",
            "\n",
            " [[-8.30005884e-01  4.24580574e-02]\n",
            "  [ 8.30005884e-01 -4.24580574e-02]\n",
            "  [-4.75189924e-01  8.02793741e-01]\n",
            "  [ 4.75189924e-01 -8.02793741e-01]\n",
            "  [-6.16601706e-01 -6.69924259e-01]\n",
            "  [ 6.16601706e-01  6.69924259e-01]]\n",
            "\n",
            " [[-4.11233902e-01 -7.46757984e-02]\n",
            "  [ 4.11233902e-01  7.46757984e-02]\n",
            "  [ 5.62826157e-01  5.33990145e-01]\n",
            "  [-5.62826157e-01 -5.33990145e-01]\n",
            "  [ 1.63706541e-01  6.74824476e-01]\n",
            "  [-1.63706541e-01 -6.74824476e-01]]\n",
            "\n",
            " [[-9.82584953e-01  9.05474663e-01]\n",
            "  [ 9.82584953e-01 -9.05474663e-01]\n",
            "  [-9.81416702e-01  7.61710167e-01]\n",
            "  [ 9.81416702e-01 -7.61710167e-01]\n",
            "  [-9.40065861e-01  3.52140188e-01]\n",
            "  [ 9.40065861e-01 -3.52140188e-01]]\n",
            "\n",
            " [[ 8.18247557e-01 -4.87315893e-01]\n",
            "  [-8.18247557e-01  4.87315893e-01]\n",
            "  [-6.53309107e-01  3.85616064e-01]\n",
            "  [ 6.53309107e-01 -3.85616064e-01]\n",
            "  [-1.75313950e-01 -7.34956264e-02]\n",
            "  [ 1.75313950e-01  7.34956264e-02]]\n",
            "\n",
            " [[-7.99009323e-01  2.16119289e-02]\n",
            "  [ 7.99009323e-01 -2.16119289e-02]\n",
            "  [-9.47630167e-01 -2.56433487e-02]\n",
            "  [ 9.47630167e-01  2.56433487e-02]\n",
            "  [ 6.27051353e-01 -4.44907904e-01]\n",
            "  [-6.27051353e-01  4.44907904e-01]]\n",
            "\n",
            " [[ 3.26507092e-02 -5.21817446e-01]\n",
            "  [-3.26507092e-02  5.21817446e-01]\n",
            "  [ 4.83421087e-01 -5.65675497e-01]\n",
            "  [-4.83421087e-01  5.65675497e-01]\n",
            "  [-5.13957262e-01 -2.48373032e-01]\n",
            "  [ 5.13957262e-01  2.48373032e-01]]\n",
            "\n",
            " [[ 2.73794889e-01 -7.34105825e-01]\n",
            "  [-2.73794889e-01  7.34105825e-01]\n",
            "  [-8.89118433e-01 -6.03988647e-01]\n",
            "  [ 8.89118433e-01  6.03988647e-01]\n",
            "  [ 2.67193317e-02 -4.55768347e-01]\n",
            "  [-2.67193317e-02  4.55768347e-01]]\n",
            "\n",
            " [[-5.19580841e-01  8.66962433e-01]\n",
            "  [ 5.19580841e-01 -8.66962433e-01]\n",
            "  [-3.83954048e-01  9.89441872e-01]\n",
            "  [ 3.83954048e-01 -9.89441872e-01]\n",
            "  [-5.19524336e-01 -3.38948250e-01]\n",
            "  [ 5.19524336e-01  3.38948250e-01]]\n",
            "\n",
            " [[ 5.86494207e-01 -6.48840666e-01]\n",
            "  [-5.86494207e-01  6.48840666e-01]\n",
            "  [-8.36607933e-01  6.43578053e-01]\n",
            "  [ 8.36607933e-01 -6.43578053e-01]\n",
            "  [-3.28426123e-01 -9.75403070e-01]\n",
            "  [ 3.28426123e-01  9.75403070e-01]]\n",
            "\n",
            " [[-2.66676188e-01  6.95046186e-01]\n",
            "  [ 2.66676188e-01 -6.95046186e-01]\n",
            "  [-3.11365604e-01  9.04807091e-01]\n",
            "  [ 3.11365604e-01 -9.04807091e-01]\n",
            "  [ 5.60424328e-01 -8.43322515e-01]\n",
            "  [-5.60424328e-01  8.43322515e-01]]\n",
            "\n",
            " [[ 5.08939743e-01  8.36646557e-01]\n",
            "  [-5.08939743e-01 -8.36646557e-01]\n",
            "  [-3.31465244e-01  9.24513578e-01]\n",
            "  [ 3.31465244e-01 -9.24513578e-01]\n",
            "  [-8.66098404e-02  8.42069149e-01]\n",
            "  [ 8.66098404e-02 -8.42069149e-01]]\n",
            "\n",
            " [[ 3.04317474e-03  8.77423286e-01]\n",
            "  [-3.04317474e-03 -8.77423286e-01]\n",
            "  [-1.57751083e-01  2.44865179e-01]\n",
            "  [ 1.57751083e-01 -2.44865179e-01]\n",
            "  [ 3.23755026e-01 -8.43495607e-01]\n",
            "  [-3.23755026e-01  8.43495607e-01]]\n",
            "\n",
            " [[-7.62946844e-01 -6.80011034e-01]\n",
            "  [ 7.62946844e-01  6.80011034e-01]\n",
            "  [ 4.72505569e-01  6.13814592e-01]\n",
            "  [-4.72505569e-01 -6.13814592e-01]\n",
            "  [ 4.43793297e-01  2.47590542e-01]\n",
            "  [-4.43793297e-01 -2.47590542e-01]]\n",
            "\n",
            " [[ 3.78397703e-01  3.82247448e-01]\n",
            "  [-3.78397703e-01 -3.82247448e-01]\n",
            "  [-4.94255781e-01  4.44800854e-02]\n",
            "  [ 4.94255781e-01 -4.44800854e-02]\n",
            "  [ 1.18639946e-01  7.42498875e-01]\n",
            "  [-1.18639946e-01 -7.42498875e-01]]\n",
            "\n",
            " [[ 8.03994656e-01 -8.27221394e-01]\n",
            "  [-8.03994656e-01  8.27221394e-01]\n",
            "  [ 6.41901016e-01 -7.35810757e-01]\n",
            "  [-6.41901016e-01  7.35810757e-01]\n",
            "  [-7.11143017e-02 -2.61831284e-03]\n",
            "  [ 7.11143017e-02  2.61831284e-03]]\n",
            "\n",
            " [[-1.73697233e-01  6.83698893e-01]\n",
            "  [ 1.73697233e-01 -6.83698893e-01]\n",
            "  [ 6.35416269e-01  4.83457088e-01]\n",
            "  [-6.35416269e-01 -4.83457088e-01]\n",
            "  [ 4.72881317e-01 -9.61666584e-01]\n",
            "  [-4.72881317e-01  9.61666584e-01]]\n",
            "\n",
            " [[-4.25182581e-01 -5.38778305e-01]\n",
            "  [ 4.25182581e-01  5.38778305e-01]\n",
            "  [ 8.24407101e-01  7.53695726e-01]\n",
            "  [-8.24407101e-01 -7.53695726e-01]\n",
            "  [ 1.08757257e-01 -9.02537823e-01]\n",
            "  [-1.08757257e-01  9.02537823e-01]]\n",
            "\n",
            " [[ 1.51038885e-01 -5.23583412e-01]\n",
            "  [-1.51038885e-01  5.23583412e-01]\n",
            "  [-1.01420641e-01  4.50458050e-01]\n",
            "  [ 1.01420641e-01 -4.50458050e-01]\n",
            "  [ 7.19800472e-01  4.01664019e-01]\n",
            "  [-7.19800472e-01 -4.01664019e-01]]\n",
            "\n",
            " [[ 9.12652016e-01 -2.41227150e-02]\n",
            "  [-9.12652016e-01  2.41227150e-02]\n",
            "  [-6.01574898e-01  3.32698345e-01]\n",
            "  [ 6.01574898e-01 -3.32698345e-01]\n",
            "  [ 2.66223431e-01 -6.93941355e-01]\n",
            "  [-2.66223431e-01  6.93941355e-01]]\n",
            "\n",
            " [[ 6.84682131e-01  7.29529619e-01]\n",
            "  [-6.84682131e-01 -7.29529619e-01]\n",
            "  [-3.70643616e-01  4.46613789e-01]\n",
            "  [ 3.70643616e-01 -4.46613789e-01]\n",
            "  [-5.56232929e-02 -4.69826460e-01]\n",
            "  [ 5.56232929e-02  4.69826460e-01]]\n",
            "\n",
            " [[-2.42791653e-01 -5.37516594e-01]\n",
            "  [ 2.42791653e-01  5.37516594e-01]\n",
            "  [ 1.76487207e-01 -1.74028873e-01]\n",
            "  [-1.76487207e-01  1.74028873e-01]\n",
            "  [-9.37187433e-01 -8.95797491e-01]\n",
            "  [ 9.37187433e-01  8.95797491e-01]]\n",
            "\n",
            " [[-2.39450216e-01  4.73863840e-01]\n",
            "  [ 2.39450216e-01 -4.73863840e-01]\n",
            "  [-9.24904346e-02 -1.50996447e-01]\n",
            "  [ 9.24904346e-02  1.50996447e-01]\n",
            "  [ 1.36408806e-01 -4.51634169e-01]\n",
            "  [-1.36408806e-01  4.51634169e-01]]\n",
            "\n",
            " [[-3.87201548e-01 -4.88883257e-01]\n",
            "  [ 3.87201548e-01  4.88883257e-01]\n",
            "  [-3.37140560e-01 -8.37893486e-01]\n",
            "  [ 3.37140560e-01  8.37893486e-01]\n",
            "  [ 9.43853855e-01 -9.08797264e-01]\n",
            "  [-9.43853855e-01  9.08797264e-01]]\n",
            "\n",
            " [[-7.95145512e-01  9.00786877e-01]\n",
            "  [ 7.95145512e-01 -9.00786877e-01]\n",
            "  [-1.01370811e-01 -8.81865978e-01]\n",
            "  [ 1.01370811e-01  8.81865978e-01]\n",
            "  [ 4.69955206e-01 -2.48489618e-01]\n",
            "  [-4.69955206e-01  2.48489618e-01]]\n",
            "\n",
            " [[ 5.52799940e-01 -7.10137367e-01]\n",
            "  [-5.52799940e-01  7.10137367e-01]\n",
            "  [-3.05563688e-01  3.98296356e-01]\n",
            "  [ 3.05563688e-01 -3.98296356e-01]\n",
            "  [ 5.82775354e-01  7.21510887e-01]\n",
            "  [-5.82775354e-01 -7.21510887e-01]]\n",
            "\n",
            " [[-8.91733170e-02 -5.39743423e-01]\n",
            "  [ 8.91733170e-02  5.39743423e-01]\n",
            "  [ 8.01956892e-01 -9.36002970e-01]\n",
            "  [-8.01956892e-01  9.36002970e-01]\n",
            "  [ 7.03355789e-01  5.27866125e-01]\n",
            "  [-7.03355789e-01 -5.27866125e-01]]\n",
            "\n",
            " [[ 7.77864933e-01  4.70807791e-01]\n",
            "  [-7.77864933e-01 -4.70807791e-01]\n",
            "  [ 9.01029587e-01  8.50266933e-01]\n",
            "  [-9.01029587e-01 -8.50266933e-01]\n",
            "  [-9.85827208e-01 -5.66329241e-01]\n",
            "  [ 9.85827208e-01  5.66329241e-01]]\n",
            "\n",
            " [[-6.75363779e-01 -3.84627342e-01]\n",
            "  [ 6.75363779e-01  3.84627342e-01]\n",
            "  [ 9.42652225e-02  8.88281822e-01]\n",
            "  [-9.42652225e-02 -8.88281822e-01]\n",
            "  [-4.94404793e-01  9.12058830e-01]\n",
            "  [ 4.94404793e-01 -9.12058830e-01]]]\n",
            "\n",
            "Primaries After NECL:\n",
            " [[[ 3.82192731e-02  1.93035901e-01]\n",
            "  [-3.82192731e-02 -1.93035901e-01]\n",
            "  [-1.44272717e-02  2.64830999e-02]\n",
            "  [ 1.44272717e-02 -2.64830999e-02]\n",
            "  [ 1.98918760e-01  4.36430611e-02]\n",
            "  [ 1.98918760e-01  4.36430611e-02]]\n",
            "\n",
            " [[-1.30111143e-01  1.31887510e-01]\n",
            "  [ 1.30111143e-01 -1.31887510e-01]\n",
            "  [-5.18599898e-02 -6.46883547e-02]\n",
            "  [ 5.18599898e-02  6.46883547e-02]\n",
            "  [ 1.90905984e-02  1.34872019e-01]\n",
            "  [ 1.90905984e-02  1.34872019e-01]]\n",
            "\n",
            " [[ 1.68808967e-01 -2.88275387e-02]\n",
            "  [-1.68808967e-01  2.88275387e-02]\n",
            "  [-1.55089363e-01  5.05356304e-02]\n",
            "  [ 1.55089363e-01 -5.05356304e-02]\n",
            "  [-1.68602705e-01  4.40133363e-02]\n",
            "  [-1.68602705e-01  4.40133363e-02]]\n",
            "\n",
            " [[-9.97756869e-02 -9.23964754e-02]\n",
            "  [ 9.97756869e-02  9.23964754e-02]\n",
            "  [ 1.46965668e-01 -9.13107991e-02]\n",
            "  [-1.46965668e-01  9.13107991e-02]\n",
            "  [ 8.73414055e-02  9.83300358e-02]\n",
            "  [ 8.73414055e-02  9.83300358e-02]]\n",
            "\n",
            " [[ 1.71837121e-01 -9.44209024e-02]\n",
            "  [-1.71837121e-01  9.44209024e-02]\n",
            "  [-1.72094360e-01  1.71863139e-02]\n",
            "  [ 1.72094360e-01 -1.71863139e-02]\n",
            "  [ 8.98933485e-02 -6.90618902e-02]\n",
            "  [ 8.98933485e-02 -6.90618902e-02]]\n",
            "\n",
            " [[-1.25950515e-01 -1.03170633e-01]\n",
            "  [ 1.25950515e-01  1.03170633e-01]\n",
            "  [-9.72812250e-02  1.03999473e-01]\n",
            "  [ 9.72812250e-02 -1.03999473e-01]\n",
            "  [ 1.52059525e-01 -2.17756797e-02]\n",
            "  [ 1.52059525e-01 -2.17756797e-02]]\n",
            "\n",
            " [[-1.86650753e-01 -2.91761514e-02]\n",
            "  [ 1.86650753e-01  2.91761514e-02]\n",
            "  [ 3.16865295e-02  1.11680478e-01]\n",
            "  [-3.16865295e-02 -1.11680478e-01]\n",
            "  [ 1.35984808e-01  7.44470805e-02]\n",
            "  [ 1.35984808e-01  7.44470805e-02]]\n",
            "\n",
            " [[-1.37174964e-01  1.68456778e-01]\n",
            "  [ 1.37174964e-01 -1.68456778e-01]\n",
            "  [ 3.74270603e-02  7.98718333e-02]\n",
            "  [-3.74270603e-02 -7.98718333e-02]\n",
            "  [ 1.28793210e-01 -1.38294790e-02]\n",
            "  [ 1.28793210e-01 -1.38294790e-02]]\n",
            "\n",
            " [[ 1.79240689e-01  1.92864742e-02]\n",
            "  [-1.79240689e-01 -1.92864742e-02]\n",
            "  [ 1.81261495e-01  8.20329636e-02]\n",
            "  [-1.81261495e-01 -8.20329636e-02]\n",
            "  [ 1.18765846e-01  3.30217257e-02]\n",
            "  [ 1.18765846e-01  3.30217257e-02]]\n",
            "\n",
            " [[ 1.87302232e-02  1.21869236e-01]\n",
            "  [-1.87302232e-02 -1.21869236e-01]\n",
            "  [-1.99839368e-01 -8.86890814e-02]\n",
            "  [ 1.99839368e-01  8.86890814e-02]\n",
            "  [ 8.23655054e-02  5.66388406e-02]\n",
            "  [ 8.23655054e-02  5.66388406e-02]]\n",
            "\n",
            " [[ 1.58965603e-01 -1.35441259e-01]\n",
            "  [-1.58965603e-01  1.35441259e-01]\n",
            "  [ 1.23833500e-01 -9.57897119e-03]\n",
            "  [-1.23833500e-01  9.57897119e-03]\n",
            "  [-7.91042969e-02 -9.06966999e-02]\n",
            "  [-7.91042969e-02 -9.06966999e-02]]\n",
            "\n",
            " [[ 7.77007863e-02  1.49508819e-01]\n",
            "  [-7.77007863e-02 -1.49508819e-01]\n",
            "  [ 6.51676729e-02  5.43164536e-02]\n",
            "  [-6.51676729e-02 -5.43164536e-02]\n",
            "  [-4.29007001e-02  1.36890098e-01]\n",
            "  [-4.29007001e-02  1.36890098e-01]]\n",
            "\n",
            " [[ 1.70137867e-01 -7.55586997e-02]\n",
            "  [-1.70137867e-01  7.55586997e-02]\n",
            "  [-8.01248327e-02 -1.29966155e-01]\n",
            "  [ 8.01248327e-02  1.29966155e-01]\n",
            "  [-1.22354351e-01 -7.31907645e-03]\n",
            "  [-1.22354351e-01 -7.31907645e-03]]\n",
            "\n",
            " [[-1.31172780e-03 -1.22313850e-01]\n",
            "  [ 1.31172780e-03  1.22313850e-01]\n",
            "  [ 1.12218007e-01 -6.14663307e-03]\n",
            "  [-1.12218007e-01  6.14663307e-03]\n",
            "  [-1.18297547e-01  1.46609753e-01]\n",
            "  [-1.18297547e-01  1.46609753e-01]]\n",
            "\n",
            " [[ 1.29657909e-01 -7.22649395e-02]\n",
            "  [-1.29657909e-01  7.22649395e-02]\n",
            "  [-2.19970450e-01 -1.06336385e-01]\n",
            "  [ 2.19970450e-01  1.06336385e-01]\n",
            "  [-6.62018731e-02 -4.57006991e-02]\n",
            "  [-6.62018731e-02 -4.57006991e-02]]\n",
            "\n",
            " [[-2.29831815e-01  8.24345872e-02]\n",
            "  [ 2.29831815e-01 -8.24345872e-02]\n",
            "  [-1.49844974e-01  1.06585458e-01]\n",
            "  [ 1.49844974e-01 -1.06585458e-01]\n",
            "  [ 4.51525375e-02  2.06189640e-02]\n",
            "  [ 4.51525375e-02  2.06189640e-02]]\n",
            "\n",
            " [[ 1.61258206e-01  3.14985439e-02]\n",
            "  [-1.61258206e-01 -3.14985439e-02]\n",
            "  [-1.77973375e-01  1.03175424e-01]\n",
            "  [ 1.77973375e-01 -1.03175424e-01]\n",
            "  [ 1.17591523e-01  3.33543420e-02]\n",
            "  [ 1.17591523e-01  3.33543420e-02]]\n",
            "\n",
            " [[ 1.80617854e-01  5.69940470e-02]\n",
            "  [-1.80617854e-01 -5.69940470e-02]\n",
            "  [ 3.88025194e-02  8.42004642e-02]\n",
            "  [-3.88025194e-02 -8.42004642e-02]\n",
            "  [ 9.40516815e-02  1.25772223e-01]\n",
            "  [ 9.40516815e-02  1.25772223e-01]]\n",
            "\n",
            " [[-1.00771137e-01 -1.71874706e-02]\n",
            "  [ 1.00771137e-01  1.71874706e-02]\n",
            "  [-2.11021796e-01  1.57105207e-01]\n",
            "  [ 2.11021796e-01 -1.57105207e-01]\n",
            "  [-1.27357023e-04 -8.05808529e-02]\n",
            "  [-1.27357023e-04 -8.05808529e-02]]\n",
            "\n",
            " [[-1.32323101e-01 -8.44802856e-02]\n",
            "  [ 1.32323101e-01  8.44802856e-02]\n",
            "  [-1.97037801e-01 -7.99167678e-02]\n",
            "  [ 1.97037801e-01  7.99167678e-02]\n",
            "  [-1.13749832e-01  2.40145195e-02]\n",
            "  [-1.13749832e-01  2.40145195e-02]]\n",
            "\n",
            " [[-1.98565479e-02  6.05969056e-02]\n",
            "  [ 1.98565479e-02 -6.05969056e-02]\n",
            "  [-1.94546744e-01  1.02467246e-01]\n",
            "  [ 1.94546744e-01 -1.02467246e-01]\n",
            "  [-1.58555880e-01 -7.85010308e-02]\n",
            "  [-1.58555880e-01 -7.85010308e-02]]\n",
            "\n",
            " [[-6.08215779e-02  5.83308935e-02]\n",
            "  [ 6.08215779e-02 -5.83308935e-02]\n",
            "  [ 1.41228899e-01  6.64593503e-02]\n",
            "  [-1.41228899e-01 -6.64593503e-02]\n",
            "  [-8.91412944e-02 -1.66727111e-01]\n",
            "  [-8.91412944e-02 -1.66727111e-01]]\n",
            "\n",
            " [[-1.01552298e-02  6.17992282e-02]\n",
            "  [ 1.01552298e-02 -6.17992282e-02]\n",
            "  [-3.60757589e-01  1.30232185e-01]\n",
            "  [ 3.60757589e-01 -1.30232185e-01]\n",
            "  [ 1.07251210e-02  2.01279446e-02]\n",
            "  [ 1.07251210e-02  2.01279446e-02]]\n",
            "\n",
            " [[ 1.59500778e-01 -1.23373665e-01]\n",
            "  [-1.59500778e-01  1.23373665e-01]\n",
            "  [-1.44424096e-01  2.25861073e-02]\n",
            "  [ 1.44424096e-01 -2.25861073e-02]\n",
            "  [ 1.29710451e-01  3.69673222e-02]\n",
            "  [ 1.29710451e-01  3.69673222e-02]]\n",
            "\n",
            " [[-9.39550623e-02  1.15149483e-01]\n",
            "  [ 9.39550623e-02 -1.15149483e-01]\n",
            "  [-1.70802370e-01  1.30325211e-02]\n",
            "  [ 1.70802370e-01 -1.30325211e-02]\n",
            "  [-1.24798253e-01 -7.56985173e-02]\n",
            "  [-1.24798253e-01 -7.56985173e-02]]\n",
            "\n",
            " [[-2.06483439e-01 -6.14386704e-03]\n",
            "  [ 2.06483439e-01  6.14386704e-03]\n",
            "  [ 1.29495367e-01 -2.66032480e-03]\n",
            "  [-1.29495367e-01  2.66032480e-03]\n",
            "  [ 1.83925539e-01  2.71240026e-02]\n",
            "  [ 1.83925539e-01  2.71240026e-02]]\n",
            "\n",
            " [[-4.90583070e-02 -1.17440112e-01]\n",
            "  [ 4.90583070e-02  1.17440112e-01]\n",
            "  [ 1.87561318e-01 -4.55270708e-02]\n",
            "  [ 0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            " [[-1.47297561e-01  6.83611706e-02]\n",
            "  [ 1.47297561e-01 -6.83611706e-02]\n",
            "  [-1.35864019e-01 -4.32976335e-02]\n",
            "  [ 1.35864019e-01  4.32976335e-02]\n",
            "  [ 1.61732495e-01  8.19439515e-02]\n",
            "  [ 1.61732495e-01  8.19439515e-02]]\n",
            "\n",
            " [[ 2.32402667e-01 -4.99846898e-02]\n",
            "  [-2.32402667e-01  4.99846898e-02]\n",
            "  [ 4.87659313e-02  1.59988720e-02]\n",
            "  [-4.87659313e-02 -1.59988720e-02]\n",
            "  [ 2.02873856e-01 -7.24521726e-02]\n",
            "  [ 2.02873856e-01 -7.24521726e-02]]\n",
            "\n",
            " [[-1.96411714e-01 -5.72001934e-02]\n",
            "  [ 1.96411714e-01  5.72001934e-02]\n",
            "  [ 1.61503498e-02  1.12731040e-01]\n",
            "  [-1.61503498e-02 -1.12731040e-01]\n",
            "  [ 1.30905703e-01 -5.39918803e-02]\n",
            "  [ 1.30905703e-01 -5.39918803e-02]]\n",
            "\n",
            " [[-1.78571716e-01 -6.28991649e-02]\n",
            "  [ 1.78571716e-01  6.28991649e-02]\n",
            "  [ 8.53007436e-02  3.57435248e-03]\n",
            "  [-8.53007436e-02 -3.57435248e-03]\n",
            "  [-6.87652379e-02  1.62012771e-01]\n",
            "  [-6.87652379e-02  1.62012771e-01]]\n",
            "\n",
            " [[-1.48428649e-01  9.02455151e-02]\n",
            "  [ 1.48428649e-01 -9.02455151e-02]\n",
            "  [-1.27820522e-01  7.03330189e-02]\n",
            "  [ 1.27820522e-01 -7.03330189e-02]\n",
            "  [ 1.99921019e-02 -1.16914548e-01]\n",
            "  [ 1.99921019e-02 -1.16914548e-01]]\n",
            "\n",
            " [[ 8.89738798e-02  1.34652346e-01]\n",
            "  [-8.89738798e-02 -1.34652346e-01]\n",
            "  [ 4.56140935e-02 -4.37824205e-02]\n",
            "  [-4.56140935e-02  4.37824205e-02]\n",
            "  [-1.79515630e-01  1.09480873e-01]\n",
            "  [-1.79515630e-01  1.09480873e-01]]\n",
            "\n",
            " [[ 9.73064601e-02 -1.21828459e-01]\n",
            "  [-9.73064601e-02  1.21828459e-01]\n",
            "  [-1.04850583e-01 -8.57999828e-03]\n",
            "  [ 1.04850583e-01  8.57999828e-03]\n",
            "  [-1.60614163e-01  1.07105836e-01]\n",
            "  [-1.60614163e-01  1.07105836e-01]]\n",
            "\n",
            " [[-3.41098346e-02  1.32077858e-01]\n",
            "  [ 3.41098346e-02 -1.32077858e-01]\n",
            "  [ 1.09580003e-01 -1.46340542e-02]\n",
            "  [-1.09580003e-01  1.46340542e-02]\n",
            "  [-1.72989801e-01 -9.93044302e-02]\n",
            "  [-1.72989801e-01 -9.93044302e-02]]\n",
            "\n",
            " [[ 2.29087174e-02 -8.46464112e-02]\n",
            "  [-2.29087174e-02  8.46464112e-02]\n",
            "  [ 1.64610162e-01 -1.04000144e-01]\n",
            "  [-1.64610162e-01  1.04000144e-01]\n",
            "  [ 1.18956938e-01 -9.70216468e-02]\n",
            "  [ 1.18956938e-01 -9.70216468e-02]]\n",
            "\n",
            " [[-1.62677824e-01  5.88426553e-03]\n",
            "  [ 1.62677824e-01 -5.88426553e-03]\n",
            "  [ 9.31510031e-02 -1.11278005e-01]\n",
            "  [-9.31510031e-02  1.11278005e-01]\n",
            "  [-1.20863415e-01 -9.28540379e-02]\n",
            "  [-1.20863415e-01 -9.28540379e-02]]\n",
            "\n",
            " [[-1.14215657e-01 -1.46656595e-02]\n",
            "  [ 1.14215657e-01  1.46656595e-02]\n",
            "  [-1.56210005e-01 -1.04797952e-01]\n",
            "  [ 1.56210005e-01  1.04797952e-01]\n",
            "  [ 4.54568714e-02  1.32497981e-01]\n",
            "  [ 4.54568714e-02  1.32497981e-01]]\n",
            "\n",
            " [[-1.43763989e-01  9.36787948e-02]\n",
            "  [ 1.43763989e-01 -9.36787948e-02]\n",
            "  [ 1.43603712e-01 -7.88110271e-02]\n",
            "  [-1.43603712e-01  7.88110271e-02]\n",
            "  [-1.37581348e-01  3.64419669e-02]\n",
            "  [-1.37581348e-01  3.64419669e-02]]\n",
            "\n",
            " [[ 2.25438550e-01 -9.49377716e-02]\n",
            "  [-2.25438550e-01  9.49377716e-02]\n",
            "  [ 1.80080727e-01 -7.51603246e-02]\n",
            "  [-1.80080727e-01  7.51603246e-02]\n",
            "  [-4.83909473e-02 -1.43447872e-02]\n",
            "  [-4.83909473e-02 -1.43447872e-02]]\n",
            "\n",
            " [[-1.66451752e-01  3.18357442e-03]\n",
            "  [ 1.66451752e-01 -3.18357442e-03]\n",
            "  [ 1.97354630e-01  3.77631490e-03]\n",
            "  [-1.97354630e-01 -3.77631490e-03]\n",
            "  [ 1.30654320e-01 -6.55504689e-02]\n",
            "  [ 1.30654320e-01 -6.55504689e-02]]\n",
            "\n",
            " [[ 9.31804534e-03 -1.05301805e-01]\n",
            "  [-9.31804534e-03  1.05301805e-01]\n",
            "  [-1.37865156e-01  1.14072591e-01]\n",
            "  [ 1.37865156e-01 -1.14072591e-01]\n",
            "  [-1.46607250e-01 -5.00977039e-02]\n",
            "  [-1.46607250e-01 -5.00977039e-02]]\n",
            "\n",
            " [[ 6.20153099e-02 -1.17575608e-01]\n",
            "  [-6.20153099e-02  1.17575608e-01]\n",
            "  [ 2.01214388e-01  9.66525301e-02]\n",
            "  [-2.01214388e-01 -9.66525301e-02]\n",
            "  [ 6.05544494e-03 -7.30381310e-02]\n",
            "  [ 6.05544494e-03 -7.30381310e-02]]\n",
            "\n",
            " [[-1.01164564e-01  1.19360484e-01]\n",
            "  [ 1.01164564e-01 -1.19360484e-01]\n",
            "  [ 7.47582242e-02 -1.36224449e-01]\n",
            "  [-7.47582242e-02  1.36224449e-01]\n",
            "  [-1.01197004e-01 -4.66853008e-02]\n",
            "  [-1.01197004e-01 -4.66853008e-02]]\n",
            "\n",
            " [[ 1.03915609e-01 -8.12905729e-02]\n",
            "  [-1.03915609e-01  8.12905729e-02]\n",
            "  [ 1.48179084e-01 -8.06029812e-02]\n",
            "  [-1.48179084e-01  8.06029812e-02]\n",
            "  [-5.81889711e-02 -1.22200251e-01]\n",
            "  [-5.81889711e-02 -1.22200251e-01]]\n",
            "\n",
            " [[-5.15352525e-02  9.49770734e-02]\n",
            "  [ 5.15352525e-02 -9.49770734e-02]\n",
            "  [ 6.01546206e-02 -1.23605944e-01]\n",
            "  [-6.01546206e-02  1.23605944e-01]\n",
            "  [ 1.08250529e-01 -1.15183890e-01]\n",
            "  [ 1.08250529e-01 -1.15183890e-01]]\n",
            "\n",
            " [[ 9.50245336e-02  1.10457800e-01]\n",
            "  [-9.50245336e-02 -1.10457800e-01]\n",
            "  [ 6.18933551e-02 -1.22068696e-01]\n",
            "  [-6.18933551e-02  1.22068696e-01]\n",
            "  [-1.61761288e-02  1.11209050e-01]\n",
            "  [-1.61761288e-02  1.11209050e-01]]\n",
            "\n",
            " [[ 7.69846200e-04  1.56953588e-01]\n",
            "  [-7.69846200e-04 -1.56953588e-01]\n",
            "  [ 3.99442017e-02 -4.38423045e-02]\n",
            "  [-3.99442017e-02  4.38423045e-02]\n",
            "  [ 8.18903446e-02 -1.50863439e-01]\n",
            "  [ 8.18903446e-02 -1.50863439e-01]]\n",
            "\n",
            " [[-1.73447922e-01 -1.09314010e-01]\n",
            "  [ 1.73447922e-01  1.09314010e-01]\n",
            "  [-1.07479729e-01 -9.87283364e-02]\n",
            "  [ 1.07479729e-01  9.87283364e-02]\n",
            "  [ 1.00984603e-01  3.98376286e-02]\n",
            "  [ 1.00984603e-01  3.98376286e-02]]\n",
            "\n",
            " [[ 1.11084312e-01  7.93476105e-02]\n",
            "  [-1.11084312e-01 -7.93476105e-02]\n",
            "  [ 1.45083889e-01 -9.23247356e-03]\n",
            "  [-1.45083889e-01  9.23247356e-03]\n",
            "  [ 3.48213948e-02  1.54097646e-01]\n",
            "  [ 3.48213948e-02  1.54097646e-01]]\n",
            "\n",
            " [[ 1.91327915e-01 -1.39197662e-01]\n",
            "  [-1.91327915e-01  1.39197662e-01]\n",
            "  [-1.52812392e-01  1.23863012e-01]\n",
            "  [ 1.52812392e-01 -1.23863012e-01]\n",
            "  [-1.69586651e-02 -4.41510696e-04]\n",
            "  [-1.69586651e-02 -4.41510696e-04]]\n",
            "\n",
            " [[-3.53720039e-02  9.84502137e-02]\n",
            "  [ 3.53720039e-02 -9.84502137e-02]\n",
            "  [-1.29345134e-01 -6.95880502e-02]\n",
            "  [ 1.29345134e-01  6.95880502e-02]\n",
            "  [ 9.62396562e-02 -1.38392136e-01]\n",
            "  [ 9.62396562e-02 -1.38392136e-01]]\n",
            "\n",
            " [[-8.22094902e-02 -7.36616701e-02]\n",
            "  [ 8.22094902e-02  7.36616701e-02]\n",
            "  [-1.59279466e-01 -1.02967247e-01]\n",
            "  [ 1.59279466e-01  1.02967247e-01]\n",
            "  [ 2.10253634e-02 -1.23377420e-01]\n",
            "  [ 2.10253634e-02 -1.23377420e-01]]\n",
            "\n",
            " [[ 4.32610214e-02 -1.06042229e-01]\n",
            "  [-4.32610214e-02  1.06042229e-01]\n",
            "  [ 2.90544052e-02 -9.12483484e-02]\n",
            "  [-2.90544052e-02  9.12483484e-02]\n",
            "  [ 2.05957353e-01  8.12667981e-02]\n",
            "  [ 2.05957353e-01  8.12667981e-02]]\n",
            "\n",
            " [[ 2.04043478e-01 -3.81354312e-03]\n",
            "  [-2.04043478e-01  3.81354312e-03]\n",
            "  [ 1.34571776e-01 -5.26259542e-02]\n",
            "  [-1.34571776e-01  5.26259542e-02]\n",
            "  [ 5.95650785e-02 -1.09787583e-01]\n",
            "  [ 5.95650785e-02 -1.09787583e-01]]\n",
            "\n",
            " [[ 1.74640417e-01  1.31578118e-01]\n",
            "  [-1.74640417e-01 -1.31578118e-01]\n",
            "  [ 9.46244076e-02 -8.06238949e-02]\n",
            "  [-9.46244076e-02  8.06238949e-02]\n",
            "  [-1.42056756e-02 -8.48452821e-02]\n",
            "  [-1.42056756e-02 -8.48452821e-02]]\n",
            "\n",
            " [[-5.96646592e-02 -9.34028924e-02]\n",
            "  [ 5.96646592e-02  9.34028924e-02]\n",
            "  [-4.33946736e-02  3.02572567e-02]\n",
            "  [ 4.33946736e-02 -3.02572567e-02]\n",
            "  [-2.29942411e-01 -1.55413046e-01]\n",
            "  [-2.29942411e-01 -1.55413046e-01]]\n",
            "\n",
            " [[-1.06368922e-01  1.48846313e-01]\n",
            "  [ 1.06368922e-01 -1.48846313e-01]\n",
            "  [ 4.11333181e-02  4.74841446e-02]\n",
            "  [-4.11333181e-02 -4.74841446e-02]\n",
            "  [ 6.06122687e-02 -1.41902462e-01]\n",
            "  [ 6.06122687e-02 -1.41902462e-01]]\n",
            "\n",
            " [[-7.15859607e-02 -6.39117882e-02]\n",
            "  [ 7.15859607e-02  6.39117882e-02]\n",
            "  [ 6.23128302e-02  1.09506600e-01]\n",
            "  [-6.23128302e-02 -1.09506600e-01]\n",
            "  [ 1.74308926e-01 -1.18677087e-01]\n",
            "  [ 1.74308926e-01 -1.18677087e-01]]\n",
            "\n",
            " [[-1.58974379e-01  1.27346665e-01]\n",
            "  [ 1.58974379e-01 -1.27346665e-01]\n",
            "  [ 2.02821307e-02  1.24763697e-01]\n",
            "  [-2.02821307e-02 -1.24763697e-01]\n",
            "  [ 9.40512866e-02 -3.51642631e-02]\n",
            "  [ 9.40512866e-02 -3.51642631e-02]]\n",
            "\n",
            " [[ 1.24389917e-01 -1.12991177e-01]\n",
            "  [-1.24389917e-01  1.12991177e-01]\n",
            "  [ 6.88061640e-02 -6.34186491e-02]\n",
            "  [-6.88061640e-02  6.34186491e-02]\n",
            "  [ 1.31127134e-01  1.14794031e-01]\n",
            "  [ 1.31127134e-01  1.14794031e-01]]\n",
            "\n",
            " [[-1.75933968e-02 -7.52986372e-02]\n",
            "  [ 1.75933968e-02  7.52986372e-02]\n",
            "  [-1.58029199e-01  1.30421311e-01]\n",
            "  [ 1.58029199e-01 -1.30421311e-01]\n",
            "  [ 1.38662815e-01  7.35857487e-02]\n",
            "  [ 1.38662815e-01  7.35857487e-02]]\n",
            "\n",
            " [[ 1.24154843e-01  5.31359054e-02]\n",
            "  [-1.24154843e-01 -5.31359054e-02]\n",
            "  [-1.43761322e-01 -9.59275290e-02]\n",
            "  [ 1.43761322e-01  9.59275290e-02]\n",
            "  [-1.57295540e-01 -6.38953969e-02]\n",
            "  [-1.57295540e-01 -6.38953969e-02]]\n",
            "\n",
            " [[-1.30760759e-01 -5.26580513e-02]\n",
            "  [ 1.30760759e-01  5.26580513e-02]\n",
            "  [-1.82543155e-02 -1.21632554e-01]\n",
            "  [ 1.82543155e-02  1.21632554e-01]\n",
            "  [-9.57094058e-02  1.24847472e-01]\n",
            "  [-9.57094058e-02  1.24847472e-01]]]\n",
            "\n",
            "Pairs[0]:\n",
            " [[ 0.03821927  0.1930359 ]\n",
            " [-0.03821927 -0.1930359 ]\n",
            " [-0.01442727  0.0264831 ]\n",
            " [ 0.01442727 -0.0264831 ]\n",
            " [ 0.19891876  0.04364306]\n",
            " [ 0.19891876  0.04364306]\n",
            " [ 0.023792    0.219519  ]\n",
            " [-0.0005514   0.00511219]\n",
            " [ 0.05264654  0.1665528 ]\n",
            " [ 0.0005514  -0.00511219]\n",
            " [-0.05264654 -0.1665528 ]\n",
            " [ 0.0005514  -0.00511219]\n",
            " [-0.023792   -0.219519  ]\n",
            " [-0.0005514   0.00511219]\n",
            " [ 0.23713803  0.23667896]\n",
            " [ 0.00760253  0.00842468]\n",
            " [ 0.23713803  0.23667896]\n",
            " [ 0.00760253  0.00842468]\n",
            " [ 0.16069949 -0.14939284]\n",
            " [-0.00760253 -0.00842468]\n",
            " [ 0.16069949 -0.14939284]\n",
            " [-0.00760253 -0.00842468]\n",
            " [ 0.18449149  0.07012616]\n",
            " [-0.00286985  0.0011558 ]\n",
            " [ 0.18449149  0.07012616]\n",
            " [-0.00286985  0.0011558 ]\n",
            " [ 0.21334603  0.01715996]\n",
            " [ 0.00286985 -0.0011558 ]\n",
            " [ 0.21334603  0.01715996]\n",
            " [ 0.00286985 -0.0011558 ]]\n",
            "\n",
            "Triplets[0]:\n",
            " [[[ 0.03821927  0.1930359 ]\n",
            "  [-0.03821927 -0.1930359 ]\n",
            "  [-0.01442727  0.0264831 ]]\n",
            "\n",
            " [[ 0.01442727 -0.0264831 ]\n",
            "  [ 0.19891876  0.04364306]\n",
            "  [ 0.19891876  0.04364306]]\n",
            "\n",
            " [[ 0.023792    0.219519  ]\n",
            "  [-0.0005514   0.00511219]\n",
            "  [ 0.05264654  0.1665528 ]]\n",
            "\n",
            " [[ 0.0005514  -0.00511219]\n",
            "  [-0.05264654 -0.1665528 ]\n",
            "  [ 0.0005514  -0.00511219]]\n",
            "\n",
            " [[-0.023792   -0.219519  ]\n",
            "  [-0.0005514   0.00511219]\n",
            "  [ 0.23713803  0.23667896]]\n",
            "\n",
            " [[ 0.00760253  0.00842468]\n",
            "  [ 0.23713803  0.23667896]\n",
            "  [ 0.00760253  0.00842468]]\n",
            "\n",
            " [[ 0.16069949 -0.14939284]\n",
            "  [-0.00760253 -0.00842468]\n",
            "  [ 0.16069949 -0.14939284]]\n",
            "\n",
            " [[-0.00760253 -0.00842468]\n",
            "  [ 0.18449149  0.07012616]\n",
            "  [-0.00286985  0.0011558 ]]\n",
            "\n",
            " [[ 0.18449149  0.07012616]\n",
            "  [-0.00286985  0.0011558 ]\n",
            "  [ 0.21334603  0.01715996]]\n",
            "\n",
            " [[ 0.00286985 -0.0011558 ]\n",
            "  [ 0.21334603  0.01715996]\n",
            "  [ 0.00286985 -0.0011558 ]]]\n",
            "\n",
            "Bits (all qubits):\n",
            " [[1 1 1 ... 0 0 0]\n",
            " [0 1 1 ... 1 1 0]\n",
            " [1 0 1 ... 0 0 1]\n",
            " ...\n",
            " [0 1 1 ... 1 1 0]\n",
            " [1 0 1 ... 0 0 1]\n",
            " [0 1 1 ... 0 0 1]]\n",
            "\n",
            "Primaries Out (promoted):\n",
            " [[[ 2.86985491e-03 -1.15580356e-03]\n",
            "  [-2.86985491e-03  1.15580356e-03]\n",
            "  [ 2.13346034e-01  1.71599612e-02]\n",
            "  [-2.13346034e-01 -1.71599612e-02]\n",
            "  [ 2.86985491e-03 -1.15580356e-03]\n",
            "  [-2.86985491e-03  1.15580356e-03]]\n",
            "\n",
            " [[ 9.90038272e-04  8.72464944e-03]\n",
            "  [-9.90038272e-04 -8.72464944e-03]\n",
            "  [ 7.09505901e-02  1.99560374e-01]\n",
            "  [-7.09505901e-02 -1.99560374e-01]\n",
            "  [ 9.90038272e-04  8.72464944e-03]\n",
            "  [-9.90038272e-04 -8.72464944e-03]]\n",
            "\n",
            " [[-2.61484869e-02 -2.22424162e-03]\n",
            "  [ 2.61484869e-02  2.22424162e-03]\n",
            "  [-1.35133415e-02 -6.52229413e-03]\n",
            "  [ 1.35133415e-02  6.52229413e-03]\n",
            "  [-2.61484869e-02 -2.22424162e-03]\n",
            "  [ 2.61484869e-02  2.22424162e-03]]\n",
            "\n",
            " [[-1.28361881e-02  8.97859409e-03]\n",
            "  [ 1.28361881e-02 -8.97859409e-03]\n",
            "  [-5.96242622e-02  1.89640835e-01]\n",
            "  [ 5.96242622e-02 -1.89640835e-01]\n",
            "  [-1.28361881e-02  8.97859409e-03]\n",
            "  [ 1.28361881e-02 -8.97859409e-03]]\n",
            "\n",
            " [[ 1.54701378e-02  1.18691928e-03]\n",
            "  [-1.54701378e-02 -1.18691928e-03]\n",
            "  [ 2.61987716e-01 -8.62482041e-02]\n",
            "  [-2.61987716e-01  8.62482041e-02]\n",
            "  [ 1.54701378e-02  1.18691928e-03]\n",
            "  [-1.54701378e-02 -1.18691928e-03]]\n",
            "\n",
            " [[ 1.47925373e-02  2.26465915e-03]\n",
            "  [-1.47925373e-02 -2.26465915e-03]\n",
            "  [ 2.49340743e-01 -1.25775158e-01]\n",
            "  [-2.49340743e-01  1.25775158e-01]\n",
            "  [ 1.47925373e-02  2.26465915e-03]\n",
            "  [-1.47925373e-02 -2.26465915e-03]]\n",
            "\n",
            " [[-4.30888683e-03 -8.31428543e-03]\n",
            "  [ 4.30888683e-03  8.31428543e-03]\n",
            "  [ 1.04298279e-01 -3.72333974e-02]\n",
            "  [-1.04298279e-01  3.72333974e-02]\n",
            "  [-4.30888683e-03 -8.31428543e-03]\n",
            "  [ 4.30888683e-03  8.31428543e-03]]\n",
            "\n",
            " [[-4.82035102e-03  1.10458583e-03]\n",
            "  [ 4.82035102e-03 -1.10458583e-03]\n",
            "  [ 9.13661495e-02 -9.37013105e-02]\n",
            "  [-9.13661495e-02  9.37013105e-02]\n",
            "  [-4.82035102e-03  1.10458583e-03]\n",
            "  [ 4.82035102e-03 -1.10458583e-03]]\n",
            "\n",
            " [[-2.15276740e-02 -2.70886999e-03]\n",
            "  [ 2.15276740e-02  2.70886999e-03]\n",
            "  [-6.24956489e-02 -4.90112379e-02]\n",
            "  [ 6.24956489e-02  4.90112379e-02]\n",
            "  [-2.15276740e-02 -2.70886999e-03]\n",
            "  [ 2.15276740e-02  2.70886999e-03]]\n",
            "\n",
            " [[ 1.64598711e-02  5.02324663e-03]\n",
            "  [-1.64598711e-02 -5.02324663e-03]\n",
            "  [ 2.82204866e-01  1.45327926e-01]\n",
            "  [-2.82204866e-01 -1.45327926e-01]\n",
            "  [ 1.64598711e-02  5.02324663e-03]\n",
            "  [-1.64598711e-02 -5.02324663e-03]]\n",
            "\n",
            " [[ 9.79576167e-03 -8.68781062e-04]\n",
            "  [-9.79576167e-03  8.68781062e-04]\n",
            "  [-2.02937797e-01 -8.11177269e-02]\n",
            "  [ 2.02937797e-01  8.11177269e-02]\n",
            "  [ 9.79576167e-03 -8.68781062e-04]\n",
            "  [-9.79576167e-03  8.68781062e-04]]\n",
            "\n",
            " [[ 2.79573887e-03 -7.43538467e-03]\n",
            "  [-2.79573887e-03  7.43538467e-03]\n",
            "  [-1.08068377e-01  8.25736448e-02]\n",
            "  [ 1.08068377e-01 -8.25736448e-02]\n",
            "  [ 2.79573887e-03 -7.43538467e-03]\n",
            "  [-2.79573887e-03  7.43538467e-03]]\n",
            "\n",
            " [[-9.80362203e-03 -9.51232214e-04]\n",
            "  [ 9.80362203e-03  9.51232214e-04]\n",
            "  [-4.22295183e-02  1.22647077e-01]\n",
            "  [ 4.22295183e-02 -1.22647077e-01]\n",
            "  [-9.80362203e-03 -9.51232214e-04]\n",
            "  [ 9.80362203e-03  9.51232214e-04]]\n",
            "\n",
            " [[ 1.32751148e-02  9.01156338e-04]\n",
            "  [-1.32751148e-02 -9.01156338e-04]\n",
            "  [-2.30515555e-01  1.52756393e-01]\n",
            "  [ 2.30515555e-01 -1.52756393e-01]\n",
            "  [ 1.32751148e-02  9.01156338e-04]\n",
            "  [-1.32751148e-02 -9.01156338e-04]]\n",
            "\n",
            " [[-1.45624559e-02 -4.85964725e-03]\n",
            "  [ 1.45624559e-02  4.85964725e-03]\n",
            "  [ 1.53768569e-01  6.06356859e-02]\n",
            "  [-1.53768569e-01 -6.06356859e-02]\n",
            "  [-1.45624559e-02 -4.85964725e-03]\n",
            "  [ 1.45624559e-02  4.85964725e-03]]\n",
            "\n",
            " [[ 6.76588062e-03 -2.19768169e-03]\n",
            "  [-6.76588062e-03  2.19768169e-03]\n",
            "  [ 1.94997519e-01 -8.59664977e-02]\n",
            "  [-1.94997519e-01  8.59664977e-02]\n",
            "  [ 6.76588062e-03 -2.19768169e-03]\n",
            "  [-6.76588062e-03  2.19768169e-03]]\n",
            "\n",
            " [[ 2.09281594e-02 -3.44134844e-03]\n",
            "  [-2.09281594e-02  3.44134844e-03]\n",
            "  [ 2.95564890e-01 -6.98210821e-02]\n",
            "  [-2.95564890e-01  6.98210821e-02]\n",
            "  [ 2.09281594e-02 -3.44134844e-03]\n",
            "  [-2.09281594e-02  3.44134844e-03]]\n",
            "\n",
            " [[-3.64944222e-03 -1.05900792e-02]\n",
            "  [ 3.64944222e-03  1.05900792e-02]\n",
            "  [ 5.52491620e-02  4.15717587e-02]\n",
            "  [-5.52491620e-02 -4.15717587e-02]\n",
            "  [-3.64944222e-03 -1.05900792e-02]\n",
            "  [ 3.64944222e-03  1.05900792e-02]]\n",
            "\n",
            " [[-2.68751082e-05  1.26596717e-02]\n",
            "  [ 2.68751082e-05 -1.26596717e-02]\n",
            "  [ 2.10894436e-01 -2.37686068e-01]\n",
            "  [-2.10894436e-01  2.37686068e-01]\n",
            "  [-2.68751082e-05  1.26596717e-02]\n",
            "  [ 2.68751082e-05 -1.26596717e-02]]\n",
            "\n",
            " [[-2.24130172e-02  1.91916281e-03]\n",
            "  [ 2.24130172e-02 -1.91916281e-03]\n",
            "  [ 8.32879692e-02  1.03931285e-01]\n",
            "  [-8.32879692e-02 -1.03931285e-01]\n",
            "  [-2.24130172e-02  1.91916281e-03]\n",
            "  [ 2.24130172e-02 -1.91916281e-03]]\n",
            "\n",
            " [[-3.08465306e-02  8.04378465e-03]\n",
            "  [ 3.08465306e-02 -8.04378465e-03]\n",
            "  [ 3.59908640e-02 -1.80968285e-01]\n",
            "  [-3.59908640e-02  1.80968285e-01]\n",
            "  [-3.08465306e-02  8.04378465e-03]\n",
            "  [ 3.08465306e-02 -8.04378465e-03]]\n",
            "\n",
            " [[ 1.25893271e-02  1.10805752e-02]\n",
            "  [-1.25893271e-02 -1.10805752e-02]\n",
            "  [-2.30370194e-01 -2.33186454e-01]\n",
            "  [ 2.30370194e-01  2.33186454e-01]\n",
            "  [ 1.25893271e-02  1.10805752e-02]\n",
            "  [-1.25893271e-02 -1.10805752e-02]]\n",
            "\n",
            " [[ 3.86916869e-03 -2.62130611e-03]\n",
            "  [-3.86916869e-03  2.62130611e-03]\n",
            "  [ 3.71482700e-01 -1.10104240e-01]\n",
            "  [-3.71482700e-01  1.10104240e-01]\n",
            "  [ 3.86916869e-03 -2.62130611e-03]\n",
            "  [-3.86916869e-03  2.62130611e-03]]\n",
            "\n",
            " [[ 1.87333152e-02 -8.34947918e-04]\n",
            "  [-1.87333152e-02  8.34947918e-04]\n",
            "  [ 2.74134547e-01  1.43812150e-02]\n",
            "  [-2.74134547e-01 -1.43812150e-02]\n",
            "  [ 1.87333152e-02 -8.34947918e-04]\n",
            "  [-1.87333152e-02  8.34947918e-04]]\n",
            "\n",
            " [[-2.13158373e-02  9.86542553e-04]\n",
            "  [ 2.13158373e-02 -9.86542553e-04]\n",
            "  [ 4.60041165e-02 -8.87310356e-02]\n",
            "  [-4.60041165e-02  8.87310356e-02]\n",
            "  [-2.13158373e-02  9.86542553e-04]\n",
            "  [ 2.13158373e-02 -9.86542553e-04]]\n",
            "\n",
            " [[-2.38175057e-02  7.21586548e-05]\n",
            "  [ 2.38175057e-02 -7.21586548e-05]\n",
            "  [ 5.44301718e-02  2.97843274e-02]\n",
            "  [-5.44301718e-02 -2.97843274e-02]\n",
            "  [-2.38175057e-02  7.21586548e-05]\n",
            "  [ 2.38175057e-02 -7.21586548e-05]]\n",
            "\n",
            " [[-4.90583070e-02 -1.17440112e-01]\n",
            "  [ 4.90583070e-02  1.17440112e-01]\n",
            "  [ 4.90583070e-02  1.17440112e-01]\n",
            "  [-4.90583070e-02 -1.17440112e-01]\n",
            "  [ 1.87561318e-01 -4.55270708e-02]\n",
            "  [-1.87561318e-01  4.55270708e-02]]\n",
            "\n",
            " [[ 2.19736267e-02  3.54797929e-03]\n",
            "  [-2.19736267e-02 -3.54797929e-03]\n",
            "  [ 2.97596514e-01  1.25241578e-01]\n",
            "  [-2.97596514e-01 -1.25241578e-01]\n",
            "  [ 2.19736267e-02  3.54797929e-03]\n",
            "  [-2.19736267e-02 -3.54797929e-03]]\n",
            "\n",
            " [[-9.89333261e-03  1.15915306e-03]\n",
            "  [ 9.89333261e-03 -1.15915306e-03]\n",
            "  [ 1.54107928e-01 -8.84510428e-02]\n",
            "  [-1.54107928e-01  8.84510428e-02]\n",
            "  [-9.89333261e-03  1.15915306e-03]\n",
            "  [ 9.89333261e-03 -1.15915306e-03]]\n",
            "\n",
            " [[-2.11417279e-03  6.08656090e-03]\n",
            "  [ 2.11417279e-03 -6.08656090e-03]\n",
            "  [ 1.14755355e-01 -1.66722924e-01]\n",
            "  [-1.14755355e-01  1.66722924e-01]\n",
            "  [-2.11417279e-03  6.08656090e-03]\n",
            "  [ 2.11417279e-03 -6.08656090e-03]]\n",
            "\n",
            " [[ 5.86572615e-03 -5.79090731e-04]\n",
            "  [-5.86572615e-03  5.79090731e-04]\n",
            "  [-1.54065982e-01  1.58438414e-01]\n",
            "  [ 1.54065982e-01 -1.58438414e-01]\n",
            "  [ 5.86572615e-03 -5.79090731e-04]\n",
            "  [-5.86572615e-03  5.79090731e-04]]\n",
            "\n",
            " [[ 2.55540083e-03  8.22295342e-03]\n",
            "  [-2.55540083e-03 -8.22295342e-03]\n",
            "  [ 1.47812620e-01 -1.87247574e-01]\n",
            "  [-1.47812620e-01  1.87247574e-01]\n",
            "  [ 2.55540083e-03  8.22295342e-03]\n",
            "  [-2.55540083e-03 -8.22295342e-03]]\n",
            "\n",
            " [[ 8.18844233e-03  4.79333755e-03]\n",
            "  [-8.18844233e-03 -4.79333755e-03]\n",
            "  [-2.25129724e-01  1.53263301e-01]\n",
            "  [ 2.25129724e-01 -1.53263301e-01]\n",
            "  [ 8.18844233e-03  4.79333755e-03]\n",
            "  [-8.18844233e-03 -4.79333755e-03]]\n",
            "\n",
            " [[-1.68404877e-02  9.18967882e-04]\n",
            "  [ 1.68404877e-02 -9.18967882e-04]\n",
            "  [-5.57635799e-02  1.15685835e-01]\n",
            "  [ 5.57635799e-02 -1.15685835e-01]\n",
            "  [-1.68404877e-02  9.18967882e-04]\n",
            "  [ 1.68404877e-02 -9.18967882e-04]]\n",
            "\n",
            " [[ 1.89562235e-02 -1.45322643e-03]\n",
            "  [-1.89562235e-02  1.45322643e-03]\n",
            "  [-2.82569796e-01 -8.46703798e-02]\n",
            "  [ 2.82569796e-01  8.46703798e-02]\n",
            "  [ 1.89562235e-02 -1.45322643e-03]\n",
            "  [-1.89562235e-02  1.45322643e-03]]\n",
            "\n",
            " [[-1.95815209e-02 -1.00902654e-02]\n",
            "  [ 1.95815209e-02  1.00902654e-02]\n",
            "  [-4.56532240e-02  6.97849691e-03]\n",
            "  [ 4.56532240e-02 -6.97849691e-03]\n",
            "  [-1.95815209e-02 -1.00902654e-02]\n",
            "  [ 1.95815209e-02  1.00902654e-02]]\n",
            "\n",
            " [[ 1.12585481e-02 -1.03326123e-02]\n",
            "  [-1.12585481e-02  1.03326123e-02]\n",
            "  [-2.14014411e-01  1.84239671e-02]\n",
            "  [ 2.14014411e-01 -1.84239671e-02]\n",
            "  [ 1.12585481e-02 -1.03326123e-02]\n",
            "  [-1.12585481e-02  1.03326123e-02]]\n",
            "\n",
            " [[ 7.10081821e-03  1.38855167e-02]\n",
            "  [-7.10081821e-03 -1.38855167e-02]\n",
            "  [ 2.01666877e-01  2.37295926e-01]\n",
            "  [-2.01666877e-01 -2.37295926e-01]\n",
            "  [ 7.10081821e-03  1.38855167e-02]\n",
            "  [-7.10081821e-03 -1.38855167e-02]]\n",
            "\n",
            " [[ 1.97571926e-02  2.87202885e-03]\n",
            "  [-1.97571926e-02 -2.87202885e-03]\n",
            "  [-2.81185061e-01  1.15252994e-01]\n",
            "  [ 2.81185061e-01 -1.15252994e-01]\n",
            "  [ 1.97571926e-02  2.87202885e-03]\n",
            "  [-1.97571926e-02 -2.87202885e-03]]\n",
            "\n",
            " [[ 8.71427730e-03 -1.07815885e-03]\n",
            "  [-8.71427730e-03  1.07815885e-03]\n",
            "  [-2.28471667e-01  6.08155355e-02]\n",
            "  [ 2.28471667e-01 -6.08155355e-02]\n",
            "  [ 8.71427730e-03 -1.07815885e-03]\n",
            "  [-8.71427730e-03  1.07815885e-03]]\n",
            "\n",
            " [[-2.57852357e-02  2.47539225e-04]\n",
            "  [ 2.57852357e-02 -2.47539225e-04]\n",
            "  [-6.67003095e-02 -6.93267807e-02]\n",
            "  [ 6.67003095e-02  6.93267807e-02]\n",
            "  [-2.57852357e-02  2.47539225e-04]\n",
            "  [ 2.57852357e-02 -2.47539225e-04]]\n",
            "\n",
            " [[-2.02120319e-02  5.71477506e-03]\n",
            "  [ 2.02120319e-02 -5.71477506e-03]\n",
            "  [-8.74209404e-03 -1.64170295e-01]\n",
            "  [ 8.74209404e-03  1.64170295e-01]\n",
            "  [-2.02120319e-02  5.71477506e-03]\n",
            "  [ 2.02120319e-02 -5.71477506e-03]]\n",
            "\n",
            " [[-1.21844269e-03  7.05932034e-03]\n",
            "  [ 1.21844269e-03 -7.05932034e-03]\n",
            "  [-1.95158944e-01 -1.69690669e-01]\n",
            "  [ 1.95158944e-01  1.69690669e-01]\n",
            "  [-1.21844269e-03  7.05932034e-03]\n",
            "  [ 1.21844269e-03 -7.05932034e-03]]\n",
            "\n",
            " [[ 7.56530836e-03 -6.35967916e-03]\n",
            "  [-7.56530836e-03  6.35967916e-03]\n",
            "  [-1.75955236e-01  8.95391479e-02]\n",
            "  [ 1.75955236e-01 -8.95391479e-02]\n",
            "  [ 7.56530836e-03 -6.35967916e-03]\n",
            "  [-7.56530836e-03  6.35967916e-03]]\n",
            "\n",
            " [[ 8.62238836e-03 -9.84970480e-03]\n",
            "  [-8.62238836e-03  9.84970480e-03]\n",
            "  [-2.06368059e-01 -4.15972695e-02]\n",
            "  [ 2.06368059e-01  4.15972695e-02]\n",
            "  [ 8.62238836e-03 -9.84970480e-03]\n",
            "  [-8.62238836e-03  9.84970480e-03]]\n",
            "\n",
            " [[-6.51176926e-03 -1.42374132e-02]\n",
            "  [ 6.51176926e-03  1.42374132e-02]\n",
            "  [ 4.80959080e-02  8.42205435e-03]\n",
            "  [-4.80959080e-02 -8.42205435e-03]\n",
            "  [-6.51176926e-03 -1.42374132e-02]\n",
            "  [ 6.51176926e-03  1.42374132e-02]]\n",
            "\n",
            " [[ 1.00119493e-03  1.35751441e-02]\n",
            "  [-1.00119493e-03 -1.35751441e-02]\n",
            "  [-7.80694857e-02  2.33277738e-01]\n",
            "  [ 7.80694857e-02 -2.33277738e-01]\n",
            "  [ 1.00119493e-03  1.35751441e-02]\n",
            "  [-1.00119493e-03 -1.35751441e-02]]\n",
            "\n",
            " [[-3.27104446e-03 -6.61420077e-03]\n",
            "  [ 3.27104446e-03  6.61420077e-03]\n",
            "  [ 4.19461429e-02 -1.07021138e-01]\n",
            "  [-4.19461429e-02  1.07021138e-01]\n",
            "  [-3.27104446e-03 -6.61420077e-03]\n",
            "  [ 3.27104446e-03  6.61420077e-03]]\n",
            "\n",
            " [[ 1.08537981e-02  3.93310282e-03]\n",
            "  [-1.08537981e-02 -3.93310282e-03]\n",
            "  [ 2.08464324e-01  1.38565958e-01]\n",
            "  [-2.08464324e-01 -1.38565958e-01]\n",
            "  [ 1.08537981e-02  3.93310282e-03]\n",
            "  [-1.08537981e-02 -3.93310282e-03]]\n",
            "\n",
            " [[-5.05202357e-03  1.42270245e-03]\n",
            "  [ 5.05202357e-03 -1.42270245e-03]\n",
            "  [-1.10262498e-01  1.63330123e-01]\n",
            "  [ 1.10262498e-01 -1.63330123e-01]\n",
            "  [-5.05202357e-03  1.42270245e-03]\n",
            "  [ 5.05202357e-03 -1.42270245e-03]]\n",
            "\n",
            " [[-2.59149424e-03  5.46868432e-05]\n",
            "  [ 2.59149424e-03 -5.46868432e-05]\n",
            "  [ 1.35853723e-01 -1.24304526e-01]\n",
            "  [-1.35853723e-01  1.24304526e-01]\n",
            "  [-2.59149424e-03  5.46868432e-05]\n",
            "  [ 2.59149424e-03 -5.46868432e-05]]\n",
            "\n",
            " [[ 1.24481311e-02 -9.63043887e-03]\n",
            "  [-1.24481311e-02  9.63043887e-03]\n",
            "  [ 2.25584790e-01 -6.88040853e-02]\n",
            "  [-2.25584790e-01  6.88040853e-02]\n",
            "  [ 1.24481311e-02 -9.63043887e-03]\n",
            "  [-1.24481311e-02  9.63043887e-03]]\n",
            "\n",
            " [[ 3.34890862e-03 -1.27038332e-02]\n",
            "  [-3.34890862e-03  1.27038332e-02]\n",
            "  [ 1.80304825e-01 -2.04101726e-02]\n",
            "  [-1.80304825e-01  2.04101726e-02]\n",
            "  [ 3.34890862e-03 -1.27038332e-02]\n",
            "  [-3.34890862e-03  1.27038332e-02]]\n",
            "\n",
            " [[-5.98396827e-03  7.41546089e-03]\n",
            "  [ 5.98396827e-03 -7.41546089e-03]\n",
            "  [ 1.76902950e-01  1.72515154e-01]\n",
            "  [-1.76902950e-01 -1.72515154e-01]\n",
            "  [-5.98396827e-03  7.41546089e-03]\n",
            "  [ 5.98396827e-03 -7.41546089e-03]]\n",
            "\n",
            " [[-8.01577885e-03 -5.77767612e-03]\n",
            "  [ 8.01577885e-03  5.77767612e-03]\n",
            "  [-7.50066936e-02 -5.71616292e-02]\n",
            "  [ 7.50066936e-02  5.71616292e-02]\n",
            "  [-8.01577885e-03 -5.77767612e-03]\n",
            "  [ 8.01577885e-03  5.77767612e-03]]\n",
            "\n",
            " [[ 1.34420360e-03 -6.84055733e-03]\n",
            "  [-1.34420360e-03  6.84055733e-03]\n",
            "  [-1.08830079e-01 -4.22138721e-03]\n",
            "  [ 1.08830079e-01  4.22138721e-03]\n",
            "  [ 1.34420360e-03 -6.84055733e-03]\n",
            "  [-1.34420360e-03  6.84055733e-03]]\n",
            "\n",
            " [[-9.97827575e-03  4.70237248e-03]\n",
            "  [ 9.97827575e-03 -4.70237248e-03]\n",
            "  [-1.86547741e-01 -1.85670301e-01]\n",
            "  [ 1.86547741e-01  1.85670301e-01]\n",
            "  [-9.97827575e-03  4.70237248e-03]\n",
            "  [ 9.97827575e-03 -4.70237248e-03]]\n",
            "\n",
            " [[-2.49318383e-03  6.73811696e-03]\n",
            "  [ 2.49318383e-03 -6.73811696e-03]\n",
            "  [ 1.94789506e-02 -1.89386606e-01]\n",
            "  [-1.94789506e-02  1.89386606e-01]\n",
            "  [-2.49318383e-03  6.73811696e-03]\n",
            "  [ 2.49318383e-03 -6.73811696e-03]]\n",
            "\n",
            " [[-1.08616827e-02  1.29959239e-02]\n",
            "  [ 1.08616827e-02 -1.29959239e-02]\n",
            "  [ 1.11996099e-01 -2.28183687e-01]\n",
            "  [-1.11996099e-01  2.28183687e-01]\n",
            "  [-1.08616827e-02  1.29959239e-02]\n",
            "  [ 1.08616827e-02 -1.29959239e-02]]\n",
            "\n",
            " [[-1.90756051e-03  4.38722363e-03]\n",
            "  [ 1.90756051e-03 -4.38722363e-03]\n",
            "  [ 7.37691522e-02 -1.59927964e-01]\n",
            "  [-7.37691522e-02  1.59927964e-01]\n",
            "  [-1.90756051e-03  4.38722363e-03]\n",
            "  [ 1.90756051e-03 -4.38722363e-03]]\n",
            "\n",
            " [[-9.02235508e-03  7.28008244e-03]\n",
            "  [ 9.02235508e-03 -7.28008244e-03]\n",
            "  [ 6.23209700e-02  1.78212672e-01]\n",
            "  [-6.23209700e-02 -1.78212672e-01]\n",
            "  [-9.02235508e-03  7.28008244e-03]\n",
            "  [ 9.02235508e-03 -7.28008244e-03]]\n",
            "\n",
            " [[ 2.19127741e-02 -9.59714968e-03]\n",
            "  [-2.19127741e-02  9.59714968e-03]\n",
            "  [ 2.96692014e-01 -5.68355620e-02]\n",
            "  [-2.96692014e-01  5.68355620e-02]\n",
            "  [ 2.19127741e-02 -9.59714968e-03]\n",
            "  [-2.19127741e-02  9.59714968e-03]]\n",
            "\n",
            " [[-2.26130150e-02 -6.12932770e-03]\n",
            "  [ 2.26130150e-02  6.12932770e-03]\n",
            "  [-1.35342181e-02  3.20321321e-02]\n",
            "  [ 1.35342181e-02 -3.20321321e-02]\n",
            "  [-2.26130150e-02 -6.12932770e-03]\n",
            "  [ 2.26130150e-02  6.12932770e-03]]\n",
            "\n",
            " [[-1.74710969e-03  1.51855173e-02]\n",
            "  [ 1.74710969e-03 -1.51855173e-02]\n",
            "  [-7.74550885e-02  2.46480018e-01]\n",
            "  [ 7.74550885e-02 -2.46480018e-01]\n",
            "  [-1.74710969e-03  1.51855173e-02]\n",
            "  [ 1.74710969e-03 -1.51855173e-02]]]\n",
            "\n",
            "Nth Identities (Conceptual, per qubit):\n",
            "\n",
            "  Qubit 0:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9272981  -0.37345946]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 1:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.11273953 0.99350995]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 2:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99636376 -0.08475266]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 3:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8193816   0.57313704]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 4:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9970054 0.0764935]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 5:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.988417   0.15132141]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 6:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.4600808 -0.8877567]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 7:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9745387   0.22331603]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 8:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9921302  -0.12484172]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 9:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9563959  0.29187426]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 10:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99598885 -0.08833373]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 11:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.3519034 -0.9359018]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 12:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9952246 -0.0965653]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 13:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9976289  0.06772217]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 14:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.94851404 -0.31652927]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 15:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.95095116 -0.30888632]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 16:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.98670197 -0.16224958]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 17:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.32577735 -0.94535214]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 18:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.00212272  0.9999187 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 19:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99630976  0.08531117]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 20:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96761096  0.25232187]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 21:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.75061053 0.6606546 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 22:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.8277162 -0.5607658]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 23:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.998955   -0.04452364]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 24:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9988839   0.04623048]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 25:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99995345  0.00302951]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 26:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.38544858 -0.92272085]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 27:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9871696  0.15939368]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 28:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9931063   0.11635738]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 29:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.3280693  0.9444894]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 30:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99499327 -0.09823018]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 31:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.29673016 0.95483977]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 32:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.86291873 0.50513405]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 33:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9984552   0.05448466]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 34:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99702185 -0.07643393]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 35:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.88888216 -0.45803678]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 36:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.7367056  -0.67611676]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 37:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.45527384 0.8902795 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 38:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9895493  0.14384706]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 39:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99232    -0.12277307]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 40:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9999151   0.00959922]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 41:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96223015  0.27206215]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 42:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.17006192  0.9852918 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 43:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.7653872 -0.6434129]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 44:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.65862286 -0.75237167]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 45:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.41590422 -0.9093382 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 46:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.07354689 0.9972181 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 47:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.44324017 -0.8962518 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 48:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9400934 0.3406627]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 49:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96237713  0.2710154 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 50:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99939185  0.0210896 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 51:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.79088324 -0.6118632 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 52:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.25488636 -0.9668923 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 53:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.62792546  0.7781386 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 54:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.81114906 -0.5846664 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 55:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.19278984 -0.98109394]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 56:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9045021   0.42625657]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 57:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.34697044  0.9377277 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 58:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.64125204  0.76725334]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 59:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.39865544  0.9168729 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 60:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.77817774  0.6279068 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 61:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9159607  -0.40116382]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 62:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96513164 -0.26160192]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 63:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.1142896  0.9933816]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "\n",
            "Info-energy Output (all qubits):\n",
            " [ 5.978291   5.909871   1.8788807  8.048074   9.574263   8.383021\n",
            "  2.6899815  5.4547615  3.3018255 11.149075   7.5465684  5.471218\n",
            "  5.282117  10.009851   4.7936034  7.546583  12.675391   2.531867\n",
            "  7.7835855  5.9663153  6.841302   8.0339365 13.22915    6.7824507\n",
            "  4.0841756  2.2178473 17.273212  12.850864   6.7963276  4.711354\n",
            "  5.825203   9.523874   8.580168   6.136269  11.452957   2.1806216\n",
            "  5.889552  11.523124  12.676606   6.2639866  4.507515   7.92362\n",
            "  5.8949337  4.778499   7.8236017  2.3562777  8.377151   4.870205\n",
            "  6.8851576  7.975957   4.8632317  7.6210327  7.5079365  6.457968\n",
            "  4.316042   3.2376335  7.4927807  6.50047    6.510468   6.4277716\n",
            "  4.2730055  8.706039   2.9310725 10.2712145]\n",
            "\n",
            "Resonance Keys (all qubits):\n",
            " ['b2771924107f5a4ce31357a03727c55ad630d4feb75e91ac0c9defa81e8bee0d', 'fbe5319fd09e514f8126fb60b92f0e1c4db88dba7b41d58d46f154e9a8f29579', '203ec9d28a949c736fb97bfc067b23033ba488f52c8b1bb7145e5d225341d3a8', '08f4e2c9878b06155435a2f674b44b562358df21303f0cd411a0515ad96582a0', 'd6c213045381770d26fb30038ae1a5577eefe4d809f1742ba32ac639fb0f8278', '70da3b107af7b6ecf621717143570c7fa8043bed4fa34ea440e18675e1ade409', 'ad795524242748e07d76e4279c5be173fff44691e039340c7ac05cb624c79414', '3c01c0c6a18f9f29b4d12becedb07649ae6121702a2c6e1927546b4b53501f96', '47e5d80b8c2ca80c72af74feb022c0ddf1aacd9f16c34dab8b2eec9804f202f6', '4a02dc21358df6a5ed139658154f1f5798cc8df0a29923ced5ae09a40e7d31d2', 'd16c836307e15a569d2716c23a156de3fc8d5c541a9233eb9d722fa7a527eac1', '08c72b1e065e92b1ee681b1d7750e1bbe49dd17865c1b888a1d2ca5ce0787ad8', '47897c417780021cd34337a9513f13c5ec4c403f0dc97f3b32848c8d7e94c830', '9c29cf81677e2526e1566e30ce00602cb18205634d468a5f63890f873d305f27', 'e7c8d44a6b9547023a15618307da1f13a7d1524980cda0f2dd0c151ddddf7cac', '4954046c71f96c21239b0dee6b399ff2f67c38d14ef3d13cb206ed7a34b30075', 'dcc2e7d60d583f1eb69c1474d3133f1b14636247362a4ada955ee1f2f89275b5', 'f887f4917e558edcdc3d6663036242c57537faf8462b4f76cbee1303096f3ee4', 'c89b5f51ce56a9f34571f413c09317247d45a229efd3ab6bd1edae897fe2ca20', '72a44fe3bb3988f188af9cf65535daabbb827b59a6548262733b8e2e680cd401', '34ad4e21ef70ad7aaa27a9c1160b888b659c5f342033619a6d4a6c3811f70630', '11f73f64fe3826b28552bf6afa48848ea0aa15c9e9248719295aeb7aa885765e', 'e52482d0611609572e60c01dd686ea5c71a0027fd146f2ab17966ab9922350d6', 'f7e8ee869e93184ee1d65005bbb34b076310cd89f329d3494364824a779df966', '2a153adf673daa63c3b85983d6b98757bd80e4ef16d4fd8f210a440b93424402', 'a064a571e050979eb26dca75ad1e0735aee23de03a3a1ebf540cccdf65b41f22', '0eb78ca01dcb5ff8d1ded8cdbb3af7bce3b4488490b6c456c9ecc309e4fc2ec7', 'e85acad4cb1f0e8afa03f0ab64b16a85e4880b75069fd1d44a094440f11fb48f', '2275b4df860d9243dab651de45d6210e3cee09e00ee86bb28e5c265b75289b16', '6faad1fb0057c7329601132ae6e547ee4d057e39b17d886a6ae1bf568b4d28f2', '9ec25a5b17d52b6249cdc49920963222e4fa01380c2bb5af92d4bacead57379b', 'a6cf9a22c3d04c77b5d4ea9b9500adae8223400a7658f524d2ad9311918e71ca', '356b21fcdb3babaa71154982204cdcc799755e05643f12ab1a6f5e6a8b4a20db', '17540bff95f3ba3a4a34729893d499d5a3774643214dacf910e5f9ac61af22e0', '681eaab9a0e996aa0a0f02b7297bc01e4851b3677abf9f42077dffbac8dc0170', '64111ad8dc24e1c4b8338004ec726f48cfbaec8707a73a58deb508a409f53e90', '606bea95ee61ca75d35df067f794614af7426d14cfdbf5d6a7c8ffd82f45b1bf', '778fc700d58ddb10d766bb2191882c88fdf27b55c967a3e4c9daf01c5ac6ddaf', '9b0e2347ffe7db87c915058152aa9408e66d97e12b67004a406b1a8fe6fe2892', 'a74243ba6cf9e2ac319bdf5c4dfa190b92084db73c31e2a88195f8bb2a664068', '55793d98b5d1dc33c1135cdf943db14c453988e3e522e2d3041951a5f1ba0f1b', '0ff56bab53617a6d45576d3aa74c9731dab4fba3ffc25b85ae29089b846cf8bc', 'bc703351f1383235ee8acc32ceacece311c33d16c6c7c0952bb5227eea9fb7cd', '722922f6a32f2522cb807e6f18a703392bc16ad32f7c8a117a6f936e2aaeaec6', 'f77ab1199eb7a29aa2a67063905a8176884c73146eb43247aca0c80973e9c0bb', '134d24998865be8a4eea94b88cd1840a0ddcd4ae54e277d764d46cb860ddc740', '94eaad74c8cca51ce9eec96dc6c1f9104aace3f551b0a4458455a1d360b13524', '7688bd8200d19850d4305b021629dd548c7b7ddab71da915cf5b5add42a3ef5d', '760790bef36c9ce1c81abf51f90faf592d3bc7394f4c53bb6a203a8c02689200', '9b14b6a1bacadffbbd067ceaeae93cb9167feedebba81617a17e9125c2be00e0', 'a661515223d8608e7144dec1be52688fb8e26600f9dc70dff163abb014a5af92', '6e8bbd3d34d37f8a960a75d74172c7db9f3ac603c150fee5feb1393717aa3f5f', '027446688f7d3cbcd256c2aa4e9d5dadb414f3f3146c9f04b02afb9b234e7f8a', '75773cee51e7ab2738ad357bacfadb200b6b5d8950c63c247ff16b26e7ba0578', '7e867e3f88e2dce907072685903545f457125742535de292839b96ecc8362fde', '1f375d8474e7e385c798007af3f9b43a9ebef267259225f80f415ceff91270b2', '4e0dde1c1fdc8b4e84fc65fb7d1c4d41864cac5428b6f5322a32c1afb9e80f13', '28e576c8707300d45d538c33b933b35b55007e234189accab5dd77d5c4919421', '8b3953a6aa63e472c13d6f5d55058573626de15f385e669429aeaed9efbb396a', '751003aa1c3f154e057909948d5edebf1a52bf6e9a9e1aedbc78814ba129678c', '279bcd6f054b0c4c4fb6fa9da920f32586dc09e3660de7060516907a5b957b17', '3949ec2e1214251f8c9c9781f6f9204e299fdce6b864c5634d83ffd9b22eabe6', '88854c38a4727d120ca52bebb3aaebca477026ceb0bfee8b7c6b062f471b6874', '59350705c1bb783edd8374451c29b2499573e5e5293e38a447bc62bea3fc7c2c']\n",
            "\n",
            "Spin (all qubits, conceptual):\n",
            " [[[ 6.21882021e-01  6.22943103e-01  4.74557340e-01]\n",
            "  [ 4.71173599e-02  8.78962636e-01  4.74557340e-01]]\n",
            "\n",
            " [[ 5.95045149e-01  5.06675303e-01 -6.23860061e-01]\n",
            "  [-5.24239600e-01  5.79630494e-01 -6.23860061e-01]]\n",
            "\n",
            " [[ 6.28640413e-01 -4.41472590e-01 -6.40244603e-01]\n",
            "  [-7.65229940e-01  6.71564341e-02 -6.40244603e-01]]\n",
            "\n",
            " [[ 8.89394522e-01  8.46002102e-02 -4.49244022e-01]\n",
            "  [ 7.56157100e-01 -4.75821674e-01 -4.49244022e-01]]\n",
            "\n",
            " [[-2.37060525e-02  1.26294956e-01  9.91709411e-01]\n",
            "  [ 5.16557731e-02  1.17660850e-01  9.91709411e-01]]\n",
            "\n",
            " [[ 9.71672058e-01  2.19771400e-01  8.69133770e-02]\n",
            "  [-6.89290345e-01  7.19253004e-01  8.69133770e-02]]\n",
            "\n",
            " [[ 2.99363554e-01 -2.31321141e-01  9.25673783e-01]\n",
            "  [-3.72664571e-01  6.51853904e-02  9.25673783e-01]]\n",
            "\n",
            " [[ 6.26460195e-01  7.61061013e-01  1.68326303e-01]\n",
            "  [-2.73164660e-01 -9.47125852e-01  1.68326303e-01]]\n",
            "\n",
            " [[ 1.65651441e-01 -8.09987843e-01  5.62564909e-01]\n",
            "  [ 5.33142507e-01  6.31885886e-01  5.62564909e-01]]\n",
            "\n",
            " [[-6.31246865e-01  3.74792725e-01  6.79012418e-01]\n",
            "  [-3.89135629e-01 -6.22507513e-01  6.79012418e-01]]\n",
            "\n",
            " [[ 5.49407125e-01  1.36555463e-01  8.24320555e-01]\n",
            "  [-5.57695270e-01 -9.73220989e-02  8.24320555e-01]]\n",
            "\n",
            " [[-8.20828021e-01  5.70320487e-01  3.12388912e-02]\n",
            "  [-9.50174212e-01  3.10150117e-01  3.12388912e-02]]\n",
            "\n",
            " [[ 9.18422639e-01  3.87818128e-01  7.80831352e-02]\n",
            "  [ 9.04574931e-01  4.19102877e-01  7.80831352e-02]]\n",
            "\n",
            " [[ 7.38184452e-01 -5.11666119e-01 -4.39637899e-01]\n",
            "  [ 4.20718677e-02 -8.97189200e-01 -4.39637899e-01]]\n",
            "\n",
            " [[ 9.04515922e-01  4.23997164e-01  4.55775261e-02]\n",
            "  [ 9.82040346e-01 -1.83083251e-01  4.55775261e-02]]\n",
            "\n",
            " [[-4.27639157e-01  8.93702745e-01 -1.35720924e-01]\n",
            "  [ 4.38126057e-01 -8.88608694e-01 -1.35720924e-01]]\n",
            "\n",
            " [[-8.70823920e-01  4.65269923e-01 -1.58712462e-01]\n",
            "  [-8.91786575e-01 -4.23706263e-01 -1.58712462e-01]]\n",
            "\n",
            " [[ 3.94639224e-01  6.78422153e-01 -6.19679928e-01]\n",
            "  [-5.20449519e-01  5.87476850e-01 -6.19679928e-01]]\n",
            "\n",
            " [[-2.46343911e-02  9.60159898e-01  2.78363317e-01]\n",
            "  [ 6.57507598e-01 -7.00141191e-01  2.78363317e-01]]\n",
            "\n",
            " [[ 6.43361449e-01  7.65325189e-01 -1.90630406e-02]\n",
            "  [ 3.53717744e-01 -9.35157955e-01 -1.90630406e-02]]\n",
            "\n",
            " [[-3.64022285e-01  3.66644599e-02 -9.30668294e-01]\n",
            "  [ 2.80191362e-01 -2.35264316e-01 -9.30668294e-01]]\n",
            "\n",
            " [[-3.13315362e-01  2.87061840e-01  9.05223191e-01]\n",
            "  [-4.01450068e-01 -1.39315665e-01  9.05223191e-01]]\n",
            "\n",
            " [[ 1.76387485e-02 -3.55267012e-03 -9.99838114e-01]\n",
            "  [-1.36221340e-02  1.17551852e-02 -9.99838114e-01]]\n",
            "\n",
            " [[-9.29735899e-02  8.48503113e-01 -5.20959079e-01]\n",
            "  [-3.15658450e-02  8.52997780e-01 -5.20959079e-01]]\n",
            "\n",
            " [[ 7.61924565e-01  1.56759962e-01  6.28408551e-01]\n",
            "  [-5.42142466e-02  7.75991976e-01  6.28408551e-01]]\n",
            "\n",
            " [[ 2.87548006e-01 -2.21330449e-01 -9.31841731e-01]\n",
            "  [-3.34709406e-01 -1.40145019e-01 -9.31841731e-01]]\n",
            "\n",
            " [[-6.49846315e-01 -6.30082905e-01  4.25082713e-01]\n",
            "  [-4.75560009e-01  7.70160615e-01  4.25082713e-01]]\n",
            "\n",
            " [[ 3.92426699e-02  9.94898677e-02 -9.94264424e-01]\n",
            "  [ 1.05483264e-01  1.76494140e-02 -9.94264424e-01]]\n",
            "\n",
            " [[ 6.21477485e-01 -6.99021697e-01  3.53743434e-01]\n",
            "  [ 8.34592164e-01 -4.22281325e-01  3.53743434e-01]]\n",
            "\n",
            " [[-5.86287320e-01  7.51262903e-02 -8.06612194e-01]\n",
            "  [ 5.79851925e-01  1.14667259e-01 -8.06612194e-01]]\n",
            "\n",
            " [[-7.65553713e-02 -9.78665888e-01  1.90662995e-01]\n",
            "  [-6.22244775e-01 -7.59249032e-01  1.90662995e-01]]\n",
            "\n",
            " [[-3.81252557e-01 -3.90731752e-01  8.37839603e-01]\n",
            "  [ 5.15995562e-01 -1.78250864e-01  8.37839603e-01]]\n",
            "\n",
            " [[ 1.22554675e-01  2.16991037e-01  9.68449891e-01]\n",
            "  [-5.37841581e-02  2.43335217e-01  9.68449891e-01]]\n",
            "\n",
            " [[-1.70624390e-01  1.70839295e-01  9.70412910e-01]\n",
            "  [-2.19515264e-01 -1.00557409e-01  9.70412910e-01]]\n",
            "\n",
            " [[ 8.64662305e-02 -9.80764866e-01 -1.74996644e-01]\n",
            "  [ 3.96593451e-01  9.01160240e-01 -1.74996644e-01]]\n",
            "\n",
            " [[-5.64657927e-01  5.62787205e-02  8.23404014e-01]\n",
            "  [-1.50745466e-01  5.47066450e-01  8.23404014e-01]]\n",
            "\n",
            " [[-6.96464300e-01  4.69433188e-01 -5.42742968e-01]\n",
            "  [ 4.30802017e-01 -7.20999062e-01 -5.42742968e-01]]\n",
            "\n",
            " [[ 4.02410299e-01 -4.84422781e-02 -9.14176822e-01]\n",
            "  [ 2.14529321e-01  3.43886435e-01 -9.14176822e-01]]\n",
            "\n",
            " [[ 5.44311851e-03  1.17009573e-01  9.93115842e-01]\n",
            "  [ 2.17620446e-03  1.17115892e-01  9.93115842e-01]]\n",
            "\n",
            " [[-5.42918183e-02 -7.22470164e-01  6.89267159e-01]\n",
            "  [ 5.69554329e-01  4.47793067e-01  6.89267159e-01]]\n",
            "\n",
            " [[-8.67630899e-01 -7.07473010e-02  4.92149830e-01]\n",
            "  [-4.76859897e-01  7.28280962e-01  4.92149830e-01]]\n",
            "\n",
            " [[ 1.23570904e-01  9.84833598e-01  1.21790923e-01]\n",
            "  [ 9.56459284e-01 -2.65240639e-01  1.21790923e-01]]\n",
            "\n",
            " [[-9.04384196e-01  2.66072422e-01 -3.33608627e-01]\n",
            "  [-1.86573356e-01 -9.24064755e-01 -3.33608627e-01]]\n",
            "\n",
            " [[-3.54623258e-01 -3.74948710e-01 -8.56537104e-01]\n",
            "  [-4.89052296e-01 -1.64839461e-01 -8.56537104e-01]]\n",
            "\n",
            " [[ 2.02673767e-02 -5.85067011e-02 -9.98081267e-01]\n",
            "  [ 5.97348586e-02  1.62956212e-02 -9.98081267e-01]]\n",
            "\n",
            " [[ 4.56108361e-01 -4.68576819e-01 -7.56571829e-01]\n",
            "  [-5.92786193e-01 -2.76050061e-01 -7.56571829e-01]]\n",
            "\n",
            " [[ 3.53303581e-01 -1.17275864e-01 -9.28128719e-01]\n",
            "  [ 1.68900594e-01  3.31737310e-01 -9.28128719e-01]]\n",
            "\n",
            " [[-3.01552266e-01 -8.34079444e-01 -4.61928308e-01]\n",
            "  [ 6.41071200e-01  6.12902939e-01 -4.61928308e-01]]\n",
            "\n",
            " [[-1.74645543e-01 -8.28060210e-01  5.32743096e-01]\n",
            "  [-4.95021671e-01 -6.86395168e-01  5.32743096e-01]]\n",
            "\n",
            " [[-8.22530091e-02  3.27848554e-01  9.41142797e-01]\n",
            "  [ 1.59474164e-01 -2.98023850e-01  9.41142797e-01]]\n",
            "\n",
            " [[-3.93779716e-03 -2.70459980e-01  9.62723136e-01]\n",
            "  [-1.94202721e-01  1.88280150e-01  9.62723136e-01]]\n",
            "\n",
            " [[-2.91943491e-01  9.56315100e-01  1.51789607e-02]\n",
            "  [-1.21129759e-01  9.92520630e-01  1.51789607e-02]]\n",
            "\n",
            " [[-6.35047108e-02  6.45700634e-01 -7.60945380e-01]\n",
            "  [ 6.48672044e-01 -1.36644412e-02 -7.60945380e-01]]\n",
            "\n",
            " [[-2.55319297e-01  8.80234480e-01 -3.99999142e-01]\n",
            "  [ 5.15963649e-03  9.16500986e-01 -3.99999142e-01]]\n",
            "\n",
            " [[-1.68006107e-01  8.06991577e-01 -5.66161215e-01]\n",
            "  [-8.24294448e-01 -3.18183214e-04 -5.66161215e-01]]\n",
            "\n",
            " [[-5.78641713e-01  8.05387855e-01 -1.28546491e-01]\n",
            "  [ 9.24928725e-01  3.57746691e-01 -1.28546491e-01]]\n",
            "\n",
            " [[ 6.47856951e-01  7.38536716e-01  1.86667740e-01]\n",
            "  [-1.53838946e-02 -9.82302666e-01  1.86667740e-01]]\n",
            "\n",
            " [[-2.25327849e-01 -1.28806636e-01 -9.65730906e-01]\n",
            "  [ 1.44074172e-01  2.15885207e-01 -9.65730906e-01]]\n",
            "\n",
            " [[-2.64379084e-01 -2.28249580e-01 -9.37019646e-01]\n",
            "  [ 2.28542447e-01  2.64125973e-01 -9.37019646e-01]]\n",
            "\n",
            " [[ 2.30383486e-01  1.42655686e-01  9.62586522e-01]\n",
            "  [ 2.66627669e-01  4.83413152e-02  9.62586522e-01]]\n",
            "\n",
            " [[ 1.99440584e-01 -7.53525317e-01 -6.26436770e-01]\n",
            "  [-3.17719817e-01  7.11780250e-01 -6.26436770e-01]]\n",
            "\n",
            " [[ 2.47729123e-01 -1.16055392e-01  9.61853147e-01]\n",
            "  [-1.86162561e-01 -2.00454667e-01  9.61853147e-01]]\n",
            "\n",
            " [[ 6.36721775e-02  9.93261635e-01 -9.68355536e-02]\n",
            "  [ 6.50375903e-01  7.53414929e-01 -9.68355536e-02]]\n",
            "\n",
            " [[ 2.58810520e-01 -5.76541126e-01 -7.74995148e-01]\n",
            "  [-4.79583919e-01 -4.11560208e-01 -7.74995148e-01]]]\n",
            "\n",
            "I_vec (all qubits, conceptual):\n",
            " [[0.23679896 0.23439662 0.07769001 ... 0.3700822  0.29901507 0.2624737 ]\n",
            " [0.00396248 0.40574586 0.07778408 ... 0.32418492 0.03715942 0.40361595]\n",
            " [0.02948453 0.3708822  0.35464147 ... 0.16944775 0.26023173 0.34702647]\n",
            " ...\n",
            " [0.5288425  0.39029458 0.03128419 ... 0.20275228 0.16903348 0.17401244]\n",
            " [0.31372014 0.17774932 0.24386486 ... 0.19526573 0.18813376 0.3391468 ]\n",
            " [0.21185058 0.3337143  0.04836354 ... 0.01722158 0.2369867  0.07669386]]\n",
            "\n",
            "NECL Manifest Checksums (per qubit, conceptual):\n",
            " ['ad27cbd13f235dc8a667c5882bd920169a31a96581b57c69aee94a5a3ababfc8', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945']\n",
            "\n",
            "TRACE Log (Conceptual - detailed lineage for error correction):\n",
            " [{'qubit': 0, 'reason': 'binary_refactor', 'source': 'tuplets', 'r_metric': 0.967706561088562, 'u_metric': 0.9713038802146912, 'dv_metric': 0.1797460913658142, 'invariant_pass': False, 'degenerate_check': False, 'correction_threshold_r': 1.02, 'correction_threshold_u': 1.02, 'correction_threshold_d': 0.765, 'corrected_bits': [1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], 'old_key': '4cb1bec2fecdf5a680928429429320d4de8f997d253a58e0ff7dbe00a5a63394', 'new_key': 'b2771924107f5a4ce31357a03727c55ad630d4feb75e91ac0c9defa81e8bee0d'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6ca1297"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review the updated code block to ensure all refactoring instructions related to collapse scope and parity application have been correctly implemented and verify that the system behaves as expected with the new collapse rules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f219b397"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **Have all refactoring instructions related to collapse scope and parity application been correctly implemented?**\n",
        "    Yes, the `detect_collapse` function has been refactored as instructed, including the update of `R_FOR_RATIO` to `64.0`, and the `apply_parity_rotation` and `COLLAPSE_Q` functions performed as expected.\n",
        "2.  **Does the system behave as expected with the new collapse rules?**\n",
        "    Yes, the system behaves as expected, with the updated `detect_collapse` function successfully integrated and producing outputs consistent with the new collapse rules.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The global constant `R_FOR_RATIO` was successfully updated to `64.0` as specified.\n",
        "*   The `detect_collapse` function was refactored to remove the nested helper function and directly implement the new triplet-level predicate for collapse detection.\n",
        "*   The triplet-level predicate includes two conditions: `[real_p >= TAU_HI AND unreal_p <= TAU_LOW]` OR `[real_p / unreal_p > R_FOR_RATIO]`, with robust handling for potential division by zero.\n",
        "*   If any index within a triplet meets the collapse condition, all three indices of that triplet are marked as collapsed, correctly updated using `tf.tensor_scatter_nd_max`.\n",
        "*   The `apply_parity_rotation` and `COLLAPSE_Q` functions operate correctly within the system, utilizing the updated collapse detection.\n",
        "*   The `correct_bits` function successfully identified an \"inconsistent\" bit pattern for Qubit 0 (due to a forced sparse state) and applied corrections, logging the intervention in the `TRACE` manifest.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The implemented triplet-level collapse detection, combined with robust error handling for ratios and the `correct_bits` function, significantly enhances the system's ability to maintain data integrity and consistency, especially in ambiguous or degenerate states.\n",
        "*   Further testing could involve more diverse initial conditions, particularly edge cases where `unreal_p` is very close to zero, to rigorously validate the `detect_collapse` function's division-by-zero handling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf6b9a03"
      },
      "source": [
        "# Task\n",
        "I've completed all the refactoring, review, and documentation tasks as per the plan. The `detect_collapse` function has been updated with the new triplet-level predicate and `R_FOR_RATIO`. I've confirmed that `apply_parity_rotation` and `COLLAPSE_Q` functions correctly utilize the refined `collapse_mask`. The `correct_bits` function has been appropriately documented. The system now incorporates the specified collapse rules, and its behavior has been verified to be as expected.\n",
        "\n",
        "I am done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a96fcdbf"
      },
      "source": [
        "## Refactor detect_collapse for Unit Preference\n",
        "\n",
        "### Subtask:\n",
        "Modify the `detect_collapse` function to adhere strictly to the 'Unit preference' rule.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1861151d"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `detect_collapse` function to adhere strictly to the 'Unit preference' rule, which involves calculating individual collapse statuses first and then applying triplet-level uniformity checks. This refactoring also removes the nested helper function and updates the function signature to explicitly accept relevant parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c764d05e",
        "outputId": "0eb34059-f90e-4a0e-cb33-118471514f9d"
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "R_FOR_RATIO = 64.0 # NEW: Ratio threshold constant for collapse detection, updated to 64.0 as per instructions\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| + n_|y, η| = n_|x+y, ξ+η|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| · n_|y, η| = n_|x·y, ξ·η|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ξ| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ξ_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW, r_for_ratio=R_FOR_RATIO):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register, adhering to 'Unit Preference' rule.\n",
        "\n",
        "    For each unit `p`, `individual_collapse_status_p = (real_p >= tau_hi AND unreal_p <= tau_low) OR (real_p / unreal_p > r_for_ratio)`.\n",
        "\n",
        "    The `final_collapse_mask` is initialized with these individual statuses. Then, for each triplet:\n",
        "    - If all three units within a triplet have a uniform collapse status (all True or all False), the triplet's units\n",
        "      in `final_collapse_mask` are updated to this uniform status.\n",
        "    - If the triplet has mixed statuses, the individual collapse statuses (calculated initially) are retained.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for unreal component (should be negative).\n",
        "        r_for_ratio (float): Ratio threshold for collapse detection.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    # 2. Inside detect_collapse, first evaluate the core collapse predicate for each of the 30 individual phase-dual units across all qubits:\n",
        "    # For each unit `p`, calculate `cond1_p = (real_p >= tau_hi) AND (unreal_p <= tau_low)`.\n",
        "    cond1_p = tf.logical_and(real_parts >= tau_hi, unreal_parts <= tau_low) # [Q, 30]\n",
        "\n",
        "    # Calculate `ratio_term_p = real_p / unreal_p`, handling potential division by zero by setting the ratio to 0 if `unreal_p` is near zero (less than `EPS`).\n",
        "    ratio_term_p = tf.where(tf.abs(unreal_parts) > EPS, real_parts / unreal_parts, tf.zeros_like(real_parts)) # [Q, 30]\n",
        "\n",
        "    # Calculate `cond2_p = (ratio_term_p > r_for_ratio)`.\n",
        "    cond2_p = (ratio_term_p > r_for_ratio) # [Q, 30]\n",
        "\n",
        "    # Determine the `individual_collapse_status_p = cond1_p OR cond2_p` for each of the 30 units (this will be a boolean tensor of shape `[Q, 30]`)\n",
        "    individual_collapse_status_p = tf.logical_or(cond1_p, cond2_p) # [Q, 30]\n",
        "\n",
        "    # 3. Initialize the `final_collapse_mask` (a `tf.int32` tensor of shape `[Q, 30]`) with the `tf.cast` version of `individual_collapse_status_p`.\n",
        "    # This tensor will hold the final collapse decisions, with individual statuses as the default fallback.\n",
        "    final_collapse_mask = tf.cast(individual_collapse_status_p, tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # 4. Iterate through each of the 10 triplets defined by the `idx` tensor:\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # For the current triplet, extract the `individual_collapse_status` for its three constituent units across all qubits\n",
        "        triplet_individual_status = tf.gather(individual_collapse_status_p, current_triplet_indices, axis=1) # [Q, 3]\n",
        "\n",
        "        # For each qubit, check if the three units within the current triplet have a uniform collapse status\n",
        "        # (i.e., all three are `True` or all three are `False`). Store this check in an `is_uniform` boolean tensor of shape `[Q]`.\n",
        "        is_uniform = tf.reduce_all(tf.equal(triplet_individual_status, triplet_individual_status[:, 0:1]), axis=1) # [Q]\n",
        "\n",
        "        # For qubits where `is_uniform` is `True`, determine the uniform status for the triplet\n",
        "        # (which will be `True` if all units were collapsed, or `False` if all were not collapsed).\n",
        "        # Replicate this uniform status across the three units of the triplet for those qubits.\n",
        "        uniform_status_value = tf.cast(triplet_individual_status[:, 0], tf.int32) # [Q]\n",
        "\n",
        "        # Construct the updates: if uniform, use the uniform_status_value for all three; otherwise, keep individual statuses\n",
        "        updates_for_triplet = tf.where(\n",
        "            tf.expand_dims(is_uniform, axis=-1), # [Q, 1] for broadcasting\n",
        "            tf.tile(tf.expand_dims(uniform_status_value, axis=-1), [1, 3]), # [Q, 3]\n",
        "            tf.cast(triplet_individual_status, tf.int32) # [Q, 3]\n",
        "        )\n",
        "\n",
        "        # Use `tf.tensor_scatter_nd_update` to update the relevant sections of `final_collapse_mask`\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1) # [Q*3, 2]\n",
        "\n",
        "        updates_flat = tf.reshape(updates_for_triplet, [-1]) # [Q*3]\n",
        "\n",
        "        final_collapse_mask = tf.tensor_scatter_nd_update(final_collapse_mask, indices_to_update, updates_flat)\n",
        "\n",
        "    return final_collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`)\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode('utf-8')).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    for b_idx_triplet in tf.range(10):\n",
        "        current_triplet_indices = idx[b_idx_triplet, :] # Shape [3]\n",
        "        s = tf.gather(signs, current_triplet_indices) # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        # Ensure the list extension is compatible with TF operations if trip_mix is later converted to Tensor\n",
        "        # Here, it's converted to Python list and then to Tensor once.\n",
        "        trip_mix.extend([has_mix.numpy().item()]*3)\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook for a single qubit (q_idx). This function performs a local\n",
        "    re-evaluation of the bit pattern for the current qubit if the initial derivation\n",
        "    is deemed 'inconsistent'.\n",
        "\n",
        "    This function is designed to:\n",
        "    - Advance *only* within the same triplet (or within the primaries 6-set) for local re-evaluation.\n",
        "      It uses the `pairs_q` and `triplets_q` already derived for this specific qubit `q_idx`.\n",
        "      It does not implicitly advance to other qubits or triplets; its scope is limited to the\n",
        "      current qubit's local tuplet structure.\n",
        "    - Record lineage for any local adjustments made. If a correction occurs, a specific\n",
        "      entry is added to the `TRACE` log, detailing the reason, source, metrics, and new key.\n",
        "    - *Not* advance across different units (triplets or qubits) unless the current local unit\n",
        "      has been exhausted. The `derive_bits_advanced` function, called internally,\n",
        "      operates solely on the provided `pairs_q` and `triplets_q` for the current qubit.\n",
        "\n",
        "    Args:\n",
        "        q_idx (int): The index of the current qubit being processed.\n",
        "        pairs_q (tf.Tensor): The 30-index phase-dual pair register for the current qubit [30, 2].\n",
        "        triplets_q (tf.Tensor): The 10 triplets for the current qubit [10, 3, 2].\n",
        "        current_bits_q (tf.Tensor): The initially derived 30-bit pattern for the current qubit [30].\n",
        "        resonance_key_q (str): The current resonance key string for the qubit.\n",
        "        TRACE (list): A list to append lineage information if corrections are made.\n",
        "        invariants (dict): Dictionary of invariant constants.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, str]:\n",
        "            - new_bits_q (tf.Tensor): The potentially corrected 30-bit pattern.\n",
        "            - updated_resonance_key_q (str): The updated resonance key string (with lineage if corrected).\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        # The updated key incorporates the correction lineage.\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs) # Pass R_FOR_RATIO implicitly from constants\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primaries In:\n",
            " [[[-0.14282727  0.4986279 ]\n",
            "  [ 0.14282727 -0.4986279 ]\n",
            "  [-0.92648005  0.25563264]\n",
            "  [ 0.92648005 -0.25563264]\n",
            "  [ 0.47266102  0.90747666]\n",
            "  [-0.47266102 -0.90747666]]\n",
            "\n",
            " [[ 0.09285569 -0.38586164]\n",
            "  [-0.09285569  0.38586164]\n",
            "  [-0.6026249  -0.06765127]\n",
            "  [ 0.6026249   0.06765127]\n",
            "  [ 0.5076792  -0.8308573 ]\n",
            "  [-0.5076792   0.8308573 ]]\n",
            "\n",
            " [[-0.6451609   0.7863047 ]\n",
            "  [ 0.6451609  -0.7863047 ]\n",
            "  [-0.39870954  0.38359904]\n",
            "  [ 0.39870954 -0.38359904]\n",
            "  [ 0.6007421  -0.00857735]\n",
            "  [-0.6007421   0.00857735]]\n",
            "\n",
            " [[ 0.15974045 -0.63659024]\n",
            "  [-0.15974045  0.63659024]\n",
            "  [-0.4069388   0.0830853 ]\n",
            "  [ 0.4069388  -0.0830853 ]\n",
            "  [-0.16929793  0.94568753]\n",
            "  [ 0.16929793 -0.94568753]]\n",
            "\n",
            " [[ 0.76533675 -0.9831886 ]\n",
            "  [-0.76533675  0.9831886 ]\n",
            "  [-0.3092246   0.17104912]\n",
            "  [ 0.3092246  -0.17104912]\n",
            "  [-0.5307014   0.8122597 ]\n",
            "  [ 0.5307014  -0.8122597 ]]\n",
            "\n",
            " [[-0.550998   -0.4066124 ]\n",
            "  [ 0.550998    0.4066124 ]\n",
            "  [-0.07883334 -0.6230664 ]\n",
            "  [ 0.07883334  0.6230664 ]\n",
            "  [ 0.24346757 -0.02133131]\n",
            "  [-0.24346757  0.02133131]]\n",
            "\n",
            " [[-0.49218655  0.322937  ]\n",
            "  [ 0.49218655 -0.322937  ]\n",
            "  [-0.8601682  -0.4485178 ]\n",
            "  [ 0.8601682   0.4485178 ]\n",
            "  [-0.38223958 -0.97815514]\n",
            "  [ 0.38223958  0.97815514]]\n",
            "\n",
            " [[-0.4326477   0.35344934]\n",
            "  [ 0.4326477  -0.35344934]\n",
            "  [-0.5175667  -0.00447249]\n",
            "  [ 0.5175667   0.00447249]\n",
            "  [ 0.592896    0.13432503]\n",
            "  [-0.592896   -0.13432503]]\n",
            "\n",
            " [[ 0.13332415 -0.28185964]\n",
            "  [-0.13332415  0.28185964]\n",
            "  [ 0.80411315  0.5374098 ]\n",
            "  [-0.80411315 -0.5374098 ]\n",
            "  [-0.66802454  0.6020751 ]\n",
            "  [ 0.66802454 -0.6020751 ]]\n",
            "\n",
            " [[-0.7768271   0.4471364 ]\n",
            "  [ 0.7768271  -0.4471364 ]\n",
            "  [ 0.06508327  0.10871863]\n",
            "  [-0.06508327 -0.10871863]\n",
            "  [ 0.61646605 -0.7680476 ]\n",
            "  [-0.61646605  0.7680476 ]]\n",
            "\n",
            " [[-0.42616463 -0.51953053]\n",
            "  [ 0.42616463  0.51953053]\n",
            "  [ 0.56290984 -0.79959106]\n",
            "  [-0.56290984  0.79959106]\n",
            "  [-0.1572051   0.02769828]\n",
            "  [ 0.1572051  -0.02769828]]\n",
            "\n",
            " [[-0.1720295   0.09248066]\n",
            "  [ 0.1720295  -0.09248066]\n",
            "  [ 0.20638466  0.6788819 ]\n",
            "  [-0.20638466 -0.6788819 ]\n",
            "  [-0.28898597 -0.30289602]\n",
            "  [ 0.28898597  0.30289602]]\n",
            "\n",
            " [[-0.84453416  0.3897431 ]\n",
            "  [ 0.84453416 -0.3897431 ]\n",
            "  [ 0.6202972  -0.7755823 ]\n",
            "  [-0.6202972   0.7755823 ]\n",
            "  [ 0.07147121  0.07394862]\n",
            "  [-0.07147121 -0.07394862]]\n",
            "\n",
            " [[ 0.75041413  0.24195647]\n",
            "  [-0.75041413 -0.24195647]\n",
            "  [-0.69101715  0.07484603]\n",
            "  [ 0.69101715 -0.07484603]\n",
            "  [-0.04326582  0.99713874]\n",
            "  [ 0.04326582 -0.99713874]]\n",
            "\n",
            " [[-0.961828    0.6677327 ]\n",
            "  [ 0.961828   -0.6677327 ]\n",
            "  [-0.6821487   0.7795696 ]\n",
            "  [ 0.6821487  -0.7795696 ]\n",
            "  [-0.08700824  0.47263408]\n",
            "  [ 0.08700824 -0.47263408]]\n",
            "\n",
            " [[ 0.8260808   0.5430019 ]\n",
            "  [-0.8260808  -0.5430019 ]\n",
            "  [-0.48939705  0.20506954]\n",
            "  [ 0.48939705 -0.20506954]\n",
            "  [-0.07970667  0.6360712 ]\n",
            "  [ 0.07970667 -0.6360712 ]]\n",
            "\n",
            " [[ 0.33050084  0.6837394 ]\n",
            "  [-0.33050084 -0.6837394 ]\n",
            "  [ 0.6646068  -0.7874408 ]\n",
            "  [-0.6646068   0.7874408 ]\n",
            "  [ 0.32315254 -0.19761562]\n",
            "  [-0.32315254  0.19761562]]\n",
            "\n",
            " [[ 0.14661121 -0.07108259]\n",
            "  [-0.14661121  0.07108259]\n",
            "  [ 0.95045996 -0.7709806 ]\n",
            "  [-0.95045996  0.7709806 ]\n",
            "  [-0.68565917  0.393373  ]\n",
            "  [ 0.68565917 -0.393373  ]]\n",
            "\n",
            " [[-0.08648753  0.6124747 ]\n",
            "  [ 0.08648753 -0.6124747 ]\n",
            "  [-0.45657325  0.101475  ]\n",
            "  [ 0.45657325 -0.101475  ]\n",
            "  [ 0.95606446  0.32150793]\n",
            "  [-0.95606446 -0.32150793]]\n",
            "\n",
            " [[-0.27008963  0.20359349]\n",
            "  [ 0.27008963 -0.20359349]\n",
            "  [-0.43073893 -0.18083477]\n",
            "  [ 0.43073893  0.18083477]\n",
            "  [-0.43699527  0.41734886]\n",
            "  [ 0.43699527 -0.41734886]]\n",
            "\n",
            " [[-0.198663    0.33857918]\n",
            "  [ 0.198663   -0.33857918]\n",
            "  [ 0.49664307  0.6031642 ]\n",
            "  [-0.49664307 -0.6031642 ]\n",
            "  [-0.2321961   0.84418917]\n",
            "  [ 0.2321961  -0.84418917]]\n",
            "\n",
            " [[ 0.22796106 -0.858062  ]\n",
            "  [-0.22796106  0.858062  ]\n",
            "  [-0.8564942  -0.8799894 ]\n",
            "  [ 0.8564942   0.8799894 ]\n",
            "  [-0.08925104  0.6707406 ]\n",
            "  [ 0.08925104 -0.6707406 ]]\n",
            "\n",
            " [[ 0.8103945   0.96789026]\n",
            "  [-0.8103945  -0.96789026]\n",
            "  [ 0.7495179   0.72298   ]\n",
            "  [-0.7495179  -0.72298   ]\n",
            "  [-0.63020444  0.8756106 ]\n",
            "  [ 0.63020444 -0.8756106 ]]\n",
            "\n",
            " [[-0.4990232  -0.5945244 ]\n",
            "  [ 0.4990232   0.5945244 ]\n",
            "  [-0.6049762  -0.4783075 ]\n",
            "  [ 0.6049762   0.4783075 ]\n",
            "  [ 0.9018066  -0.306715  ]\n",
            "  [-0.9018066   0.306715  ]]\n",
            "\n",
            " [[ 0.65091896 -0.5936284 ]\n",
            "  [-0.65091896  0.5936284 ]\n",
            "  [ 0.36904025  0.24650311]\n",
            "  [-0.36904025 -0.24650311]\n",
            "  [-0.9035835  -0.6083534 ]\n",
            "  [ 0.9035835   0.6083534 ]]\n",
            "\n",
            " [[-0.2551396  -0.9653218 ]\n",
            "  [ 0.2551396   0.9653218 ]\n",
            "  [ 0.45302463 -0.40691686]\n",
            "  [-0.45302463  0.40691686]\n",
            "  [ 0.02040172 -0.3005917 ]\n",
            "  [-0.02040172  0.3005917 ]]\n",
            "\n",
            " [[-0.45542026 -0.6516881 ]\n",
            "  [ 0.45542026  0.6516881 ]\n",
            "  [-0.96917534  0.333395  ]\n",
            "  [ 0.96917534 -0.333395  ]\n",
            "  [-0.8812113  -0.573616  ]\n",
            "  [ 0.8812113   0.573616  ]]\n",
            "\n",
            " [[-0.20780993 -0.6904013 ]\n",
            "  [ 0.20780993  0.6904013 ]\n",
            "  [-0.04625607 -0.40278745]\n",
            "  [ 0.04625607  0.40278745]\n",
            "  [-0.394526   -0.8655286 ]\n",
            "  [ 0.394526    0.8655286 ]]\n",
            "\n",
            " [[-0.72387743 -0.9206426 ]\n",
            "  [ 0.72387743  0.9206426 ]\n",
            "  [ 0.8010497  -0.1069808 ]\n",
            "  [-0.8010497   0.1069808 ]\n",
            "  [-0.34335303  0.7448466 ]\n",
            "  [ 0.34335303 -0.7448466 ]]\n",
            "\n",
            " [[ 0.26772714 -0.7667258 ]\n",
            "  [-0.26772714  0.7667258 ]\n",
            "  [ 0.6269741  -0.87513804]\n",
            "  [-0.6269741   0.87513804]\n",
            "  [-0.7920344  -0.0638597 ]\n",
            "  [ 0.7920344   0.0638597 ]]\n",
            "\n",
            " [[ 0.21343946  0.4613471 ]\n",
            "  [-0.21343946 -0.4613471 ]\n",
            "  [ 0.5881345   0.08689284]\n",
            "  [-0.5881345  -0.08689284]\n",
            "  [ 0.44937205 -0.48233104]\n",
            "  [-0.44937205  0.48233104]]\n",
            "\n",
            " [[ 0.7425349   0.04719996]\n",
            "  [-0.7425349  -0.04719996]\n",
            "  [-0.8762233  -0.16705441]\n",
            "  [ 0.8762233   0.16705441]\n",
            "  [-0.5404768   0.8586395 ]\n",
            "  [ 0.5404768  -0.8586395 ]]\n",
            "\n",
            " [[ 0.4848938  -0.587553  ]\n",
            "  [-0.4848938   0.587553  ]\n",
            "  [-0.2914486   0.08516645]\n",
            "  [ 0.2914486  -0.08516645]\n",
            "  [ 0.15161872  0.7026255 ]\n",
            "  [-0.15161872 -0.7026255 ]]\n",
            "\n",
            " [[-0.79932356 -0.6721115 ]\n",
            "  [ 0.79932356  0.6721115 ]\n",
            "  [-0.29254174 -0.24217439]\n",
            "  [ 0.29254174  0.24217439]\n",
            "  [ 0.42819643  0.15252519]\n",
            "  [-0.42819643 -0.15252519]]\n",
            "\n",
            " [[ 0.29416656 -0.5688226 ]\n",
            "  [-0.29416656  0.5688226 ]\n",
            "  [-0.49425435  0.6013763 ]\n",
            "  [ 0.49425435 -0.6013763 ]\n",
            "  [-0.11697173  0.06905127]\n",
            "  [ 0.11697173 -0.06905127]]\n",
            "\n",
            " [[ 0.6294861  -0.29012465]\n",
            "  [-0.6294861   0.29012465]\n",
            "  [ 0.9219856  -0.06383061]\n",
            "  [-0.9219856   0.06383061]\n",
            "  [ 0.07590342  0.46380782]\n",
            "  [-0.07590342 -0.46380782]]\n",
            "\n",
            " [[-0.31221008 -0.9293411 ]\n",
            "  [ 0.31221008  0.9293411 ]\n",
            "  [ 0.64043665  0.4152155 ]\n",
            "  [-0.64043665 -0.4152155 ]\n",
            "  [ 0.62663364  0.94632316]\n",
            "  [-0.62663364 -0.94632316]]\n",
            "\n",
            " [[ 0.7335043   0.09904146]\n",
            "  [-0.7335043  -0.09904146]\n",
            "  [-0.67551064 -0.47272635]\n",
            "  [ 0.67551064  0.47272635]\n",
            "  [-0.14991021 -0.23038292]\n",
            "  [ 0.14991021  0.23038292]]\n",
            "\n",
            " [[ 0.53724265  0.73004866]\n",
            "  [-0.53724265 -0.73004866]\n",
            "  [-0.7150209  -0.21063781]\n",
            "  [ 0.7150209   0.21063781]\n",
            "  [-0.7859118  -0.29181242]\n",
            "  [ 0.7859118   0.29181242]]\n",
            "\n",
            " [[-0.37218642 -0.2104671 ]\n",
            "  [ 0.37218642  0.2104671 ]\n",
            "  [-0.4646616  -0.83125615]\n",
            "  [ 0.4646616   0.83125615]\n",
            "  [-0.14432883  0.7222185 ]\n",
            "  [ 0.14432883 -0.7222185 ]]\n",
            "\n",
            " [[-0.30933952  0.792119  ]\n",
            "  [ 0.30933952 -0.792119  ]\n",
            "  [ 0.37267923  0.00300956]\n",
            "  [-0.37267923 -0.00300956]\n",
            "  [-0.7411058   0.17748785]\n",
            "  [ 0.7411058  -0.17748785]]\n",
            "\n",
            " [[ 0.37974286  0.05085683]\n",
            "  [-0.37974286 -0.05085683]\n",
            "  [-0.28679776 -0.8405287 ]\n",
            "  [ 0.28679776  0.8405287 ]\n",
            "  [-0.17582488 -0.59641147]\n",
            "  [ 0.17582488  0.59641147]]\n",
            "\n",
            " [[ 0.2702899   0.12801194]\n",
            "  [-0.2702899  -0.12801194]\n",
            "  [-0.79913306 -0.17473936]\n",
            "  [ 0.79913306  0.17473936]\n",
            "  [-0.83624864 -0.7704375 ]\n",
            "  [ 0.83624864  0.7704375 ]]\n",
            "\n",
            " [[ 0.04299974  0.20403385]\n",
            "  [-0.04299974 -0.20403385]\n",
            "  [ 0.17281032 -0.34200168]\n",
            "  [-0.17281032  0.34200168]\n",
            "  [ 0.9426987   0.87322736]\n",
            "  [-0.9426987  -0.87322736]]\n",
            "\n",
            " [[-0.22800756 -0.6610391 ]\n",
            "  [ 0.22800756  0.6610391 ]\n",
            "  [-0.57638264  0.05960226]\n",
            "  [ 0.57638264 -0.05960226]\n",
            "  [-0.67931056  0.13396883]\n",
            "  [ 0.67931056 -0.13396883]]\n",
            "\n",
            " [[-0.44659686  0.35347056]\n",
            "  [ 0.44659686 -0.35347056]\n",
            "  [-0.72721267  0.0265646 ]\n",
            "  [ 0.72721267 -0.0265646 ]\n",
            "  [-0.6988361  -0.5503521 ]\n",
            "  [ 0.6988361   0.5503521 ]]\n",
            "\n",
            " [[-0.19331813 -0.8861072 ]\n",
            "  [ 0.19331813  0.8861072 ]\n",
            "  [-0.00723863  0.522305  ]\n",
            "  [ 0.00723863 -0.522305  ]\n",
            "  [ 0.45223308 -0.03544068]\n",
            "  [-0.45223308  0.03544068]]\n",
            "\n",
            " [[ 0.98222136  0.7888317 ]\n",
            "  [-0.98222136 -0.7888317 ]\n",
            "  [-0.6908412  -0.06802773]\n",
            "  [ 0.6908412   0.06802773]\n",
            "  [-0.3045528   0.6428511 ]\n",
            "  [ 0.3045528  -0.6428511 ]]\n",
            "\n",
            " [[-0.73481894  0.5572312 ]\n",
            "  [ 0.73481894 -0.5572312 ]\n",
            "  [ 0.36659884  0.10425687]\n",
            "  [-0.36659884 -0.10425687]\n",
            "  [-0.386523   -0.26072812]\n",
            "  [ 0.386523    0.26072812]]\n",
            "\n",
            " [[-0.53823066  0.7014656 ]\n",
            "  [ 0.53823066 -0.7014656 ]\n",
            "  [-0.1416781   0.6334162 ]\n",
            "  [ 0.1416781  -0.6334162 ]\n",
            "  [-0.47934127  0.12940145]\n",
            "  [ 0.47934127 -0.12940145]]\n",
            "\n",
            " [[-0.27425957 -0.41160846]\n",
            "  [ 0.27425957  0.41160846]\n",
            "  [-0.24818397 -0.9785104 ]\n",
            "  [ 0.24818397  0.9785104 ]\n",
            "  [ 0.3385613  -0.68481064]\n",
            "  [-0.3385613   0.68481064]]\n",
            "\n",
            " [[-0.7201793   0.47830415]\n",
            "  [ 0.7201793  -0.47830415]\n",
            "  [ 0.16101193  0.72783494]\n",
            "  [-0.16101193 -0.72783494]\n",
            "  [ 0.46885157 -0.49173164]\n",
            "  [-0.46885157  0.49173164]]\n",
            "\n",
            " [[-0.3551998   0.6064112 ]\n",
            "  [ 0.3551998  -0.6064112 ]\n",
            "  [-0.5729151  -0.9626703 ]\n",
            "  [ 0.5729151   0.9626703 ]\n",
            "  [ 0.10256529  0.53071404]\n",
            "  [-0.10256529 -0.53071404]]\n",
            "\n",
            " [[-0.504087    0.2868116 ]\n",
            "  [ 0.504087   -0.2868116 ]\n",
            "  [-0.48620105  0.9356966 ]\n",
            "  [ 0.48620105 -0.9356966 ]\n",
            "  [-0.55584335 -0.8035877 ]\n",
            "  [ 0.55584335  0.8035877 ]]\n",
            "\n",
            " [[-0.7463436  -0.49719906]\n",
            "  [ 0.7463436   0.49719906]\n",
            "  [-0.88563776  0.5685456 ]\n",
            "  [ 0.88563776 -0.5685456 ]\n",
            "  [-0.5567541  -0.66202235]\n",
            "  [ 0.5567541   0.66202235]]\n",
            "\n",
            " [[ 0.7330353  -0.54174376]\n",
            "  [-0.7330353   0.54174376]\n",
            "  [ 0.07852793 -0.3963952 ]\n",
            "  [-0.07852793  0.3963952 ]\n",
            "  [-0.6968045   0.6135545 ]\n",
            "  [ 0.6968045  -0.6135545 ]]\n",
            "\n",
            " [[ 0.7080457  -0.9479401 ]\n",
            "  [-0.7080457   0.9479401 ]\n",
            "  [ 0.35896468  0.55078244]\n",
            "  [-0.35896468 -0.55078244]\n",
            "  [-0.36044478  0.8729019 ]\n",
            "  [ 0.36044478 -0.8729019 ]]\n",
            "\n",
            " [[ 0.6991017   0.14074588]\n",
            "  [-0.6991017  -0.14074588]\n",
            "  [-0.24005866  0.02483606]\n",
            "  [ 0.24005866 -0.02483606]\n",
            "  [ 0.40413594 -0.82036996]\n",
            "  [-0.40413594  0.82036996]]\n",
            "\n",
            " [[ 0.15284586  0.58173084]\n",
            "  [-0.15284586 -0.58173084]\n",
            "  [-0.7215147   0.99961066]\n",
            "  [ 0.7215147  -0.99961066]\n",
            "  [ 0.5908582  -0.44129467]\n",
            "  [-0.5908582   0.44129467]]\n",
            "\n",
            " [[-0.19184804 -0.6869981 ]\n",
            "  [ 0.19184804  0.6869981 ]\n",
            "  [ 0.31702137  0.29949284]\n",
            "  [-0.31702137 -0.29949284]\n",
            "  [-0.9277563  -0.1620431 ]\n",
            "  [ 0.9277563   0.1620431 ]]\n",
            "\n",
            " [[-0.2969401   0.03188467]\n",
            "  [ 0.2969401  -0.03188467]\n",
            "  [-0.6689763  -0.17665195]\n",
            "  [ 0.6689763   0.17665195]\n",
            "  [ 0.17021632 -0.46552014]\n",
            "  [-0.17021632  0.46552014]]\n",
            "\n",
            " [[ 0.88624287 -0.16856933]\n",
            "  [-0.88624287  0.16856933]\n",
            "  [ 0.8100424  -0.3407514 ]\n",
            "  [-0.8100424   0.3407514 ]\n",
            "  [-0.8974323  -0.5380535 ]\n",
            "  [ 0.8974323   0.5380535 ]]\n",
            "\n",
            " [[-0.3625214  -0.13255262]\n",
            "  [ 0.3625214   0.13255262]\n",
            "  [ 0.7687626   0.08028674]\n",
            "  [-0.7687626  -0.08028674]\n",
            "  [ 0.00955629 -0.949517  ]\n",
            "  [-0.00955629  0.949517  ]]\n",
            "\n",
            " [[-0.07866573 -0.5117066 ]\n",
            "  [ 0.07866573  0.5117066 ]\n",
            "  [-0.8548415   0.05004573]\n",
            "  [ 0.8548415  -0.05004573]\n",
            "  [-0.85184216  0.10370064]\n",
            "  [ 0.85184216 -0.10370064]]]\n",
            "\n",
            "Primaries After NECL:\n",
            " [[[-0.02993535  0.07389835]\n",
            "  [ 0.02993535 -0.07389835]\n",
            "  [ 0.19396394 -0.03784306]\n",
            "  [-0.19396394  0.03784306]\n",
            "  [ 0.09898333  0.13437942]\n",
            "  [ 0.09898333  0.13437942]]\n",
            "\n",
            " [[ 0.02464057 -0.07240337]\n",
            "  [-0.02464057  0.07240337]\n",
            "  [ 0.15978728  0.012684  ]\n",
            "  [-0.15978728 -0.012684  ]\n",
            "  [ 0.13455382 -0.15571056]\n",
            "  [ 0.13455382 -0.15571056]]\n",
            "\n",
            " [[-0.15569636  0.13417955]\n",
            "  [ 0.15569636 -0.13417955]\n",
            "  [ 0.09630214 -0.06551517]\n",
            "  [-0.09630214  0.06551517]\n",
            "  [ 0.14506046 -0.00146453]\n",
            "  [ 0.14506046 -0.00146453]]\n",
            "\n",
            " [[ 0.04121532 -0.11614185]\n",
            "  [-0.04121532  0.11614185]\n",
            "  [ 0.10501318 -0.01516086]\n",
            "  [-0.10501318  0.01516086]\n",
            "  [-0.04365852  0.17244478]\n",
            "  [-0.04365852  0.17244478]]\n",
            "\n",
            " [[ 0.15605368 -0.14175661]\n",
            "  [-0.15605368  0.14175661]\n",
            "  [ 0.06313757 -0.0246956 ]\n",
            "  [-0.06313757  0.0246956 ]\n",
            "  [-0.10826404  0.11716931]\n",
            "  [-0.10826404  0.11716931]]\n",
            "\n",
            " [[-0.18539295 -0.09674062]\n",
            "  [ 0.18539295  0.09674062]\n",
            "  [ 0.02653966  0.1483217 ]\n",
            "  [-0.02653966 -0.1483217 ]\n",
            "  [ 0.08201819 -0.00508126]\n",
            "  [ 0.08201819 -0.00508126]]\n",
            "\n",
            " [[-0.09894028  0.04590354]\n",
            "  [ 0.09894028 -0.04590354]\n",
            "  [ 0.17278887  0.06370845]\n",
            "  [-0.17278887 -0.06370845]\n",
            "  [-0.0768021  -0.13897294]\n",
            "  [-0.0768021  -0.13897294]]\n",
            "\n",
            " [[-0.13466735  0.07779292]\n",
            "  [ 0.13466735 -0.07779292]\n",
            "  [ 0.          0.        ]\n",
            "  [ 0.          0.        ]\n",
            "  [ 0.1844916   0.02955562]\n",
            "  [ 0.1844916   0.02955562]]\n",
            "\n",
            " [[ 0.03211566 -0.04800937]\n",
            "  [-0.03211566  0.04800937]\n",
            "  [-0.19340985 -0.09140122]\n",
            "  [ 0.19340985  0.09140122]\n",
            "  [-0.16071282  0.10242212]\n",
            "  [-0.16071282  0.10242212]]\n",
            "\n",
            " [[-0.20269337  0.0824974 ]\n",
            "  [ 0.20269337 -0.0824974 ]\n",
            "  [-0.01701303 -0.02009562]\n",
            "  [ 0.01701303  0.02009562]\n",
            "  [ 0.16085806 -0.14171205]\n",
            "  [ 0.16085806 -0.14171205]]\n",
            "\n",
            " [[-0.1234571  -0.10642283]\n",
            "  [ 0.1234571   0.10642283]\n",
            "  [-0.16296555  0.16368538]\n",
            "  [ 0.16296555 -0.16368538]\n",
            "  [-0.04559214  0.00568017]\n",
            "  [-0.04559214  0.00568017]]\n",
            "\n",
            " [[-0.06819186  0.02592182]\n",
            "  [ 0.06819186 -0.02592182]\n",
            "  [-0.0817057  -0.19004402]\n",
            "  [ 0.0817057   0.19004402]\n",
            "  [-0.11447705 -0.08484383]\n",
            "  [-0.11447705 -0.08484383]]\n",
            "\n",
            " [[-0.21835625  0.07125442]\n",
            "  [ 0.21835625 -0.07125442]\n",
            "  [-0.16040312  0.1418162 ]\n",
            "  [ 0.16040312 -0.1418162 ]\n",
            "  [ 0.01851551  0.01354627]\n",
            "  [ 0.01851551  0.01354627]]\n",
            "\n",
            " [[ 0.15851003  0.03613915]\n",
            "  [-0.15851003 -0.03613915]\n",
            "  [ 0.14598611 -0.01118089]\n",
            "  [-0.14598611  0.01118089]\n",
            "  [-0.00914021  0.14895381]\n",
            "  [-0.00914021  0.14895381]]\n",
            "\n",
            " [[-0.18752867  0.09205724]\n",
            "  [ 0.18752867 -0.09205724]\n",
            "  [ 0.13304734 -0.1075145 ]\n",
            "  [-0.13304734  0.1075145 ]\n",
            "  [-0.016987    0.06524786]\n",
            "  [-0.016987    0.06524786]]\n",
            "\n",
            " [[ 0.20033914  0.09311714]\n",
            "  [-0.20033914 -0.09311714]\n",
            "  [ 0.1187973  -0.03519909]\n",
            "  [-0.1187973   0.03519909]\n",
            "  [-0.01935057  0.10919175]\n",
            "  [-0.01935057  0.10919175]]\n",
            "\n",
            " [[ 0.07990232  0.11688598]\n",
            "  [-0.07990232 -0.11688598]\n",
            "  [-0.1605722   0.13452667]\n",
            "  [ 0.1605722  -0.13452667]\n",
            "  [ 0.07816783 -0.03380078]\n",
            "  [ 0.07816783 -0.03380078]]\n",
            "\n",
            " [[ 0.03533955 -0.01211552]\n",
            "  [-0.03533955  0.01211552]\n",
            "  [-0.2286077   0.13112499]\n",
            "  [ 0.2286077  -0.13112499]\n",
            "  [-0.16505148  0.06695773]\n",
            "  [-0.16505148  0.06695773]]\n",
            "\n",
            " [[-0.02165127  0.10841843]\n",
            "  [ 0.02165127 -0.10841843]\n",
            "  [ 0.11429288 -0.01796192]\n",
            "  [-0.11429288  0.01796192]\n",
            "  [ 0.23903269  0.05683904]\n",
            "  [ 0.23903269  0.05683904]]\n",
            "\n",
            " [[-0.10048044  0.05355777]\n",
            "  [ 0.10048044 -0.05355777]\n",
            "  [ 0.16016492  0.04754668]\n",
            "  [-0.16016492 -0.04754668]\n",
            "  [-0.1624464   0.10970277]\n",
            "  [-0.1624464   0.10970277]]\n",
            "\n",
            " [[-0.0508529   0.06128357]\n",
            "  [ 0.0508529  -0.06128357]\n",
            "  [-0.12702218 -0.10908267]\n",
            "  [ 0.12702218  0.10908267]\n",
            "  [-0.05938888  0.15267748]\n",
            "  [-0.05938888  0.15267748]]\n",
            "\n",
            " [[ 0.04280825 -0.11393851]\n",
            "  [-0.04280825  0.11393851]\n",
            "  [ 0.16072096  0.11676443]\n",
            "  [-0.16072096 -0.11676443]\n",
            "  [-0.0167652   0.08909124]\n",
            "  [-0.0167652   0.08909124]]\n",
            "\n",
            " [[ 0.12558267  0.10605821]\n",
            "  [-0.12558267 -0.10605821]\n",
            "  [-0.11617525 -0.07923971]\n",
            "  [ 0.11617525  0.07923971]\n",
            "  [-0.09768509  0.09597162]\n",
            "  [-0.09768509  0.09597162]]\n",
            "\n",
            " [[-0.10466026 -0.08816896]\n",
            "  [ 0.10466026  0.08816896]\n",
            "  [ 0.12687151  0.07092804]\n",
            "  [-0.12687151 -0.07092804]\n",
            "  [ 0.18903227 -0.04546138]\n",
            "  [ 0.18903227 -0.04546138]]\n",
            "\n",
            " [[ 0.1413332  -0.09114166]\n",
            "  [-0.1413332   0.09114166]\n",
            "  [-0.08018999 -0.0378751 ]\n",
            "  [ 0.08018999  0.0378751 ]\n",
            "  [-0.19610217 -0.09335876]\n",
            "  [-0.19610217 -0.09335876]]\n",
            "\n",
            " [[-0.07004413 -0.18739198]\n",
            "  [ 0.07004413  0.18739198]\n",
            "  [-0.1244325   0.07903195]\n",
            "  [ 0.1244325  -0.07903195]\n",
            "  [ 0.00560849 -0.05843072]\n",
            "  [ 0.00560849 -0.05843072]]\n",
            "\n",
            " [[-0.08317333 -0.08415823]\n",
            "  [ 0.08317333  0.08415823]\n",
            "  [ 0.1768928  -0.04302807]\n",
            "  [-0.1768928   0.04302807]\n",
            "  [-0.16084535 -0.07403459]\n",
            "  [-0.16084535 -0.07403459]]\n",
            "\n",
            " [[-0.05244467 -0.12320311]\n",
            "  [ 0.05244467  0.12320311]\n",
            "  [ 0.01168037  0.07191984]\n",
            "  [-0.01168037 -0.07191984]\n",
            "  [-0.09951866 -0.1543815 ]\n",
            "  [-0.09951866 -0.1543815 ]]\n",
            "\n",
            " [[-0.13551643 -0.12187174]\n",
            "  [ 0.13551643  0.12187174]\n",
            "  [-0.15000898  0.01416604]\n",
            "  [ 0.15000898 -0.01416604]\n",
            "  [-0.06431835  0.09866107]\n",
            "  [-0.06431835  0.09866107]]\n",
            "\n",
            " [[ 0.05232346 -0.10595686]\n",
            "  [-0.05232346  0.10595686]\n",
            "  [-0.12247019  0.12087664]\n",
            "  [ 0.12247019 -0.12087664]\n",
            "  [-0.1547375  -0.00882193]\n",
            "  [-0.1547375  -0.00882193]]\n",
            "\n",
            " [[ 0.06352284  0.09708853]\n",
            "  [-0.06352284 -0.09708853]\n",
            "  [-0.1749379  -0.01827579]\n",
            "  [ 0.1749379   0.01827579]\n",
            "  [ 0.13367395 -0.10145441]\n",
            "  [ 0.13367395 -0.10145441]]\n",
            "\n",
            " [[ 0.14686552  0.0066013 ]\n",
            "  [-0.14686552 -0.0066013 ]\n",
            "  [ 0.17326169  0.02335773]\n",
            "  [-0.17326169 -0.02335773]\n",
            "  [-0.10688656  0.12007204]\n",
            "  [-0.10688656  0.12007204]]\n",
            "\n",
            " [[ 0.14242198 -0.12202884]\n",
            "  [-0.14242198  0.12202884]\n",
            "  [ 0.08568537 -0.0177051 ]\n",
            "  [-0.08568537  0.0177051 ]\n",
            "  [ 0.04454797  0.14597686]\n",
            "  [ 0.04454797  0.14597686]]\n",
            "\n",
            " [[-0.22282203 -0.1324835 ]\n",
            "  [ 0.22282203  0.1324835 ]\n",
            "  [ 0.08167803  0.0478113 ]\n",
            "  [-0.08167803 -0.0478113 ]\n",
            "  [ 0.11952039  0.03010409]\n",
            "  [ 0.11952039  0.03010409]]\n",
            "\n",
            " [[ 0.09918073 -0.13561127]\n",
            "  [-0.09918073  0.13561127]\n",
            "  [ 0.1665598  -0.14330158]\n",
            "  [-0.1665598   0.14330158]\n",
            "  [-0.03948511  0.01648197]\n",
            "  [-0.03948511  0.01648197]]\n",
            "\n",
            " [[ 0.1580785  -0.05151768]\n",
            "  [-0.1580785   0.05151768]\n",
            "  [-0.23138744  0.01132738]\n",
            "  [ 0.23138744 -0.01132738]\n",
            "  [ 0.01907595  0.08242291]\n",
            "  [ 0.01907595  0.08242291]]\n",
            "\n",
            " [[-0.05686853 -0.11969753]\n",
            "  [ 0.05686853  0.11969753]\n",
            "  [-0.1166591  -0.05348118]\n",
            "  [ 0.1166591   0.05348118]\n",
            "  [ 0.11410278  0.12184479]\n",
            "  [ 0.11410278  0.12184479]]\n",
            "\n",
            " [[ 0.20892473  0.01994753]\n",
            "  [-0.20892473 -0.01994753]\n",
            "  [ 0.19239755  0.09520552]\n",
            "  [-0.19239755 -0.09520552]\n",
            "  [-0.04275886 -0.04646545]\n",
            "  [-0.04275886 -0.04646545]]\n",
            "\n",
            " [[ 0.11309746  0.10867237]\n",
            "  [-0.11309746 -0.10867237]\n",
            "  [ 0.1505268   0.0313557 ]\n",
            "  [-0.1505268  -0.0313557 ]\n",
            "  [-0.16542359 -0.04343225]\n",
            "  [-0.16542359 -0.04343225]]\n",
            "\n",
            " [[-0.09223892 -0.03688272]\n",
            "  [ 0.09223892  0.03688272]\n",
            "  [ 0.11506241  0.14555146]\n",
            "  [-0.11506241 -0.14555146]\n",
            "  [-0.03575804  0.12652439]\n",
            "  [-0.03575804  0.12652439]]\n",
            "\n",
            " [[-0.08167812  0.14789236]\n",
            "  [ 0.08167812 -0.14789236]\n",
            "  [ 0.          0.        ]\n",
            "  [ 0.          0.        ]\n",
            "  [-0.19562685  0.0331285 ]\n",
            "  [-0.19562685  0.0331285 ]]\n",
            "\n",
            " [[ 0.10520909  0.00996318]\n",
            "  [-0.10520909 -0.00996318]\n",
            "  [ 0.07939998  0.16454405]\n",
            "  [-0.07939998 -0.16454405]\n",
            "  [-0.0487032  -0.11681756]\n",
            "  [-0.0487032  -0.11681756]]\n",
            "\n",
            " [[ 0.06291211  0.0210688 ]\n",
            "  [-0.06291211 -0.0210688 ]\n",
            "  [ 0.18578888  0.02872608]\n",
            "  [-0.18578888 -0.02872608]\n",
            "  [-0.1943363  -0.12660208]\n",
            "  [-0.1943363  -0.12660208]]\n",
            "\n",
            " [[ 0.01202425  0.04034405]\n",
            "  [-0.01202425 -0.04034405]\n",
            "  [-0.04830503  0.06759832]\n",
            "  [ 0.04830503 -0.06759832]\n",
            "  [ 0.26292834  0.17221732]\n",
            "  [ 0.26292834  0.17221732]]\n",
            "\n",
            " [[-0.06064925 -0.12433356]\n",
            "  [ 0.06064925  0.12433356]\n",
            "  [ 0.15329342 -0.01120883]\n",
            "  [-0.15329342  0.01120883]\n",
            "  [-0.1806185   0.02518736]\n",
            "  [-0.1806185   0.02518736]]\n",
            "\n",
            " [[-0.1070933   0.0599356 ]\n",
            "  [ 0.1070933  -0.0599356 ]\n",
            "  [ 0.17429872 -0.00450216]\n",
            "  [-0.17429872  0.00450216]\n",
            "  [-0.16746973 -0.09325811]\n",
            "  [-0.16746973 -0.09325811]]\n",
            "\n",
            " [[-0.05380756 -0.1743982 ]\n",
            "  [ 0.05380756  0.1743982 ]\n",
            "  [ 0.00201631 -0.10287496]\n",
            "  [-0.00201631  0.10287496]\n",
            "  [ 0.12594083 -0.00697897]\n",
            "  [ 0.12594083 -0.00697897]]\n",
            "\n",
            " [[ 0.1930653   0.10963879]\n",
            "  [-0.1930653  -0.10963879]\n",
            "  [ 0.13590284  0.00946284]\n",
            "  [-0.13590284 -0.00946284]\n",
            "  [-0.0599282   0.08944664]\n",
            "  [-0.0599282   0.08944664]]\n",
            "\n",
            " [[-0.21749382  0.11662374]\n",
            "  [ 0.21749382 -0.11662374]\n",
            "  [-0.10864782 -0.0218484 ]\n",
            "  [ 0.10864782  0.0218484 ]\n",
            "  [-0.11453512 -0.05463063]\n",
            "  [-0.11453512 -0.05463063]]\n",
            "\n",
            " [[-0.13896535  0.1280647 ]\n",
            "  [ 0.13896535 -0.1280647 ]\n",
            "  [ 0.03660335 -0.1157157 ]\n",
            "  [-0.03660335  0.1157157 ]\n",
            "  [-0.12383503  0.02363866]\n",
            "  [-0.12383503  0.02363866]]\n",
            "\n",
            " [[-0.06342909 -0.06731255]\n",
            "  [ 0.06342909  0.06731255]\n",
            "  [ 0.05735615  0.159903  ]\n",
            "  [-0.05735615 -0.159903  ]\n",
            "  [ 0.07826749 -0.11194369]\n",
            "  [ 0.07826749 -0.11194369]]\n",
            "\n",
            " [[-0.16486324  0.07742342]\n",
            "  [ 0.16486324 -0.07742342]\n",
            "  [-0.03687943 -0.11788104]\n",
            "  [ 0.03687943  0.11788104]\n",
            "  [ 0.10737899 -0.07963374]\n",
            "  [ 0.10737899 -0.07963374]]\n",
            "\n",
            " [[-0.07880479  0.0951332 ]\n",
            "  [ 0.07880479 -0.0951332 ]\n",
            "  [ 0.12701784  0.1509166 ]\n",
            "  [-0.12701784 -0.1509166 ]\n",
            "  [ 0.02276325  0.08328742]\n",
            "  [ 0.02276325  0.08328742]]\n",
            "\n",
            " [[-0.10123164  0.04072795]\n",
            "  [ 0.10123164 -0.04072795]\n",
            "  [ 0.09758793 -0.13280067]\n",
            "  [-0.09758793  0.13280067]\n",
            "  [-0.11157178 -0.11405656]\n",
            "  [-0.11157178 -0.11405656]]\n",
            "\n",
            " [[-0.139028   -0.06549056]\n",
            "  [ 0.139028    0.06549056]\n",
            "  [ 0.16493234 -0.07486865]\n",
            "  [-0.16493234  0.07486865]\n",
            "  [-0.10372946 -0.08721603]\n",
            "  [-0.10372946 -0.08721603]]\n",
            "\n",
            " [[ 0.17118128 -0.08945616]\n",
            "  [-0.17118128  0.08945616]\n",
            "  [-0.01836003  0.06553341]\n",
            "  [ 0.01836003 -0.06553341]\n",
            "  [-0.16272277  0.10131542]\n",
            "  [-0.16272277  0.10131542]]\n",
            "\n",
            " [[ 0.13324    -0.12613606]\n",
            "  [-0.13324     0.12613606]\n",
            "  [-0.06760392 -0.07334749]\n",
            "  [ 0.06760392  0.07334749]\n",
            "  [-0.06786013  0.11620542]\n",
            "  [-0.06786013  0.11620542]]\n",
            "\n",
            " [[ 0.19600855  0.02790329]\n",
            "  [-0.19600855 -0.02790329]\n",
            "  [ 0.06738948 -0.00492995]\n",
            "  [-0.06738948  0.00492995]\n",
            "  [ 0.11330815 -0.16264038]\n",
            "  [ 0.11330815 -0.16264038]]\n",
            "\n",
            " [[ 0.0311756   0.0839012 ]\n",
            "  [-0.0311756  -0.0839012 ]\n",
            "  [ 0.14700249 -0.14401087]\n",
            "  [-0.14700249  0.14401087]\n",
            "  [ 0.12046223 -0.06361819]\n",
            "  [ 0.12046223 -0.06361819]]\n",
            "\n",
            " [[-0.04810372 -0.12180407]\n",
            "  [ 0.04810372  0.12180407]\n",
            "  [-0.07951629 -0.05311767]\n",
            "  [ 0.07951629  0.05311767]\n",
            "  [-0.23239544 -0.02870181]\n",
            "  [-0.23239544 -0.02870181]]\n",
            "\n",
            " [[-0.10478778  0.00795626]\n",
            "  [ 0.10478778 -0.00795626]\n",
            "  [ 0.23577307  0.04402374]\n",
            "  [-0.23577307 -0.04402374]\n",
            "  [ 0.06005329 -0.11613391]\n",
            "  [ 0.06005329 -0.11613391]]\n",
            "\n",
            " [[ 0.16430645 -0.02209863]\n",
            "  [-0.16430645  0.02209863]\n",
            "  [-0.15019217  0.04467476]\n",
            "  [ 0.15019217 -0.04467476]\n",
            "  [-0.1663573  -0.07052622]\n",
            "  [-0.1663573  -0.07052622]]\n",
            "\n",
            " [[-0.09018473 -0.023317  ]\n",
            "  [ 0.09018473  0.023317  ]\n",
            "  [-0.19106624 -0.01410979]\n",
            "  [ 0.19106624  0.01410979]\n",
            "  [ 0.00237565 -0.16690971]\n",
            "  [ 0.00237565 -0.16690971]]\n",
            "\n",
            " [[-0.01848675 -0.08503171]\n",
            "  [ 0.01848675  0.08503171]\n",
            "  [ 0.20067304 -0.00830722]\n",
            "  [-0.20067304  0.00830722]\n",
            "  [-0.19996922  0.01721355]\n",
            "  [-0.19996922  0.01721355]]]\n",
            "\n",
            "Pairs[0]:\n",
            " [[-0.02993535  0.07389835]\n",
            " [ 0.02993535 -0.07389835]\n",
            " [ 0.19396394 -0.03784306]\n",
            " [-0.19396394  0.03784306]\n",
            " [ 0.09898333  0.13437942]\n",
            " [ 0.09898333  0.13437942]\n",
            " [ 0.1640286   0.03605529]\n",
            " [-0.00580638 -0.00279654]\n",
            " [-0.22389929  0.11174141]\n",
            " [ 0.00580638  0.00279654]\n",
            " [ 0.22389929 -0.11174141]\n",
            " [ 0.00580638  0.00279654]\n",
            " [-0.1640286  -0.03605529]\n",
            " [-0.00580638 -0.00279654]\n",
            " [ 0.06904797  0.20827776]\n",
            " [-0.0029631   0.00993042]\n",
            " [ 0.06904797  0.20827776]\n",
            " [-0.0029631   0.00993042]\n",
            " [ 0.12891868  0.06048106]\n",
            " [ 0.0029631  -0.00993042]\n",
            " [ 0.12891868  0.06048106]\n",
            " [ 0.0029631  -0.00993042]\n",
            " [ 0.29294726  0.09653635]\n",
            " [ 0.0191992  -0.00508533]\n",
            " [ 0.29294726  0.09653635]\n",
            " [ 0.0191992  -0.00508533]\n",
            " [-0.09498062  0.17222248]\n",
            " [-0.0191992   0.00508533]\n",
            " [-0.09498062  0.17222248]\n",
            " [-0.0191992   0.00508533]]\n",
            "\n",
            "Triplets[0]:\n",
            " [[[-0.02993535  0.07389835]\n",
            "  [ 0.02993535 -0.07389835]\n",
            "  [ 0.19396394 -0.03784306]]\n",
            "\n",
            " [[-0.19396394  0.03784306]\n",
            "  [ 0.09898333  0.13437942]\n",
            "  [ 0.09898333  0.13437942]]\n",
            "\n",
            " [[ 0.1640286   0.03605529]\n",
            "  [-0.00580638 -0.00279654]\n",
            "  [-0.22389929  0.11174141]]\n",
            "\n",
            " [[ 0.00580638  0.00279654]\n",
            "  [ 0.22389929 -0.11174141]\n",
            "  [ 0.00580638  0.00279654]]\n",
            "\n",
            " [[-0.1640286  -0.03605529]\n",
            "  [-0.00580638 -0.00279654]\n",
            "  [ 0.06904797  0.20827776]]\n",
            "\n",
            " [[-0.0029631   0.00993042]\n",
            "  [ 0.06904797  0.20827776]\n",
            "  [-0.0029631   0.00993042]]\n",
            "\n",
            " [[ 0.12891868  0.06048106]\n",
            "  [ 0.0029631  -0.00993042]\n",
            "  [ 0.12891868  0.06048106]]\n",
            "\n",
            " [[ 0.0029631  -0.00993042]\n",
            "  [ 0.29294726  0.09653635]\n",
            "  [ 0.0191992  -0.00508533]]\n",
            "\n",
            " [[ 0.29294726  0.09653635]\n",
            "  [ 0.0191992  -0.00508533]\n",
            "  [-0.09498062  0.17222248]]\n",
            "\n",
            " [[-0.0191992   0.00508533]\n",
            "  [-0.09498062  0.17222248]\n",
            "  [-0.0191992   0.00508533]]]\n",
            "\n",
            "Bits (all qubits):\n",
            " [[1 1 1 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 1]\n",
            " [0 1 0 ... 1 1 1]\n",
            " ...\n",
            " [1 0 1 ... 0 0 1]\n",
            " [0 1 1 ... 1 1 0]\n",
            " [0 1 0 ... 0 0 0]]\n",
            "\n",
            "Primaries Out (promoted):\n",
            " [[[-1.91991962e-02  5.08532813e-03]\n",
            "  [ 1.91991962e-02 -5.08532813e-03]\n",
            "  [-9.49806198e-02  1.72222480e-01]\n",
            "  [ 9.49806198e-02 -1.72222480e-01]\n",
            "  [-1.91991962e-02  5.08532813e-03]\n",
            "  [ 1.91991962e-02 -5.08532813e-03]]\n",
            "\n",
            " [[-2.14999896e-02  1.97503227e-03]\n",
            "  [ 2.14999896e-02 -1.97503227e-03]\n",
            "  [-2.52334625e-02 -1.68394566e-01]\n",
            "  [ 2.52334625e-02  1.68394566e-01]\n",
            "  [-2.14999896e-02  1.97503227e-03]\n",
            "  [ 2.14999896e-02 -1.97503227e-03]]\n",
            "\n",
            " [[-1.39696337e-02 -9.59490644e-05]\n",
            "  [ 1.39696337e-02  9.59490644e-05]\n",
            "  [ 4.87583205e-02  6.40506372e-02]\n",
            "  [-4.87583205e-02 -6.40506372e-02]\n",
            "  [-1.39696337e-02 -9.59490644e-05]\n",
            "  [ 1.39696337e-02  9.59490644e-05]]\n",
            "\n",
            " [[ 4.58472036e-03  2.61441176e-03]\n",
            "  [-4.58472036e-03 -2.61441176e-03]\n",
            "  [-1.48671702e-01  1.87605634e-01]\n",
            "  [ 1.48671702e-01 -1.87605634e-01]\n",
            "  [ 4.58472036e-03  2.61441176e-03]\n",
            "  [-4.58472036e-03 -2.61441176e-03]]\n",
            "\n",
            " [[ 6.83552865e-03  2.89356662e-03]\n",
            "  [-6.83552865e-03 -2.89356662e-03]\n",
            "  [-1.71401620e-01  1.41864911e-01]\n",
            "  [ 1.71401620e-01 -1.41864911e-01]\n",
            "  [ 6.83552865e-03  2.89356662e-03]\n",
            "  [-6.83552865e-03 -2.89356662e-03]]\n",
            "\n",
            " [[-2.17673462e-03  7.53661443e-04]\n",
            "  [ 2.17673462e-03 -7.53661443e-04]\n",
            "  [ 5.54785319e-02 -1.53402969e-01]\n",
            "  [-5.54785319e-02  1.53402969e-01]\n",
            "  [-2.17673462e-03  7.53661443e-04]\n",
            "  [ 2.17673462e-03 -7.53661443e-04]]\n",
            "\n",
            " [[ 1.32705495e-02  8.85375123e-03]\n",
            "  [-1.32705495e-02 -8.85375123e-03]\n",
            "  [-2.49590978e-01 -2.02681392e-01]\n",
            "  [ 2.49590978e-01  2.02681392e-01]\n",
            "  [ 1.32705495e-02  8.85375123e-03]\n",
            "  [-1.32705495e-02 -8.85375123e-03]]\n",
            "\n",
            " [[-1.34667352e-01  7.77929202e-02]\n",
            "  [ 1.34667352e-01 -7.77929202e-02]\n",
            "  [ 1.34667352e-01 -7.77929202e-02]\n",
            "  [-1.34667352e-01  7.77929202e-02]\n",
            "  [ 1.84491605e-01  2.95556169e-02]\n",
            "  [-1.84491605e-01 -2.95556169e-02]]\n",
            "\n",
            " [[-3.10834423e-02  9.36150644e-03]\n",
            "  [ 3.10834423e-02 -9.36150644e-03]\n",
            "  [ 3.26970220e-02  1.93823338e-01]\n",
            "  [-3.26970220e-02 -1.93823338e-01]\n",
            "  [-3.10834423e-02  9.36150644e-03]\n",
            "  [ 3.10834423e-02 -9.36150644e-03]]\n",
            "\n",
            " [[ 2.73668347e-03 -2.84779142e-03]\n",
            "  [-2.73668347e-03  2.84779142e-03]\n",
            "  [ 1.77871093e-01 -1.21616438e-01]\n",
            "  [-1.77871093e-01  1.21616438e-01]\n",
            "  [ 2.73668347e-03 -2.84779142e-03]\n",
            "  [-2.73668347e-03  2.84779142e-03]]\n",
            "\n",
            " [[-7.42994761e-03 -9.29760223e-04]\n",
            "  [ 7.42994761e-03  9.29760223e-04]\n",
            "  [ 1.17373414e-01 -1.58005208e-01]\n",
            "  [-1.17373414e-01  1.58005208e-01]\n",
            "  [-7.42994761e-03 -9.29760223e-04]\n",
            "  [ 7.42994761e-03  9.29760223e-04]]\n",
            "\n",
            " [[-9.35342722e-03 -1.61240622e-02]\n",
            "  [ 9.35342722e-03  1.61240622e-02]\n",
            "  [-3.27713415e-02  1.05200186e-01]\n",
            "  [ 3.27713415e-02 -1.05200186e-01]\n",
            "  [-9.35342722e-03 -1.61240622e-02]\n",
            "  [ 9.35342722e-03  1.61240622e-02]]\n",
            "\n",
            " [[ 2.96994555e-03 -1.92108017e-03]\n",
            "  [-2.96994555e-03  1.92108017e-03]\n",
            "  [ 1.78918630e-01 -1.28269926e-01]\n",
            "  [-1.78918630e-01  1.28269926e-01]\n",
            "  [ 2.96994555e-03 -1.92108017e-03]\n",
            "  [-2.96994555e-03  1.92108017e-03]]\n",
            "\n",
            " [[ 1.33434311e-03  1.66543643e-03]\n",
            "  [-1.33434311e-03 -1.66543643e-03]\n",
            "  [-1.55126318e-01  1.60134703e-01]\n",
            "  [ 1.55126318e-01 -1.60134703e-01]\n",
            "  [ 1.33434311e-03  1.66543643e-03]\n",
            "  [-1.33434311e-03 -1.66543643e-03]]\n",
            "\n",
            " [[ 2.26007472e-03  7.01509044e-03]\n",
            "  [-2.26007472e-03 -7.01509044e-03]\n",
            "  [-1.50034338e-01  1.72762364e-01]\n",
            "  [ 1.50034338e-01 -1.72762364e-01]\n",
            "  [ 2.26007472e-03  7.01509044e-03]\n",
            "  [-2.26007472e-03 -7.01509044e-03]]\n",
            "\n",
            " [[ 2.29879515e-03  3.84344975e-03]\n",
            "  [-2.29879515e-03 -3.84344975e-03]\n",
            "  [-1.38147876e-01  1.44390836e-01]\n",
            "  [ 1.38147876e-01 -1.44390836e-01]\n",
            "  [ 2.29879515e-03  3.84344975e-03]\n",
            "  [-2.29879515e-03 -3.84344975e-03]]\n",
            "\n",
            " [[ 1.25515815e-02  4.54710657e-03]\n",
            "  [-1.25515815e-02 -4.54710657e-03]\n",
            "  [ 2.38740027e-01 -1.68327451e-01]\n",
            "  [-2.38740027e-01  1.68327451e-01]\n",
            "  [ 1.25515815e-02  4.54710657e-03]\n",
            "  [-1.25515815e-02 -4.54710657e-03]]\n",
            "\n",
            " [[-3.77320386e-02 -8.77983123e-03]\n",
            "  [ 3.77320386e-02  8.77983123e-03]\n",
            "  [ 6.35562241e-02 -6.41672611e-02]\n",
            "  [-6.35562241e-02  6.41672611e-02]\n",
            "  [-3.77320386e-02 -8.77983123e-03]\n",
            "  [ 3.77320386e-02  8.77983123e-03]]\n",
            "\n",
            " [[-2.73197349e-02  1.02093839e-03]\n",
            "  [ 2.73197349e-02 -1.02093839e-03]\n",
            "  [ 1.24739803e-01  7.48009607e-02]\n",
            "  [-1.24739803e-01 -7.48009607e-02]\n",
            "  [-2.73197349e-02  1.02093839e-03]\n",
            "  [ 2.73197349e-02 -1.02093839e-03]]\n",
            "\n",
            " [[ 2.60182135e-02 -5.21600340e-03]\n",
            "  [-2.60182135e-02  5.21600340e-03]\n",
            "  [-3.22611332e-01  6.21560887e-02]\n",
            "  [ 3.22611332e-01 -6.21560887e-02]\n",
            "  [ 2.60182135e-02 -5.21600340e-03]\n",
            "  [-2.60182135e-02  5.21600340e-03]]\n",
            "\n",
            " [[-7.54370447e-03  1.66544672e-02]\n",
            "  [ 7.54370447e-03 -1.66544672e-02]\n",
            "  [ 6.76333010e-02  2.61760145e-01]\n",
            "  [-6.76333010e-02 -2.61760145e-01]\n",
            "  [-7.54370447e-03  1.66544672e-02]\n",
            "  [ 7.54370447e-03 -1.66544672e-02]]\n",
            "\n",
            " [[ 2.69451900e-03 -1.04026878e-02]\n",
            "  [-2.69451900e-03  1.04026878e-02]\n",
            "  [-1.77486151e-01 -2.76731849e-02]\n",
            "  [ 1.77486151e-01  2.76731849e-02]\n",
            "  [ 2.69451900e-03 -1.04026878e-02]\n",
            "  [-2.69451900e-03  1.04026878e-02]]\n",
            "\n",
            " [[-1.13485903e-02  7.60476338e-03]\n",
            "  [ 1.13485903e-02 -7.60476338e-03]\n",
            "  [ 1.84901580e-02  1.75211340e-01]\n",
            "  [-1.84901580e-02 -1.75211340e-01]\n",
            "  [-1.13485903e-02  7.60476338e-03]\n",
            "  [ 1.13485903e-02 -7.60476338e-03]]\n",
            "\n",
            " [[-2.39828099e-02  3.22448649e-03]\n",
            "  [ 2.39828099e-02 -3.22448649e-03]\n",
            "  [ 6.21607602e-02 -1.16389424e-01]\n",
            "  [-6.21607602e-02  1.16389424e-01]\n",
            "  [-2.39828099e-02  3.22448649e-03]\n",
            "  [ 2.39828099e-02 -3.22448649e-03]]\n",
            "\n",
            " [[-1.57254301e-02 -3.53597221e-03]\n",
            "  [ 1.57254301e-02  3.53597221e-03]\n",
            "  [-1.15912184e-01 -5.54836541e-02]\n",
            "  [ 1.15912184e-01  5.54836541e-02]\n",
            "  [-1.57254301e-02 -3.53597221e-03]\n",
            "  [ 1.57254301e-02  3.53597221e-03]]\n",
            "\n",
            " [[ 6.97878422e-04  4.61789407e-03]\n",
            "  [-6.97878422e-04 -4.61789407e-03]\n",
            "  [ 1.30040988e-01 -1.37462676e-01]\n",
            "  [-1.30040988e-01  1.37462676e-01]\n",
            "  [ 6.97878422e-04  4.61789407e-03]\n",
            "  [-6.97878422e-04 -4.61789407e-03]]\n",
            "\n",
            " [[ 2.84523852e-02 -3.18556582e-03]\n",
            "  [-2.84523852e-02  3.18556582e-03]\n",
            "  [-3.37738156e-01 -3.10065225e-02]\n",
            "  [ 3.37738156e-01  3.10065225e-02]\n",
            "  [ 2.84523852e-02 -3.18556582e-03]\n",
            "  [-2.84523852e-02  3.18556582e-03]]\n",
            "\n",
            " [[ 1.16241456e-03  1.11030918e-02]\n",
            "  [-1.16241456e-03 -1.11030918e-02]\n",
            "  [-1.11199029e-01 -2.26301342e-01]\n",
            "  [ 1.11199029e-01  2.26301342e-01]\n",
            "  [ 1.16241456e-03  1.11030918e-02]\n",
            "  [-1.16241456e-03 -1.11030918e-02]]\n",
            "\n",
            " [[-9.64833051e-03 -1.39763707e-03]\n",
            "  [ 9.64833051e-03  1.39763707e-03]\n",
            "  [ 8.56906250e-02  8.44950303e-02]\n",
            "  [-8.56906250e-02 -8.44950303e-02]\n",
            "  [-9.64833051e-03 -1.39763707e-03]\n",
            "  [ 9.64833051e-03  1.39763707e-03]]\n",
            "\n",
            " [[-1.89507324e-02  1.06636493e-03]\n",
            "  [ 1.89507324e-02 -1.06636493e-03]\n",
            "  [-3.22673097e-02 -1.29698575e-01]\n",
            "  [ 3.22673097e-02  1.29698575e-01]\n",
            "  [-1.89507324e-02  1.06636493e-03]\n",
            "  [ 1.89507324e-02 -1.06636493e-03]]\n",
            "\n",
            " [[ 2.33846400e-02 -1.85415964e-03]\n",
            "  [-2.33846400e-02  1.85415964e-03]\n",
            "  [ 3.08611870e-01 -8.31786171e-02]\n",
            "  [-3.08611870e-01  8.31786171e-02]\n",
            "  [ 2.33846400e-02 -1.85415964e-03]\n",
            "  [-2.33846400e-02  1.85415964e-03]]\n",
            "\n",
            " [[ 1.85193457e-02 -2.80461018e-03]\n",
            "  [-1.85193457e-02  2.80461018e-03]\n",
            "  [-2.80148238e-01  9.67143029e-02]\n",
            "  [ 2.80148238e-01 -9.67143029e-02]\n",
            "  [ 1.85193457e-02 -2.80461018e-03]\n",
            "  [-1.85193457e-02  2.80461018e-03]]\n",
            "\n",
            " [[-3.81710916e-03  2.58453423e-03]\n",
            "  [ 3.81710916e-03 -2.58453423e-03]\n",
            "  [-4.11374047e-02  1.63681954e-01]\n",
            "  [ 4.11374047e-02 -1.63681954e-01]\n",
            "  [-3.81710916e-03  2.58453423e-03]\n",
            "  [ 3.81710916e-03 -2.58453423e-03]]\n",
            "\n",
            " [[-9.76219028e-03 -1.43931585e-03]\n",
            "  [ 9.76219028e-03  1.43931585e-03]\n",
            "  [ 3.78423557e-02 -1.77072119e-02]\n",
            "  [-3.78423557e-02  1.77072119e-02]\n",
            "  [-9.76219028e-03 -1.43931585e-03]\n",
            "  [ 9.76219028e-03  1.43931585e-03]]\n",
            "\n",
            " [[ 6.57663215e-03  2.36189202e-03]\n",
            "  [-6.57663215e-03 -2.36189202e-03]\n",
            "  [-2.06044912e-01  1.59783542e-01]\n",
            "  [ 2.06044912e-01 -1.59783542e-01]\n",
            "  [ 6.57663215e-03  2.36189202e-03]\n",
            "  [-6.57663215e-03 -2.36189202e-03]]\n",
            "\n",
            " [[ 4.41393536e-03 -9.33635980e-04]\n",
            "  [-4.41393536e-03  9.33635980e-04]\n",
            "  [ 2.50463396e-01  7.10955262e-02]\n",
            "  [-2.50463396e-01 -7.10955262e-02]\n",
            "  [ 4.41393536e-03 -9.33635980e-04]\n",
            "  [-4.41393536e-03  9.33635980e-04]]\n",
            "\n",
            " [[ 1.33111272e-02  6.51640352e-03]\n",
            "  [-1.33111272e-02 -6.51640352e-03]\n",
            "  [ 2.30761886e-01  1.75325975e-01]\n",
            "  [-2.30761886e-01 -1.75325975e-01]\n",
            "  [ 1.33111272e-02  6.51640352e-03]\n",
            "  [-1.33111272e-02 -6.51640352e-03]]\n",
            "\n",
            " [[ 8.22670013e-03  4.42376733e-03]\n",
            "  [-8.22670013e-03 -4.42376733e-03]\n",
            "  [-2.35156417e-01 -1.41670972e-01]\n",
            "  [ 2.35156417e-01  1.41670972e-01]\n",
            "  [ 8.22670013e-03  4.42376733e-03]\n",
            "  [-8.22670013e-03 -4.42376733e-03]]\n",
            "\n",
            " [[ 2.49006841e-02  1.36184867e-03]\n",
            "  [-2.49006841e-02 -1.36184867e-03]\n",
            "  [-3.15950394e-01 -7.47879520e-02]\n",
            "  [ 3.15950394e-01  7.47879520e-02]\n",
            "  [ 2.49006841e-02  1.36184867e-03]\n",
            "  [-2.49006841e-02 -1.36184867e-03]]\n",
            "\n",
            " [[ 4.11440618e-03 -1.84158087e-02]\n",
            "  [-4.11440618e-03  1.84158087e-02]\n",
            "  [-1.50820449e-01 -1.90270692e-02]\n",
            "  [ 1.50820449e-01  1.90270692e-02]\n",
            "  [ 4.11440618e-03 -1.84158087e-02]\n",
            "  [-4.11440618e-03  1.84158087e-02]]\n",
            "\n",
            " [[-8.16781223e-02  1.47892356e-01]\n",
            "  [ 8.16781223e-02 -1.47892356e-01]\n",
            "  [ 8.16781223e-02 -1.47892356e-01]\n",
            "  [-8.16781223e-02  1.47892356e-01]\n",
            "  [ 0.00000000e+00  0.00000000e+00]\n",
            "  [-0.00000000e+00 -0.00000000e+00]]\n",
            "\n",
            " [[ 3.86703317e-03  1.92216337e-02]\n",
            "  [-3.86703317e-03 -1.92216337e-02]\n",
            "  [-1.28103182e-01 -2.81361610e-01]\n",
            "  [ 1.28103182e-01  2.81361610e-01]\n",
            "  [ 3.86703317e-03  1.92216337e-02]\n",
            "  [-3.86703317e-03 -1.92216337e-02]]\n",
            "\n",
            " [[ 3.61055247e-02  3.63678159e-03]\n",
            "  [-3.61055247e-02 -3.63678159e-03]\n",
            "  [-3.80125165e-01 -1.55328169e-01]\n",
            "  [ 3.80125165e-01  1.55328169e-01]\n",
            "  [ 3.61055247e-02  3.63678159e-03]\n",
            "  [-3.61055247e-02 -3.63678159e-03]]\n",
            "\n",
            " [[ 1.27007607e-02 -1.16416020e-02]\n",
            "  [-1.27007607e-02  1.16416020e-02]\n",
            "  [ 3.11233371e-01  1.04619004e-01]\n",
            "  [-3.11233371e-01 -1.04619004e-01]\n",
            "  [ 1.27007607e-02 -1.16416020e-02]\n",
            "  [-1.27007607e-02  1.16416020e-02]]\n",
            "\n",
            " [[ 2.76876260e-02  2.82320805e-04]\n",
            "  [-2.76876260e-02 -2.82320805e-04]\n",
            "  [-3.33911896e-01  3.63961868e-02]\n",
            "  [ 3.33911896e-01 -3.63961868e-02]\n",
            "  [ 2.76876260e-02  2.82320805e-04]\n",
            "  [-2.76876260e-02 -2.82320805e-04]]\n",
            "\n",
            " [[ 2.91897580e-02 -4.19863005e-04]\n",
            "  [-2.91897580e-02  4.19863005e-04]\n",
            "  [-3.41768444e-01 -8.87559429e-02]\n",
            "  [ 3.41768444e-01  8.87559429e-02]\n",
            "  [ 2.91897580e-02 -4.19863005e-04]\n",
            "  [-2.91897580e-02  4.19863005e-04]]\n",
            "\n",
            " [[-5.38075604e-02 -1.74398199e-01]\n",
            "  [ 5.38075604e-02  1.74398199e-01]\n",
            "  [ 5.38075604e-02  1.74398199e-01]\n",
            "  [-5.38075604e-02 -1.74398199e-01]\n",
            "  [ 2.01630709e-03 -1.02874964e-01]\n",
            "  [-2.01630709e-03  1.02874964e-01]]\n",
            "\n",
            " [[ 8.14441219e-03 -8.46418843e-04]\n",
            "  [-8.14441219e-03  8.46418843e-04]\n",
            "  [-1.95831031e-01  7.99838081e-02]\n",
            "  [ 1.95831031e-01 -7.99838081e-02]\n",
            "  [ 8.14441219e-03 -8.46418843e-04]\n",
            "  [-8.14441219e-03  8.46418843e-04]]\n",
            "\n",
            " [[-1.24439914e-02 -1.19359174e-03]\n",
            "  [ 1.24439914e-02  1.19359174e-03]\n",
            "  [-5.88730723e-03 -3.27822343e-02]\n",
            "  [ 5.88730723e-03  3.27822343e-02]\n",
            "  [-1.24439914e-02 -1.19359174e-03]\n",
            "  [ 1.24439914e-02  1.19359174e-03]]\n",
            "\n",
            " [[ 4.53277724e-03  2.73536379e-03]\n",
            "  [-4.53277724e-03 -2.73536379e-03]\n",
            "  [-1.60438389e-01  1.39354363e-01]\n",
            "  [ 1.60438389e-01 -1.39354363e-01]\n",
            "  [ 4.53277724e-03  2.73536379e-03]\n",
            "  [-4.53277724e-03 -2.73536379e-03]]\n",
            "\n",
            " [[-4.48912149e-03  1.79001335e-02]\n",
            "  [ 4.48912149e-03 -1.79001335e-02]\n",
            "  [ 2.09113471e-02 -2.71846712e-01]\n",
            "  [-2.09113471e-02  2.71846712e-01]\n",
            "  [-4.48912149e-03  1.79001335e-02]\n",
            "  [ 4.48912149e-03 -1.79001335e-02]]\n",
            "\n",
            " [[ 3.96007579e-03 -9.38730780e-03]\n",
            "  [-3.96007579e-03  9.38730780e-03]\n",
            "  [ 1.44258410e-01  3.82473096e-02]\n",
            "  [-1.44258410e-01 -3.82473096e-02]\n",
            "  [ 3.96007579e-03 -9.38730780e-03]\n",
            "  [-3.96007579e-03  9.38730780e-03]]\n",
            "\n",
            " [[-2.89133866e-03 -1.25694545e-02]\n",
            "  [ 2.89133866e-03  1.25694545e-02]\n",
            "  [-1.04254588e-01 -6.76291883e-02]\n",
            "  [ 1.04254588e-01  6.76291883e-02]\n",
            "  [-2.89133866e-03 -1.25694545e-02]\n",
            "  [ 2.89133866e-03  1.25694545e-02]]\n",
            "\n",
            " [[ 1.08880587e-02 -1.51467873e-02]\n",
            "  [-1.08880587e-02  1.51467873e-02]\n",
            "  [-2.09159702e-01  1.87441111e-02]\n",
            "  [ 2.09159702e-01 -1.87441111e-02]\n",
            "  [ 1.08880587e-02 -1.51467873e-02]\n",
            "  [-1.08880587e-02  1.51467873e-02]]\n",
            "\n",
            " [[ 1.71083417e-02 -6.52974611e-03]\n",
            "  [-1.71083417e-02  6.52974611e-03]\n",
            "  [-2.68661797e-01 -1.23473778e-02]\n",
            "  [ 2.68661797e-01  1.23473778e-02]\n",
            "  [ 1.71083417e-02 -6.52974611e-03]\n",
            "  [-1.71083417e-02  6.52974611e-03]]\n",
            "\n",
            " [[-2.98759551e-03 -6.63954439e-03]\n",
            "  [ 2.98759551e-03  6.63954439e-03]\n",
            "  [-1.44362733e-01  3.57820094e-02]\n",
            "  [ 1.44362733e-01 -3.57820094e-02]\n",
            "  [-2.98759551e-03 -6.63954439e-03]\n",
            "  [ 2.98759551e-03  6.63954439e-03]]\n",
            "\n",
            " [[-4.58761025e-03  8.52337573e-03]\n",
            "  [ 4.58761025e-03 -8.52337573e-03]\n",
            "  [-2.56210566e-04  1.89552903e-01]\n",
            "  [ 2.56210566e-04 -1.89552903e-01]\n",
            "  [-4.58761025e-03  8.52337573e-03]\n",
            "  [ 4.58761025e-03 -8.52337573e-03]]\n",
            "\n",
            " [[-7.63577782e-03 -8.01808841e-04]\n",
            "  [ 7.63577782e-03  8.01808841e-04]\n",
            "  [ 4.59186733e-02 -1.57710433e-01]\n",
            "  [-4.59186733e-02  1.57710433e-01]\n",
            "  [-7.63577782e-03 -8.01808841e-04]\n",
            "  [ 7.63577782e-03  8.01808841e-04]]\n",
            "\n",
            " [[-1.77082475e-02 -9.16171074e-03]\n",
            "  [ 1.77082475e-02  9.16171074e-03]\n",
            "  [-2.65402570e-02  8.03926811e-02]\n",
            "  [ 2.65402570e-02 -8.03926811e-02]\n",
            "  [-1.77082475e-02 -9.16171074e-03]\n",
            "  [ 1.77082475e-02  9.16171074e-03]]\n",
            "\n",
            " [[-1.84792243e-02 -1.52457296e-03]\n",
            "  [ 1.84792243e-02  1.52457296e-03]\n",
            "  [-1.52879149e-01  2.44158600e-02]\n",
            "  [ 1.52879149e-01 -2.44158600e-02]\n",
            "  [-1.84792243e-02 -1.52457296e-03]\n",
            "  [ 1.84792243e-02  1.52457296e-03]]\n",
            "\n",
            " [[-1.41589483e-02  5.11264894e-03]\n",
            "  [ 1.41589483e-02 -5.11264894e-03]\n",
            "  [-1.75719783e-01 -1.60157651e-01]\n",
            "  [ 1.75719783e-01  1.60157651e-01]\n",
            "  [-1.41589483e-02  5.11264894e-03]\n",
            "  [ 1.41589483e-02 -5.11264894e-03]]\n",
            "\n",
            " [[-2.49855630e-02  3.15074180e-03]\n",
            "  [ 2.49855630e-02 -3.15074180e-03]\n",
            "  [-1.61651224e-02 -1.15200981e-01]\n",
            "  [ 1.61651224e-02  1.15200981e-01]\n",
            "  [-2.49855630e-02  3.15074180e-03]\n",
            "  [ 2.49855630e-02 -3.15074180e-03]]\n",
            "\n",
            " [[ 4.53907443e-04 -2.35506077e-03]\n",
            "  [-4.53907443e-04  2.35506077e-03]\n",
            "  [ 1.93441898e-01 -1.52799919e-01]\n",
            "  [-1.93441898e-01  1.52799919e-01]\n",
            "  [ 4.53907443e-04 -2.35506077e-03]\n",
            "  [-4.53907443e-04  2.35506077e-03]]\n",
            "\n",
            " [[ 4.01284322e-02  1.42996665e-04]\n",
            "  [-4.01284322e-02 -1.42996665e-04]\n",
            "  [-4.00642276e-01  2.55207643e-02]\n",
            "  [ 4.00642276e-01 -2.55207643e-02]\n",
            "  [ 4.01284322e-02  1.42996665e-04]\n",
            "  [-4.01284322e-02 -1.42996665e-04]]]\n",
            "\n",
            "Nth Identities (Conceptual, per qubit):\n",
            "\n",
            "  Qubit 0:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96661687  0.25602967]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 1:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9957611   0.09147261]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 2:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9999048  -0.00686775]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 3:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.86852133 0.49526957]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 4:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9207653 0.3897717]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 5:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9445523   0.32703695]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 6:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.83180374 0.5549569 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 7:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.865901    0.50020266]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 8:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.957487    0.28836963]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 9:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.6927258 -0.7208501]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 10:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99212873 -0.12415186]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 11:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.50175023 -0.86495054]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 12:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.83941656 -0.54296833]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 13:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.6249717  0.78004724]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 14:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.30661    0.95169276]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 15:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.51318634 0.8580172 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 16:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.94013387 0.34058568]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 17:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.97395474 -0.22662857]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 18:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9992659   0.03734256]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 19:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.980454  -0.1965566]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 20:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.4125784   0.91086197]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 21:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.2507231  -0.96796274]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 22:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8306683   0.55663615]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 23:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99104136  0.13324542]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 24:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9755791  -0.21936575]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 25:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.14939609 0.988561  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 26:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99375594 -0.1112622 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 27:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.10411447 0.99447525]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 28:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9895688  -0.14334688]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 29:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9983679   0.05617854]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 30:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9968288 -0.0790382]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 31:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9886734  -0.14972685]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 32:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.82786494  0.5605408 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 33:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.98920476 -0.14584617]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 34:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.94101226 0.33794948]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 35:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9781366  -0.20689555]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 36:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.8980909  0.43965644]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 37:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.88064456 0.47355157]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 38:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99846774 0.05460741]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 39:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.21802999 -0.9758878 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 40:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.48344806  0.8753663 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 41:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.19721949 0.9803073 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 42:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9949381  0.10021658]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 43:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.7371334 -0.6756614]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 44:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99991196 0.01019574]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 45:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99986225 -0.01438193]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 46:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.2948178 -0.9555478]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 47:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99452156 -0.10335697]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 48:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9953518  -0.09547127]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 49:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.8560204 0.5165767]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 50:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.24324088  0.9699101 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 51:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.38864616 -0.9212806 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 52:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.22415712 -0.9744734 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 53:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.5836509 -0.8119387]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 54:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9342134 -0.3565615]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 55:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.41028556 -0.9118066 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 56:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.4738987  0.8804621]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 57:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99440247 -0.10441905]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 58:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.88812655 -0.45948976]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 59:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9965602  -0.08221821]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 60:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9404979  0.339604 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 61:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9921032   0.12510669]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 62:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.18917505 -0.9815189 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 63:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9999687  0.00356336]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "\n",
            "Info-energy Output (all qubits):\n",
            " [ 6.0628347  8.368595   3.0368686  5.067149   5.2318625  6.632316\n",
            " 13.425177  19.4688     8.722145   8.27327    6.715794   5.385579\n",
            "  6.1150208  8.475992   8.980501   5.0689244 11.634561   5.2804303\n",
            "  6.967414  11.429877  11.372609   5.2187014  5.978589   5.185052\n",
            "  4.5131364  5.7361803 11.348766   9.918271   4.6360545  3.9725118\n",
            "  7.54095    7.245845   5.527384   1.8271302 10.656752   5.8348455\n",
            " 10.842032   7.8531528  7.6025434  7.310624   7.750889   8.464991\n",
            " 14.967314  11.475288  15.581389  10.606848  14.129144   8.828581\n",
            "  1.6185381  5.5003395 10.777225   5.0245376  5.537517   5.1418924\n",
            " 10.122603   3.9790387  7.9902673  4.265578   4.1592984  5.6973534\n",
            "  8.090609   5.6172104  6.232552  15.572096 ]\n",
            "\n",
            "Resonance Keys (all qubits):\n",
            " ['630ed64f694296ca43679cc97308dd71aa58ec41e1044ae3da7419b08df45d54', 'ba8f65d1a89f27ccca7544f3b53d384d7dd6cabfff351b110b59577ffd70c3bf', '455a50878392c0c254fd71b22a57e2abb7d2c4d42a6d4c1d14d87f68d9aeaddf', 'b4f8dde2b4f6c4415901d55d176de4c492778a8f25249768e6f750cfbfa01a99', 'ec03da6e7015dbc8cdcb5a8923304570e16aba322da1759448793f0d01dfda8a', '6fa0445a19a0382ce7d12e997b8df113694a09e219fcd2ac8378c6831105ab1f', '02a452ee8c4f71434911e28de096d33cb75eb5486da3054d9bf043b0759f1fa6', '3d6cb9cd73b485f782142a48aacf0fa5f37e4fa23bc0855241356202290507ea', 'e522525b3fd57f7266d5ee90b8631c3af0e7ce4cdb7c8779a7039b834d6efbcd', '6f5bf871a97820fbd1d718a2ebd8f2c20282610cab19a1114d432dd140f0d5ed', '93b9c6bdfd72fe9fae29617cb6d265873abc51d9defde8a10afa359564ea7f7d', '7ed73e0fefafbb48cd0f1a95ccaef8d9c172841a7998e834e3184407a57f4fb6', 'a86fc412fa1ebddfc788867bf78bb61f581be059f0235bf4c9ee96a0d240c72e', 'ab09dcb43518d23c3db854d9e059cfd095c3b0266c9c81503bff06d4c1119442', '50723165955ab854d9a263f09fcee73b4e7c808a241ed92cec903b2a5ecb9d07', 'fa78404cda55ccb9fd6cae05c918338bbdd586a5328957b09de2042b760d43fc', 'c5f5c239027d6c5ac56e00faef8470cdb0f3470e33c33d920ed37628ddfcb8ed', '6b59245a882c1d21d016d46fb778f3c4d54a959efc689500718958fd7fce41e6', 'f9c4242946c7b8aee7402d16f698603ae5b0c1d7af1839da5d5f18cd34aeee4f', 'a9bb2bc0e0e4b2508265bda6fa92e9a3eea90e269529fccd071796b77cda1c15', '6bb0a6398637819c902fcc62a5f2cc6c8254ed4bb9b1cd74e69f671e4b518a8c', 'a596de78eb0b4818384d19551ee247bcf72eccdba22ef2c5b78c3ecdc757a169', '267e5d69dca4121dfd3fa925d91a80a2cb5269bce1a33e84503ac6e112b03599', '6792f98095ca0d8e9f7dc14ecf0e0111e6c79471478d8d79973d1ff07865ef9b', '215fca4d7e3b1c9a9820b81905f7c6dd58257af54d4929ca670341b674962c20', '8d50c226a5b4b696fc2d402185c6e8673b987a7357943d356a141173e4038b96', 'c78851976a6c5e33b6cd0b51ff7dcdd8b0a6896c2f865e6d6d8944183a9f2b9d', 'dc0dab618eb804417e492ccc6249701acea9f56f4845639ed3e6d813bba6d868', 'ab70a0c8fd000320e46a9d37c53812a75551ae58f31aec81b3e75d41c9c1e2aa', 'faac7363bf4b835ebd957c1cf081bbad3b5eaaef9fd486facdbd65f6d3457a74', '49242010f0f2b1fce4e175cc2cf729d29875dacb69c056762bf1f5388f483416', '0b1076fb0fed8d6822b305897a62dd075da60dc805ebea93e9a57de7cd456565', '3912173f4592b6de6f66503f78ef5fadd40cdd67ba6061ab235acdb293cdff8d', '52d0a4832e998666604df3b09be893d1e86be1b45571f2f63f88915d4f23eddb', 'f2621aecf4976453ee5f22fed0660d2492dd8cf3cef01c8a9056ac4c4b22c274', '8c530a194868ada415701d1452cfa761f63042c3e7451a21fd5d524bd3e714ca', '0631a5b64e7d6b95e2703e15a494c7532e47021421cb9afc42cab3aa01203d0d', '21818f330e69107137c384bedb9e394df82fe839ecf9681ba2e2ef0e6b29b8f0', '410c396adfd5fe624501b49aa8b8d69927ff3a42c1bc51301a804c076679dced', '7f900f20d1ebe47d5aedd85434a9d49a493310dad00ebac145b8509ca505e9a6', '0b5cc6ca7ec8c38d5aaee3d5faeeabd67f826b3bacbbcaf0548adecb08a5056d', '49b64fe33aa2df8b832fe9407517ead66e2c90d474439941829998efcc23c7b0', '1196a8e7f0c6ca652f38dc1fa2033022159e8665024f08b8323b598b8979b62d', '644e75789befbd7adbcb2eb95d48b3e0e1342279b7bf7df401cbbeb23a5241a0', '3666770f9c765614800a0761cd38f001475a851fbb5d880d08211c0969f104da', 'fa7b39840c5b757a87cdf9d2de73e67ddf4fe4d2d585480e40beaaae51108c60', '5e1512dbe727170b7c4899016494d6ef2f2a89f331e9ea6c28d63a7252dd26b9', '63e1587686380dac70208eccdd44b0ae4502d99024025dbd3089f6a8c93d252c', 'e4434aa3bc6161f86392a9da1d9221ce6b5580305eee5d2e841b0e8ae7c5acc5', 'f4ed0088b81a3399b9c268db8e016e6f4fa166ab03e2cee7af15f67672b08078', '9e4ddceb7ce569830c875691e255d66704baef288d1084d6791a4eaaecca9d3a', '69b416fad834d755e80714504da15917f402625d67755ef58d611797a9e4b5ae', '0fc313261f8a9c4abb35132fcd23b0045468164d012ac21dee4bea0a6ea51ee8', '4f0ba08e83052017cb93ffff8b2b2b14d1e3e3de3d6163134f6502ef5316792c', 'd2e2ce5f55f747f151c33c01c5f46ee8cc5d363d08577d5c79422225c43a1ebc', '1b6fc2e11a8433ed3021bcc7db2857b2034b674109760dc52307c19dde57abcd', '20f06c1e7f559507f75bb7bffb365f794af2325d8e1eedf321e032ae865c8b76', '0b9c05230dfe1e2aefbd57ceacdcf2b578a3c903d48b4ea2eaa91db930fcfd2d', 'a2d173ca09a3a3d056026d5a1f38482749326381a9ce11c86b5e550bb9e680a5', '94bd678628d1b4b8578b9005f946a8639200493a9fced42841d61aaa87e8cfe3', '4381903d6a6abbc475f75b5465f5616fa751a8004fef3069a3d504aadfda6003', 'd37eb26d750e1c501f3c646810a518db9d91aa0763d26ed9cfcafc0ac80a955f', '3ceebf4a4be9a796cad3f7c7b4972895b329e12872a397dcd0dc3fde45669f67', '05271bfa398ab9a3fef0bdb344bd854f6796460b44dd4faee814f79a57e79b42']\n",
            "\n",
            "Spin (all qubits, conceptual):\n",
            " [[[-0.00743671 -0.2418201  -0.9702926 ]\n",
            "  [-0.12319423 -0.2082197  -0.9702926 ]]\n",
            "\n",
            " [[ 0.34941176  0.12000215 -0.92925286]\n",
            "  [ 0.22191367 -0.29536995 -0.92925286]]\n",
            "\n",
            " [[-0.44320872  0.08256013 -0.89260846]\n",
            "  [-0.45047864  0.01786484 -0.89260846]]\n",
            "\n",
            " [[-0.40170652 -0.769316    0.49677438]\n",
            "  [-0.7183574   0.4870091   0.49677438]]\n",
            "\n",
            " [[ 0.9376517  -0.31837997 -0.13943985]\n",
            "  [-0.8204999   0.55437934 -0.13943985]]\n",
            "\n",
            " [[ 0.1875986  -0.36283597  0.91277426]\n",
            "  [-0.11906833  0.39072487  0.91277426]]\n",
            "\n",
            " [[-0.6695018  -0.73733705 -0.09000823]\n",
            "  [-0.7359375   0.6710399  -0.09000823]]\n",
            "\n",
            " [[ 0.7546989  -0.36108038  0.5477687 ]\n",
            "  [ 0.62125874  0.5603455   0.5477687 ]]\n",
            "\n",
            " [[-0.37823784 -0.09583247  0.92073464]\n",
            "  [ 0.3886277   0.03487475  0.92073464]]\n",
            "\n",
            " [[ 0.0131127   0.3045169  -0.95241666]\n",
            "  [-0.23073031  0.19916329 -0.95241666]]\n",
            "\n",
            " [[ 0.8441788  -0.33987302  0.4145461 ]\n",
            "  [-0.8158749  -0.40311253  0.4145461 ]]\n",
            "\n",
            " [[ 0.28014022  0.26365846  0.9230415 ]\n",
            "  [ 0.20139751 -0.3277703   0.9230415 ]]\n",
            "\n",
            " [[-0.52512705  0.8507385  -0.02203531]\n",
            "  [ 0.2275505  -0.97351694 -0.02203531]]\n",
            "\n",
            " [[-0.23141061  0.7969595  -0.5579468 ]\n",
            "  [-0.71348655 -0.42383054 -0.5579468 ]]\n",
            "\n",
            " [[-0.9980021   0.06288853  0.00607056]\n",
            "  [-0.9200502   0.39175352  0.00607056]]\n",
            "\n",
            " [[-0.1001243  -0.0049035   0.9949629 ]\n",
            "  [-0.06982811  0.07192325  0.9949629 ]]\n",
            "\n",
            " [[-0.10006708 -0.67323476  0.7326265 ]\n",
            "  [ 0.44969803  0.51091105  0.7326265 ]]\n",
            "\n",
            " [[ 0.13318202  0.9898662  -0.04926958]\n",
            "  [-0.5501065  -0.8336398  -0.04926958]]\n",
            "\n",
            " [[ 0.14601265 -0.14564672  0.9785026 ]\n",
            "  [-0.10954787 -0.17473388  0.9785026 ]]\n",
            "\n",
            " [[ 0.28111556 -0.6271667  -0.72638553]\n",
            "  [-0.6009227  -0.3335505  -0.72638553]]\n",
            "\n",
            " [[-0.289733    0.20963623  0.9338669 ]\n",
            "  [ 0.20598243 -0.2923419   0.9338669 ]]\n",
            "\n",
            " [[-0.2496419   0.6957716   0.6734841 ]\n",
            "  [-0.19042498 -0.7142531   0.6734841 ]]\n",
            "\n",
            " [[-0.40593863  0.7248953   0.55654347]\n",
            "  [-0.5572054  -0.6162642   0.55654347]]\n",
            "\n",
            " [[-0.02921589  0.46342358 -0.8856551 ]\n",
            "  [ 0.3511002  -0.30388096 -0.8856551 ]]\n",
            "\n",
            " [[-0.1041955   0.28187636 -0.9537762 ]\n",
            "  [ 0.02704542 -0.29929838 -0.9537762 ]]\n",
            "\n",
            " [[ 0.36646187 -0.68827355  0.62608725]\n",
            "  [ 0.7612498   0.16885954  0.62608725]]\n",
            "\n",
            " [[ 0.01613878  0.00105312  0.9998692 ]\n",
            "  [ 0.00214122 -0.01603073  0.9998692 ]]\n",
            "\n",
            " [[ 0.8202286  -0.3453112   0.45605394]\n",
            "  [-0.8098987  -0.36888877  0.45605394]]\n",
            "\n",
            " [[ 0.9961285  -0.08783569  0.00359773]\n",
            "  [-0.02276191  0.99973446  0.00359773]]\n",
            "\n",
            " [[ 0.8241343  -0.5494912  -0.1373394 ]\n",
            "  [ 0.09018166  0.98641026 -0.1373394 ]]\n",
            "\n",
            " [[ 0.5858212   0.28882274  0.75722843]\n",
            "  [-0.16540034 -0.63186055  0.75722843]]\n",
            "\n",
            " [[-0.58166385  0.12133613 -0.80432874]\n",
            "  [ 0.44813156 -0.39017102 -0.80432874]]\n",
            "\n",
            " [[ 0.94153446 -0.32584566  0.08565874]\n",
            "  [ 0.9873894  -0.13313447  0.08565874]]\n",
            "\n",
            " [[ 0.02976857 -0.29690224 -0.95444375]\n",
            "  [ 0.02665943  0.29719755 -0.95444375]]\n",
            "\n",
            " [[-0.7268187   0.33124876 -0.60167176]\n",
            "  [-0.3624238   0.71178657 -0.60167176]]\n",
            "\n",
            " [[ 0.02432719  0.91411066  0.40473434]\n",
            "  [-0.52728087  0.7471044   0.40473434]]\n",
            "\n",
            " [[-0.8110415  -0.2049145  -0.547925  ]\n",
            "  [ 0.3606095  -0.7548106  -0.547925  ]]\n",
            "\n",
            " [[-0.10389385 -0.3229648  -0.9406911 ]\n",
            "  [ 0.17036024  0.2933898  -0.9406911 ]]\n",
            "\n",
            " [[-0.6495599   0.01711233  0.7601178 ]\n",
            "  [-0.44188988  0.47639716  0.7601178 ]]\n",
            "\n",
            " [[ 0.5343097   0.71488154  0.4510627 ]\n",
            "  [ 0.49418622  0.743184    0.4510627 ]]\n",
            "\n",
            " [[ 0.6380977  -0.3227375   0.69905066]\n",
            "  [-0.11667489  0.7054893   0.69905066]]\n",
            "\n",
            " [[-0.12920676  0.6452596  -0.75295794]\n",
            "  [-0.5982278  -0.2741858  -0.75295794]]\n",
            "\n",
            " [[-0.19551924 -0.08639478  0.976887  ]\n",
            "  [ 0.21098062  0.03433662  0.976887  ]]\n",
            "\n",
            " [[ 0.03379563 -0.1953324   0.98015463]\n",
            "  [ 0.18607457  0.06836037  0.98015463]]\n",
            "\n",
            " [[ 0.96908885 -0.05795214  0.23980887]\n",
            "  [ 0.10385907 -0.96524864  0.23980887]]\n",
            "\n",
            " [[ 0.13451213 -0.17016117 -0.9761924 ]\n",
            "  [-0.14993638 -0.15673998 -0.9761924 ]]\n",
            "\n",
            " [[ 0.9661972   0.17646459 -0.18794489]\n",
            "  [-0.86777264 -0.46005154 -0.18794489]]\n",
            "\n",
            " [[-0.68973243 -0.51738256 -0.5065417 ]\n",
            "  [ 0.6999762  -0.503437   -0.5065417 ]]\n",
            "\n",
            " [[-0.5601348  -0.48480386 -0.6717248 ]\n",
            "  [ 0.07697747 -0.73679054 -0.6717248 ]]\n",
            "\n",
            " [[ 0.04761394  0.13143116  0.99018115]\n",
            "  [ 0.12124352 -0.06957906  0.99018115]]\n",
            "\n",
            " [[-0.14169799  0.5251494  -0.8391304 ]\n",
            "  [ 0.39749858  0.37128842 -0.8391304 ]]\n",
            "\n",
            " [[-0.07926727  0.08436452  0.9932771 ]\n",
            "  [-0.05462174 -0.10206438  0.9932771 ]]\n",
            "\n",
            " [[-0.43270752 -0.20226648 -0.87855136]\n",
            "  [ 0.07700799 -0.4713993  -0.87855136]]\n",
            "\n",
            " [[-0.45764497  0.11331183  0.88188523]\n",
            "  [ 0.3812535  -0.2773522   0.88188523]]\n",
            "\n",
            " [[ 0.31104088 -0.7583426   0.57286125]\n",
            "  [ 0.69132    -0.44034836  0.57286125]]\n",
            "\n",
            " [[-0.25915504 -0.6415459  -0.72198164]\n",
            "  [ 0.4280777  -0.54359174 -0.72198164]]\n",
            "\n",
            " [[ 0.03039871  0.82819855  0.5596098 ]\n",
            "  [ 0.6389885   0.52775997  0.5596098 ]]\n",
            "\n",
            " [[ 0.17573944  0.6172101   0.7669207 ]\n",
            "  [ 0.64164615  0.01108318  0.7669207 ]]\n",
            "\n",
            " [[ 0.8099841   0.06550296 -0.58278227]\n",
            "  [-0.09352069 -0.80722904 -0.58278227]]\n",
            "\n",
            " [[-0.2371694  -0.04991063  0.97018534]\n",
            "  [-0.20276482 -0.13276602  0.97018534]]\n",
            "\n",
            " [[ 0.11567283  0.06595876 -0.99109495]\n",
            "  [ 0.09188914  0.09636985 -0.99109495]]\n",
            "\n",
            " [[-0.27953812 -0.3548783  -0.89214337]\n",
            "  [-0.17484424 -0.4165449  -0.89214337]]\n",
            "\n",
            " [[ 0.686839   -0.71163243  0.14775468]\n",
            "  [ 0.71921396 -0.678896    0.14775468]]\n",
            "\n",
            " [[-0.05778665 -0.02460457 -0.9980257 ]\n",
            "  [-0.05897379 -0.02160495 -0.9980257 ]]]\n",
            "\n",
            "I_vec (all qubits, conceptual):\n",
            " [[0.02090921 0.28614348 0.04173805 ... 0.40926942 0.38019687 0.0346257 ]\n",
            " [0.08159138 0.09208306 0.522603   ... 0.0264905  0.25631073 0.34754613]\n",
            " [0.05677797 0.33175856 0.06526984 ... 0.4889835  0.00441093 0.28094748]\n",
            " ...\n",
            " [0.06763633 0.28125694 0.12783188 ... 0.22480845 0.12937684 0.28330684]\n",
            " [0.0310679  0.08531801 0.32512292 ... 0.44633308 0.06253885 0.26475486]\n",
            " [0.04194438 0.36179274 0.23044108 ... 0.28712133 0.390767   0.3371693 ]]\n",
            "\n",
            "NECL Manifest Checksums (per qubit, conceptual):\n",
            " ['fc3442c3925887bfc9cbbdd74d1390d688d0a7892e5316059ecee12df62e5339', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945']\n",
            "\n",
            "TRACE Log (Conceptual - detailed lineage for error correction):\n",
            " [{'qubit': 0, 'reason': 'binary_refactor', 'source': 'tuplets', 'r_metric': 0.9708396196365356, 'u_metric': 0.980225682258606, 'dv_metric': 0.08210545778274536, 'invariant_pass': False, 'degenerate_check': False, 'correction_threshold_r': 1.02, 'correction_threshold_u': 1.02, 'correction_threshold_d': 0.765, 'corrected_bits': [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0], 'old_key': '74c5478db1b9d4bc71db2524ea91c6d155dbd53644b67dc33bb312246eb7e339', 'new_key': '630ed64f694296ca43679cc97308dd71aa58ec41e1044ae3da7419b08df45d54'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4b56982"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires modifying the `detect_collapse` function to adhere strictly to the 'Unit preference' rule. This involves calculating individual collapse statuses first and then applying triplet-level uniformity checks. This refactoring also removes the nested helper function and updates the function signature to explicitly accept relevant parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f16d54e5",
        "outputId": "173e3c19-1ec6-4124-c02e-133732bff9d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import hashlib\n",
        "import numpy as np # For make_keys numpy conversion\n",
        "import math\n",
        "\n",
        "# =========================\n",
        "# Config and constants\n",
        "# =========================\n",
        "THETA_PHIPI = 0.001  # phi-pi tolerance constant\n",
        "TAU_HI      = 1.0    # high threshold center (for collapse detection)\n",
        "TAU_LOW     = -TAU_HI # low threshold for negative values (for collapse detection)\n",
        "EPS         = 1e-6   # near-zero buffer\n",
        "\n",
        "R_FOR_RATIO = 64.0 # NEW: Ratio threshold constant for collapse detection, updated to 64.0 as per instructions\n",
        "\n",
        "# Advanced error correction metrics thresholds\n",
        "TAU_R_METRIC = 0.85  # Adjusted Threshold for real stability metric (higher for stricter stability)\n",
        "TAU_U_METRIC = 0.85  # Adjusted Threshold for unreal stability metric (higher for stricter stability)\n",
        "TAU_D_METRIC = 0.85  # Adjusted Threshold for real/unreal divergence metric (higher for stricter consistency)\n",
        "\n",
        "# Prime index mask for 0..29 (2,3,5,7,11,13,17,19,23,29)\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Phase-Dual Helper Operations\n",
        "# =========================\n",
        "\n",
        "def add_phase_dual(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise addition for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| + n_|y, η| = n_|x+y, ξ+η|\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def mul_phase_dual_component_wise(a, b):\n",
        "    \"\"\"\n",
        "    Performs component-wise multiplication for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    n_|x, ξ| · n_|y, η| = n_|x·y, ξ·η|\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def neg_phase_dual(a):\n",
        "    \"\"\"\n",
        "    Performs component-wise negation for phase-dual tensors.\n",
        "    Assumes last dimension is phase-dual (real, unreal).\n",
        "    \"\"\"\n",
        "    return -a\n",
        "\n",
        "# =========================\n",
        "# Nth Identities\n",
        "# =========================\n",
        "def n_identity(order, selector_primary=None):\n",
        "    \"\"\"\n",
        "    Conceptual Nth identity n^k.\n",
        "    Args:\n",
        "        order (int or str): The order of the identity. Can be 0, 1, 2, or 'p' for placeholder.\n",
        "        selector_primary (tf.Tensor, optional): A 1x2 tensor representing promoted primary (x, xi)\n",
        "                                               from which to derive n^1. Defaults to None.\n",
        "    Returns:\n",
        "        tf.Tensor: A 1x2 tensor representing the conceptual Nth identity.\n",
        "    \"\"\"\n",
        "    if order == 0:\n",
        "        # n^0 = n_|1, ξ| (base identity)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # [1, 2]\n",
        "    elif order == 1:\n",
        "        if selector_primary is not None:\n",
        "            # Dynamically derive n^1 from a provided promoted primary\n",
        "            # Normalize it to represent a unit selector\n",
        "            magnitude = tf.norm(selector_primary, axis=-1, keepdims=True) # [1]\n",
        "            # Handle potential division by zero by adding EPS\n",
        "            normalized_selector = selector_primary / (magnitude + EPS)\n",
        "            return tf.reshape(normalized_selector, [1, 2]) # Ensure output shape is [1, 2]\n",
        "        else:\n",
        "            # Default n^1 if no specific selector is provided\n",
        "            return tf.constant([[1.0, 1.0]], dtype=tf.float32) / math.sqrt(2.0) # [1, 2]\n",
        "    elif order == 2:\n",
        "        # n^2 = ∏ n_|x_i, ξ_i| (product of two first-order selectors)\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder: could be more complex\n",
        "    else:\n",
        "        # For higher orders, we use a placeholder or a product of initial primaries\n",
        "        return tf.constant([[1.0, 0.0]], dtype=tf.float32) # Placeholder for n^k (k > 1)\n",
        "\n",
        "# =========================\n",
        "# Core ISA Functions (Multi-Qubit, Phase-Dual Aware)\n",
        "# =========================\n",
        "\n",
        "def compute_pairs(prim):\n",
        "    \"\"\"\n",
        "    Computes the 30-index phase-dual pair register from 6 primary phase-dual values.\n",
        "    Takes `[Q, 6, 2]` primaries and returns a `[Q, 30, 2]` pair register,\n",
        "    ensuring canonical index order and phase-dual component-wise operations.\n",
        "\n",
        "    Args:\n",
        "        prim (tf.Tensor): Input primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "                          The last dimension holds [real, unreal] components.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert prim.shape.rank == 3 and (tf.shape(prim)[-2] == 6).numpy().item() and (tf.shape(prim)[-1] == 2).numpy().item() and (prim.dtype == tf.float32), \\\n",
        "        f\"Input prim must have shape [Q, 6, 2] and dtype tf.float32, but got shape {prim.shape} and dtype {prim.dtype}\"\n",
        "\n",
        "    # Each x, xi, y, yi, z, zi will be a tensor of shape [Q, 2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=-2) # Unstack along the 6-dimension\n",
        "\n",
        "    # Build full 30 vector: 6 primaries + 24 combinatorials\n",
        "    # Operations are now component-wise for phase-dual values\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_phase_dual(x, y),   mul_phase_dual_component_wise(x, y),  add_phase_dual(x, yi),  mul_phase_dual_component_wise(x, yi),\n",
        "        add_phase_dual(xi, y),  mul_phase_dual_component_wise(xi, y), add_phase_dual(xi, yi), mul_phase_dual_component_wise(xi, yi),\n",
        "        add_phase_dual(x, z),   mul_phase_dual_component_wise(x, z),  add_phase_dual(x, zi),  mul_phase_dual_component_wise(x, zi),\n",
        "        add_phase_dual(xi, z),  mul_phase_dual_component_wise(xi, z), add_phase_dual(xi, zi), mul_phase_dual_component_wise(xi, zi),\n",
        "        add_phase_dual(y, z),   mul_phase_dual_component_wise(y, z),  add_phase_dual(y, zi),  mul_phase_dual_component_wise(y, zi),\n",
        "        add_phase_dual(yi, z),  mul_phase_dual_component_wise(yi, z), add_phase_dual(yi, zi), mul_phase_dual_component_wise(yi, zi)\n",
        "    ], axis=-2) # Stack along the 30-dimension\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs):\n",
        "    \"\"\"\n",
        "    Groups the 30-index phase-dual pair register into 10 explicit triplets of 3 phase-dual values each.\n",
        "    Takes `[Q, 30, 2]` pairs and returns `[Q, 10, 3, 2]` triplets using explicit index groups.\n",
        "    These are 'Nth Lines' in the context of the ISA.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets (as 3D points)\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # Use tf.gather to select and group the pairs. The last dimension (2) is preserved.\n",
        "    triplets = tf.gather(pairs, idx, axis=1) # Shape [Q, 10, 3, 2]\n",
        "    return triplets\n",
        "\n",
        "def detect_collapse(pairs, tau_hi=TAU_HI, tau_low=TAU_LOW, r_for_ratio=R_FOR_RATIO):\n",
        "    \"\"\"\n",
        "    Detects collapse across the 10 triplets within the phase-dual pair register, adhering to 'Unit Preference' rule.\n",
        "\n",
        "    For each unit `p`, `individual_collapse_status_p = (real_p >= tau_hi AND unreal_p <= tau_low) OR (real_p / unreal_p > r_for_ratio)`.\n",
        "\n",
        "    The `final_collapse_mask` is initialized with these individual statuses. Then, for each triplet:\n",
        "    - If all three units within a triplet have a uniform collapse status (all True or all False), the triplet's units\n",
        "      in `final_collapse_mask` are updated to this uniform status.\n",
        "    - If the triplet has mixed statuses, the individual collapse statuses (calculated initially) are retained.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        tau_hi (float): High threshold for real component.\n",
        "        tau_low (float): Low threshold for unreal component (should be negative).\n",
        "        r_for_ratio (float): Ratio threshold for collapse detection.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "                   (collapse is a per-unit binary flag, not phase-dual itself).\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "\n",
        "    real_parts = pairs[..., 0] # [Q, 30]\n",
        "    unreal_parts = pairs[..., 1] # [Q, 30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    # 2. Inside detect_collapse, first evaluate the core collapse predicate for each of the 30 individual phase-dual units across all qubits:\n",
        "    # For each unit `p`, calculate `cond1_p = (real_p >= tau_hi) AND (unreal_p <= tau_low)`.\n",
        "    cond1_p = tf.logical_and(real_parts >= tau_hi, unreal_parts <= tau_low) # [Q, 30]\n",
        "\n",
        "    # Calculate `ratio_term_p = real_p / unreal_p`, handling potential division by zero by setting the ratio to 0 if `unreal_p` is near zero (less than `EPS`).\n",
        "    ratio_term_p = tf.where(tf.abs(unreal_parts) > EPS, real_parts / unreal_parts, tf.zeros_like(real_parts)) # [Q, 30]\n",
        "\n",
        "    # Calculate `cond2_p = (ratio_term_p > r_for_ratio)`.\n",
        "    cond2_p = (ratio_term_p > r_for_ratio) # [Q, 30]\n",
        "\n",
        "    # Determine the `individual_collapse_status_p = cond1_p OR cond2_p` for each of the 30 units (this will be a boolean tensor of shape `[Q, 30]`)\n",
        "    individual_collapse_status_p = tf.logical_or(cond1_p, cond2_p) # [Q, 30]\n",
        "\n",
        "    # 3. Initialize the `final_collapse_mask` (a `tf.int32` tensor of shape `[Q, 30]`) with the `tf.cast` version of `individual_collapse_status_p`.\n",
        "    # This tensor will hold the final collapse decisions, with individual statuses as the default fallback.\n",
        "    final_collapse_mask = tf.cast(individual_collapse_status_p, tf.int32) # [Q, 30]\n",
        "\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant(\n",
        "        [[0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    # 4. Iterate through each of the 10 triplets defined by the `idx` tensor:\n",
        "    for i in tf.range(10): # 10 triplets\n",
        "        current_triplet_indices = idx[i, :] # Shape [3]\n",
        "\n",
        "        # For the current triplet, extract the `individual_collapse_status` for its three constituent units across all qubits\n",
        "        triplet_individual_status = tf.gather(individual_collapse_status_p, current_triplet_indices, axis=1) # [Q, 3]\n",
        "\n",
        "        # For each qubit, check if the three units within the current triplet have a uniform collapse status\n",
        "        # (i.e., all three are `True` or all three are `False`). Store this check in an `is_uniform` boolean tensor of shape `[Q]`.\n",
        "        is_uniform = tf.reduce_all(tf.equal(triplet_individual_status, triplet_individual_status[:, 0:1]), axis=1) # [Q]\n",
        "\n",
        "        # For qubits where `is_uniform` is `True`, determine the uniform status for the triplet\n",
        "        # (which will be `True` if all units were collapsed, or `False` if all were not collapsed).\n",
        "        # Replicate this uniform status across the three units of the triplet for those qubits.\n",
        "        uniform_status_value = tf.cast(triplet_individual_status[:, 0], tf.int32) # [Q]\n",
        "\n",
        "        # Construct the updates: if uniform, use the uniform_status_value for all three; otherwise, keep individual statuses\n",
        "        updates_for_triplet = tf.where(\n",
        "            tf.expand_dims(is_uniform, axis=-1), # [Q, 1] for broadcasting\n",
        "            tf.tile(tf.expand_dims(uniform_status_value, axis=-1), [1, 3]), # [Q, 3]\n",
        "            tf.cast(triplet_individual_status, tf.int32) # [Q, 3]\n",
        "        )\n",
        "\n",
        "        # Use `tf.tensor_scatter_nd_update` to update the relevant sections of `final_collapse_mask` for the units belonging to the current triplet, applying the uniform status where `is_uniform` is true, and otherwise keeping the existing `individual_collapse_status` (already in `final_collapse_mask`).\n",
        "        indices_to_update = tf.stack([\n",
        "            tf.repeat(tf.range(Q), 3),\n",
        "            tf.tile(current_triplet_indices, [Q])\n",
        "        ], axis=1) # [Q*3, 2]\n",
        "\n",
        "        updates_flat = tf.reshape(updates_for_triplet, [-1]) # [Q*3]\n",
        "\n",
        "        final_collapse_mask = tf.tensor_scatter_nd_update(final_collapse_mask, indices_to_update, updates_flat)\n",
        "\n",
        "    return final_collapse_mask\n",
        "\n",
        "def apply_parity_rotation(pairs, collapse_mask, prime_mask=PRIME_MASK):\n",
        "    \"\"\"\n",
        "    Applies half-rotation (sign flip) to elements of a phase-dual pair register\n",
        "    based on prime indices or detected collapse. The sign change applies to both\n",
        "    real and unreal components. PAR(x, π) operation.\n",
        "\n",
        "    Args:\n",
        "        pairs (tf.Tensor): The 30-index phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        collapse_mask (tf.Tensor): The collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): A boolean mask for prime indices, shape [30] and dtype tf.int32.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - rotated (tf.Tensor): The rotated phase-dual pair register of shape [Q, 30, 2] and dtype tf.float32.\n",
        "            - affected (tf.Tensor): A mask of affected indices of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert pairs.shape.rank == 3 and (tf.shape(pairs)[-2] == 30).numpy().item() and (tf.shape(pairs)[-1] == 2).numpy().item() and (pairs.dtype == tf.float32), \\\n",
        "        f\"Input pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {pairs.shape} and dtype {pairs.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(pairs)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "\n",
        "    # Broadcast prime_mask to match the batch dimension of collapse_mask\n",
        "    prime = tf.broadcast_to(prime_mask, tf.shape(collapse_mask)) # [Q, 30]\n",
        "\n",
        "    # An index is 'affected' if it's a prime index OR part of a collapsed block\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32) # [Q, 30]\n",
        "\n",
        "    # Sign is -1.0 for affected indices, 1.0 otherwise. Expand sign to [Q, 30, 1] to broadcast across real/unreal.\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, dtype=tf.float32), tf.constant(1.0, dtype=tf.float32))\n",
        "    sign_expanded = tf.expand_dims(sign, axis=-1) # [Q, 30, 1]\n",
        "\n",
        "    rotated = pairs * sign_expanded # [Q, 30, 2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs, eps=EPS):\n",
        "    \"\"\"\n",
        "    Converts the phase-dual pair register into a binary bitmap.\n",
        "    The bit is determined by the sign of the real component (leading value):\n",
        "    1 if real_part > EPS (additive operation), 0 otherwise (subtractive/near-zero).\n",
        "\n",
        "    Args:\n",
        "        rotated_pairs (tf.Tensor): The phase-dual pair register values of shape [Q, 30, 2] and dtype tf.float32.\n",
        "        eps (float): Near-zero buffer for tie-breaking.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A binary bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "    \"\"\"\n",
        "    assert rotated_pairs.shape.rank == 3 and (tf.shape(rotated_pairs)[-2] == 30).numpy().item() and (tf.shape(rotated_pairs)[-1] == 2).numpy().item() and (rotated_pairs.dtype == tf.float32), \\\n",
        "        f\"Input rotated_pairs must have shape [Q, 30, 2] and dtype tf.float32, but got shape {rotated_pairs.shape} and dtype {rotated_pairs.dtype}\"\n",
        "\n",
        "    # Get the real component (leading value) of each phase-dual unit\n",
        "    real_parts = rotated_pairs[..., 0] # Shape [Q, 30]\n",
        "\n",
        "    # Bit is 1 if real_part > EPS, else 0 (negatives and ties go to 0)\n",
        "    bits = tf.cast(real_parts > eps, tf.int32) # Shape [Q, 30]\n",
        "    return bits\n",
        "\n",
        "def _value_unique_axis_phase_dual(vals, axis_vals, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Helper function to determine if phase-dual values are unique along an axis within a tolerance.\n",
        "    Uniqueness is determined based on the magnitude (`tf.norm`) of phase-dual units.\n",
        "    It must handle `vals` of shape `[Q, 2]` (for individual primaries) and `[Q, 10, 2]` (for candidates).\n",
        "\n",
        "    Args:\n",
        "        vals (tf.Tensor): Candidate values for the axis, shape [Q, 2] or [Q, 10, 2].\n",
        "        axis_vals (tf.Tensor): Observed values along the axis (from other qubits), shape [Q, K, 2].\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: A boolean tensor (cast to int32) of shape [Q] or [Q, 10] indicating uniqueness.\n",
        "    \"\"\"\n",
        "    assert vals.dtype == tf.float32, f\"Input vals must have dtype tf.float32, got {vals.dtype}\"\n",
        "    assert axis_vals.dtype == tf.float32, f\"Input axis_vals must have dtype tf.float32, got {axis_vals.dtype}\"\n",
        "    assert axis_vals.shape.rank == 3 and (tf.shape(axis_vals)[-1] == 2).numpy().item(), f\"Input axis_vals must have shape [Q, K, 2], got {axis_vals.shape}\"\n",
        "    assert (tf.shape(vals)[0] == tf.shape(axis_vals)[0]).numpy().item(), f\"Batch dimension of vals ({tf.shape(vals)[0]}) and axis_vals ({tf.shape(axis_vals)[0]}) must match.\"\n",
        "\n",
        "    if vals.shape.rank == 2: # vals is [Q, 2] (e.g., fx, fy, fz)\n",
        "        # Expand vals to [Q, 1, 2] and axis_vals to [Q, K, 2] for broadcasting.\n",
        "        # diffs will be [Q, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=1) - axis_vals)\n",
        "    elif vals.shape.rank == 3: # vals is [Q, 10, 2] (e.g., x_candidates)\n",
        "        # Expand vals to [Q, 10, 1, 2] and axis_vals to [Q, 1, K, 2] for correct broadcasting.\n",
        "        # diffs will be [Q, 10, K, 2]\n",
        "        diffs = tf.abs(tf.expand_dims(vals, axis=2) - tf.expand_dims(axis_vals, axis=1))\n",
        "    else:\n",
        "        raise ValueError(f\"Input vals must be rank 2 or 3 (representing phase-duals), but got rank {tf.rank(vals)}\")\n",
        "\n",
        "    # Calculate magnitude of differences (distance between phase-dual units)\n",
        "    magnitudes = tf.norm(diffs, axis=-1) # [Q, K] or [Q, 10, K]\n",
        "\n",
        "    # Unique if ALL magnitudes are greater than theta across the K dimension\n",
        "    unique = tf.reduce_all(magnitudes > theta, axis=-1)\n",
        "    return tf.cast(unique, tf.int32) # [Q] or [Q, 10]\n",
        "\n",
        "def _first_unique_selection_phase_dual(cand_bool, vals):\n",
        "    \"\"\"\n",
        "    Helper function to select the first phase-dual value from `vals` where `cand_bool` is True.\n",
        "\n",
        "    Args:\n",
        "        cand_bool (tf.Tensor): Boolean tensor (int32) of shape [Q, 10] indicating uniqueness.\n",
        "        vals (tf.Tensor): Phase-dual values from which to select, shape [Q, 10, 2].\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Selected phase-dual values of shape [Q, 2].\n",
        "    \"\"\"\n",
        "    assert cand_bool.shape.rank == 2 and (tf.shape(cand_bool)[-1] == 10).numpy().item() and (cand_bool.dtype == tf.int32), \\\n",
        "        f\"Input cand_bool must have shape [Q, 10] and dtype tf.int32, but got shape {cand_bool.shape} and dtype {cand_bool.dtype}\"\n",
        "    assert vals.shape.rank == 3 and (tf.shape(vals)[-2] == 10).numpy().item() and (tf.shape(vals)[-1] == 2).numpy().item() and (vals.dtype == tf.float32), \\\n",
        "        f\"Input vals must have shape [Q, 10, 2] and dtype tf.float32, but got shape {vals.shape} and dtype {vals.dtype}\"\n",
        "    assert (tf.shape(cand_bool)[0] == tf.shape(vals)[0]).numpy().item(), f\"Batch dimension of cand_bool ({tf.shape(cand_bool)[0]}) and vals ({tf.shape(vals)[0]}) must match.\"\n",
        "\n",
        "    # tf.argmax returns the index of the first True, or 0 if no True value\n",
        "    idx = tf.argmax(cand_bool, axis=1) # [Q]\n",
        "\n",
        "    # Gather elements based on batch and determined index.\n",
        "    # This needs to select a [Q, 2] tensor from [Q, 10, 2].\n",
        "    batch_indices = tf.stack([tf.range(tf.shape(vals)[0], dtype=tf.int64), tf.cast(idx, tf.int64)], axis=1) # [Q, 2]\n",
        "    selected_vals = tf.gather_nd(vals, batch_indices) # [Q, 2]\n",
        "    return selected_vals\n",
        "\n",
        "def promote_primaries(triplets, axis_maps, theta=THETA_PHIPI):\n",
        "    \"\"\"\n",
        "    Promotes primaries based on uniqueness of the final triplet, with axis-level fallback.\n",
        "    Handles phase-dual components.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): 10 triplets of shape [Q, 10, 3, 2] and dtype tf.float32.\n",
        "        axis_maps (dict): Dictionary with keys 'x', 'y', 'z' and values being tf.Tensor\n",
        "                          of observed values from other qubits for that axis, shape [Q, K, 2] and dtype tf.float32.\n",
        "        theta (float): Tolerance threshold.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert triplets.shape.rank == 4 and (tf.shape(triplets)[-3] == 10).numpy().item() and (tf.shape(triplets)[-2] == 3).numpy().item() and (tf.shape(triplets)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input triplets must have shape [Q, 10, 3, 2] and dtype tf.float32, but got shape {triplets.shape}\"\n",
        "    assert triplets.dtype == tf.float32, \\\n",
        "        f\"Input triplets must have dtype tf.float32, but got {triplets.dtype}\"\n",
        "    for k, v in axis_maps.items():\n",
        "        assert isinstance(v, tf.Tensor) and v.dtype == tf.float32 and v.shape.rank == 3 and (tf.shape(v)[-1] == 2).numpy().item(), \\\n",
        "            f\"axis_maps['{k}'] must be tf.Tensor of shape [Q, K, 2] and dtype tf.float32, but got shape {v.shape} and dtype {v.dtype}\"\n",
        "    assert (tf.shape(triplets)[0] == tf.shape(axis_maps['x'])[0]).numpy().item(), f\"Batch dimension of triplets ({tf.shape(triplets)[0]}) and axis_maps ({tf.shape(axis_maps['x'])[0]}) must match.\"\n",
        "\n",
        "\n",
        "    # Triplet-first promotion logic\n",
        "    final_triplet = triplets[:, -1, :, :]  # [Q, 3, 2]\n",
        "    fx, fy, fz = final_triplet[:,0,:], final_triplet[:,1,:], final_triplet[:,2,:] # Each [Q, 2]\n",
        "\n",
        "    # Check uniqueness of final triplet components against respective axis maps\n",
        "    ux_final = _value_unique_axis_phase_dual(fx, axis_maps['x'], theta) # [Q]\n",
        "    uy_final = _value_unique_axis_phase_dual(fy, axis_maps['y'], theta) # [Q]\n",
        "    uz_final = _value_unique_axis_phase_dual(fz, axis_maps['z'], theta) # [Q]\n",
        "\n",
        "    # Triplet is unique if all its components are unique\n",
        "    triplet_unique = tf.cast(tf.logical_and(tf.logical_and(ux_final > 0, uy_final > 0), uz_final > 0), tf.int32) # [Q]\n",
        "\n",
        "    # Construct prim_trip with phase-dual conjugates (-x, -y, -z for both real and unreal components)\n",
        "    prim_trip = tf.stack([fx, neg_phase_dual(fx), fy, neg_phase_dual(fy), fz, neg_phase_dual(fz)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Axis-fallback promotion logic\n",
        "    x_candidates = triplets[:,:,0,:] # [Q, 10, 2]\n",
        "    y_candidates = triplets[:,:,1,:] # [Q, 10, 2]\n",
        "    z_candidates = triplets[:,:,2,:] # [Q, 10, 2]\n",
        "\n",
        "    # Determine uniqueness for all 10 candidates per axis (magnitudes)\n",
        "    ux_all_candidates = _value_unique_axis_phase_dual(x_candidates, axis_maps['x'], theta) # [Q, 10]\n",
        "    uy_all_candidates = _value_unique_axis_phase_dual(y_candidates, axis_maps['y'], theta) # [Q, 10]\n",
        "    uz_all_candidates = _value_unique_axis_phase_dual(z_candidates, axis_maps['z'], theta) # [Q, 10]\n",
        "\n",
        "    # Select the first unique candidate (phase-dual) for each axis\n",
        "    x_sel = _first_unique_selection_phase_dual(ux_all_candidates, x_candidates) # [Q, 2]\n",
        "    y_sel = _first_unique_selection_phase_dual(uy_all_candidates, y_candidates) # [Q, 2]\n",
        "    z_sel = _first_unique_selection_phase_dual(uz_all_candidates, z_candidates) # [Q, 2]\n",
        "\n",
        "    # Construct prim_axis with phase-dual conjugates\n",
        "    prim_axis = tf.stack([x_sel, neg_phase_dual(x_sel), y_sel, neg_phase_dual(y_sel), z_sel, neg_phase_dual(z_sel)], axis=1) # [Q, 6, 2]\n",
        "\n",
        "    # Choose between triplet-first and axis-fallback based on triplet_unique\n",
        "    # choose_trip_expanded needs to be [Q, 1, 1] to broadcast with [Q, 6, 2]\n",
        "    choose_trip_expanded = tf.cast(tf.expand_dims(tf.expand_dims(triplet_unique, axis=-1), axis=-1), tf.float32) # [Q, 1, 1]\n",
        "\n",
        "    primaries_out = tf.where(choose_trip_expanded > 0, prim_trip, prim_axis) # Resulting shape [Q, 6, 2]\n",
        "\n",
        "    return primaries_out\n",
        "\n",
        "def make_keys(bits, prime_mask, collapse_mask, parity_mask, lineage_list=None):\n",
        "    \"\"\"\n",
        "    Generates SHA256 resonance keys for each batch sample.\n",
        "    Hashing is performed in pure Python/NumPy after tensors are materialized.\n",
        "    Accepts an optional `lineage_list` for logging resonance keys,\n",
        "    concatenating the lineage string to the base hash.\n",
        "\n",
        "    Args:\n",
        "        bits (tf.Tensor): Bitmap of shape [Q, 30] and dtype tf.int32.\n",
        "        prime_mask (tf.Tensor): Prime index mask of shape [30] and dtype tf.int32 (global constant).\n",
        "        collapse_mask (tf.Tensor): Collapse mask of shape [Q, 30] and dtype tf.int32.\n",
        "        parity_mask (tf.Tensor): Parity mask of shape [Q, 30] and dtype tf.int32.\n",
        "        lineage_list (list[str], optional): A list of lineage strings for each batch sample. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: A list of SHA256 hex digests, one for each batch sample.\n",
        "    \"\"\"\n",
        "    assert bits.shape.rank == 2 and (tf.shape(bits)[-1] == 30).numpy().item() and (bits.dtype == tf.int32), \\\n",
        "        f\"Input bits must have shape [Q, 30] and dtype tf.int32, but got shape {bits.shape} and dtype {bits.dtype}\"\n",
        "    assert prime_mask.shape.rank == 1 and (tf.shape(prime_mask)[-1] == 30).numpy().item() and (prime_mask.dtype == tf.int32), \\\n",
        "        f\"Input prime_mask must have shape [30] and dtype tf.int32, but got shape {prime_mask.shape} and dtype {prime_mask.dtype}\"\n",
        "    assert collapse_mask.shape.rank == 2 and (tf.shape(collapse_mask)[-1] == 30).numpy().item() and (tf.shape(collapse_mask)[0] == tf.shape(bits)[0]).numpy().item() and (collapse_mask.dtype == tf.int32), \\\n",
        "        f\"Input collapse_mask must have shape [Q, 30] and dtype tf.int32, but got shape {collapse_mask.shape} and dtype {collapse_mask.dtype}\"\n",
        "    assert parity_mask.shape.rank == 2 and (tf.shape(parity_mask)[-1] == 30).numpy().item() and (tf.shape(parity_mask)[0] == tf.shape(bits)[0]).numpy().item() and (parity_mask.dtype == tf.int32), \\\n",
        "        f\"Input parity_mask must have shape [Q, 30] and dtype tf.int32, but got shape {parity_mask.shape} and dtype {parity_mask.dtype}\"\n",
        "    assert (tf.shape(bits)[0].numpy().item() == tf.shape(collapse_mask)[0].numpy().item()) and (tf.shape(bits)[0].numpy().item() == tf.shape(parity_mask)[0].numpy().item()), \\\n",
        "        f\"Batch dimensions of bits ({tf.shape(bits)[0].numpy().item()}), collapse_mask ({tf.shape(collapse_mask)[0].numpy().item()}), and parity_mask ({tf.shape(parity_mask)[0].numpy().item()}) must match.\"\n",
        "    if lineage_list is not None:\n",
        "        assert isinstance(lineage_list, list) and len(lineage_list) == tf.shape(bits)[0].numpy().item(), \\\n",
        "            f\"If provided, lineage_list must be a list of strings with length matching batch size ({tf.shape(bits)[0].numpy().item()})\"\n",
        "\n",
        "    Q = tf.shape(bits)[0].numpy().item() # Use Q for multi-qubit batch size\n",
        "    keys = []\n",
        "\n",
        "    # Convert all tensors to NumPy arrays first (if not already) for pure Python/NumPy hashing\n",
        "    bits_np = bits.numpy()\n",
        "    prime_mask_np = prime_mask.numpy()\n",
        "    collapse_np = collapse_mask.numpy()\n",
        "    parity_np = parity_mask.numpy()\n",
        "\n",
        "    # Broadcast the global prime_mask to match batch dimension for concatenation\n",
        "    prime_mask_broadcasted = np.broadcast_to(prime_mask_np, (Q, 30))\n",
        "\n",
        "    for q_idx in range(Q):\n",
        "        # Construct lineage manifest (e.g., concatenate all relevant info into a string)\n",
        "        lineage_manifest = f\"bits:{bits_np[q_idx].tolist()}|prime:{prime_mask_broadcasted[q_idx].tolist()}|collapse:{collapse_np[q_idx].tolist()}|parity:{parity_np[q_idx].tolist()}\"\n",
        "        if lineage_list and lineage_list[q_idx]:\n",
        "            lineage_manifest += f\"|path:{lineage_list[q_idx]}\"\n",
        "\n",
        "        # Hash the lineage manifest\n",
        "        final_hash = hashlib.sha256(lineage_manifest.encode(\"utf-8\")).hexdigest()\n",
        "        keys.append(final_hash)\n",
        "    return keys\n",
        "\n",
        "def compute_info_energy(primaries_out, k_values, a_U_constant):\n",
        "    \"\"\"\n",
        "    NGFT-inspired function to compute InfoUnit components like k and I.\n",
        "    Info-energy is proportional to sum of magnitudes of primary values\n",
        "    weighted by k (real-valued) and a universal constant.\n",
        "    E_info = (k+1) · a_U · I\n",
        "\n",
        "    Args:\n",
        "        primaries_out (tf.Tensor): Promoted primaries of shape [Q, 6, 2] (phase-dual) and dtype tf.float32.\n",
        "        k_values (tf.Tensor): Batch-wise 'k' components, shape [Q, 1] and dtype tf.float32.\n",
        "        a_U_constant (tf.Tensor): A universal constant, scalar tf.float32.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Computed Info-energy for each qubit, shape [Q] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert primaries_out.shape.rank == 3 and (tf.shape(primaries_out)[-1] == 2).numpy().item(), \\\n",
        "        f\"Input primaries_out must have shape [Q, 6, 2] and rank 3, but got shape {primaries_out.shape} and rank {primaries_out.shape.rank}\"\n",
        "    assert (primaries_out.dtype == tf.float32), f\"primaries_out must have dtype tf.float32, but got {primaries_out.dtype}\"\n",
        "    assert (tf.shape(primaries_out)[-2] == 6).numpy().item(), f\"primaries_out must have shape [Q, 6, 2], but got {primaries_out.shape}\"\n",
        "    assert (k_values.dtype == tf.float32), f\"k_values must have dtype tf.float32, but got {k_values.dtype}\"\n",
        "    assert ( (tf.rank(k_values) == 2).numpy().item() and (tf.shape(k_values)[-1] == 1).numpy().item() ) or \\\n",
        "           ( (tf.rank(k_values) == 1).numpy().item() and (tf.shape(k_values)[0] == tf.shape(primaries_out)[0]).numpy().item() ), \\\n",
        "           f\"k_values must have shape [Q, 1] or [Q], but got {k_values.shape}\"\n",
        "    assert (a_U_constant.dtype == tf.float32), f\"a_U_constant must have dtype tf.float32, but got {a_U_constant.dtype}\"\n",
        "    assert (tf.rank(a_U_constant) == 0).numpy().item(), f\"a_U_constant must be a scalar, but got rank {tf.rank(a_U_constant)}\"\n",
        "\n",
        "    # Normalize k_values to ensure it's always [Q, 1] for consistent multiplication\n",
        "    if (tf.rank(k_values) == 1).numpy().item(): # Use .numpy().item() to convert boolean tensor to Python bool\n",
        "        k_values_normalized = tf.expand_dims(k_values, axis=-1) # Converts [Q] to [Q, 1]\n",
        "    else:\n",
        "        k_values_normalized = k_values # Already [Q, 1] or expected [Q, 1]\n",
        "\n",
        "    # Calculate magnitude for each phase-dual primary unit, resulting in shape [Q, 6]\n",
        "    magnitudes_per_primary = tf.norm(primaries_out, axis=-1) # Shape [Q, 6]\n",
        "\n",
        "    # Sum these magnitudes along axis 1 (the 6 components), resulting in shape [Q]\n",
        "    sum_magnitudes = tf.reduce_sum(magnitudes_per_primary, axis=1) # Shape [Q]\n",
        "\n",
        "    # Explicitly expand dimensions to make it [Q, 1] for multiplication\n",
        "    I_component = tf.expand_dims(sum_magnitudes, axis=-1) # Shape [Q, 1]\n",
        "\n",
        "    # Info-energy calculation: (k+1) * I * a_U_constant\n",
        "    info_energy = (k_values_normalized + 1.0) * I_component * a_U_constant # Shape [Q, 1]\n",
        "\n",
        "    # Return info_energy squeezed along axis=1 to get shape [Q]\n",
        "    return tf.squeeze(info_energy, axis=1)\n",
        "\n",
        "# =========================\n",
        "# NECL v0.1 Operations\n",
        "# =========================\n",
        "\n",
        "def CURV(primaries, params_kappa):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a curvilinear transformation.\n",
        "    X ← X / (1 + |kappa|·|X|)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_kappa (tf.Tensor): Scalar or broadcastable tensor for kappa parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Ensure kappa is broadcastable to primaries (Q,6,2)\n",
        "    kappa = tf.cast(params_kappa, primaries.dtype)\n",
        "    # Compute magnitude |X|\n",
        "    prim_magnitude = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    return primaries / (1.0 + tf.abs(kappa) * prim_magnitude)\n",
        "\n",
        "def GEOD(primaries, params_t):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a geodesic transformation.\n",
        "    X ← X + t·sign(X)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_t (tf.Tensor): Scalar or broadcastable tensor for 't' parameter.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    t = tf.cast(params_t, primaries.dtype)\n",
        "    return primaries + t * tf.sign(primaries)\n",
        "\n",
        "def TWIST(primaries, params_theta):\n",
        "    \"\"\"\n",
        "    NECL function: Applies a twist transformation to the unreal component.\n",
        "    X[...,1] ← X[...,1]·cos(theta)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_theta (tf.Tensor): Scalar or broadcastable tensor for 'theta' angle.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    theta = tf.cast(params_theta, primaries.dtype)\n",
        "    unreal_twisted = primaries[..., 1] * tf.cos(theta)\n",
        "    return tf.stack([primaries[..., 0], unreal_twisted], axis=-1)\n",
        "\n",
        "def LIFT(primaries, params_d):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Projects to higher coordinates, preserving invariants.\n",
        "    For this software emulation, a simplified conceptual implementation that scales\n",
        "    based on 'd' (e.g., a simple multiplicative factor).\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_d (tf.Tensor): Scalar parameter for higher dimension 'd'.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    d_factor = tf.cast(params_d, primaries.dtype) # Convert to float for multiplication\n",
        "    # Conceptual: maybe scale magnitude by sqrt(d) or some other invariant preserving factor\n",
        "    return primaries * (1.0 + d_factor * 0.1) # Simple scaling for conceptual lift\n",
        "\n",
        "def GLUE(primaries, params_sigma):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Simulates 'gluing' of primaries.\n",
        "    X ← X + sigma·roll(X, +1, axis=k)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_sigma (tf.Tensor): Scalar parameter for gluing strength.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    sigma = tf.cast(params_sigma, primaries.dtype)\n",
        "    # Roll along the 'k' (selectors) axis for conceptual inter-selector influence\n",
        "    return primaries + sigma * tf.roll(primaries, shift=1, axis=1)\n",
        "\n",
        "def SPLIT(primaries, params_tau):\n",
        "    \"\"\"\n",
        "    Conceptual NECL function: Splits primaries, potentially increasing `k`.\n",
        "    X ← concat(X·(1−tau), X·tau)\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        params_tau (tf.Tensor): Scalar parameter for split ratio.\n",
        "    Returns:\n",
        "        tf.Tensor: Transformed primaries of shape [Q, 12, 2] (doubles k dimension).\n",
        "    \"\"\"\n",
        "    tau = tf.cast(params_tau, primaries.dtype)\n",
        "    # This increases the K dimension, so the output shape changes.\n",
        "    return tf.concat([primaries * (1.0 - tau), primaries * tau], axis=1)\n",
        "\n",
        "# =========================\n",
        "# Hash->State Mapping Function\n",
        "# =========================\n",
        "\n",
        "def decode_lineage_hash(hex_hash_str, q_idx, D, num_qubits, invariants):\n",
        "    \"\"\"\n",
        "    A Python function that takes a hex hash string, number of qubits Q_count, and dimension D.\n",
        "    It parses portions of the hash to conceptually generate `spin_vec` (shape `[Q, 2, 3]`) and `i_vec` (shape `[Q, D]`)\n",
        "    The generation is conceptual, mapping parts of the hash to float/int values and scaling them.\n",
        "\n",
        "    Args:\n",
        "        hex_hash_str (str): A SHA256 hex hash string for one qubit.\n",
        "        q_idx (int): The index of the qubit.\n",
        "        D (int): Dimensionality for i_vec.\n",
        "        num_qubits (int): Total number of qubits (for seed generation consistency).\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, tf.Tensor]:\n",
        "            - spin_vec (tf.Tensor): Conceptual spin vector of shape [1, 2, 3] and dtype tf.float32.\n",
        "            - i_vec (tf.Tensor): Conceptual internal state vector of shape [1, D] and dtype tf.float32.\n",
        "    \"\"\"\n",
        "    assert isinstance(hex_hash_str, str) and len(hex_hash_str) == 64, f\"Hex hash string must be 64 characters, got {len(hex_hash_str)}\"\n",
        "    assert D >= 16, f\"D for I_vec must be at least 16, got {D}\"\n",
        "\n",
        "    # Use the entire hash for more unique seeding, combined with qubit index for per-qubit determinism\n",
        "    seed_value = int(hashlib.sha256(f\"{hex_hash_str}-{q_idx}\".encode('utf-8')).hexdigest()[:16], 16)\n",
        "    np.random.seed(seed_value % (2**32 - 1)) # Ensure seed fits numpy's typical seed range\n",
        "\n",
        "    # 1) bytes = hex_to_bytes(H); r = (bytes/255)\n",
        "    # Conceptual: Use parts of the hash string directly for pseudo-random number generation\n",
        "    # For this conceptual implementation, we'll just derive randoms from the seed.\n",
        "\n",
        "    # 2) θ = 2π·r0, φ = 2π·r1, twist = 2π·r2\n",
        "    # Generate random angles for spherical coordinates and twist\n",
        "    r_vals = np.random.rand(3) # pseudo-random values for r0, r1, r2\n",
        "    theta = 2 * math.pi * r_vals[0]\n",
        "    phi = 2 * math.pi * r_vals[1]\n",
        "    twist_angle = 2 * math.pi * r_vals[2]\n",
        "\n",
        "    # 3) Real spin: (x,y,z) = (sinθ cosφ, sinθ sinφ, cosθ)\n",
        "    real_spin_x = math.sin(theta) * math.cos(phi)\n",
        "    real_spin_y = math.sin(theta) * math.sin(phi)\n",
        "    real_spin_z = math.cos(theta)\n",
        "\n",
        "    # 4) Unreal spin: rotate (x,y) around z by 'twist'\n",
        "    # Apply 2D rotation matrix for x,y components of unreal spin\n",
        "    unreal_spin_x = real_spin_x * math.cos(twist_angle) - real_spin_y * math.sin(twist_angle)\n",
        "    unreal_spin_y = real_spin_x * math.sin(twist_angle) + real_spin_y * math.cos(twist_angle)\n",
        "    unreal_spin_z = real_spin_z # Z-component remains unchanged by Z-axis twist\n",
        "\n",
        "    spin_vec_data = np.array([\n",
        "        [real_spin_x, real_spin_y, real_spin_z], # Real components\n",
        "        [unreal_spin_x, unreal_spin_y, unreal_spin_z] # Unreal components\n",
        "    ], dtype=np.float32)\n",
        "    spin_vec = tf.reshape(tf.constant(spin_vec_data), (1, 2, 3)) # Reshape to [1, 2, 3]\n",
        "\n",
        "    # 5) I_vec: take r[3:3+16], normalize to ||I_vec||=1 (or your ν); bind H to resonance key\n",
        "    # For simplicity, generating D random floats and normalizing.\n",
        "    i_vec_data = np.random.rand(D).astype(np.float32)\n",
        "    # Apply conceptual normalization based on invariants (e.g., Euclidean norm to 1)\n",
        "    i_vec_data = i_vec_data / np.linalg.norm(i_vec_data) if np.linalg.norm(i_vec_data) > EPS else i_vec_data # Avoid div by zero\n",
        "    i_vec = tf.reshape(tf.constant(i_vec_data), (1, D)) # Reshape to [1, D]\n",
        "\n",
        "    return spin_vec, i_vec\n",
        "\n",
        "# =========================\n",
        "# Multi-Qubit Ops Wrappers (ISA instructions for multi-qubit)\n",
        "# =========================\n",
        "\n",
        "def NORMALIZE_Q(primaries, invariants):\n",
        "    \"\"\"\n",
        "    NORM(X, ν): Multi-qubit wrapper for normalization to canonical invariants.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        invariants (dict): Dictionary of invariant constants (e.g., 'units', 'tol', 'ordering').\n",
        "    Returns:\n",
        "        tf.Tensor: Normalized primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    # Conceptual normalization: Scale each primary unit (real, unreal) by its total magnitude\n",
        "    # across all 6 primary units for that qubit, to a 'unit' scale defined by invariants.\n",
        "    magnitudes = tf.norm(primaries, axis=-1, keepdims=True) # [Q, 6, 1]\n",
        "    total_magnitudes_per_qubit = tf.reduce_sum(magnitudes, axis=1, keepdims=True) # [Q, 1, 1]\n",
        "\n",
        "    # Avoid division by zero for zero-magnitudes\n",
        "    # Scale to a conceptual 'unit' value (e.g., 1.0) or invariant 'units'\n",
        "    unit_scale = invariants.get('units', 1.0) # Default unit scale\n",
        "    normalized_primaries = primaries / (total_magnitudes_per_qubit + EPS) * tf.where(total_magnitudes_per_qubit > EPS, tf.cast(unit_scale, primaries.dtype), 0.0)\n",
        "    return normalized_primaries\n",
        "\n",
        "def PARITY_Q(primaries, prime_mask):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for apply_parity_rotation. PAR(X, π) operation.\n",
        "    Computes pairs and collapse mask internally to determine affected elements.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "        prime_mask (tf.Tensor): Global prime mask [30].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on parity rotation [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs)\n",
        "    rotated_pairs, _ = apply_parity_rotation(pairs, collapse_mask, prime_mask)\n",
        "    # The rotated_pairs are [Q, 30, 2], but primaries are [Q, 6, 2].\n",
        "    # We extract the first 6 elements corresponding to the primaries themselves.\n",
        "    return rotated_pairs[:, 0:6, :]\n",
        "\n",
        "def COLLAPSE_Q(primaries):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for detect_collapse. COLL(X, χ) operation.\n",
        "    Zeroes out only the specific primary units that are part of a collapsed block,\n",
        "    rather than zeroing out the entire qubit's primaries.\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Primaries of shape [Q, 6, 2].\n",
        "    Returns:\n",
        "        tf.Tensor: Primaries updated based on collapse detection [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    pairs = compute_pairs(primaries)\n",
        "    collapse_mask = detect_collapse(pairs) # [Q, 30]\n",
        "\n",
        "    # 1. Extract the portion of the mask that corresponds to the 6 primary units\n",
        "    primary_collapse_flags = collapse_mask[:, 0:6] # Shape [Q, 6]\n",
        "\n",
        "    # 2. Expand primary_collapse_flags to have a shape compatible with primaries [Q, 6, 2]\n",
        "    primary_collapse_flags_expanded = tf.expand_dims(primary_collapse_flags, axis=-1) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 3. Convert this expanded mask to a tf.float32 tensor for use with tf.where\n",
        "    primary_collapse_flags_float = tf.cast(primary_collapse_flags_expanded, tf.float32) # Shape [Q, 6, 1]\n",
        "\n",
        "    # 4. Use tf.where to create updated_primaries\n",
        "    # If the flag is 1, set the primary unit (real and unreal components) to [0.0, 0.0]\n",
        "    # Otherwise, keep the original primary unit value.\n",
        "    updated_primaries = tf.where(primary_collapse_flags_float > 0, tf.zeros_like(primaries), primaries)\n",
        "    return updated_primaries\n",
        "\n",
        "def ASSOC_Q(triplets, axis_maps, theta_phipi):\n",
        "    \"\"\"\n",
        "    Multi-qubit wrapper for promote_primaries. ASSOC(A, B, α) operation.\n",
        "    Args:\n",
        "        triplets (tf.Tensor): Triplets of shape [Q, 10, 3, 2].\n",
        "        axis_maps (dict): Axis maps for uniqueness checks.\n",
        "        theta_phipi (float): Tolerance for uniqueness.\n",
        "    Returns:\n",
        "        tf.Tensor: Promoted primaries of shape [Q, 6, 2].\n",
        "    \"\"\"\n",
        "    return promote_primaries(triplets, axis_maps, theta_phipi)\n",
        "\n",
        "def APPLY_NECL(primaries, necl_program_list, params_dict, prime_mask, conceptual_target_state=None):\n",
        "    \"\"\"\n",
        "    Applies a sequence of NECL operations to multi-qubit primaries.\n",
        "    Handles conceptual operations and integrated ISA steps like PARITY_Q and COLLAPSE_Q.\n",
        "\n",
        "    Args:\n",
        "        primaries (tf.Tensor): Input primaries of shape [Q, 6, 2].\n",
        "        necl_program_list (list[str]): List of NECL operation names to apply.\n",
        "        params_dict (dict): Dictionary mapping NECL op names to their parameters.\n",
        "        prime_mask (tf.Tensor): Global prime mask needed for PARITY_Q.\n",
        "        conceptual_target_state (tf.Tensor, optional): A target state for GEOD. Defaults to zeros_like.\n",
        "\n",
        "    Returns:\n",
        "        tf.Tensor: Final primaries after applying the NECL program.\n",
        "        str: Checksum of the applied NECL program.\n",
        "    \"\"\"\n",
        "    current_primaries = primaries\n",
        "    Q = tf.shape(primaries)[0].numpy().item()\n",
        "\n",
        "    if conceptual_target_state is None:\n",
        "        conceptual_target_state = tf.zeros_like(primaries)\n",
        "\n",
        "    # Build a manifest of the applied program for checksum\n",
        "    program_manifest = \"\"\n",
        "\n",
        "    for op_name in necl_program_list:\n",
        "        program_manifest += op_name # Add op name to manifest\n",
        "\n",
        "        if op_name == 'CURV':\n",
        "            op_params = params_dict.get('CURV', tf.constant(0.01, dtype=tf.float32))\n",
        "            current_primaries = CURV(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GEOD':\n",
        "            op_params = params_dict.get('GEOD', tf.constant(0.05, dtype=tf.float32))\n",
        "            current_primaries = GEOD(current_primaries, op_params) # GEOD uses a target state; simplified here.\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'TWIST':\n",
        "            op_params = params_dict.get('TWIST', tf.constant(math.pi/4, dtype=tf.float32)) # Use a radian value\n",
        "            current_primaries = TWIST(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'LIFT':\n",
        "            op_params = params_dict.get('LIFT', tf.constant(0.5, dtype=tf.float32)) # Default 'd' factor\n",
        "            current_primaries = LIFT(current_primaries, op_params)\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'GLUE':\n",
        "            op_params = params_dict.get('GLUE', tf.constant(0.1, dtype=tf.float32)) # Sigma for gluing strength\n",
        "            if Q % 2 != 0:\n",
        "                print(f\"Warning: GLUE operation skipped for odd Q ({Q})\")\n",
        "            else:\n",
        "                # For conceptual multi-qubit GLUE, average current with a 'rolled' version of itself\n",
        "                # This mimics interaction/averaging across an 'nth line'\n",
        "                current_primaries = GLUE(current_primaries, tf.roll(current_primaries, shift=1, axis=0) * op_params) # Roll along Q dimension\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'SPLIT':\n",
        "            op_params = params_dict.get('SPLIT', tf.constant(0.5, dtype=tf.float32)) # Tau for split ratio\n",
        "            # For simplicity, if SPLIT is called directly in NECL program, we just return original primaries\n",
        "            # as the problem implies a constant K for the main pipeline. A real split would return doubled K.\n",
        "            # For this example, we'll return primaries*1 for consistency of shape.\n",
        "            current_primaries = current_primaries # Simplified as per instructions for 'main pipeline example to keep K constant'\n",
        "            program_manifest += f\"({op_params.numpy().item()})\"\n",
        "        elif op_name == 'PARITY_Q':\n",
        "            current_primaries = PARITY_Q(current_primaries, prime_mask)\n",
        "        elif op_name == 'COLLAPSE_Q':\n",
        "            current_primaries = COLLAPSE_Q(current_primaries)\n",
        "        else:\n",
        "            print(f\"Warning: Unknown NECL operation: {op_name}\")\n",
        "\n",
        "    necl_checksum = hashlib.sha256(program_manifest.encode('utf-8')).hexdigest()\n",
        "    return current_primaries, necl_checksum\n",
        "\n",
        "# =========================\n",
        "# Error Correction (New) - Advanced\n",
        "# =========================\n",
        "\n",
        "def r_metric(real_parts):\n",
        "    \"\"\"\n",
        "    Quantifies real stability/cohesion based on variance of real parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    # 1 - (normalized variance). A value close to 1 means low variance (high stability).\n",
        "    # Ensure inputs are not all identical to avoid division by zero in variance calculation.\n",
        "    max_val = tf.reduce_max(real_parts)\n",
        "    min_val = tf.reduce_min(real_parts)\n",
        "    if (max_val - min_val) < EPS: # Check if all values are effectively the same\n",
        "        return 1.0 # Max stability if no variance\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(real_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def u_metric(unreal_parts):\n",
        "    \"\"\"\n",
        "    Quantifies unreal stability/cohesion based on variance of unreal parts of pairs.\n",
        "    Higher value implies higher stability.\n",
        "    \"\"\"\n",
        "    max_val = tf.reduce_max(unreal_parts)\n",
        "    min_val = tf.reduce_min(unreal_parts)\n",
        "    if (max_val - min_val) < EPS:\n",
        "        return 1.0\n",
        "\n",
        "    return 1.0 - (tf.math.reduce_variance(unreal_parts) / (max_val - min_val + EPS))\n",
        "\n",
        "def dv_metric(pairs_q):\n",
        "    \"\"\"\n",
        "    Quantifies real/unreal divergence based on the mean absolute difference between\n",
        "    real and unreal components for each pair, relative to their magnitude.\n",
        "    Higher value implies lower divergence (higher consistency).\n",
        "    \"\"\"\n",
        "    real_parts = pairs_q[..., 0]\n",
        "    unreal_parts = pairs_q[..., 1]\n",
        "    abs_diff = tf.abs(real_parts - unreal_parts)\n",
        "    magnitudes = tf.norm(pairs_q, axis=-1)\n",
        "\n",
        "    # Avoid division by zero, if magnitude is very small, divergence is also small\n",
        "    divergence_per_index = tf.where(magnitudes > EPS, abs_diff / (magnitudes + EPS), tf.zeros_like(magnitudes))\n",
        "    mean_divergence = tf.reduce_mean(divergence_per_index)\n",
        "    return 1.0 - mean_divergence # High value for low divergence\n",
        "\n",
        "def invariant_check_conceptual(pairs_q, triplets_q, invariants):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for invariants (e.g., specific sum/product rules).\n",
        "    Returns True if a conceptual invariant holds, False otherwise.\n",
        "    \"\"\"\n",
        "    # Example invariant: The sum of magnitudes of the 6 primaries should be close to 'units'\n",
        "    # For this, we need magnitudes of the actual primaries (first 6 pairs).\n",
        "    prim_magnitudes = tf.norm(pairs_q[:6, :], axis=-1) # Magnitudes of the 6 primaries\n",
        "    sum_prim_magnitudes = tf.reduce_sum(prim_magnitudes) # Scalar\n",
        "    units = invariants.get('units', 1.0)\n",
        "    return tf.abs(sum_prim_magnitudes - units) < invariants.get('tol', EPS)\n",
        "\n",
        "def degenerate_check(primaries_q):\n",
        "    \"\"\"\n",
        "    Conceptual function to check for degenerate states (e.g., all zeros/near-zeros).\n",
        "    Returns True if primaries are degenerate, False otherwise.\n",
        "    \"\"\"\n",
        "    # Degenerate if all primaries are very close to zero\n",
        "    return tf.reduce_all(tf.norm(primaries_q, axis=-1) < EPS)\n",
        "\n",
        "def derive_bits_advanced(pairs_q, triplets_q, invariants, initial_TAU_R, initial_TAU_U, initial_TAU_D):\n",
        "    \"\"\"\n",
        "    Derives corrected bits based on a per-index rule and guards.\n",
        "    Rule: b_i=1 if r_i>TAU_R AND u_i>TAU_U AND dv_i>TAU_D AND trip_mix>0 AND inv==True AND deg==False else 0.\n",
        "    Returns corrected bits and the final thresholds used for derivation.\n",
        "    \"\"\"\n",
        "    current_TAU_R = initial_TAU_R\n",
        "    current_TAU_U = initial_TAU_U\n",
        "    current_TAU_D = initial_TAU_D\n",
        "\n",
        "    real = pairs_q[:,0]     # [30]\n",
        "    unreal = pairs_q[:,1]   # [30]\n",
        "    mag = tf.norm(pairs_q, axis=-1) # Magnitude of each pair_q unit\n",
        "\n",
        "    # Per-index stability/divergence metrics (conceptual)\n",
        "    r_i = tf.where(mag > EPS, tf.abs(real) / mag, tf.zeros_like(mag)) # Ratio of real component magnitude to total magnitude\n",
        "    u_i = tf.where(mag > EPS, tf.abs(unreal) / mag, tf.zeros_like(mag)) # Ratio of unreal component magnitude to total magnitude\n",
        "    dv_i = tf.where(mag > EPS, tf.abs(real - unreal) / mag, tf.zeros_like(mag)) # Ratio of diff magnitude to total magnitude\n",
        "\n",
        "    # Triplet diversity: require sign-mix within each triplet block\n",
        "    signs = tf.sign(pairs_q[:,0]) # Signs of the real parts of each pair\n",
        "    trip_mix = []\n",
        "    # Define the explicit indices for grouping into 10 triplets\n",
        "    idx = tf.constant([\n",
        "        [0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "        [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]\n",
        "    ], dtype=tf.int32) # Shape [10, 3]\n",
        "\n",
        "    for b_idx_triplet in tf.range(10):\n",
        "        current_triplet_indices = idx[b_idx_triplet, :] # Shape [3]\n",
        "        s = tf.gather(signs, current_triplet_indices) # Select signs for the current triplet block\n",
        "        # Check if there is any sign difference within the triplet block\n",
        "        has_mix = tf.cast(tf.reduce_any(tf.not_equal(s, s[0])), tf.int32)\n",
        "        # Ensure the list extension is compatible with TF operations if trip_mix is later converted to Tensor\n",
        "        # Here, it's converted to Python list and then to Tensor once.\n",
        "        trip_mix.extend([has_mix.numpy().item()]*3)\n",
        "    trip_mix = tf.convert_to_tensor(trip_mix, dtype=tf.int32)  # [30]\n",
        "\n",
        "    # Global invariant checks\n",
        "    invariant_ok = invariant_check_conceptual(pairs_q, triplets_q, invariants)\n",
        "    not_degenerate = tf.logical_not(degenerate_check(pairs_q[:6, :])) # Check degeneracy of primaries\n",
        "\n",
        "    # Initial bit derivation using provided thresholds\n",
        "    b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 1: Minimum entropy check. If current bit pattern has low entropy, adjust thresholds\n",
        "    def min_entropy_ok(bits):\n",
        "        p = tf.reduce_mean(tf.cast(bits, tf.float32))\n",
        "        H = - (p * tf.math.log(p + EPS) + (1.0 - p) * tf.math.log(1.0 - p + EPS))\n",
        "        return H > 0.3 # Example entropy threshold\n",
        "\n",
        "    if not min_entropy_ok(b):\n",
        "        # Adjust thresholds to encourage more sparsity/less certainty\n",
        "        current_TAU_R *= 1.2\n",
        "        current_TAU_U *= 1.2\n",
        "        current_TAU_D = max(current_TAU_D * 0.9, 0.25) # Example adjustments\n",
        "        b = tf.cast((r_i > current_TAU_R) & (u_i > current_TAU_U) & (dv_i > current_TAU_D) & (trip_mix > 0) & invariant_ok & not_degenerate, tf.int32)\n",
        "\n",
        "    # Guard 2: Never allow all-ones or all-zeros final decision, if it happens, fallback\n",
        "    if tf.reduce_all(b == 1) or tf.reduce_all(b == 0):\n",
        "        # Fallback to marking indices where the real component magnitude exceeds EPS and triplet mix holds\n",
        "        b = tf.cast((tf.abs(real) > EPS) & (trip_mix > 0), tf.int32)\n",
        "\n",
        "    return b, current_TAU_R, current_TAU_U, current_TAU_D # Return adjusted thresholds\n",
        "\n",
        "def correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, resonance_key_q, TRACE, invariants):\n",
        "    \"\"\"\n",
        "    Advanced Error Correction hook for a single qubit (q_idx). This function performs a local\n",
        "    re-evaluation of the bit pattern for the current qubit if the initial derivation\n",
        "    is deemed 'inconsistent'.\n",
        "\n",
        "    This function is designed to:\n",
        "    - Advance *only* within the same triplet (or within the primaries 6-set) for local re-evaluation.\n",
        "      It uses the `pairs_q` and `triplets_q` already derived for this specific qubit `q_idx`.\n",
        "      It does not implicitly advance to other qubits or triplets; its scope is limited to the\n",
        "      current qubit's local tuplet structure.\n",
        "    - Record lineage for any local adjustments made. If a correction occurs, a specific\n",
        "      entry is added to the `TRACE` log, detailing the reason, source, metrics, and new key.\n",
        "    - *Not* advance across different units (triplets or qubits) unless the current local unit\n",
        "      has been exhausted. The `derive_bits_advanced` function, called internally,\n",
        "      operates solely on the provided `pairs_q` and `triplets_q` for the current qubit.\n",
        "\n",
        "    Args:\n",
        "        q_idx (int): The index of the current qubit being processed.\n",
        "        pairs_q (tf.Tensor): The 30-index phase-dual pair register for the current qubit [30, 2].\n",
        "        triplets_q (tf.Tensor): The 10 triplets for the current qubit [10, 3, 2].\n",
        "        current_bits_q (tf.Tensor): The initially derived 30-bit pattern for the current qubit [30].\n",
        "        resonance_key_q (str): The current resonance key string for the qubit.\n",
        "        TRACE (list): A list to append lineage information if corrections are made.\n",
        "        invariants (dict): Dictionary of invariant constants.\n",
        "\n",
        "    Returns:\n",
        "        tuple[tf.Tensor, str]:\n",
        "            - new_bits_q (tf.Tensor): The potentially corrected 30-bit pattern.\n",
        "            - updated_resonance_key_q (str): The updated resonance key string (with lineage if corrected).\n",
        "    \"\"\"\n",
        "    # Check for inconsistency: if all bits are 1s, or all 0s, or if the count of ones is very low/high\n",
        "    num_ones = tf.reduce_sum(current_bits_q)\n",
        "    is_all_ones = tf.reduce_all(tf.equal(current_bits_q, 1))\n",
        "    is_all_zeros = tf.reduce_all(tf.equal(current_bits_q, 0))\n",
        "    is_sparse = num_ones < 5 # Example: less than 5 bits are 1\n",
        "    is_dense = num_ones > 25 # Example: more than 25 bits are 1\n",
        "\n",
        "    is_inconsistent = (is_all_ones or is_all_zeros or is_sparse or is_dense).numpy().item() # Convert boolean tensor to Python boolean\n",
        "\n",
        "    if is_inconsistent:\n",
        "        # Call the advanced bit derivation function and capture adjusted thresholds\n",
        "        corrected_bits, adjusted_TAU_R, adjusted_TAU_U, adjusted_TAU_D = derive_bits_advanced(pairs_q, triplets_q, invariants, TAU_R_METRIC, TAU_U_METRIC, TAU_D_METRIC)\n",
        "\n",
        "        # Update Bits[q] with corrected_bits\n",
        "        new_bits_q = corrected_bits\n",
        "\n",
        "        # Update lineage and ResonanceKey[q]\n",
        "        # The updated key incorporates the correction lineage.\n",
        "        updated_resonance_key_q = hashlib.sha256((resonance_key_q + \"REFactorBits\" + str(new_bits_q.numpy().tolist())).encode(\"utf-8\")).hexdigest()\n",
        "        TRACE.append({'qubit': q_idx, 'reason':\"binary_refactor\", 'source':\"tuplets\",\n",
        "                      'r_metric': r_metric(pairs_q[:,0]).numpy().item(), # Log metrics for trace\n",
        "                      'u_metric': u_metric(pairs_q[:,1]).numpy().item(),\n",
        "                      'dv_metric': dv_metric(pairs_q).numpy().item(),\n",
        "                      'invariant_pass': invariant_check_conceptual(pairs_q, triplets_q, invariants).numpy().item(),\n",
        "                      'degenerate_check': degenerate_check(pairs_q[:6, :]).numpy().item(),\n",
        "                      'correction_threshold_r': adjusted_TAU_R, # Log adjusted thresholds\n",
        "                      'correction_threshold_u': adjusted_TAU_U,\n",
        "                      'correction_threshold_d': adjusted_TAU_D, \\\n",
        "                      'corrected_bits': new_bits_q.numpy().tolist(),\n",
        "                      'old_key': resonance_key_q, 'new_key': updated_resonance_key_q}) # Fix: Use updated_resonance_key_q\n",
        "        return new_bits_q, updated_resonance_key_q # Fix: Return updated_resonance_key_q\n",
        "    else:\n",
        "        return current_bits_q, resonance_key_q\n",
        "\n",
        "# =========================\n",
        "# Reproducible Example (Multi-Qubit)\n",
        "# =========================\n",
        "\n",
        "# Number of virtual qubits\n",
        "Q = 64 # Changed Q to 64 as per instructions\n",
        "\n",
        "# Dynamically generate initial_primaries\n",
        "# Each primary (x, y, z) is a phase-dual [real, unreal]\n",
        "# Need to generate Q sets of (x,y,z) then derive their negations.\n",
        "\n",
        "# Generate random x, y, z components (each as a phase-dual [real, unreal]) for Q qubits\n",
        "# Shape [Q, 3, 2] representing (x,y,z) base primaries\n",
        "base_primaries_xyz = tf.random.uniform(shape=[Q, 3, 2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Construct initial_primaries = [x, -x, y, -y, z, -z]\n",
        "# Where x, y, z are from base_primaries_xyz and -x is neg_phase_dual(x)\n",
        "initial_primaries = tf.concat([\n",
        "    base_primaries_xyz[:, 0, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 0, :])[:, tf.newaxis, :], # x, -x\n",
        "    base_primaries_xyz[:, 1, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 1, :])[:, tf.newaxis, :], # y, -y\n",
        "    base_primaries_xyz[:, 2, :][:, tf.newaxis, :], neg_phase_dual(base_primaries_xyz[:, 2, :])[:, tf.newaxis, :], # z, -z\n",
        "], axis=1) # Shape [Q, 6, 2]\n",
        "\n",
        "# Dynamically generate axis_maps\n",
        "# axis_maps for each axis ('x', 'y', 'z') should be of shape [Q, K_max, 2]\n",
        "# where K_max is the maximum K across all qubits and axes.\n",
        "\n",
        "list_of_axis_maps_x = []\n",
        "list_of_axis_maps_y = []\n",
        "list_of_axis_maps_z = []\n",
        "\n",
        "max_k_dynamic = 0\n",
        "min_k_val = 3 # Minimum K as per problem description\n",
        "max_k_val = 11 # Arbitrary maximum K for random generation\n",
        "\n",
        "for q_idx in range(Q):\n",
        "    # Generate a random K for each qubit and for each axis map (for x, y, z separately)\n",
        "    k_x = np.random.randint(min_k_val, max_k_val)\n",
        "    k_y = np.random.randint(min_k_val, max_k_val)\n",
        "    k_z = np.random.randint(min_k_val, max_k_val)\n",
        "\n",
        "    list_of_axis_maps_x.append(tf.random.uniform(shape=[k_x, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_y.append(tf.random.uniform(shape=[k_y, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "    list_of_axis_maps_z.append(tf.random.uniform(shape=[k_z, 2], minval=-1.0, maxval=1.0, dtype=tf.float32))\n",
        "\n",
        "    max_k_dynamic = max(max_k_dynamic, k_x, k_y, k_z)\n",
        "\n",
        "# Pad all generated axis map tensors to max_k_dynamic\n",
        "axis_maps = {\n",
        "    'x': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_x]),\n",
        "    'y': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_y]),\n",
        "    'z': tf.stack([tf.pad(t, [[0, max_k_dynamic - tf.shape(t)[0]], [0, 0]], \"CONSTANT\", constant_values=0.0) for t in list_of_axis_maps_z]),\n",
        "}\n",
        "\n",
        "# Update k_values to have a shape [Q, 1] with random float32 values between 0.0 and 1.0\n",
        "k_values = tf.random.uniform(shape=[Q, 1], minval=0.0, maxval=1.0, dtype=tf.float32)\n",
        "\n",
        "# Define a_U_constant (from NGFT)\n",
        "a_U_constant = tf.constant(10.0, dtype=tf.float32) # Scalar\n",
        "\n",
        "# Dynamically generate lineage_hashes\n",
        "lineage_hashes = []\n",
        "for q_idx in range(Q):\n",
        "    lineage_hashes.append(hashlib.sha256(f\"Q{q_idx}_PathDynamic_{np.random.randint(0, 1000)}\".encode('utf-8')).hexdigest())\n",
        "\n",
        "# Sample NECL program (list of operation strings) - NECL[q] = [op(args), ...]\n",
        "# For this example, all qubits share the same NECL program.\n",
        "necl_program_shared = ['TWIST', 'CURV', 'PARITY_Q', 'COLLAPSE_Q', 'LIFT']\n",
        "\n",
        "# Placeholder parameters for NECL operations (can be expanded)\n",
        "necl_params = {\n",
        "    'CURV': tf.constant(0.01, dtype=tf.float32), # kappa\n",
        "    'GEOD': tf.constant(0.05, dtype=tf.float32), # t\n",
        "    'TWIST': tf.constant(math.pi/4, dtype=tf.float32),  # theta (radians)\n",
        "    'LIFT': tf.constant(0.5, dtype=tf.float32),   # d (e.g., a scaling factor based on d)\n",
        "    'GLUE': tf.constant(0.1, dtype=tf.float32),   # sigma\n",
        "    'SPLIT': tf.constant(0.5, dtype=tf.float32),  # tau\n",
        "}\n",
        "\n",
        "# Invariants ν: {units, tol, ordering}\n",
        "invariants = {\n",
        "    'units': 1.0,\n",
        "    'tol': 1e-5, # A new tolerance for error correction\n",
        "    'ordering': 'real_unreal_first',\n",
        "    'correction_threshold': 0.1 # Threshold for scores in error correction\n",
        "}\n",
        "\n",
        "# TRACE (lineage manifest) - list of dictionaries to log events\n",
        "TRACE = []\n",
        "\n",
        "# =========================\n",
        "# Main Cycle (per run)\n",
        "# =========================\n",
        "\n",
        "# 1) X ← NORM(X, ν)\n",
        "primaries_normalized = NORMALIZE_Q(initial_primaries, invariants)\n",
        "\n",
        "# 2) X ← APPLY_NECL(X, NECL)       # default order: TWIST → CURV → PARITY_Q → COLLAPSE_Q\n",
        "primaries_after_necl, necl_program_checksum = APPLY_NECL(primaries_normalized, necl_program_shared, necl_params, PRIME_MASK)\n",
        "\n",
        "# 3) Pairs[q], Triplets[q] ← compute_tuplets(X[q]) (This step implies per-qubit computation for pairs and triplets)\n",
        "# In our vectorized setup, we compute for all Q simultaneously.\n",
        "all_pairs = compute_pairs(primaries_after_necl) # [Q, 30, 2]\n",
        "all_triplets = group_triplets(all_pairs) # [Q, 10, 3, 2]\n",
        "\n",
        "# 4) Bits[q] ← bitmap(X[q].real)  # binary collapse map (phase-dual aware)\n",
        "# We'll re-detect collapse and parity for the final state to generate initial bits for error correction.\n",
        "final_collapse_mask = detect_collapse(all_pairs) # Pass R_FOR_RATIO implicitly from constants\n",
        "final_rotated_pairs, final_parity_mask = apply_parity_rotation(all_pairs, final_collapse_mask, PRIME_MASK)\n",
        "initial_bits = bitmap(final_rotated_pairs) # [Q, 30]\n",
        "\n",
        "corrected_bits_list = []\n",
        "final_resonance_keys = []\n",
        "\n",
        "# Loop through each qubit for error correction (if needed) and key generation\n",
        "for q_idx in range(Q):\n",
        "    # Extract per-qubit data\n",
        "    pairs_q = all_pairs[q_idx] # [30, 2]\n",
        "    triplets_q = all_triplets[q_idx] # [10, 3, 2]\n",
        "    current_bits_q = initial_bits[q_idx] # [30]\n",
        "    current_lineage_hash = lineage_hashes[q_idx]\n",
        "\n",
        "    # Manual modification to force an 'inconsistent' state for Qubit 0 for demonstration\n",
        "    if q_idx == 0:\n",
        "        # Example: set Qubit 0's bits to be very sparse (e.g., only one '1')\n",
        "        sparse_bits_for_q0 = tf.concat([tf.ones([1], dtype=tf.int32), tf.zeros([29], dtype=tf.int32)], axis=0)\n",
        "        current_bits_q = sparse_bits_for_q0\n",
        "\n",
        "    # Error Correction (Step A & B from instructions)\n",
        "    corrected_bits_q, updated_key_q = correct_bits(q_idx, pairs_q, triplets_q, current_bits_q, current_lineage_hash, TRACE, invariants)\n",
        "    corrected_bits_list.append(corrected_bits_q)\n",
        "    # The updated_key_q already contains the 'REFactorBits' lineage if correction occurred\n",
        "    final_resonance_keys.append(updated_key_q)\n",
        "\n",
        "# Convert corrected_bits_list back to a tensor for subsequent use if needed\n",
        "corrected_bits_tensor = tf.stack(corrected_bits_list)\n",
        "\n",
        "# 5) PrimariesOut[q] ← promote_primaries(Pairs[q], Triplets[q])\n",
        "# This step uses the full triplets and axis maps to promote new primaries\n",
        "primaries_out_promoted = ASSOC_Q(all_triplets, axis_maps, THETA_PHIPI)\n",
        "\n",
        "# 6) InfoEnergy[q] ← (k+1)·a_U·I   # I from tuplet entropy\n",
        "info_energy_output = compute_info_energy(primaries_out_promoted, k_values, a_U_constant)\n",
        "\n",
        "# 7) ResonanceKey[q] ← hash(lineage_manifest)\n",
        "# This is done within the loop for correct_bits and then in make_keys\n",
        "# The final_resonance_keys list already holds the updated keys after potential error correction.\n",
        "\n",
        "# 8) Spin[q], I_vec[q] ← decode_hash(H[q])\n",
        "# Decode for the first qubit as an example.\n",
        "Q_for_decode_example = 1 # We decode for 1 qubit per hash call\n",
        "D_for_decode_example = 16 # D ≥ 16 as per instruction\n",
        "\n",
        "all_spin_vecs_decoded = []\n",
        "all_i_vecs_decoded = []\n",
        "for q_idx in range(Q):\n",
        "    spin_vec_decoded, i_vec_decoded = decode_lineage_hash(lineage_hashes[q_idx], q_idx, D=D_for_decode_example, num_qubits=Q, invariants=invariants)\n",
        "    all_spin_vecs_decoded.append(spin_vec_decoded)\n",
        "    all_i_vecs_decoded.append(i_vec_decoded)\n",
        "\n",
        "# Concatenate decoded spins and i_vecs to get [Q, 2, 3] and [Q, D]\n",
        "spin_vecs_decoded_tensor = tf.concat(all_spin_vecs_decoded, axis=0)\n",
        "i_vecs_decoded_tensor = tf.concat(all_i_vecs_decoded, axis=0)\n",
        "\n",
        "# =========================\n",
        "# --- Print Results ---\n",
        "# =========================\n",
        "print(\"Primaries In:\\n\", initial_primaries.numpy())\n",
        "print(\"\\nPrimaries After NECL:\\n\", primaries_after_necl.numpy())\n",
        "# Print pairs and triplets per-qubit, as they are part of the intermediate tuplet constructs\n",
        "print(\"\\nPairs[0]:\\n\", all_pairs[0].numpy())\n",
        "print(\"\\nTriplets[0]:\\n\", all_triplets[0].numpy())\n",
        "print(\"\\nBits (all qubits):\\n\", corrected_bits_tensor.numpy()) # Use corrected bits\n",
        "print(\"\\nPrimaries Out (promoted):\\n\", primaries_out_promoted.numpy())\n",
        "\n",
        "# Conceptual Nth identities: {n^1, n^2, n^3, n^p} per qubit\n",
        "print(\"\\nNth Identities (Conceptual, per qubit):\\n\")\n",
        "for q_idx in range(Q):\n",
        "    # Extract promoted_primary_x for the current qubit\n",
        "    promoted_primary_x = primaries_out_promoted[q_idx, 0, :] # Shape [2]\n",
        "\n",
        "    # Ensure promoted_primary_x is explicitly converted to a Tensor for n_identity\n",
        "    promoted_primary_x_tensor = tf.convert_to_tensor(promoted_primary_x, dtype=tf.float32)\n",
        "\n",
        "    print(f\"  Qubit {q_idx}:\")\n",
        "    print(f\"    n^0 (base identity): {n_identity(0).numpy()[0]}\")\n",
        "    print(f\"    n^1 (first-order selector): {n_identity(1, selector_primary=promoted_primary_x_tensor).numpy()[0]}\")\n",
        "    print(f\"    n^2 (second-order product): {n_identity(2).numpy()[0]}\") # Placeholder\n",
        "    print(f\"    n^p (p-order product): {n_identity('p').numpy()[0]}\") # Placeholder\n",
        "\n",
        "print(\"\\nInfo-energy Output (all qubits):\\n\", info_energy_output.numpy())\n",
        "print(\"\\nResonance Keys (all qubits):\\n\", final_resonance_keys)\n",
        "print(\"\\nSpin (all qubits, conceptual):\\n\", spin_vecs_decoded_tensor.numpy())\n",
        "print(\"\\nI_vec (all qubits, conceptual):\\n\", i_vecs_decoded_tensor.numpy())\n",
        "\n",
        "# NECL manifest + checksum per qubit - Conceptual: print TRACE log and a checksum of it\n",
        "necl_manifest_checksums = []\n",
        "for q_idx in range(Q):\n",
        "    qubit_trace_entries = [entry for entry in TRACE if entry['qubit'] == q_idx]\n",
        "    manifest_str = str(qubit_trace_entries)\n",
        "    checksum = hashlib.sha256(manifest_str.encode('utf-8')).hexdigest()\n",
        "    necl_manifest_checksums.append(checksum)\n",
        "print(\"\\nNECL Manifest Checksums (per qubit, conceptual):\\n\", necl_manifest_checksums)\n",
        "print(\"\\nTRACE Log (Conceptual - detailed lineage for error correction):\\n\", TRACE)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primaries In:\n",
            " [[[ 0.38381505  0.4721625 ]\n",
            "  [-0.38381505 -0.4721625 ]\n",
            "  [-0.9002569   0.30928206]\n",
            "  [ 0.9002569  -0.30928206]\n",
            "  [-0.77344847 -0.25261378]\n",
            "  [ 0.77344847  0.25261378]]\n",
            "\n",
            " [[ 0.9345577   0.7938018 ]\n",
            "  [-0.9345577  -0.7938018 ]\n",
            "  [-0.20542765  0.41429496]\n",
            "  [ 0.20542765 -0.41429496]\n",
            "  [ 0.6797228  -0.41083193]\n",
            "  [-0.6797228   0.41083193]]\n",
            "\n",
            " [[-0.16832232 -0.9434247 ]\n",
            "  [ 0.16832232  0.9434247 ]\n",
            "  [ 0.06129098 -0.34418797]\n",
            "  [-0.06129098  0.34418797]\n",
            "  [-0.38914895 -0.63503885]\n",
            "  [ 0.38914895  0.63503885]]\n",
            "\n",
            " [[-0.98245907  0.5274403 ]\n",
            "  [ 0.98245907 -0.5274403 ]\n",
            "  [-0.42973685  0.9610157 ]\n",
            "  [ 0.42973685 -0.9610157 ]\n",
            "  [ 0.27415085  0.25171733]\n",
            "  [-0.27415085 -0.25171733]]\n",
            "\n",
            " [[ 0.71996427  0.6754923 ]\n",
            "  [-0.71996427 -0.6754923 ]\n",
            "  [-0.46750283  0.04121709]\n",
            "  [ 0.46750283 -0.04121709]\n",
            "  [-0.69546294 -0.17058277]\n",
            "  [ 0.69546294  0.17058277]]\n",
            "\n",
            " [[ 0.41989803 -0.79322433]\n",
            "  [-0.41989803  0.79322433]\n",
            "  [ 0.22988105  0.07526851]\n",
            "  [-0.22988105 -0.07526851]\n",
            "  [ 0.72737     0.22108269]\n",
            "  [-0.72737    -0.22108269]]\n",
            "\n",
            " [[-0.57559586 -0.29849434]\n",
            "  [ 0.57559586  0.29849434]\n",
            "  [ 0.01936173  0.6499014 ]\n",
            "  [-0.01936173 -0.6499014 ]\n",
            "  [-0.8747065  -0.70279765]\n",
            "  [ 0.8747065   0.70279765]]\n",
            "\n",
            " [[ 0.9885354   0.26631546]\n",
            "  [-0.9885354  -0.26631546]\n",
            "  [-0.43131113  0.12471485]\n",
            "  [ 0.43131113 -0.12471485]\n",
            "  [-0.7008858   0.68838835]\n",
            "  [ 0.7008858  -0.68838835]]\n",
            "\n",
            " [[-0.4463327   0.5466888 ]\n",
            "  [ 0.4463327  -0.5466888 ]\n",
            "  [-0.29636526  0.04926229]\n",
            "  [ 0.29636526 -0.04926229]\n",
            "  [ 0.08389831 -0.81831074]\n",
            "  [-0.08389831  0.81831074]]\n",
            "\n",
            " [[-0.2266593   0.5271039 ]\n",
            "  [ 0.2266593  -0.5271039 ]\n",
            "  [ 0.91745377  0.9301381 ]\n",
            "  [-0.91745377 -0.9301381 ]\n",
            "  [-0.48633218 -0.9107089 ]\n",
            "  [ 0.48633218  0.9107089 ]]\n",
            "\n",
            " [[-0.8802383   0.71891475]\n",
            "  [ 0.8802383  -0.71891475]\n",
            "  [ 0.38370967  0.01921535]\n",
            "  [-0.38370967 -0.01921535]\n",
            "  [ 0.07834792 -0.1310792 ]\n",
            "  [-0.07834792  0.1310792 ]]\n",
            "\n",
            " [[ 0.47669125  0.88266397]\n",
            "  [-0.47669125 -0.88266397]\n",
            "  [-0.17950106 -0.03071165]\n",
            "  [ 0.17950106  0.03071165]\n",
            "  [ 0.5103848  -0.19340539]\n",
            "  [-0.5103848   0.19340539]]\n",
            "\n",
            " [[ 0.2921877   0.8368478 ]\n",
            "  [-0.2921877  -0.8368478 ]\n",
            "  [ 0.41489697 -0.2932713 ]\n",
            "  [-0.41489697  0.2932713 ]\n",
            "  [-0.7291095   0.26096177]\n",
            "  [ 0.7291095  -0.26096177]]\n",
            "\n",
            " [[ 0.49890804 -0.31858802]\n",
            "  [-0.49890804  0.31858802]\n",
            "  [ 0.5073261  -0.56813264]\n",
            "  [-0.5073261   0.56813264]\n",
            "  [-0.81207395 -0.0302093 ]\n",
            "  [ 0.81207395  0.0302093 ]]\n",
            "\n",
            " [[-0.529299   -0.34599614]\n",
            "  [ 0.529299    0.34599614]\n",
            "  [ 0.90164447  0.90080714]\n",
            "  [-0.90164447 -0.90080714]\n",
            "  [-0.6080859  -0.59432554]\n",
            "  [ 0.6080859   0.59432554]]\n",
            "\n",
            " [[ 0.7781098  -0.19763541]\n",
            "  [-0.7781098   0.19763541]\n",
            "  [ 0.45202494 -0.49152946]\n",
            "  [-0.45202494  0.49152946]\n",
            "  [ 0.08098221  0.86686254]\n",
            "  [-0.08098221 -0.86686254]]\n",
            "\n",
            " [[-0.24983335 -0.7022252 ]\n",
            "  [ 0.24983335  0.7022252 ]\n",
            "  [ 0.6701596   0.8395338 ]\n",
            "  [-0.6701596  -0.8395338 ]\n",
            "  [-0.8375037   0.05375504]\n",
            "  [ 0.8375037  -0.05375504]]\n",
            "\n",
            " [[-0.39319086 -0.8920417 ]\n",
            "  [ 0.39319086  0.8920417 ]\n",
            "  [-0.48658943  0.05017066]\n",
            "  [ 0.48658943 -0.05017066]\n",
            "  [ 0.1536982   0.7663038 ]\n",
            "  [-0.1536982  -0.7663038 ]]\n",
            "\n",
            " [[-0.5466616   0.48729682]\n",
            "  [ 0.5466616  -0.48729682]\n",
            "  [-0.0752275   0.77060556]\n",
            "  [ 0.0752275  -0.77060556]\n",
            "  [-0.69455504 -0.7493539 ]\n",
            "  [ 0.69455504  0.7493539 ]]\n",
            "\n",
            " [[-0.13549352  0.13872242]\n",
            "  [ 0.13549352 -0.13872242]\n",
            "  [ 0.9832022   0.5295372 ]\n",
            "  [-0.9832022  -0.5295372 ]\n",
            "  [-0.53177214  0.29594994]\n",
            "  [ 0.53177214 -0.29594994]]\n",
            "\n",
            " [[ 0.08480668  0.40975332]\n",
            "  [-0.08480668 -0.40975332]\n",
            "  [ 0.393044   -0.8180449 ]\n",
            "  [-0.393044    0.8180449 ]\n",
            "  [ 0.8346062   0.24193025]\n",
            "  [-0.8346062  -0.24193025]]\n",
            "\n",
            " [[-0.6986613   0.09478092]\n",
            "  [ 0.6986613  -0.09478092]\n",
            "  [-0.84923196 -0.5711312 ]\n",
            "  [ 0.84923196  0.5711312 ]\n",
            "  [ 0.93874574  0.77395105]\n",
            "  [-0.93874574 -0.77395105]]\n",
            "\n",
            " [[-0.2066741   0.6602013 ]\n",
            "  [ 0.2066741  -0.6602013 ]\n",
            "  [ 0.9187441  -0.4649067 ]\n",
            "  [-0.9187441   0.4649067 ]\n",
            "  [ 0.8621261   0.8770418 ]\n",
            "  [-0.8621261  -0.8770418 ]]\n",
            "\n",
            " [[-0.5988529   0.12265801]\n",
            "  [ 0.5988529  -0.12265801]\n",
            "  [-0.08016777  0.81593895]\n",
            "  [ 0.08016777 -0.81593895]\n",
            "  [-0.619858    0.17416763]\n",
            "  [ 0.619858   -0.17416763]]\n",
            "\n",
            " [[-0.80006385 -0.48108792]\n",
            "  [ 0.80006385  0.48108792]\n",
            "  [-0.52110004  0.7111223 ]\n",
            "  [ 0.52110004 -0.7111223 ]\n",
            "  [ 0.23950839 -0.7180047 ]\n",
            "  [-0.23950839  0.7180047 ]]\n",
            "\n",
            " [[-0.5013728  -0.01608372]\n",
            "  [ 0.5013728   0.01608372]\n",
            "  [-0.4063108   0.3956306 ]\n",
            "  [ 0.4063108  -0.3956306 ]\n",
            "  [-0.39121294 -0.35503078]\n",
            "  [ 0.39121294  0.35503078]]\n",
            "\n",
            " [[-0.5828543   0.7014234 ]\n",
            "  [ 0.5828543  -0.7014234 ]\n",
            "  [ 0.7866614   0.60666275]\n",
            "  [-0.7866614  -0.60666275]\n",
            "  [ 0.27109885 -0.02247024]\n",
            "  [-0.27109885  0.02247024]]\n",
            "\n",
            " [[ 0.06893229 -0.5980551 ]\n",
            "  [-0.06893229  0.5980551 ]\n",
            "  [ 0.93850064 -0.04586434]\n",
            "  [-0.93850064  0.04586434]\n",
            "  [ 0.30765867 -0.65760684]\n",
            "  [-0.30765867  0.65760684]]\n",
            "\n",
            " [[-0.25864506  0.78638506]\n",
            "  [ 0.25864506 -0.78638506]\n",
            "  [-0.05244732 -0.27851796]\n",
            "  [ 0.05244732  0.27851796]\n",
            "  [ 0.27653933 -0.30981874]\n",
            "  [-0.27653933  0.30981874]]\n",
            "\n",
            " [[-0.49987936  0.70598507]\n",
            "  [ 0.49987936 -0.70598507]\n",
            "  [ 0.15026021  0.6513119 ]\n",
            "  [-0.15026021 -0.6513119 ]\n",
            "  [-0.03391576 -0.848804  ]\n",
            "  [ 0.03391576  0.848804  ]]\n",
            "\n",
            " [[-0.9354074   0.7687597 ]\n",
            "  [ 0.9354074  -0.7687597 ]\n",
            "  [ 0.09465194 -0.21238613]\n",
            "  [-0.09465194  0.21238613]\n",
            "  [-0.37059116  0.65733385]\n",
            "  [ 0.37059116 -0.65733385]]\n",
            "\n",
            " [[ 0.98881674 -0.4776857 ]\n",
            "  [-0.98881674  0.4776857 ]\n",
            "  [-0.57845473 -0.46990418]\n",
            "  [ 0.57845473  0.46990418]\n",
            "  [-0.2456479  -0.16276789]\n",
            "  [ 0.2456479   0.16276789]]\n",
            "\n",
            " [[ 0.86677766  0.29433918]\n",
            "  [-0.86677766 -0.29433918]\n",
            "  [-0.6106653  -0.16959119]\n",
            "  [ 0.6106653   0.16959119]\n",
            "  [-0.12530851 -0.26029348]\n",
            "  [ 0.12530851  0.26029348]]\n",
            "\n",
            " [[-0.08614874 -0.6699295 ]\n",
            "  [ 0.08614874  0.6699295 ]\n",
            "  [ 0.20525146  0.7373011 ]\n",
            "  [-0.20525146 -0.7373011 ]\n",
            "  [-0.8296752  -0.50893784]\n",
            "  [ 0.8296752   0.50893784]]\n",
            "\n",
            " [[ 0.14115095  0.9929328 ]\n",
            "  [-0.14115095 -0.9929328 ]\n",
            "  [-0.15717602  0.42432857]\n",
            "  [ 0.15717602 -0.42432857]\n",
            "  [ 0.90442777 -0.02760029]\n",
            "  [-0.90442777  0.02760029]]\n",
            "\n",
            " [[-0.9301841   0.06319523]\n",
            "  [ 0.9301841  -0.06319523]\n",
            "  [-0.92262053 -0.7274513 ]\n",
            "  [ 0.92262053  0.7274513 ]\n",
            "  [ 0.71191025  0.9960606 ]\n",
            "  [-0.71191025 -0.9960606 ]]\n",
            "\n",
            " [[-0.20391989 -0.9943433 ]\n",
            "  [ 0.20391989  0.9943433 ]\n",
            "  [-0.37081385  0.31377387]\n",
            "  [ 0.37081385 -0.31377387]\n",
            "  [ 0.07404661 -0.9218011 ]\n",
            "  [-0.07404661  0.9218011 ]]\n",
            "\n",
            " [[-0.11255121  0.58311796]\n",
            "  [ 0.11255121 -0.58311796]\n",
            "  [ 0.5425267  -0.97987676]\n",
            "  [-0.5425267   0.97987676]\n",
            "  [-0.21034718 -0.7423043 ]\n",
            "  [ 0.21034718  0.7423043 ]]\n",
            "\n",
            " [[-0.9716053   0.5799062 ]\n",
            "  [ 0.9716053  -0.5799062 ]\n",
            "  [ 0.6860521  -0.640008  ]\n",
            "  [-0.6860521   0.640008  ]\n",
            "  [ 0.5715666  -0.3412161 ]\n",
            "  [-0.5715666   0.3412161 ]]\n",
            "\n",
            " [[-0.800863    0.33559465]\n",
            "  [ 0.800863   -0.33559465]\n",
            "  [-0.6787069   0.8991325 ]\n",
            "  [ 0.6787069  -0.8991325 ]\n",
            "  [-0.08008695 -0.12324119]\n",
            "  [ 0.08008695  0.12324119]]\n",
            "\n",
            " [[ 0.8544278   0.5050018 ]\n",
            "  [-0.8544278  -0.5050018 ]\n",
            "  [ 0.17527652  0.3049848 ]\n",
            "  [-0.17527652 -0.3049848 ]\n",
            "  [-0.04599357 -0.10830259]\n",
            "  [ 0.04599357  0.10830259]]\n",
            "\n",
            " [[-0.7864766   0.64068437]\n",
            "  [ 0.7864766  -0.64068437]\n",
            "  [ 0.1439693   0.6025708 ]\n",
            "  [-0.1439693  -0.6025708 ]\n",
            "  [-0.07919478 -0.8199308 ]\n",
            "  [ 0.07919478  0.8199308 ]]\n",
            "\n",
            " [[ 0.2593465  -0.34812617]\n",
            "  [-0.2593465   0.34812617]\n",
            "  [-0.15096283 -0.49069571]\n",
            "  [ 0.15096283  0.49069571]\n",
            "  [ 0.62005424 -0.6780586 ]\n",
            "  [-0.62005424  0.6780586 ]]\n",
            "\n",
            " [[ 0.15715528  0.6711173 ]\n",
            "  [-0.15715528 -0.6711173 ]\n",
            "  [ 0.5213585  -0.13281631]\n",
            "  [-0.5213585   0.13281631]\n",
            "  [ 0.6680386   0.10808921]\n",
            "  [-0.6680386  -0.10808921]]\n",
            "\n",
            " [[-0.54339385 -0.8188846 ]\n",
            "  [ 0.54339385  0.8188846 ]\n",
            "  [-0.6709871  -0.01406217]\n",
            "  [ 0.6709871   0.01406217]\n",
            "  [ 0.35320115 -0.50083685]\n",
            "  [-0.35320115  0.50083685]]\n",
            "\n",
            " [[-0.0248065   0.7593806 ]\n",
            "  [ 0.0248065  -0.7593806 ]\n",
            "  [ 0.40168095  0.90595794]\n",
            "  [-0.40168095 -0.90595794]\n",
            "  [ 0.6343603  -0.7404716 ]\n",
            "  [-0.6343603   0.7404716 ]]\n",
            "\n",
            " [[-0.6838856   0.72349644]\n",
            "  [ 0.6838856  -0.72349644]\n",
            "  [-0.06179595  0.6006899 ]\n",
            "  [ 0.06179595 -0.6006899 ]\n",
            "  [ 0.5022881  -0.56767917]\n",
            "  [-0.5022881   0.56767917]]\n",
            "\n",
            " [[ 0.53027654 -0.2797594 ]\n",
            "  [-0.53027654  0.2797594 ]\n",
            "  [ 0.04551554  0.20622563]\n",
            "  [-0.04551554 -0.20622563]\n",
            "  [-0.12323833 -0.6700678 ]\n",
            "  [ 0.12323833  0.6700678 ]]\n",
            "\n",
            " [[-0.5346613  -0.7164674 ]\n",
            "  [ 0.5346613   0.7164674 ]\n",
            "  [-0.21751285  0.14734387]\n",
            "  [ 0.21751285 -0.14734387]\n",
            "  [-0.4723611  -0.3946383 ]\n",
            "  [ 0.4723611   0.3946383 ]]\n",
            "\n",
            " [[-0.93546486  0.38846135]\n",
            "  [ 0.93546486 -0.38846135]\n",
            "  [ 0.6863506   0.24933004]\n",
            "  [-0.6863506  -0.24933004]\n",
            "  [-0.24339104  0.45156264]\n",
            "  [ 0.24339104 -0.45156264]]\n",
            "\n",
            " [[ 0.21366453  0.98731375]\n",
            "  [-0.21366453 -0.98731375]\n",
            "  [ 0.93316364  0.16631937]\n",
            "  [-0.93316364 -0.16631937]\n",
            "  [-0.6521175   0.6241455 ]\n",
            "  [ 0.6521175  -0.6241455 ]]\n",
            "\n",
            " [[ 0.36255932  0.28108644]\n",
            "  [-0.36255932 -0.28108644]\n",
            "  [-0.39375663 -0.8123145 ]\n",
            "  [ 0.39375663  0.8123145 ]\n",
            "  [-0.1218679   0.3795328 ]\n",
            "  [ 0.1218679  -0.3795328 ]]\n",
            "\n",
            " [[ 0.70942926  0.98204565]\n",
            "  [-0.70942926 -0.98204565]\n",
            "  [ 0.21726632 -0.3307147 ]\n",
            "  [-0.21726632  0.3307147 ]\n",
            "  [-0.20798278  0.6245308 ]\n",
            "  [ 0.20798278 -0.6245308 ]]\n",
            "\n",
            " [[-0.86422896 -0.47317505]\n",
            "  [ 0.86422896  0.47317505]\n",
            "  [ 0.94702005  0.7681589 ]\n",
            "  [-0.94702005 -0.7681589 ]\n",
            "  [-0.8827915   0.34052253]\n",
            "  [ 0.8827915  -0.34052253]]\n",
            "\n",
            " [[-0.67925024 -0.27889776]\n",
            "  [ 0.67925024  0.27889776]\n",
            "  [-0.01623011 -0.944051  ]\n",
            "  [ 0.01623011  0.944051  ]\n",
            "  [ 0.65218425  0.6221273 ]\n",
            "  [-0.65218425 -0.6221273 ]]\n",
            "\n",
            " [[ 0.12396431  0.42152357]\n",
            "  [-0.12396431 -0.42152357]\n",
            "  [ 0.82304287 -0.07823491]\n",
            "  [-0.82304287  0.07823491]\n",
            "  [ 0.7428222  -0.85165024]\n",
            "  [-0.7428222   0.85165024]]\n",
            "\n",
            " [[-0.43516517  0.79246855]\n",
            "  [ 0.43516517 -0.79246855]\n",
            "  [ 0.22694445  0.20331907]\n",
            "  [-0.22694445 -0.20331907]\n",
            "  [-0.9838319  -0.22339249]\n",
            "  [ 0.9838319   0.22339249]]\n",
            "\n",
            " [[-0.4869783  -0.24127388]\n",
            "  [ 0.4869783   0.24127388]\n",
            "  [-0.08765244  0.55232525]\n",
            "  [ 0.08765244 -0.55232525]\n",
            "  [-0.25947618  0.60875344]\n",
            "  [ 0.25947618 -0.60875344]]\n",
            "\n",
            " [[-0.04915261 -0.4381106 ]\n",
            "  [ 0.04915261  0.4381106 ]\n",
            "  [ 0.941869   -0.49857664]\n",
            "  [-0.941869    0.49857664]\n",
            "  [-0.4466889   0.12480879]\n",
            "  [ 0.4466889  -0.12480879]]\n",
            "\n",
            " [[ 0.9087713   0.25391555]\n",
            "  [-0.9087713  -0.25391555]\n",
            "  [ 0.80130816  0.83705664]\n",
            "  [-0.80130816 -0.83705664]\n",
            "  [ 0.36931777 -0.49281526]\n",
            "  [-0.36931777  0.49281526]]\n",
            "\n",
            " [[ 0.22574377  0.10281014]\n",
            "  [-0.22574377 -0.10281014]\n",
            "  [-0.16745877 -0.5875113 ]\n",
            "  [ 0.16745877  0.5875113 ]\n",
            "  [ 0.9504404  -0.12925029]\n",
            "  [-0.9504404   0.12925029]]\n",
            "\n",
            " [[-0.01320648  0.4571402 ]\n",
            "  [ 0.01320648 -0.4571402 ]\n",
            "  [ 0.55960727 -0.58340406]\n",
            "  [-0.55960727  0.58340406]\n",
            "  [-0.38160586  0.9491389 ]\n",
            "  [ 0.38160586 -0.9491389 ]]\n",
            "\n",
            " [[-0.41279364 -0.5139289 ]\n",
            "  [ 0.41279364  0.5139289 ]\n",
            "  [-0.31450653 -0.98219275]\n",
            "  [ 0.31450653  0.98219275]\n",
            "  [-0.13393855 -0.7775302 ]\n",
            "  [ 0.13393855  0.7775302 ]]\n",
            "\n",
            " [[ 0.05545926 -0.34161425]\n",
            "  [-0.05545926  0.34161425]\n",
            "  [-0.49632406  0.27487278]\n",
            "  [ 0.49632406 -0.27487278]\n",
            "  [ 0.28313136 -0.03500986]\n",
            "  [-0.28313136  0.03500986]]]\n",
            "\n",
            "Primaries After NECL:\n",
            " [[[ 0.08478673  0.07375345]\n",
            "  [-0.08478673 -0.07375345]\n",
            "  [ 0.19869676 -0.04826853]\n",
            "  [-0.19869676  0.04826853]\n",
            "  [-0.17075635 -0.03943552]\n",
            "  [-0.17075635 -0.03943552]]\n",
            "\n",
            " [[ 0.19718038  0.11842807]\n",
            "  [-0.19718038 -0.11842807]\n",
            "  [ 0.04340663 -0.06190016]\n",
            "  [-0.04340663  0.06190016]\n",
            "  [ 0.1435145  -0.06133567]\n",
            "  [ 0.1435145  -0.06133567]]\n",
            "\n",
            " [[-0.04297789 -0.17033175]\n",
            "  [ 0.04297789  0.17033175]\n",
            "  [-0.01566613  0.06220794]\n",
            "  [ 0.01566613 -0.06220794]\n",
            "  [-0.09938442 -0.11468001]\n",
            "  [-0.09938442 -0.11468001]]\n",
            "\n",
            " [[-0.20264864  0.07692855]\n",
            "  [ 0.20264864 -0.07692855]\n",
            "  [ 0.08868343 -0.14023465]\n",
            "  [-0.08868343  0.14023465]\n",
            "  [ 0.05662874  0.03676592]\n",
            "  [ 0.05662874  0.03676592]]\n",
            "\n",
            " [[ 0.17362863  0.11519026]\n",
            "  [-0.17362863 -0.11519026]\n",
            "  [ 0.11284684 -0.00703505]\n",
            "  [-0.11284684  0.00703505]\n",
            "  [-0.16778077 -0.02909969]\n",
            "  [-0.16778077 -0.02909969]]\n",
            "\n",
            " [[ 0.11583378 -0.15472926]\n",
            "  [-0.11583378  0.15472926]\n",
            "  [-0.06349289 -0.0147001 ]\n",
            "  [ 0.06349289  0.0147001 ]\n",
            "  [ 0.20063068  0.04312029]\n",
            "  [ 0.20063068  0.04312029]]\n",
            "\n",
            " [[-0.12467969 -0.04571925]\n",
            "  [ 0.12467969  0.04571925]\n",
            "  [-0.00419527 -0.0995744 ]\n",
            "  [ 0.00419527  0.0995744 ]\n",
            "  [-0.18931653 -0.10755768]\n",
            "  [-0.18931653 -0.10755768]]\n",
            "\n",
            " [[ 0.210951    0.04018562]\n",
            "  [-0.210951   -0.04018562]\n",
            "  [ 0.09214672 -0.0188405 ]\n",
            "  [-0.09214672  0.0188405 ]\n",
            "  [-0.14961378  0.10390653]\n",
            "  [-0.14961378  0.10390653]]\n",
            "\n",
            " [[-0.12792507  0.11079551]\n",
            "  [ 0.12792507 -0.11079551]\n",
            "  [ 0.08501011 -0.00999178]\n",
            "  [-0.08501011  0.00999178]\n",
            "  [ 0.02404678 -0.16584677]\n",
            "  [ 0.02404678 -0.16584677]]\n",
            "\n",
            " [[-0.040824    0.06713101]\n",
            "  [ 0.040824   -0.06713101]\n",
            "  [-0.16504808 -0.11832016]\n",
            "  [ 0.16504808  0.11832016]\n",
            "  [-0.08753846 -0.11591255]\n",
            "  [-0.08753846 -0.11591255]]\n",
            "\n",
            " [[-0.27532122  0.15900171]\n",
            "  [ 0.27532122 -0.15900171]\n",
            "  [-0.1202434  -0.00425786]\n",
            "  [ 0.1202434   0.00425786]\n",
            "  [ 0.0245712  -0.02906817]\n",
            "  [ 0.0245712  -0.02906817]]\n",
            "\n",
            " [[ 0.14424396  0.18886037]\n",
            "  [-0.14424396 -0.18886037]\n",
            "  [ 0.05441075  0.00658273]\n",
            "  [-0.05441075 -0.00658273]\n",
            "  [ 0.15455388 -0.04141291]\n",
            "  [ 0.15455388 -0.04141291]]\n",
            "\n",
            " [[ 0.07061973  0.14301962]\n",
            "  [-0.07061973 -0.14301962]\n",
            "  [-0.10032298  0.05014351]\n",
            "  [ 0.10032298 -0.05014351]\n",
            "  [-0.1761833   0.04458963]\n",
            "  [-0.1761833   0.04458963]]\n",
            "\n",
            " [[ 0.12075897 -0.05452722]\n",
            "  [-0.12075897  0.05452722]\n",
            "  [-0.12276831  0.09721511]\n",
            "  [ 0.12276831 -0.09721511]\n",
            "  [-0.19643971 -0.00516725]\n",
            "  [-0.19643971 -0.00516725]]\n",
            "\n",
            " [[-0.1006788  -0.04653645]\n",
            "  [ 0.1006788   0.04653645]\n",
            "  [-0.17134154 -0.12104425]\n",
            "  [ 0.17134154  0.12104425]\n",
            "  [-0.11563227 -0.07991412]\n",
            "  [-0.11563227 -0.07991412]]\n",
            "\n",
            " [[ 0.17418991 -0.03128469]\n",
            "  [-0.17418991  0.03128469]\n",
            "  [-0.10123918  0.07784323]\n",
            "  [ 0.10123918 -0.07784323]\n",
            "  [ 0.01813557  0.13727039]\n",
            "  [ 0.01813557  0.13727039]]\n",
            "\n",
            " [[-0.04928026 -0.0979454 ]\n",
            "  [ 0.04928026  0.0979454 ]\n",
            "  [-0.13210647 -0.1170224 ]\n",
            "  [ 0.13210647  0.1170224 ]\n",
            "  [-0.16511214  0.0074937 ]\n",
            "  [-0.16511214  0.0074937 ]]\n",
            "\n",
            " [[-0.09177292 -0.14722489]\n",
            "  [ 0.09177292  0.14722489]\n",
            "  [ 0.11363717 -0.008285  ]\n",
            "  [-0.11363717  0.008285  ]\n",
            "  [ 0.03588837  0.12652344]\n",
            "  [ 0.03588837  0.12652344]]\n",
            "\n",
            " [[-0.11336795  0.07145791]\n",
            "  [ 0.11336795 -0.07145791]\n",
            "  [ 0.01560382 -0.11302417]\n",
            "  [-0.01560382  0.11302417]\n",
            "  [-0.14397378 -0.10983702]\n",
            "  [-0.14397378 -0.10983702]]\n",
            "\n",
            " [[-0.03704778  0.02682102]\n",
            "  [ 0.03704778 -0.02682102]\n",
            "  [-0.26821747 -0.10214701]\n",
            "  [ 0.26821747  0.10214701]\n",
            "  [-0.14524874  0.05715971]\n",
            "  [-0.14524874  0.05715971]]\n",
            "\n",
            " [[ 0.02027039  0.06925315]\n",
            "  [-0.02027039 -0.06925315]\n",
            "  [-0.09385998  0.13813427]\n",
            "  [ 0.09385998 -0.13813427]\n",
            "  [ 0.19923708  0.04083793]\n",
            "  [ 0.19923708  0.04083793]]\n",
            "\n",
            " [[-0.12439527  0.01193282]\n",
            "  [ 0.12439527 -0.01193282]\n",
            "  [ 0.15114295  0.07187577]\n",
            "  [-0.15114295 -0.07187577]\n",
            "  [ 0.16703287  0.09737611]\n",
            "  [ 0.16703287  0.09737611]]\n",
            "\n",
            " [[-0.03673311  0.08297227]\n",
            "  [ 0.03673311 -0.08297227]\n",
            "  [-0.16316397  0.05838221]\n",
            "  [ 0.16316397 -0.05838221]\n",
            "  [ 0.1530866   0.11012139]\n",
            "  [ 0.1530866   0.11012139]]\n",
            "\n",
            " [[-0.15129526  0.0219122 ]\n",
            "  [ 0.15129526 -0.0219122 ]\n",
            "  [ 0.02025483 -0.14577109]\n",
            "  [-0.02025483  0.14577109]\n",
            "  [-0.15659192  0.03111212]\n",
            "  [-0.15659192  0.03111212]]\n",
            "\n",
            " [[-0.16302958 -0.06931882]\n",
            "  [ 0.16302958  0.06931882]\n",
            "  [ 0.10621486 -0.10249282]\n",
            "  [-0.10621486  0.10249282]\n",
            "  [ 0.04883398 -0.10351749]\n",
            "  [ 0.04883398 -0.10351749]]\n",
            "\n",
            " [[-0.16456015 -0.00373281]\n",
            "  [ 0.16456015  0.00373281]\n",
            "  [ 0.13336238 -0.09182267]\n",
            "  [-0.13336238  0.09182267]\n",
            "  [-0.1284183  -0.08240711]\n",
            "  [-0.1284183  -0.08240711]]\n",
            "\n",
            " [[-0.14028549  0.11937627]\n",
            "  [ 0.14028549 -0.11937627]\n",
            "  [-0.1892825  -0.10321789]\n",
            "  [ 0.1892825   0.10321789]\n",
            "  [ 0.06532393 -0.00382858]\n",
            "  [ 0.06532393 -0.00382858]]\n",
            "\n",
            " [[ 0.01594393 -0.09781351]\n",
            "  [-0.01594393  0.09781351]\n",
            "  [-0.21682982  0.00749281]\n",
            "  [ 0.21682982 -0.00749281]\n",
            "  [ 0.07114073 -0.10752278]\n",
            "  [ 0.07114073 -0.10752278]]\n",
            "\n",
            " [[-0.08877438  0.19085507]\n",
            "  [ 0.08877438 -0.19085507]\n",
            "  [ 0.01802555  0.06768669]\n",
            "  [-0.01802555 -0.06768669]\n",
            "  [ 0.09499708 -0.07525685]\n",
            "  [ 0.09499708 -0.07525685]]\n",
            "\n",
            " [[-0.10996836  0.10982042]\n",
            "  [ 0.10996836 -0.10982042]\n",
            "  [-0.0330711  -0.1013628 ]\n",
            "  [ 0.0330711   0.1013628 ]\n",
            "  [-0.00746277 -0.13206592]\n",
            "  [-0.00746277 -0.13206592]]\n",
            "\n",
            " [[-0.22288668  0.1295266 ]\n",
            "  [ 0.22288668 -0.1295266 ]\n",
            "  [-0.02259982  0.03585805]\n",
            "  [ 0.02259982 -0.03585805]\n",
            "  [-0.08840138  0.11087535]\n",
            "  [-0.08840138  0.11087535]]\n",
            "\n",
            " [[ 0.24220732 -0.08273679]\n",
            "  [-0.24220732  0.08273679]\n",
            "  [ 0.14181554  0.08146081]\n",
            "  [-0.14181554 -0.08146081]\n",
            "  [-0.06027941 -0.02824293]\n",
            "  [-0.06027941 -0.02824293]]\n",
            "\n",
            " [[ 0.24697733  0.05930379]\n",
            "  [-0.24697733 -0.05930379]\n",
            "  [ 0.1741285   0.03419439]\n",
            "  [-0.1741285  -0.03419439]\n",
            "  [-0.03576999 -0.05253957]\n",
            "  [-0.03576999 -0.05253957]]\n",
            "\n",
            " [[-0.01871617 -0.10291582]\n",
            "  [ 0.01871617  0.10291582]\n",
            "  [-0.04458445 -0.1132471 ]\n",
            "  [ 0.04458445  0.1132471 ]\n",
            "  [-0.1800928  -0.07811563]\n",
            "  [-0.1800928  -0.07811563]]\n",
            "\n",
            " [[ 0.03134898  0.15593533]\n",
            "  [-0.03134898 -0.15593533]\n",
            "  [ 0.03493597 -0.06669201]\n",
            "  [-0.03493597  0.06669201]\n",
            "  [ 0.20078924 -0.00433277]\n",
            "  [ 0.20078924 -0.00433277]]\n",
            "\n",
            " [[-0.14637756  0.00703194]\n",
            "  [ 0.14637756 -0.00703194]\n",
            "  [ 0.14516011  0.08093066]\n",
            "  [-0.14516011 -0.08093066]\n",
            "  [ 0.1120173   0.11082319]\n",
            "  [ 0.1120173   0.11082319]]\n",
            "\n",
            " [[-0.04407085 -0.15195437]\n",
            "  [ 0.04407085  0.15195437]\n",
            "  [ 0.08018924 -0.04798018]\n",
            "  [-0.08018924  0.04798018]\n",
            "  [ 0.01600534 -0.14089061]\n",
            "  [ 0.01600534 -0.14089061]]\n",
            "\n",
            " [[-0.02375365  0.08702048]\n",
            "  [ 0.02375365 -0.08702048]\n",
            "  [-0.11439482  0.14609712]\n",
            "  [ 0.11439482 -0.14609712]\n",
            "  [-0.04438093 -0.11074563]\n",
            "  [-0.04438093 -0.11074563]]\n",
            "\n",
            " [[-0.18611893  0.0785495 ]\n",
            "  [ 0.18611893 -0.0785495 ]\n",
            "  [-0.13147469  0.08672723]\n",
            "  [ 0.13147469 -0.08672723]\n",
            "  [ 0.10957505 -0.04625507]\n",
            "  [ 0.10957505 -0.04625507]]\n",
            "\n",
            " [[-0.19592184  0.058053  ]\n",
            "  [ 0.19592184 -0.058053  ]\n",
            "  [ 0.16600114 -0.15550254]\n",
            "  [-0.16600114  0.15550254]\n",
            "  [-0.01962512 -0.0213546 ]\n",
            "  [-0.01962512 -0.0213546 ]]\n",
            "\n",
            " [[ 0.3058671   0.12783073]\n",
            "  [-0.3058671  -0.12783073]\n",
            "  [-0.06288424 -0.07737155]\n",
            "  [ 0.06288424  0.07737155]\n",
            "  [-0.01651183 -0.02749298]\n",
            "  [-0.01651183 -0.02749298]]\n",
            "\n",
            " [[-0.16769403  0.09659639]\n",
            "  [ 0.16769403 -0.09659639]\n",
            "  [-0.03072598 -0.09093454]\n",
            "  [ 0.03072598  0.09093454]\n",
            "  [-0.01689713 -0.1237025 ]\n",
            "  [-0.01689713 -0.1237025 ]]\n",
            "\n",
            " [[ 0.07288475 -0.06917958]\n",
            "  [-0.07288475  0.06917958]\n",
            "  [ 0.04242307  0.09750555]\n",
            "  [-0.04242307 -0.09750555]\n",
            "  [ 0.17405672 -0.13459018]\n",
            "  [ 0.17405672 -0.13459018]]\n",
            "\n",
            " [[ 0.04327623  0.13067843]\n",
            "  [-0.04327623 -0.13067843]\n",
            "  [-0.1435565   0.02585967]\n",
            "  [ 0.1435565  -0.02585967]\n",
            "  [ 0.18387623  0.02103737]\n",
            "  [ 0.18387623  0.02103737]]\n",
            "\n",
            " [[-0.12563415 -0.13387537]\n",
            "  [ 0.12563415  0.13387537]\n",
            "  [ 0.          0.        ]\n",
            "  [ 0.          0.        ]\n",
            "  [ 0.08171395 -0.08193234]\n",
            "  [ 0.08171395 -0.08193234]]\n",
            "\n",
            " [[-0.00477305  0.10331772]\n",
            "  [ 0.00477305 -0.10331772]\n",
            "  [-0.07725697 -0.12321097]\n",
            "  [ 0.07725697  0.12321097]\n",
            "  [ 0.12199432 -0.10069247]\n",
            "  [ 0.12199432 -0.10069247]]\n",
            "\n",
            " [[-0.1520269   0.11372563]\n",
            "  [ 0.1520269  -0.11372563]\n",
            "  [ 0.01374953 -0.09450681]\n",
            "  [-0.01374953  0.09450681]\n",
            "  [ 0.11170792 -0.08927277]\n",
            "  [ 0.11170792 -0.08927277]]\n",
            "\n",
            " [[ 0.1862332  -0.06947433]\n",
            "  [-0.1862332   0.06947433]\n",
            "  [-0.01600719 -0.05128413]\n",
            "  [ 0.01600719  0.05128413]\n",
            "  [-0.04329238 -0.1664445 ]\n",
            "  [-0.04329238 -0.1664445 ]]\n",
            "\n",
            " [[-0.1580594  -0.14976938]\n",
            "  [ 0.1580594   0.14976938]\n",
            "  [ 0.06439211 -0.03084358]\n",
            "  [-0.06439211  0.03084358]\n",
            "  [-0.13971584 -0.08253834]\n",
            "  [-0.13971584 -0.08253834]]\n",
            "\n",
            " [[-0.2172128   0.06378091]\n",
            "  [ 0.2172128  -0.06378091]\n",
            "  [-0.15946293 -0.04096127]\n",
            "  [ 0.15946293  0.04096127]\n",
            "  [-0.0565866   0.07423557]\n",
            "  [-0.0565866   0.07423557]]\n",
            "\n",
            " [[ 0.03916193  0.1279593 ]\n",
            "  [-0.03916193 -0.1279593 ]\n",
            "  [-0.17097394 -0.02154765]\n",
            "  [ 0.17097394  0.02154765]\n",
            "  [-0.1195127   0.08088334]\n",
            "  [-0.1195127   0.08088334]]\n",
            "\n",
            " [[ 0.10801709  0.0592159 ]\n",
            "  [-0.10801709 -0.0592159 ]\n",
            "  [ 0.11721759  0.17099135]\n",
            "  [-0.11721759 -0.17099135]\n",
            "  [-0.03632027  0.07998233]\n",
            "  [-0.03632027  0.07998233]]\n",
            "\n",
            " [[ 0.16404599  0.16057324]\n",
            "  [-0.16404599 -0.16057324]\n",
            "  [-0.05031455  0.05415514]\n",
            "  [ 0.05031455 -0.05415514]\n",
            "  [-0.04814673  0.10222998]\n",
            "  [-0.04814673  0.10222998]]\n",
            "\n",
            " [[-0.14378707 -0.05566701]\n",
            "  [ 0.14378707  0.05566701]\n",
            "  [-0.15752034 -0.09034696]\n",
            "  [ 0.15752034  0.09034696]\n",
            "  [-0.14687815  0.04006175]\n",
            "  [-0.14687815  0.04006175]]\n",
            "\n",
            " [[-0.13804133 -0.0400783 ]\n",
            "  [ 0.13804133  0.0400783 ]\n",
            "  [ 0.00329863  0.13567287]\n",
            "  [-0.00329863 -0.13567287]\n",
            "  [ 0.13252044  0.08938751]\n",
            "  [ 0.13252044  0.08938751]]\n",
            "\n",
            " [[ 0.02714177  0.06526019]\n",
            "  [-0.02714177 -0.06526019]\n",
            "  [-0.18001533  0.01209964]\n",
            "  [ 0.18001533 -0.01209964]\n",
            "  [ 0.16242509 -0.13167839]\n",
            "  [ 0.16242509 -0.13167839]]\n",
            "\n",
            " [[-0.10285452  0.13244523]\n",
            "  [ 0.10285452 -0.13244523]\n",
            "  [-0.05369329 -0.03401446]\n",
            "  [ 0.05369329  0.03401446]\n",
            "  [-0.23238589 -0.03731148]\n",
            "  [-0.23238589 -0.03731148]]\n",
            "\n",
            " [[-0.14468503 -0.05068849]\n",
            "  [ 0.14468503  0.05068849]\n",
            "  [ 0.02605075 -0.11607431]\n",
            "  [-0.02605075  0.11607431]\n",
            "  [-0.07709531  0.12789598]\n",
            "  [-0.07709531  0.12789598]]\n",
            "\n",
            " [[-0.01308632 -0.08247828]\n",
            "  [ 0.01308632  0.08247828]\n",
            "  [-0.25032258  0.09369715]\n",
            "  [ 0.25032258 -0.09369715]\n",
            "  [-0.11888308  0.02348795]\n",
            "  [-0.11888308  0.02348795]]\n",
            "\n",
            " [[ 0.17522408  0.03461892]\n",
            "  [-0.17522408 -0.03461892]\n",
            "  [-0.15448384 -0.1141099 ]\n",
            "  [ 0.15448384  0.1141099 ]\n",
            "  [ 0.07126452 -0.06724226]\n",
            "  [ 0.07126452 -0.06724226]]\n",
            "\n",
            " [[ 0.06514208  0.02097813]\n",
            "  [-0.06514208 -0.02097813]\n",
            "  [ 0.04829501  0.11981069]\n",
            "  [-0.04829501 -0.11981069]\n",
            "  [ 0.2737253  -0.02632126]\n",
            "  [ 0.2737253  -0.02632126]]\n",
            "\n",
            " [[-0.00302724  0.07409599]\n",
            "  [ 0.00302724 -0.07409599]\n",
            "  [-0.12817147  0.09448492]\n",
            "  [ 0.12817147 -0.09448492]\n",
            "  [-0.08738769  0.15369156]\n",
            "  [-0.08738769  0.15369156]]\n",
            "\n",
            " [[-0.08730714 -0.07686078]\n",
            "  [ 0.08730714  0.07686078]\n",
            "  [ 0.06649067  0.14682929]\n",
            "  [-0.06649067 -0.14682929]\n",
            "  [-0.02832752 -0.11628004]\n",
            "  [-0.02832752 -0.11628004]]\n",
            "\n",
            " [[ 0.02426404 -0.10568417]\n",
            "  [-0.02426404  0.10568417]\n",
            "  [ 0.21688952 -0.08493564]\n",
            "  [-0.21688952  0.08493564]\n",
            "  [ 0.12385432 -0.01082925]\n",
            "  [ 0.12385432 -0.01082925]]]\n",
            "\n",
            "Pairs[0]:\n",
            " [[ 0.08478673  0.07375345]\n",
            " [-0.08478673 -0.07375345]\n",
            " [ 0.19869676 -0.04826853]\n",
            " [-0.19869676  0.04826853]\n",
            " [-0.17075635 -0.03943552]\n",
            " [-0.17075635 -0.03943552]\n",
            " [ 0.2834835   0.02548492]\n",
            " [ 0.01684685 -0.00355997]\n",
            " [-0.11391003  0.12202199]\n",
            " [-0.01684685  0.00355997]\n",
            " [ 0.11391003 -0.12202199]\n",
            " [-0.01684685  0.00355997]\n",
            " [-0.2834835  -0.02548492]\n",
            " [ 0.01684685 -0.00355997]\n",
            " [-0.08596963  0.03431794]\n",
            " [-0.01447787 -0.00290851]\n",
            " [-0.08596963  0.03431794]\n",
            " [-0.01447787 -0.00290851]\n",
            " [-0.25554308 -0.11318897]\n",
            " [ 0.01447787  0.00290851]\n",
            " [-0.25554308 -0.11318897]\n",
            " [ 0.01447787  0.00290851]\n",
            " [ 0.02794041 -0.08770405]\n",
            " [-0.03392873  0.00190349]\n",
            " [ 0.02794041 -0.08770405]\n",
            " [-0.03392873  0.00190349]\n",
            " [-0.36945313  0.00883301]\n",
            " [ 0.03392873 -0.00190349]\n",
            " [-0.36945313  0.00883301]\n",
            " [ 0.03392873 -0.00190349]]\n",
            "\n",
            "Triplets[0]:\n",
            " [[[ 0.08478673  0.07375345]\n",
            "  [-0.08478673 -0.07375345]\n",
            "  [ 0.19869676 -0.04826853]]\n",
            "\n",
            " [[-0.19869676  0.04826853]\n",
            "  [-0.17075635 -0.03943552]\n",
            "  [-0.17075635 -0.03943552]]\n",
            "\n",
            " [[ 0.2834835   0.02548492]\n",
            "  [ 0.01684685 -0.00355997]\n",
            "  [-0.11391003  0.12202199]]\n",
            "\n",
            " [[-0.01684685  0.00355997]\n",
            "  [ 0.11391003 -0.12202199]\n",
            "  [-0.01684685  0.00355997]]\n",
            "\n",
            " [[-0.2834835  -0.02548492]\n",
            "  [ 0.01684685 -0.00355997]\n",
            "  [-0.08596963  0.03431794]]\n",
            "\n",
            " [[-0.01447787 -0.00290851]\n",
            "  [-0.08596963  0.03431794]\n",
            "  [-0.01447787 -0.00290851]]\n",
            "\n",
            " [[-0.25554308 -0.11318897]\n",
            "  [ 0.01447787  0.00290851]\n",
            "  [-0.25554308 -0.11318897]]\n",
            "\n",
            " [[ 0.01447787  0.00290851]\n",
            "  [ 0.02794041 -0.08770405]\n",
            "  [-0.03392873  0.00190349]]\n",
            "\n",
            " [[ 0.02794041 -0.08770405]\n",
            "  [-0.03392873  0.00190349]\n",
            "  [-0.36945313  0.00883301]]\n",
            "\n",
            " [[ 0.03392873 -0.00190349]\n",
            "  [-0.36945313  0.00883301]\n",
            "  [ 0.03392873 -0.00190349]]]\n",
            "\n",
            "Bits (all qubits):\n",
            " [[1 1 1 ... 1 1 1]\n",
            " [1 0 0 ... 0 0 1]\n",
            " [0 1 1 ... 0 0 1]\n",
            " ...\n",
            " [0 1 1 ... 0 1 1]\n",
            " [0 1 0 ... 1 0 0]\n",
            " [1 0 0 ... 0 0 1]]\n",
            "\n",
            "Primaries Out (promoted):\n",
            " [[[ 3.39287333e-02 -1.90349447e-03]\n",
            "  [-3.39287333e-02  1.90349447e-03]\n",
            "  [-3.69453132e-01  8.83301347e-03]\n",
            "  [ 3.69453132e-01 -8.83301347e-03]\n",
            "  [ 3.39287333e-02 -1.90349447e-03]\n",
            "  [-3.39287333e-02  1.90349447e-03]]\n",
            "\n",
            " [[-6.22948119e-03 -3.79668805e-03]\n",
            "  [ 6.22948119e-03  3.79668805e-03]\n",
            "  [ 1.00107864e-01  5.64489514e-04]\n",
            "  [-1.00107864e-01 -5.64489514e-04]\n",
            "  [-6.22948119e-03 -3.79668805e-03]\n",
            "  [ 6.22948119e-03  3.79668805e-03]]\n",
            "\n",
            " [[-1.55696936e-03  7.13400822e-03]\n",
            "  [ 1.55696936e-03 -7.13400822e-03]\n",
            "  [-8.37182850e-02 -1.76887959e-01]\n",
            "  [ 8.37182850e-02  1.76887959e-01]\n",
            "  [-1.55696936e-03  7.13400822e-03]\n",
            "  [ 1.55696936e-03 -7.13400822e-03]]\n",
            "\n",
            " [[-5.02203032e-03  5.15585579e-03]\n",
            "  [ 5.02203032e-03 -5.15585579e-03]\n",
            "  [-3.20546888e-02  1.77000567e-01]\n",
            "  [ 3.20546888e-02 -1.77000567e-01]\n",
            "  [-5.02203032e-03  5.15585579e-03]\n",
            "  [ 5.02203032e-03 -5.15585579e-03]]\n",
            "\n",
            " [[ 1.89335309e-02 -2.04717915e-04]\n",
            "  [-1.89335309e-02  2.04717915e-04]\n",
            "  [-2.80627608e-01 -2.20646374e-02]\n",
            "  [ 2.80627608e-01  2.20646374e-02]\n",
            "  [ 1.89335309e-02 -2.04717915e-04]\n",
            "  [-1.89335309e-02  2.04717915e-04]]\n",
            "\n",
            " [[ 1.27386227e-02  6.33872522e-04]\n",
            "  [-1.27386227e-02 -6.33872522e-04]\n",
            "  [ 2.64123559e-01  5.78203909e-02]\n",
            "  [-2.64123559e-01 -5.78203909e-02]\n",
            "  [ 1.27386227e-02  6.33872522e-04]\n",
            "  [-1.27386227e-02 -6.33872522e-04]]\n",
            "\n",
            " [[-7.94233172e-04 -1.07099917e-02]\n",
            "  [ 7.94233172e-04  1.07099917e-02]\n",
            "  [-1.85121253e-01 -7.98328221e-03]\n",
            "  [ 1.85121253e-01  7.98328221e-03]\n",
            "  [-7.94233172e-04 -1.07099917e-02]\n",
            "  [ 7.94233172e-04  1.07099917e-02]]\n",
            "\n",
            " [[ 1.37864202e-02  1.95765099e-03]\n",
            "  [-1.37864202e-02 -1.95765099e-03]\n",
            "  [-2.41760507e-01  1.22747034e-01]\n",
            "  [ 2.41760507e-01 -1.22747034e-01]\n",
            "  [ 1.37864202e-02  1.95765099e-03]\n",
            "  [-1.37864202e-02 -1.95765099e-03]]\n",
            "\n",
            " [[-2.04421976e-03 -1.65710459e-03]\n",
            "  [ 2.04421976e-03  1.65710459e-03]\n",
            "  [-6.09633289e-02 -1.55854985e-01]\n",
            "  [ 6.09633289e-02  1.55854985e-01]\n",
            "  [-2.04421976e-03 -1.65710459e-03]\n",
            "  [ 2.04421976e-03  1.65710459e-03]]\n",
            "\n",
            " [[-1.44480541e-02 -1.37147913e-02]\n",
            "  [ 1.44480541e-02  1.37147913e-02]\n",
            "  [ 7.75096193e-02  2.40761042e-03]\n",
            "  [-7.75096193e-02 -2.40761042e-03]\n",
            "  [-1.44480541e-02 -1.37147913e-02]\n",
            "  [ 1.44480541e-02  1.37147913e-02]]\n",
            "\n",
            " [[ 2.95452517e-03 -1.23768303e-04]\n",
            "  [-2.95452517e-03  1.23768303e-04]\n",
            "  [ 1.44814610e-01 -2.48103105e-02]\n",
            "  [-1.44814610e-01  2.48103105e-02]\n",
            "  [ 2.95452517e-03 -1.23768303e-04]\n",
            "  [-2.95452517e-03  1.23768303e-04]]\n",
            "\n",
            " [[-8.40939302e-03  2.72609905e-04]\n",
            "  [ 8.40939302e-03 -2.72609905e-04]\n",
            "  [ 1.00143120e-01 -4.79956381e-02]\n",
            "  [-1.00143120e-01  4.79956381e-02]\n",
            "  [-8.40939302e-03  2.72609905e-04]\n",
            "  [ 8.40939302e-03 -2.72609905e-04]]\n",
            "\n",
            " [[-1.76752340e-02 -2.23588059e-03]\n",
            "  [ 1.76752340e-02  2.23588059e-03]\n",
            "  [-7.58603141e-02 -5.55388629e-03]\n",
            "  [ 7.58603141e-02  5.55388629e-03]\n",
            "  [-1.76752340e-02 -2.23588059e-03]\n",
            "  [ 1.76752340e-02  2.23588059e-03]]\n",
            "\n",
            " [[-2.41165701e-02  5.02334617e-04]\n",
            "  [ 2.41165701e-02 -5.02334617e-04]\n",
            "  [-7.36714080e-02 -1.02382354e-01]\n",
            "  [ 7.36714080e-02  1.02382354e-01]\n",
            "  [-2.41165701e-02  5.02334617e-04]\n",
            "  [ 2.41165701e-02 -5.02334617e-04]]\n",
            "\n",
            " [[-1.98126119e-02 -9.67314467e-03]\n",
            "  [ 1.98126119e-02  9.67314467e-03]\n",
            "  [ 5.57092652e-02  4.11301255e-02]\n",
            "  [-5.57092652e-02 -4.11301255e-02]\n",
            "  [-1.98126119e-02 -9.67314467e-03]\n",
            "  [ 1.98126119e-02  9.67314467e-03]]\n",
            "\n",
            " [[ 1.83603063e-03 -1.06855705e-02]\n",
            "  [-1.83603063e-03  1.06855705e-02]\n",
            "  [ 1.19374752e-01  5.94271645e-02]\n",
            "  [-1.19374752e-01 -5.94271645e-02]\n",
            "  [ 1.83603063e-03 -1.06855705e-02]\n",
            "  [-1.83603063e-03  1.06855705e-02]]\n",
            "\n",
            " [[-2.18123812e-02  8.76931124e-04]\n",
            "  [ 2.18123812e-02 -8.76931124e-04]\n",
            "  [-3.30056697e-02  1.24516107e-01]\n",
            "  [ 3.30056697e-02 -1.24516107e-01]\n",
            "  [-2.18123812e-02  8.76931124e-04]\n",
            "  [ 2.18123812e-02 -8.76931124e-04]]\n",
            "\n",
            " [[-4.07825317e-03  1.04824663e-03]\n",
            "  [ 4.07825317e-03 -1.04824663e-03]\n",
            "  [-7.77487978e-02  1.34808436e-01]\n",
            "  [ 7.77487978e-02 -1.34808436e-01]\n",
            "  [-4.07825317e-03  1.04824663e-03]\n",
            "  [ 4.07825317e-03 -1.04824663e-03]]\n",
            "\n",
            " [[ 2.24654051e-03 -1.24142375e-02]\n",
            "  [-2.24654051e-03  1.24142375e-02]\n",
            "  [-1.59577593e-01  3.18714976e-03]\n",
            "  [ 1.59577593e-01 -3.18714976e-03]\n",
            "  [ 2.24654051e-03 -1.24142375e-02]\n",
            "  [-2.24654051e-03  1.24142375e-02]]\n",
            "\n",
            " [[-3.89582515e-02  5.83869405e-03]\n",
            "  [ 3.89582515e-02 -5.83869405e-03]\n",
            "  [ 1.22968733e-01  1.59306735e-01]\n",
            "  [-1.22968733e-01 -1.59306735e-01]\n",
            "  [-3.89582515e-02  5.83869405e-03]\n",
            "  [ 3.89582515e-02 -5.83869405e-03]]\n",
            "\n",
            " [[ 1.87003873e-02 -5.64111816e-03]\n",
            "  [-1.87003873e-02  5.64111816e-03]\n",
            "  [ 2.93097049e-01 -9.72963423e-02]\n",
            "  [-2.93097049e-01  9.72963423e-02]\n",
            "  [ 1.87003873e-02 -5.64111816e-03]\n",
            "  [-1.87003873e-02  5.64111816e-03]]\n",
            "\n",
            " [[-2.52458416e-02 -6.99898321e-03]\n",
            "  [ 2.52458416e-02  6.99898321e-03]\n",
            "  [ 1.58899128e-02  2.55003348e-02]\n",
            "  [-1.58899128e-02 -2.55003348e-02]\n",
            "  [-2.52458416e-02 -6.99898321e-03]\n",
            "  [ 2.52458416e-02  6.99898321e-03]]\n",
            "\n",
            " [[ 2.49782186e-02 -6.42912975e-03]\n",
            "  [-2.49782186e-02  6.42912975e-03]\n",
            "  [ 3.16250563e-01  5.17391860e-02]\n",
            "  [-3.16250563e-01 -5.17391860e-02]\n",
            "  [ 2.49782186e-02 -6.42912975e-03]\n",
            "  [-2.49782186e-02  6.42912975e-03]]\n",
            "\n",
            " [[ 3.17174266e-03  4.53524711e-03]\n",
            "  [-3.17174266e-03 -4.53524711e-03]\n",
            "  [-1.76846758e-01  1.76883206e-01]\n",
            "  [ 1.76846758e-01 -1.76883206e-01]\n",
            "  [ 3.17174266e-03  4.53524711e-03]\n",
            "  [-3.17174266e-03 -4.53524711e-03]]\n",
            "\n",
            " [[-5.18689491e-03 -1.06098000e-02]\n",
            "  [ 5.18689491e-03  1.06098000e-02]\n",
            "  [-5.73808737e-02 -1.02466345e-03]\n",
            "  [ 5.73808737e-02  1.02466345e-03]\n",
            "  [-5.18689491e-03 -1.06098000e-02]\n",
            "  [ 5.18689491e-03  1.06098000e-02]]\n",
            "\n",
            " [[ 1.71261709e-02 -7.56684085e-03]\n",
            "  [-1.71261709e-02  7.56684085e-03]\n",
            "  [-2.61780679e-01  9.41555947e-03]\n",
            "  [ 2.61780679e-01 -9.41555947e-03]\n",
            "  [ 1.71261709e-02 -7.56684085e-03]\n",
            "  [-1.71261709e-02  7.56684085e-03]]\n",
            "\n",
            " [[ 1.23646762e-02 -3.95177485e-04]\n",
            "  [-1.23646762e-02  3.95177485e-04]\n",
            "  [ 2.54606426e-01  9.93893147e-02]\n",
            "  [-2.54606426e-01 -9.93893147e-02]\n",
            "  [ 1.23646762e-02 -3.95177485e-04]\n",
            "  [-1.23646762e-02  3.95177485e-04]]\n",
            "\n",
            " [[ 1.54254315e-02  8.05647578e-04]\n",
            "  [-1.54254315e-02 -8.05647578e-04]\n",
            "  [ 2.87970543e-01 -1.15015589e-01]\n",
            "  [-2.87970543e-01  1.15015589e-01]\n",
            "  [ 1.54254315e-02  8.05647578e-04]\n",
            "  [-1.54254315e-02 -8.05647578e-04]]\n",
            "\n",
            " [[-1.71237416e-03  5.09388698e-03]\n",
            "  [ 1.71237416e-03 -5.09388698e-03]\n",
            "  [ 7.69715309e-02 -1.42943531e-01]\n",
            "  [-7.69715309e-02  1.42943531e-01]\n",
            "  [-1.71237416e-03  5.09388698e-03]\n",
            "  [ 1.71237416e-03 -5.09388698e-03]]\n",
            "\n",
            " [[-2.46801937e-04 -1.33865718e-02]\n",
            "  [ 2.46801937e-04  1.33865718e-02]\n",
            "  [ 2.56083328e-02 -3.07031199e-02]\n",
            "  [-2.56083328e-02  3.07031199e-02]\n",
            "  [-2.46801937e-04 -1.33865718e-02]\n",
            "  [ 2.46801937e-04  1.33865718e-02]]\n",
            "\n",
            " [[-1.99785572e-03 -3.97577416e-03]\n",
            "  [ 1.99785572e-03  3.97577416e-03]\n",
            "  [-6.58015609e-02  7.50172883e-02]\n",
            "  [ 6.58015609e-02 -7.50172883e-02]\n",
            "  [-1.99785572e-03 -3.97577416e-03]\n",
            "  [ 1.99785572e-03  3.97577416e-03]]\n",
            "\n",
            " [[ 8.54855776e-03  2.30069156e-03]\n",
            "  [-8.54855776e-03 -2.30069156e-03]\n",
            "  [-2.02094957e-01 -1.09703735e-01]\n",
            "  [ 2.02094957e-01  1.09703735e-01]\n",
            "  [ 8.54855776e-03  2.30069156e-03]\n",
            "  [-8.54855776e-03 -2.30069156e-03]]\n",
            "\n",
            " [[ 6.22857502e-03  1.79655850e-03]\n",
            "  [-6.22857502e-03 -1.79655850e-03]\n",
            "  [-2.09898502e-01 -8.67339596e-02]\n",
            "  [ 2.09898502e-01  8.67339596e-02]\n",
            "  [ 6.22857502e-03  1.79655850e-03]\n",
            "  [-6.22857502e-03 -1.79655850e-03]]\n",
            "\n",
            " [[-8.02933890e-03 -8.84636957e-03]\n",
            "  [ 8.02933890e-03  8.84636957e-03]\n",
            "  [-1.35508344e-01  3.51314694e-02]\n",
            "  [ 1.35508344e-01 -3.51314694e-02]\n",
            "  [-8.02933890e-03 -8.84636957e-03]\n",
            "  [ 8.02933890e-03  8.84636957e-03]]\n",
            "\n",
            " [[-7.01476680e-03 -2.88960844e-04]\n",
            "  [ 7.01476680e-03  2.88960844e-04]\n",
            "  [ 1.65853277e-01  6.23592436e-02]\n",
            "  [-1.65853277e-01 -6.23592436e-02]\n",
            "  [-7.01476680e-03 -2.88960844e-04]\n",
            "  [ 7.01476680e-03  2.88960844e-04]]\n",
            "\n",
            " [[-1.62604433e-02 -8.96899402e-03]\n",
            "  [ 1.62604433e-02  8.96899402e-03]\n",
            "  [-3.31428051e-02  2.98925340e-02]\n",
            "  [ 3.31428051e-02 -2.98925340e-02]\n",
            "  [-1.62604433e-02 -8.96899402e-03]\n",
            "  [ 1.62604433e-02  8.96899402e-03]]\n",
            "\n",
            " [[-1.28345634e-03 -6.75995694e-03]\n",
            "  [ 1.28345634e-03  6.75995694e-03]\n",
            "  [-6.41838908e-02 -9.29104388e-02]\n",
            "  [ 6.41838908e-02  9.29104388e-02]\n",
            "  [-1.28345634e-03 -6.75995694e-03]\n",
            "  [ 1.28345634e-03  6.75995694e-03]]\n",
            "\n",
            " [[-5.07694809e-03  1.61796175e-02]\n",
            "  [ 5.07694809e-03 -1.61796175e-02]\n",
            "  [ 7.00138956e-02 -2.56842762e-01]\n",
            "  [-7.00138956e-02  2.56842762e-01]\n",
            "  [-5.07694809e-03  1.61796175e-02]\n",
            "  [ 5.07694809e-03 -1.61796175e-02]]\n",
            "\n",
            " [[ 1.44063458e-02  4.01157374e-03]\n",
            "  [-1.44063458e-02 -4.01157374e-03]\n",
            "  [ 2.41049737e-01 -1.32982299e-01]\n",
            "  [-2.41049737e-01  1.32982299e-01]\n",
            "  [ 1.44063458e-02  4.01157374e-03]\n",
            "  [-1.44063458e-02 -4.01157374e-03]]\n",
            "\n",
            " [[ 3.25779268e-03 -3.32069490e-03]\n",
            "  [-3.25779268e-03  3.32069490e-03]\n",
            "  [-1.85626268e-01  1.34147942e-01]\n",
            "  [ 1.85626268e-01 -1.34147942e-01]\n",
            "  [ 3.25779268e-03 -3.32069490e-03]\n",
            "  [-3.25779268e-03  3.32069490e-03]]\n",
            "\n",
            " [[-1.03833363e-03 -2.12717475e-03]\n",
            "  [ 1.03833363e-03  2.12717475e-03]\n",
            "  [ 4.63724136e-02  4.98785675e-02]\n",
            "  [-4.63724136e-02 -4.98785675e-02]\n",
            "  [-1.03833363e-03 -2.12717475e-03]\n",
            "  [ 1.03833363e-03  2.12717475e-03]]\n",
            "\n",
            " [[-5.19180729e-04 -1.12488298e-02]\n",
            "  [ 5.19180729e-04  1.12488298e-02]\n",
            "  [ 1.38288531e-02 -3.27679664e-02]\n",
            "  [-1.38288531e-02  3.27679664e-02]\n",
            "  [-5.19180729e-04 -1.12488298e-02]\n",
            "  [ 5.19180729e-04  1.12488298e-02]]\n",
            "\n",
            " [[-7.38402037e-03  1.31232897e-02]\n",
            "  [ 7.38402037e-03 -1.31232897e-02]\n",
            "  [ 1.31633654e-01 -2.32095733e-01]\n",
            "  [-1.31633654e-01  2.32095733e-01]\n",
            "  [-7.38402037e-03  1.31232897e-02]\n",
            "  [ 7.38402037e-03 -1.31232897e-02]]\n",
            "\n",
            " [[ 2.63966285e-02 -5.44019218e-04]\n",
            "  [-2.63966285e-02  5.44019218e-04]\n",
            "  [ 3.27432752e-01 -4.82229888e-03]\n",
            "  [-3.27432752e-01  4.82229888e-03]\n",
            "  [ 2.63966285e-02 -5.44019218e-04]\n",
            "  [-2.63966285e-02  5.44019218e-04]]\n",
            "\n",
            " [[-1.25634149e-01 -1.33875370e-01]\n",
            "  [ 1.25634149e-01  1.33875370e-01]\n",
            "  [ 1.25634149e-01  1.33875370e-01]\n",
            "  [-1.25634149e-01 -1.33875370e-01]\n",
            "  [ 8.17139521e-02 -8.19323361e-02]\n",
            "  [-8.17139521e-02  8.19323361e-02]]\n",
            "\n",
            " [[ 9.42491088e-03 -1.24064172e-02]\n",
            "  [-9.42491088e-03  1.24064172e-02]\n",
            "  [ 1.99251294e-01  2.25185081e-02]\n",
            "  [-1.99251294e-01 -2.25185081e-02]\n",
            "  [ 9.42491088e-03 -1.24064172e-02]\n",
            "  [-9.42491088e-03  1.24064172e-02]]\n",
            "\n",
            " [[-1.53593090e-03 -8.43688380e-03]\n",
            "  [ 1.53593090e-03  8.43688380e-03]\n",
            "  [ 9.79583934e-02  5.23404032e-03]\n",
            "  [-9.79583934e-02 -5.23404032e-03]\n",
            "  [-1.53593090e-03 -8.43688380e-03]\n",
            "  [ 1.53593090e-03  8.43688380e-03]]\n",
            "\n",
            " [[-6.92989212e-04 -8.53596162e-03]\n",
            "  [ 6.92989212e-04  8.53596162e-03]\n",
            "  [-2.72851940e-02 -1.15160361e-01]\n",
            "  [ 2.72851940e-02  1.15160361e-01]\n",
            "  [-6.92989212e-04 -8.53596162e-03]\n",
            "  [ 6.92989212e-04  8.53596162e-03]]\n",
            "\n",
            " [[ 8.99659749e-03 -2.54577817e-03]\n",
            "  [-8.99659749e-03  2.54577817e-03]\n",
            "  [-2.04107940e-01 -5.16947508e-02]\n",
            "  [ 2.04107940e-01  5.16947508e-02]\n",
            "  [ 8.99659749e-03 -2.54577817e-03]\n",
            "  [-8.99659749e-03  2.54577817e-03]]\n",
            "\n",
            " [[-9.02346522e-03  3.04078264e-03]\n",
            "  [ 9.02346522e-03 -3.04078264e-03]\n",
            "  [ 1.02876328e-01  1.15196832e-01]\n",
            "  [-1.02876328e-01 -1.15196832e-01]\n",
            "  [-9.02346522e-03  3.04078264e-03]\n",
            "  [ 9.02346522e-03 -3.04078264e-03]]\n",
            "\n",
            " [[-2.04335582e-02  1.74284610e-03]\n",
            "  [ 2.04335582e-02 -1.74284610e-03]\n",
            "  [ 5.14612421e-02  1.02430992e-01]\n",
            "  [-5.14612421e-02 -1.02430992e-01]\n",
            "  [-2.04335582e-02  1.74284610e-03]\n",
            "  [ 2.04335582e-02 -1.74284610e-03]]\n",
            "\n",
            " [[ 4.25737444e-03 -1.36762857e-02]\n",
            "  [-4.25737444e-03  1.36762857e-02]\n",
            "  [-1.53537855e-01 -9.10090208e-02]\n",
            "  [ 1.53537855e-01  9.10090208e-02]\n",
            "  [ 4.25737444e-03 -1.36762857e-02]\n",
            "  [-4.25737444e-03  1.36762857e-02]]\n",
            "\n",
            " [[-2.42248108e-03 -5.53627824e-03]\n",
            "  [ 2.42248108e-03  5.53627824e-03]\n",
            "  [ 2.16781721e-03  4.80748378e-02]\n",
            "  [-2.16781721e-03 -4.80748378e-02]\n",
            "  [-2.42248108e-03 -5.53627824e-03]\n",
            "  [ 2.42248108e-03  5.53627824e-03]]\n",
            "\n",
            " [[-2.31362972e-02  3.61945713e-03]\n",
            "  [ 2.31362972e-02 -3.61945713e-03]\n",
            "  [ 1.06421858e-02  1.30408704e-01]\n",
            "  [-1.06421858e-02 -1.30408704e-01]\n",
            "  [-2.31362972e-02  3.61945713e-03]\n",
            "  [ 2.31362972e-02 -3.61945713e-03]]\n",
            "\n",
            " [[-4.37136187e-04 -1.21274600e-02]\n",
            "  [ 4.37136187e-04  1.21274600e-02]\n",
            "  [ 1.29221812e-01 -4.62853536e-02]\n",
            "  [-1.29221812e-01  4.62853536e-02]\n",
            "  [-4.37136187e-04 -1.21274600e-02]\n",
            "  [ 4.37136187e-04  1.21274600e-02]]\n",
            "\n",
            " [[ 2.92390045e-02  1.59326161e-03]\n",
            "  [-2.92390045e-02 -1.59326161e-03]\n",
            "  [ 3.42440426e-01 -1.43778026e-01]\n",
            "  [-3.42440426e-01  1.43778026e-01]\n",
            "  [ 2.92390045e-02  1.59326161e-03]\n",
            "  [-2.92390045e-02 -1.59326161e-03]]\n",
            "\n",
            " [[-1.24775628e-02 -1.26912969e-03]\n",
            "  [ 1.24775628e-02  1.26912969e-03]\n",
            "  [-1.78692594e-01 -3.29701602e-03]\n",
            "  [ 1.78692594e-01  3.29701602e-03]\n",
            "  [-1.24775628e-02 -1.26912969e-03]\n",
            "  [ 1.24775628e-02  1.26912969e-03]]\n",
            "\n",
            " [[ 2.00839085e-03  1.48454374e-02]\n",
            "  [-2.00839085e-03 -1.48454374e-02]\n",
            "  [-1.03146061e-01  2.43970290e-01]\n",
            "  [ 1.03146061e-01 -2.43970290e-01]\n",
            "  [ 2.00839085e-03  1.48454374e-02]\n",
            "  [-2.00839085e-03 -1.48454374e-02]]\n",
            "\n",
            " [[-2.97591202e-02 -2.20075366e-03]\n",
            "  [ 2.97591202e-02  2.20075366e-03]\n",
            "  [ 1.31439507e-01 -7.02092052e-02]\n",
            "  [-1.31439507e-01  7.02092052e-02]\n",
            "  [-2.97591202e-02 -2.20075366e-03]\n",
            "  [ 2.97591202e-02  2.20075366e-03]]\n",
            "\n",
            " [[ 1.10092163e-02 -7.67300744e-03]\n",
            "  [-1.10092163e-02  7.67300744e-03]\n",
            "  [ 2.25748360e-01  4.68676463e-02]\n",
            "  [-2.25748360e-01 -4.68676463e-02]\n",
            "  [ 1.10092163e-02 -7.67300744e-03]\n",
            "  [-1.10092163e-02  7.67300744e-03]]\n",
            "\n",
            " [[-1.32195652e-02  3.15356790e-03]\n",
            "  [ 1.32195652e-02 -3.15356790e-03]\n",
            "  [ 2.25430295e-01 -1.46131948e-01]\n",
            "  [-2.25430295e-01  1.46131948e-01]\n",
            "  [-1.32195652e-02  3.15356790e-03]\n",
            "  [ 1.32195652e-02 -3.15356790e-03]]\n",
            "\n",
            " [[-1.12006087e-02 -1.45215346e-02]\n",
            "  [ 1.12006087e-02  1.45215346e-02]\n",
            "  [ 4.07837853e-02  5.92066422e-02]\n",
            "  [-4.07837853e-02 -5.92066422e-02]\n",
            "  [-1.12006087e-02 -1.45215346e-02]\n",
            "  [ 1.12006087e-02  1.45215346e-02]]\n",
            "\n",
            " [[ 1.88351539e-03  1.70733165e-02]\n",
            "  [-1.88351539e-03 -1.70733165e-02]\n",
            "  [-9.48181823e-02 -2.63109326e-01]\n",
            "  [ 9.48181823e-02  2.63109326e-01]\n",
            "  [ 1.88351539e-03  1.70733165e-02]\n",
            "  [-1.88351539e-03 -1.70733165e-02]]\n",
            "\n",
            " [[-2.68627051e-02 -9.19789600e-04]\n",
            "  [ 2.68627051e-02  9.19789600e-04]\n",
            "  [-9.30351913e-02  7.41063803e-02]\n",
            "  [ 9.30351913e-02 -7.41063803e-02]\n",
            "  [-2.68627051e-02 -9.19789600e-04]\n",
            "  [ 2.68627051e-02  9.19789600e-04]]]\n",
            "\n",
            "Nth Identities (Conceptual, per qubit):\n",
            "\n",
            "  Qubit 0:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9984006 -0.056013 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 1:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.85378736 -0.5203586 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 2:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.21319781  0.9768689 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 3:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.69765204  0.71624285]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 4:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9998887  -0.01081125]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 5:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99868596 0.04969451]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 6:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.07394818 -0.99716866]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 7:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9899971 0.1405781]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 8:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.7765296  -0.62947774]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 9:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.7252352 -0.6884283]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 10:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9987859  -0.04184024]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 11:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9993562   0.03239644]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 12:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99203813 -0.12549077]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 13:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99974173  0.02082406]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 14:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8985765  -0.43871352]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 15:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.16932617 -0.9854665 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 16:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.99914706  0.04016908]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 17:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.96828866  0.24888237]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 18:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.17805843 -0.98393935]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 19:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.98893005  0.14821148]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 20:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9573393  -0.28878888]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 21:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9636163  -0.26714635]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 22:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9683978  -0.24925536]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 23:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.5730034  0.81933254]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 24:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.43916485 -0.8983123 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 25:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.91464835 -0.40411827]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 26:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.99940884 -0.0319413 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 27:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9985742  0.05215406]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 28:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.31858107  0.94769937]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 29:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.01843202 -0.9997554 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 30:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.44890413 -0.8933285 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 31:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9655306 0.2598553]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 32:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.9606814  0.27709714]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 33:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.672029  -0.7404118]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 34:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9990104  -0.04115246]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 35:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.8755825  -0.48295698]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 36:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.18650232 -0.98230666]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 37:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.29937553  0.9540735 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 38:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.96328413 0.26823494]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 39:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.70016307 -0.71368194]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 40:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.43847296 -0.8982745 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 41:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.04610103 -0.99884796]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 42:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.49033812  0.871456  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 43:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.9997498  -0.02060426]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 44:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.68430257 -0.7291907 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 45:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.6048831 -0.7962337]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 46:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.17908488 -0.98371506]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 47:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.08090899 -0.9966043 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 48:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.96211517 -0.2722509 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 49:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.94754016  0.3193079 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 50:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9963337   0.08498061]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 51:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.29720685 -0.95474005]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 52:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.40080243 -0.915984  ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 53:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.98794115  0.15455414]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 54:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.0360188 -0.9992687]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 55:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.99848455 0.05440839]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 56:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9947877  -0.10118279]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 57:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.1340565 0.9909063]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 58:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9972432  -0.07374837]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 59:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [ 0.8203399 -0.5717459]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 60:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.97263414  0.23202486]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 61:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.61071146 -0.7917844 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 62:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [0.10964762 0.9939119 ]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "  Qubit 63:\n",
            "    n^0 (base identity): [1. 0.]\n",
            "    n^1 (first-order selector): [-0.9993772  -0.03421907]\n",
            "    n^2 (second-order product): [1. 0.]\n",
            "    n^p (p-order product): [1. 0.]\n",
            "\n",
            "Info-energy Output (all qubits):\n",
            " [12.941372   2.9662833  8.240009   5.608717   7.1086826 11.213027\n",
            "  7.4686146  9.142639   5.744784   4.6867967  4.415695   4.6379604\n",
            "  2.8240373  4.162184   3.6759248  5.321188   5.1558657  4.958288\n",
            "  5.592925   7.1985083 10.578345   2.1914139 12.348207  10.357465\n",
            "  2.1499965 10.950516   9.669588   8.327785   4.3472047  2.5302413\n",
            "  4.1929903  5.1325755  8.127955   6.1437345  5.09744    1.8135719\n",
            "  4.626118   9.242924  11.484297   7.285349   2.0319247  1.6826417\n",
            "  7.862608  12.062358  18.69851    5.4504704  3.3800197  3.0413187\n",
            "  8.356384   4.862377   4.517396   6.6728764  1.2231965  5.9410696\n",
            "  6.084655  10.745203   4.669489   6.1804004  5.0212836  7.6741867\n",
            "  6.5539002  2.8255486  8.812801   5.0438623]\n",
            "\n",
            "Resonance Keys (all qubits):\n",
            " ['1b4971394e2d59bca92a6f119c14e2a3394f49ab2e711af69ef1a3eea0b6a662', 'f4ecff432fa3d0370c78f8c0f5105f3abea0bdd599a100f9e19f69aabbc9da34', '5c13e71b01118fddd6e1deb76201e7a1b178a29b21b7b7f04c218447f4f8c861', 'a48a4735b1f561b4aeebacedac9ce7f13b6292947c10f07f0341645a39b827ce', 'ac67b626f8d481851237f549126ba824844b425e32ccf821d6d9e92de3b2c3ab', 'b2493ab14a596bebf937f27a1bbd7f839cc6c29009454c45652e806f2845b295', '85ced6e3e15992d5fcdf14f38daf9dbdf0741970766f2719bc31ff10a89019ce', 'b4b07cf96ac8e19981e491f20400e874c7791f3678bfc83d7e3fc25462000c5e', '07b670c961051793c2584a280787a36578723cb7f224dbca73fdd1949403ea77', 'a8fdd4ac9e4e829b3e9ef2e8c1eb609d4127be69ebbb2fec5b618f3a84c6c281', 'b5b14c20277f3ccb6b9dcab813c06f0a497a7464854d3fe50f21f9e03892b847', 'ee70108fb2c5091c64730f7c06613d610df896ac2c0049f3f274a42fa5831055', '66b8a9dace95e30888491f65fee9927a145818c11bea0626f8557722328cfe08', '7f2bfba576a82b8f53ee68cef459d11fd5d9524380160cfe24a3c364f3f4a1a0', '52a9e426192cd4c7430eac01738b84754a11f991a2d9b452354178a14d03e209', '9bc49c1ab3a433237f2405b3ac409092750f5e5014a35a03d94d20cba4004d3b', '6e5c1b5d9afafa8e3d3e98bcef7c3328fa8a1e9e0698c47f1ba8be4a0353188f', '80976565f37e2e64a93ea4d972a09ff247a618344eaf208d3ea1f46844f24241', 'f91c63546061bb9a068b91640bab6c7940d54d278d6ca94bbb60672b5b7917cf', 'acce54f34d66d32171318502b51f2462017e800ca09d3822320c8c6757e50530', '9553d2784e239849e6a7de7ddb45496f0fef201721b28f9fafc18c9ee2bd951a', '9dae3a5d6b516460bd0a98729ff1d09067b8ea320d0f69c261e79fbd5015cce4', '8abaeece117685dea3a1241cb8258d93b40a8d520ec3eed24be53abfc5b862eb', '602993919dd14da3c2e2284c20b248ed256b3cf6f387151c5d7a0e68ca6a1ca9', '66a28feba79501fe93a3168a141cd575468d51857661ff6b97ece7b6711eadae', 'd4bece08a2fdbeea461220a55067eefb95ed8a6cf7636be82a5ea01ed7efbdf9', '76b44223f2fc3f73b14872d50c86dd899316c541eeca82439baef963d0cbff5f', 'd2ad7fba9c0a03bbcddd10ca9935c75574247de6e8690848ae403f370221c215', '3a2996773d5e2fb6834adb9d21236d17a40be2a898fd5e96273c15346d171e16', '0113d818833902aa30e498e6b716d5398743a9974c228c0e6c88dda912c6ce8d', '2bc5c8dbf8167a8424339348933be3ca9b0b138b7207feb6482220f2dc36a253', 'be83d9df71f78c607d9123f66c84deb742cd0a3f67e0dde6147e90dbbc4bfd47', 'b6e7bfeff4b2fe4f6d9d7517e4c193c3feaf624c6cda8f5c047e2cc874d503e6', '753cdb2a84c55a59335580fe045c610cffe3cf19a816fb148a530a1fb80b924e', '53cf837a128854900fa9d99f4ea34dc41ec26961982780eaa866bf803c423cdc', 'c4024a1c2336722b0d52801da84c0435a4df842275eae8312d1d378d9d849316', 'e2ed78300ece12816262bf6b64458dcf90463dacd631e82be39ac086a7eeb9db', 'ee7c5588a8ba7897a1d0ace4b91f77a5ecc496c0ed459c202dd9e761fb81e42d', '429e8b67bf9de1b3c9fc8d9f903fbdbd176a8880c621e15c9d202bc53f501689', 'f72920352e901b0223d1d749809d4497f90268556552f143357b408e85f367d0', '5ff5ec1feb1b9c2b9e882ac89f863a86a6854734486f9cafbcf81f12e4aa2fda', '316627cf745808d1233c05c8e105f514f90b96c71eccd6983e912aa533dac316', 'e10ee3ba99162af10fd2b1cb45909e1dc682942adc46c4afe10975d37db7310a', '12f70216ac72fca6a39de70579bf8ee7916ca9bb285fe6cee45959cd345c2c81', '7df11ece112eada62dfa8988f44f9218ce174db00253b94696b53869d71f22a3', '9c4bd53675e6f39e1163181c7dfef29f556ac228af098838f2f6f29450603026', 'a646ede07bfdf3e15b9e00066ecadf4b86c295abc3b0160a283c6687ffadcd80', '8dd4e30fa350c5c38d2b38b4e11d25ea21a1793de12c1211192ee6a4691aafc9', '6b8e6090339b52de873744600176f0cd4a46eba345e2de97819e31756397446a', '411aa76705fde3bb1e707e3855141faf76e0a0604f847c3dc94b17c06fff9fca', '3b794bc1e30ed47a86744a4ec8e01312d7a973d6f42cc8e3347ab16855dc479b', '45ce0e2c771355617efd16b8fbf2cd2afe8975b089e0485924c9fa4a0bcfcb0e', '0a70683f2cc458a7719c1fc5106f7c75b6869820424f415f8fa5220441d3c465', '4e6ab72e85a240704c3a79df33658401d31c2ae092105d87b22f73a29f3b0648', '1ecb897d12f2a8d6511342bc8b6850ed911fba9bae98b1f111b37d773502290b', 'ecde3bf3fd8626ffce43dd5954e18ddc0c9af3ea1371770bbc1737b43c17bc9d', '28091bc58bc735a0a327950396de0f6ef09d6c9c73b08b5ffaf69794dfbb611b', '076504cb4dc6b3f8b1ff9edc959d7f0c4723633895470c863cfdbc0993772d00', '8863f5d691797a19744183f487415f748bd56574c7aa84a815e25e4586137134', 'f327c6cc1e603576318c9d3e013b36f0f9dedd1eec0f3f7d0bec981e891f9550', '5a0d2701bc0b115f177bb27e25b3045f4f28f4ac1c083e89f80c0aca3b9a0528', '3095869b9de63bd167f200632fa4c436e1c75af3999b3bfd57424c1f1fd6785b', '6d812cf9562f913c28323c7aba700edcfa666ebbf9c21de6dcf7013a7fa41e28', '55a89ac20ca3cc95dc497b49221eee2b8f4c1cd10bcf29ebd0074fc768335ba2']\n",
            "\n",
            "Spin (all qubits, conceptual):\n",
            " [[[-0.9888869   0.1012755  -0.10883939]\n",
            "  [ 0.9723132   0.20678721 -0.10883939]]\n",
            "\n",
            " [[ 0.12094338 -0.06297799 -0.9906596 ]\n",
            "  [ 0.12803738 -0.04690374 -0.9906596 ]]\n",
            "\n",
            " [[-0.06955653 -0.07893278 -0.99445033]\n",
            "  [-0.09224019 -0.05059883 -0.99445033]]\n",
            "\n",
            " [[-0.37226817 -0.21319775 -0.9033068 ]\n",
            "  [-0.42712095  0.04005687 -0.9033068 ]]\n",
            "\n",
            " [[-0.8361149  -0.50306207 -0.2187246 ]\n",
            "  [-0.81725514  0.53315437 -0.2187246 ]]\n",
            "\n",
            " [[ 0.642255    0.34756428 -0.68316   ]\n",
            "  [ 0.3938844  -0.61493695 -0.68316   ]]\n",
            "\n",
            " [[ 0.30082837  0.8909999  -0.34003147]\n",
            "  [-0.7300454   0.59280044 -0.34003147]]\n",
            "\n",
            " [[ 0.13918617 -0.47958857 -0.86638445]\n",
            "  [-0.20311096  0.45620602 -0.86638445]]\n",
            "\n",
            " [[ 0.70802504  0.64667845 -0.28373843]\n",
            "  [ 0.8428636   0.4572455  -0.28373843]]\n",
            "\n",
            " [[ 0.87392956  0.07210252  0.48067486]\n",
            "  [ 0.5022235  -0.71883464  0.48067486]]\n",
            "\n",
            " [[-0.13436233  0.5314905   0.83634   ]\n",
            "  [-0.4574525  -0.30211353  0.83634   ]]\n",
            "\n",
            " [[ 0.04256573  0.22245526 -0.97401327]\n",
            "  [ 0.17368549 -0.14536692 -0.97401327]]\n",
            "\n",
            " [[ 0.2777698  -0.2691447  -0.9221741 ]\n",
            "  [-0.34926772 -0.16615354 -0.9221741 ]]\n",
            "\n",
            " [[ 0.0061674  -0.0122141   0.99990636]\n",
            "  [-0.0130044  -0.00425519  0.99990636]]\n",
            "\n",
            " [[ 0.17976825 -0.05382361 -0.98223543]\n",
            "  [ 0.10289904  0.1569248  -0.98223543]]\n",
            "\n",
            " [[ 0.08068928 -0.6509542   0.7548165 ]\n",
            "  [ 0.00910655 -0.6558729   0.7548165 ]]\n",
            "\n",
            " [[ 0.03735372  0.9014458  -0.4312774 ]\n",
            "  [-0.12403613 -0.89365256 -0.4312774 ]]\n",
            "\n",
            " [[ 0.47747335  0.18570563  0.8587972 ]\n",
            "  [-0.43203795  0.27533722  0.8587972 ]]\n",
            "\n",
            " [[-0.0558468   0.02045771  0.99822974]\n",
            "  [-0.01674617 -0.05706968  0.99822974]]\n",
            "\n",
            " [[-0.04556124  0.08629385  0.9952274 ]\n",
            "  [-0.09435628 -0.02488671  0.9952274 ]]\n",
            "\n",
            " [[-0.48218533  0.6515793   0.58561224]\n",
            "  [-0.66802233 -0.45913446  0.58561224]]\n",
            "\n",
            " [[-0.7644793  -0.49086764  0.41787603]\n",
            "  [ 0.41386685 -0.8087607   0.41787603]]\n",
            "\n",
            " [[-0.4164448  -0.23759496  0.87756616]\n",
            "  [ 0.1844786  -0.4425441   0.87756616]]\n",
            "\n",
            " [[ 0.1385295  -0.02109106 -0.9901337 ]\n",
            "  [ 0.11508808  0.0799374  -0.9901337 ]]\n",
            "\n",
            " [[ 0.25811064 -0.823876   -0.50458616]\n",
            "  [ 0.7129643  -0.48690322 -0.50458616]]\n",
            "\n",
            " [[-0.9617355  -0.0903515   0.25865328]\n",
            "  [-0.34504053  0.9022447   0.25865328]]\n",
            "\n",
            " [[-0.51990306 -0.48365232 -0.7041173 ]\n",
            "  [ 0.37934124 -0.6002658  -0.7041173 ]]\n",
            "\n",
            " [[ 0.5767075  -0.02380333  0.8166039 ]\n",
            "  [ 0.45259985 -0.35820588  0.8166039 ]]\n",
            "\n",
            " [[-0.73004293  0.46587774  0.49999523]\n",
            "  [ 0.341689    0.7957722   0.49999523]]\n",
            "\n",
            " [[ 0.5113857   0.6418162   0.5714513 ]\n",
            "  [ 0.745146    0.34380347  0.5714513 ]]\n",
            "\n",
            " [[-0.14917745  0.5890809   0.7941849 ]\n",
            "  [-0.5251468   0.30576324  0.7941849 ]]\n",
            "\n",
            " [[ 0.6599467   0.5772235  -0.48091936]\n",
            "  [-0.14703417  0.86434805 -0.48091936]]\n",
            "\n",
            " [[ 0.8420227  -0.53350466 -0.07981557]\n",
            "  [ 0.9017049  -0.42492086 -0.07981557]]\n",
            "\n",
            " [[ 0.61054885  0.3280853  -0.720826  ]\n",
            "  [ 0.3512486   0.59752345 -0.720826  ]]\n",
            "\n",
            " [[ 0.7606007   0.6444865   0.07825449]\n",
            "  [ 0.69547397  0.71427745  0.07825449]]\n",
            "\n",
            " [[ 0.635589    0.5126613   0.57723916]\n",
            "  [-0.44961825  0.6816439   0.57723916]]\n",
            "\n",
            " [[-0.18817261 -0.3741696  -0.90806836]\n",
            "  [-0.4181244   0.02416174 -0.90806836]]\n",
            "\n",
            " [[ 0.16114728 -0.08208819 -0.9835106 ]\n",
            "  [ 0.17413892  0.04881143 -0.9835106 ]]\n",
            "\n",
            " [[ 0.01447462  0.03011186  0.99944174]\n",
            "  [-0.00933225 -0.03208034  0.99944174]]\n",
            "\n",
            " [[ 0.22944988 -0.08744509 -0.9693844 ]\n",
            "  [ 0.22991621 -0.08621152 -0.9693844 ]]\n",
            "\n",
            " [[-0.6087166   0.3305106  -0.7212675 ]\n",
            "  [ 0.47376895  0.5052882  -0.7212675 ]]\n",
            "\n",
            " [[ 0.19136105 -0.20513487 -0.95984405]\n",
            "  [ 0.19598201  0.20072474 -0.95984405]]\n",
            "\n",
            " [[-0.2958586   0.36466348  0.8828863 ]\n",
            "  [-0.42113686  0.20773908  0.8828863 ]]\n",
            "\n",
            " [[ 0.9543244  -0.15107295  0.25776324]\n",
            "  [-0.7489495  -0.6104365   0.25776324]]\n",
            "\n",
            " [[ 0.5068776  -0.08530102  0.85778713]\n",
            "  [-0.35596472  0.37079686  0.85778713]]\n",
            "\n",
            " [[-0.08553509  0.07334635  0.9936318 ]\n",
            "  [-0.10481938  0.04133808  0.9936318 ]]\n",
            "\n",
            " [[ 0.0691072  -0.68010664  0.7298487 ]\n",
            "  [-0.07137375  0.6798725   0.7298487 ]]\n",
            "\n",
            " [[ 0.11469932  0.10575628 -0.9877549 ]\n",
            "  [ 0.14902177 -0.04618261 -0.9877549 ]]\n",
            "\n",
            " [[ 0.5346675  -0.6269702   0.5666031 ]\n",
            "  [-0.7621614   0.3131627   0.5666031 ]]\n",
            "\n",
            " [[ 0.27538806 -0.96125543 -0.01222224]\n",
            "  [ 0.88522613 -0.46500036 -0.01222224]]\n",
            "\n",
            " [[-0.06026843 -0.16912566 -0.9837501 ]\n",
            "  [-0.07819574 -0.16162054 -0.9837501 ]]\n",
            "\n",
            " [[ 0.17939919 -0.44510087 -0.87732613]\n",
            "  [ 0.34427673  0.3343238  -0.87732613]]\n",
            "\n",
            " [[-0.3227168   0.7389015  -0.5915052 ]\n",
            "  [ 0.79474443  0.13602498 -0.5915052 ]]\n",
            "\n",
            " [[-0.22156031  0.12975399 -0.96647555]\n",
            "  [ 0.1812675  -0.18184377 -0.96647555]]\n",
            "\n",
            " [[ 0.31911364  0.69195217 -0.6475868 ]\n",
            "  [ 0.65033376 -0.3971112  -0.6475868 ]]\n",
            "\n",
            " [[-0.8506372  -0.5243372   0.03856079]\n",
            "  [ 0.6314279  -0.7744753   0.03856079]]\n",
            "\n",
            " [[-0.2077575  -0.16418833 -0.96430236]\n",
            "  [-0.22467953  0.14014311 -0.96430236]]\n",
            "\n",
            " [[-0.5126964   0.421679    0.7478832 ]\n",
            "  [-0.37584233 -0.54718673  0.7478832 ]]\n",
            "\n",
            " [[-0.07448516 -0.61664367 -0.7837108 ]\n",
            "  [-0.5978761  -0.16834979 -0.7837108 ]]\n",
            "\n",
            " [[ 0.08103016 -0.00835208 -0.9966767 ]\n",
            "  [-0.07622661  0.0287254  -0.9966767 ]]\n",
            "\n",
            " [[ 0.5416974  -0.43771437 -0.7176141 ]\n",
            "  [-0.0583191   0.6939948  -0.7176141 ]]\n",
            "\n",
            " [[-0.43294403 -0.29322267  0.8523966 ]\n",
            "  [-0.35168642  0.3869583   0.8523966 ]]\n",
            "\n",
            " [[-0.5740595   0.8002219  -0.17349514]\n",
            "  [ 0.6980049  -0.69475794 -0.17349514]]\n",
            "\n",
            " [[ 0.1508789  -0.07732373 -0.9855235 ]\n",
            "  [-0.11043143 -0.1286402  -0.9855235 ]]]\n",
            "\n",
            "I_vec (all qubits, conceptual):\n",
            " [[0.16712674 0.2054132  0.452924   ... 0.27486277 0.23445305 0.3171169 ]\n",
            " [0.2037062  0.3443484  0.33060217 ... 0.31031337 0.17531449 0.08810763]\n",
            " [0.18638219 0.24912381 0.04227383 ... 0.49732715 0.46859553 0.08169107]\n",
            " ...\n",
            " [0.38898513 0.3513227  0.0064081  ... 0.26500177 0.42439112 0.12028619]\n",
            " [0.00352895 0.03587261 0.03798284 ... 0.24907991 0.16372235 0.03417913]\n",
            " [0.14143653 0.48253402 0.02578617 ... 0.33726317 0.26886258 0.12349554]]\n",
            "\n",
            "NECL Manifest Checksums (per qubit, conceptual):\n",
            " ['42ba5695f3cd61ff54d0c4c14b674604b9d1c6143c512ab4482849ce18820113', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945', '4f53cda18c2baa0c0354bb5f9a3ecbe5ed12ab4d8e11ba873c2f11161202b945']\n",
            "\n",
            "TRACE Log (Conceptual - detailed lineage for error correction):\n",
            " [{'qubit': 0, 'reason': 'binary_refactor', 'source': 'tuplets', 'r_metric': 0.965915322303772, 'u_metric': 0.9879583716392517, 'dv_metric': 0.03269016742706299, 'invariant_pass': False, 'degenerate_check': False, 'correction_threshold_r': 1.02, 'correction_threshold_u': 1.02, 'correction_threshold_d': 0.765, 'corrected_bits': [1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'old_key': '0ef25942cfb80808d9134e4a26c015dbd7b90d6b3e2d4ec6944a27e77991cf0d', 'new_key': '1b4971394e2d59bca92a6f119c14e2a3394f49ab2e711af69ef1a3eea0b6a662'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab-ready single-cell test harness for an Nth/NGFT-inspired \"ISA step\"\n",
        "# Keeps: triplet loops, per-triplet scatter updates, and adds explicit cross-qubit state arbitration.\n",
        "# Goal: 64 qubits -> 30-bit word each (1920 bits total), plus canonical shared-state grouping and unique per-qubit addressing IDs.\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "# -----------------------------\n",
        "# Config / constants (spec knobs)\n",
        "# -----------------------------\n",
        "THETA_PHIPI = 0.001\n",
        "TAU_HI      = 1.0\n",
        "TAU_LOW     = -TAU_HI\n",
        "EPS         = 1e-6\n",
        "R_FOR_RATIO = 64.0\n",
        "\n",
        "TAU_R_METRIC = 0.85\n",
        "TAU_U_METRIC = 0.85\n",
        "TAU_D_METRIC = 0.85\n",
        "\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "TRIPLET_IDX = tf.constant(\n",
        "    [[0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "     [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers: phase-dual operations (float32; last dim=2 -> [real, unreal])\n",
        "# -----------------------------\n",
        "def add_pd(a, b): return a + b\n",
        "def mul_pd(a, b): return a * b\n",
        "def neg_pd(a): return -a\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers: packing and bit-slicing\n",
        "# -----------------------------\n",
        "def pack30_to_u32_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    bits30_i32: [Q,30] int32 {0,1}\n",
        "    Returns: [Q] uint32 packed (bit i holds bits30[:,i])\n",
        "    \"\"\"\n",
        "    bits_u32 = tf.cast(bits30_i32, tf.uint32)\n",
        "    shifts = tf.cast(tf.range(30), tf.uint32)  # [30]\n",
        "    packed = tf.reduce_sum(tf.bitwise.left_shift(bits_u32, shifts), axis=1)  # [Q]\n",
        "    return packed\n",
        "\n",
        "def bitslice_30_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    bits30_i32: [Q,30] int32 {0,1}, Q<=64\n",
        "    Returns: [30] uint64 mask per bit-position (lane=q)\n",
        "    \"\"\"\n",
        "    Q = tf.shape(bits30_i32)[0]\n",
        "    weights = tf.bitwise.left_shift(tf.constant(1, tf.uint64), tf.cast(tf.range(Q), tf.uint64))  # [Q]\n",
        "    bits_u64 = tf.cast(bits30_i32, tf.uint64)  # [Q,30]\n",
        "    # For each i in 0..29: mask[i] = sum_q bits[q,i] * (1<<q)\n",
        "    masks = tf.reduce_sum(tf.transpose(bits_u64, [1,0]) * tf.expand_dims(weights, axis=0), axis=1)  # [30]\n",
        "    return masks\n",
        "\n",
        "# -----------------------------\n",
        "# Core ISA: pairs and triplets\n",
        "# -----------------------------\n",
        "def compute_pairs(prim: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    prim: [Q,6,2] float32 -> pairs: [Q,30,2]\n",
        "    Canonical expansion (same structure as your original).\n",
        "    \"\"\"\n",
        "    tf.debugging.assert_shapes([(prim, (\"Q\", 6, 2))])\n",
        "    tf.debugging.assert_type(prim, tf.float32)\n",
        "\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=1)  # each [Q,2]\n",
        "\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_pd(x, y),   mul_pd(x, y),  add_pd(x, yi),  mul_pd(x, yi),\n",
        "        add_pd(xi, y),  mul_pd(xi, y), add_pd(xi, yi), mul_pd(xi, yi),\n",
        "        add_pd(x, z),   mul_pd(x, z),  add_pd(x, zi),  mul_pd(x, zi),\n",
        "        add_pd(xi, z),  mul_pd(xi, z), add_pd(xi, zi), mul_pd(xi, zi),\n",
        "        add_pd(y, z),   mul_pd(y, z),  add_pd(y, zi),  mul_pd(y, zi),\n",
        "        add_pd(yi, z),  mul_pd(yi, z), add_pd(yi, zi), mul_pd(yi, zi)\n",
        "    ], axis=1)\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    pairs: [Q,30,2] -> triplets: [Q,10,3,2]\n",
        "    \"\"\"\n",
        "    tf.debugging.assert_shapes([(pairs, (\"Q\", 30, 2))])\n",
        "    return tf.gather(pairs, TRIPLET_IDX, axis=1)\n",
        "\n",
        "# -----------------------------\n",
        "# Collapse detection: triplet loop + scatter update (preserves your structure)\n",
        "# -----------------------------\n",
        "def detect_collapse_triplet_scatter(pairs: tf.Tensor,\n",
        "                                   tau_hi: float = TAU_HI,\n",
        "                                   tau_low: float = TAU_LOW,\n",
        "                                   r_for_ratio: float = R_FOR_RATIO) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    pairs: [Q,30,2] -> collapse_mask: [Q,30] int32\n",
        "    Semantics:\n",
        "      1) compute individual collapse per unit\n",
        "      2) for each triplet, if uniform (all same), enforce uniform into final mask\n",
        "         else keep individual values\n",
        "    Implemented via triplet loop and tf.tensor_scatter_nd_update to match your intent.\n",
        "    \"\"\"\n",
        "    tf.debugging.assert_shapes([(pairs, (\"Q\", 30, 2))])\n",
        "    real = pairs[..., 0]   # [Q,30]\n",
        "    unreal = pairs[..., 1] # [Q,30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    cond1 = tf.logical_and(real >= tau_hi, unreal <= tau_low)\n",
        "    ratio = tf.where(tf.abs(unreal) > EPS, real / unreal, tf.zeros_like(real))\n",
        "    cond2 = ratio > r_for_ratio\n",
        "    individual = tf.logical_or(cond1, cond2)  # [Q,30] bool\n",
        "\n",
        "    final_mask = tf.cast(individual, tf.int32)  # init fallback\n",
        "\n",
        "    # Triplet loop with scatter updates (write-back to the 30-wide mask).\n",
        "    for t in tf.range(10):\n",
        "        idx3 = TRIPLET_IDX[t]  # [3]\n",
        "\n",
        "        trip_ind = tf.gather(individual, idx3, axis=1)  # [Q,3] bool\n",
        "\n",
        "        # uniform per qubit if all 3 equal\n",
        "        is_uniform = tf.reduce_all(tf.equal(trip_ind, trip_ind[:, 0:1]), axis=1)  # [Q] bool\n",
        "        uniform_val = tf.cast(trip_ind[:, 0], tf.int32)  # [Q] 0/1\n",
        "\n",
        "        # updates_for_triplet: [Q,3] int32\n",
        "        updates_for_triplet = tf.where(\n",
        "            tf.expand_dims(is_uniform, axis=1),  # [Q,1]\n",
        "            tf.tile(tf.expand_dims(uniform_val, axis=1), [1,3]),\n",
        "            tf.cast(trip_ind, tf.int32)\n",
        "        )\n",
        "\n",
        "        # scatter indices: [Q*3,2] for updating final_mask[q, idx3[j]]\n",
        "        q_idx = tf.repeat(tf.range(Q), repeats=3)          # [Q*3]\n",
        "        p_idx = tf.tile(idx3, multiples=[Q])               # [Q*3]\n",
        "        scatter_idx = tf.stack([q_idx, p_idx], axis=1)     # [Q*3,2]\n",
        "\n",
        "        final_mask = tf.tensor_scatter_nd_update(final_mask, scatter_idx, tf.reshape(updates_for_triplet, [-1]))\n",
        "\n",
        "    return final_mask\n",
        "\n",
        "# -----------------------------\n",
        "# Parity rotation + bitmap\n",
        "# -----------------------------\n",
        "def apply_parity_rotation(pairs: tf.Tensor, collapse_mask: tf.Tensor, prime_mask: tf.Tensor = PRIME_MASK):\n",
        "    \"\"\"\n",
        "    pairs: [Q,30,2], collapse_mask: [Q,30] int32 -> rotated_pairs: [Q,30,2], affected(parity_mask): [Q,30] int32\n",
        "    \"\"\"\n",
        "    tf.debugging.assert_shapes([(pairs, (\"Q\", 30, 2)), (collapse_mask, (\"Q\", 30))])\n",
        "\n",
        "    Q = tf.shape(pairs)[0]\n",
        "    prime = tf.broadcast_to(tf.cast(prime_mask, tf.int32)[tf.newaxis, :], [Q, 30])\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32)\n",
        "\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, tf.float32), tf.constant(1.0, tf.float32))  # [Q,30]\n",
        "    rotated = pairs * sign[..., tf.newaxis]  # [Q,30,2]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs: tf.Tensor, eps: float = EPS) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    rotated_pairs: [Q,30,2] -> bits: [Q,30] int32, 1 if real>eps else 0\n",
        "    \"\"\"\n",
        "    tf.debugging.assert_shapes([(rotated_pairs, (\"Q\", 30, 2))])\n",
        "    real = rotated_pairs[..., 0]\n",
        "    return tf.cast(real > eps, tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# Canonical commitment and decode (portable serialization; uses Python hashlib for test)\n",
        "# -----------------------------\n",
        "def commit_qubit_u32(packed_bits_u32: int,\n",
        "                     packed_collapse_u32: int,\n",
        "                     packed_parity_u32: int,\n",
        "                     packed_prime_u32: int,\n",
        "                     domain_sep: bytes = b\"NTHISA0\") -> bytes:\n",
        "    msg = (\n",
        "        domain_sep +\n",
        "        packed_prime_u32.to_bytes(4, \"little\", signed=False) +\n",
        "        packed_bits_u32.to_bytes(4, \"little\", signed=False) +\n",
        "        packed_collapse_u32.to_bytes(4, \"little\", signed=False) +\n",
        "        packed_parity_u32.to_bytes(4, \"little\", signed=False)\n",
        "    )\n",
        "    return hashlib.blake2s(msg, digest_size=32).digest()\n",
        "\n",
        "def prf_expand(key32: bytes, personalization: bytes, out_len: int) -> bytes:\n",
        "    out = b\"\"\n",
        "    ctr = 0\n",
        "    while len(out) < out_len:\n",
        "        out += hashlib.blake2s(personalization + key32 + ctr.to_bytes(4, \"little\"), digest_size=32).digest()\n",
        "        ctr += 1\n",
        "    return out[:out_len]\n",
        "\n",
        "def decode_commitment_to_spin_I(commitment32: bytes, D: int = 16) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    raw = prf_expand(commitment32, b\"SPINIVEC\", 12 + 4*D)\n",
        "    a0 = int.from_bytes(raw[0:4], \"little\")\n",
        "    a1 = int.from_bytes(raw[4:8], \"little\")\n",
        "    a2 = int.from_bytes(raw[8:12], \"little\")\n",
        "    r0 = a0 / 2**32\n",
        "    r1 = a1 / 2**32\n",
        "    r2 = a2 / 2**32\n",
        "\n",
        "    theta = 2.0 * math.pi * r0\n",
        "    phi   = 2.0 * math.pi * r1\n",
        "    twist = 2.0 * math.pi * r2\n",
        "\n",
        "    real_spin = np.array([\n",
        "        math.sin(theta) * math.cos(phi),\n",
        "        math.sin(theta) * math.sin(phi),\n",
        "        math.cos(theta)\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    unreal_spin = np.array([\n",
        "        real_spin[0] * math.cos(twist) - real_spin[1] * math.sin(twist),\n",
        "        real_spin[0] * math.sin(twist) + real_spin[1] * math.cos(twist),\n",
        "        real_spin[2]\n",
        "    ], dtype=np.float32)\n",
        "\n",
        "    spin = np.stack([real_spin, unreal_spin], axis=0)  # [2,3]\n",
        "\n",
        "    ivec = np.empty((D,), dtype=np.float32)\n",
        "    off = 12\n",
        "    for i in range(D):\n",
        "        u = int.from_bytes(raw[off+4*i:off+4*i+4], \"little\")\n",
        "        ivec[i] = u / 2**32\n",
        "    n = float(np.linalg.norm(ivec))\n",
        "    if n > EPS:\n",
        "        ivec /= n\n",
        "    return spin, ivec\n",
        "\n",
        "# -----------------------------\n",
        "# Global state arbitration (cross-qubit): collision groups + unique per-qubit address IDs\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class ArbitrationResult:\n",
        "    canonical_state_u32: np.ndarray      # [Q] uint32 (30-bit canonical state)\n",
        "    unique_state_id_u64: np.ndarray      # [Q] uint64 (unique address tag per qubit)\n",
        "    groups: Dict[int, List[int]]         # {canonical_u32: [q indices]}\n",
        "    collision_count: int                 # total number of qubits involved in collisions (beyond first in each group)\n",
        "\n",
        "def arbitrate_states(packed_state_u32: np.ndarray,\n",
        "                     instruction_counter: int,\n",
        "                     necl_checksum32: bytes,\n",
        "                     mode: str = \"unique_address_keep_shared_state\") -> ArbitrationResult:\n",
        "    \"\"\"\n",
        "    Enforces your requirement at the ISA level:\n",
        "      - qubits may share canonical state if they converge (shared informational states)\n",
        "      - but addressing must be unique per qubit for \"single-qubit addressed per state calculation\"\n",
        "\n",
        "    This function:\n",
        "      1) groups qubits by canonical 30-bit state (packed_state_u32)\n",
        "      2) produces a unique per-qubit 64-bit address id derived from (canonical_state, q_idx, instr_counter, program checksum)\n",
        "         This creates unique start-state identifiers for the next instruction without destroying the shared canonical state.\n",
        "\n",
        "    If you later decide you truly want to *force* canonical uniqueness (no shared states),\n",
        "    you can swap the mode to apply deterministic symmetry-breaking transforms to primaries and re-run.\n",
        "    \"\"\"\n",
        "    Q = packed_state_u32.shape[0]\n",
        "    groups: Dict[int, List[int]] = {}\n",
        "    for q in range(Q):\n",
        "        k = int(packed_state_u32[q])\n",
        "        groups.setdefault(k, []).append(q)\n",
        "\n",
        "    unique_ids = np.zeros((Q,), dtype=np.uint64)\n",
        "    collision_count = 0\n",
        "\n",
        "    for k, qs in groups.items():\n",
        "        if len(qs) > 1:\n",
        "            collision_count += (len(qs) - 1)\n",
        "\n",
        "        for rank, q in enumerate(qs):\n",
        "            # Deterministic address: hash(canonical_state || q || instr_counter || necl_checksum)\n",
        "            msg = (\n",
        "                b\"NTHADDR0\" +\n",
        "                int(k).to_bytes(4, \"little\", signed=False) +\n",
        "                int(q).to_bytes(2, \"little\", signed=False) +\n",
        "                int(instruction_counter).to_bytes(4, \"little\", signed=False) +\n",
        "                necl_checksum32\n",
        "            )\n",
        "            h = hashlib.blake2s(msg, digest_size=8).digest()  # 64-bit id\n",
        "            unique_ids[q] = int.from_bytes(h, \"little\", signed=False)\n",
        "\n",
        "    return ArbitrationResult(\n",
        "        canonical_state_u32=packed_state_u32.astype(np.uint32),\n",
        "        unique_state_id_u64=unique_ids,\n",
        "        groups=groups,\n",
        "        collision_count=collision_count\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Minimal NECL checksum placeholder for the step (portable program identity)\n",
        "# -----------------------------\n",
        "def necl_program_checksum(necl_program_list: List[str], params_dict: Dict[str, float]) -> bytes:\n",
        "    # Canonical program manifest bytes (no float formatting ambiguity: pack params as float32 bytes)\n",
        "    b = b\"NECL0\"\n",
        "    for op in necl_program_list:\n",
        "        b += op.encode(\"ascii\") + b\"\\x00\"\n",
        "        if op in params_dict:\n",
        "            b += np.float32(params_dict[op]).tobytes()\n",
        "        else:\n",
        "            b += np.float32(0.0).tobytes()\n",
        "    # 32 bytes checksum\n",
        "    return hashlib.blake2s(b, digest_size=32).digest()\n",
        "\n",
        "# -----------------------------\n",
        "# One ISA \"instruction step\" (test): primaries -> pairs -> collapse -> parity -> bits -> commitments -> arbitration\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class StepOutputs:\n",
        "    primaries: tf.Tensor                 # [Q,6,2]\n",
        "    pairs: tf.Tensor                     # [Q,30,2]\n",
        "    triplets: tf.Tensor                  # [Q,10,3,2]\n",
        "    collapse_mask: tf.Tensor             # [Q,30] int32\n",
        "    rotated_pairs: tf.Tensor             # [Q,30,2]\n",
        "    parity_mask: tf.Tensor               # [Q,30] int32\n",
        "    bits: tf.Tensor                      # [Q,30] int32\n",
        "    bitmasks_30x_u64: tf.Tensor          # [30] uint64\n",
        "    commitments: List[bytes]             # len Q\n",
        "    arbitration: ArbitrationResult       # global uniqueness + shared-state groups\n",
        "    spin_vecs: np.ndarray                # [Q,2,3] float32\n",
        "    i_vecs: np.ndarray                   # [Q,D] float32\n",
        "\n",
        "def isa_step(primaries: tf.Tensor,\n",
        "             necl_program: List[str],\n",
        "             necl_params: Dict[str, float],\n",
        "             instruction_counter: int = 0,\n",
        "             D_decode: int = 16) -> StepOutputs:\n",
        "    Q = primaries.shape[0]\n",
        "    if Q is None:\n",
        "        Q = int(tf.shape(primaries)[0].numpy())\n",
        "\n",
        "    # Program identity (used in arbitration/addressing)\n",
        "    necl_chk = necl_program_checksum(necl_program, necl_params)\n",
        "\n",
        "    # Core pipeline (no removal of triplet loops / scatter updates)\n",
        "    pairs = compute_pairs(primaries)\n",
        "    triplets = group_triplets(pairs)\n",
        "    collapse_mask = detect_collapse_triplet_scatter(pairs)  # triplet loop + scatter update retained\n",
        "    rotated_pairs, parity_mask = apply_parity_rotation(pairs, collapse_mask, PRIME_MASK)\n",
        "    bits = bitmap(rotated_pairs)\n",
        "\n",
        "    # Bit-sliced 30×u64 = 1920 bits at Q=64\n",
        "    bitmasks_30x_u64 = bitslice_30_tf(bits)\n",
        "\n",
        "    # Pack for commitments / arbitration (materialize once; Q small)\n",
        "    packed_bits = pack30_to_u32_tf(bits).numpy().astype(np.uint32)\n",
        "    packed_collapse = pack30_to_u32_tf(collapse_mask).numpy().astype(np.uint32)\n",
        "    packed_parity = pack30_to_u32_tf(parity_mask).numpy().astype(np.uint32)\n",
        "    packed_prime = int(pack30_to_u32_tf(tf.broadcast_to(PRIME_MASK[tf.newaxis,:], [tf.shape(bits)[0],30]))[0].numpy())\n",
        "\n",
        "    # Commit per qubit\n",
        "    commitments = []\n",
        "    for q in range(Q):\n",
        "        commitments.append(commit_qubit_u32(\n",
        "            int(packed_bits[q]),\n",
        "            int(packed_collapse[q]),\n",
        "            int(packed_parity[q]),\n",
        "            int(packed_prime)\n",
        "        ))\n",
        "\n",
        "    # Cross-qubit arbitration: shared canonical grouping + unique address id per qubit\n",
        "    arbitration = arbitrate_states(\n",
        "        packed_state_u32=packed_bits,\n",
        "        instruction_counter=instruction_counter,\n",
        "        necl_checksum32=necl_chk,\n",
        "        mode=\"unique_address_keep_shared_state\"\n",
        "    )\n",
        "\n",
        "    # Decode commitments into conceptual spin + I vectors (portable PRF)\n",
        "    spin_vecs = np.zeros((Q,2,3), dtype=np.float32)\n",
        "    i_vecs = np.zeros((Q,D_decode), dtype=np.float32)\n",
        "    for q in range(Q):\n",
        "        s, iv = decode_commitment_to_spin_I(commitments[q], D=D_decode)\n",
        "        spin_vecs[q] = s\n",
        "        i_vecs[q] = iv\n",
        "\n",
        "    return StepOutputs(\n",
        "        primaries=primaries,\n",
        "        pairs=pairs,\n",
        "        triplets=triplets,\n",
        "        collapse_mask=collapse_mask,\n",
        "        rotated_pairs=rotated_pairs,\n",
        "        parity_mask=parity_mask,\n",
        "        bits=bits,\n",
        "        bitmasks_30x_u64=bitmasks_30x_u64,\n",
        "        commitments=commitments,\n",
        "        arbitration=arbitration,\n",
        "        spin_vecs=spin_vecs,\n",
        "        i_vecs=i_vecs\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Demo / test run (Colab)\n",
        "# -----------------------------\n",
        "tf.random.set_seed(7)\n",
        "np.random.seed(7)\n",
        "\n",
        "Q = 64  # fixed for the 1920-bit per instruction demonstration\n",
        "\n",
        "# Start state: 3D point (x,y,z) each phase-dual -> expand to [x,-x,y,-y,z,-z]\n",
        "base_xyz = tf.random.uniform([Q,3,2], minval=-1.0, maxval=1.0, dtype=tf.float32)\n",
        "x = base_xyz[:,0,:]; y = base_xyz[:,1,:]; z = base_xyz[:,2,:]\n",
        "primaries0 = tf.stack([x, -x, y, -y, z, -z], axis=1)\n",
        "\n",
        "# NECL program identity (kept as identity here; your real NECL would transform primaries first)\n",
        "necl_program = [\"TWIST\",\"CURV\",\"PARITY_Q\",\"COLLAPSE_Q\",\"LIFT\"]\n",
        "necl_params = {\"TWIST\": float(math.pi/4), \"CURV\": 0.01, \"LIFT\": 0.5}\n",
        "\n",
        "out = isa_step(primaries0, necl_program, necl_params, instruction_counter=0, D_decode=16)\n",
        "\n",
        "print(\"=== ISA STEP OUTPUTS ===\")\n",
        "print(\"primaries:\", out.primaries.shape)\n",
        "print(\"pairs:\", out.pairs.shape)\n",
        "print(\"triplets:\", out.triplets.shape)\n",
        "print(\"collapse_mask:\", out.collapse_mask.shape, out.collapse_mask.dtype)\n",
        "print(\"parity_mask:\", out.parity_mask.shape, out.parity_mask.dtype)\n",
        "print(\"bits:\", out.bits.shape, out.bits.dtype)\n",
        "print(\"bitmasks_30x_u64:\", out.bitmasks_30x_u64.shape, out.bitmasks_30x_u64.dtype)\n",
        "print(\"Total bits per instruction (Q*30):\", Q*30)\n",
        "\n",
        "# Show 30 masks (each a 64-bit lane mask)\n",
        "masks_np = out.bitmasks_30x_u64.numpy()\n",
        "print(\"Mask[0] u64:\", int(masks_np[0]))\n",
        "print(\"Mask[1] u64:\", int(masks_np[1]))\n",
        "print(\"Mask[29] u64:\", int(masks_np[29]))\n",
        "\n",
        "# Commitments and decoded states\n",
        "print(\"\\nCommitment[0] (hex):\", out.commitments[0].hex())\n",
        "print(\"spin_vec[0]:\\n\", out.spin_vecs[0])\n",
        "print(\"i_vec[0] (norm):\", float(np.linalg.norm(out.i_vecs[0])))\n",
        "\n",
        "# Global novelty / uniqueness\n",
        "arb = out.arbitration\n",
        "print(\"\\n=== GLOBAL STATE ARBITRATION ===\")\n",
        "print(\"Unique address IDs per qubit (first 5):\", arb.unique_state_id_u64[:5].tolist())\n",
        "print(\"Number of canonical state groups:\", len(arb.groups))\n",
        "print(\"Collision qubits beyond first per group:\", arb.collision_count)\n",
        "\n",
        "# Show the largest collision group (if any)\n",
        "largest = max(arb.groups.items(), key=lambda kv: len(kv[1]))\n",
        "print(\"Largest canonical group size:\", len(largest[1]))\n",
        "if len(largest[1]) > 1:\n",
        "    print(\"Canonical packed state (u32):\", largest[0], \"qubits:\", largest[1][:16], \"...\")\n",
        "else:\n",
        "    print(\"No collisions (all canonical states unique in this run).\")\n",
        "\n",
        "# Optional: demonstrate that canonical states can be shared while addresses are unique\n",
        "# Pick a collision group if present\n",
        "coll_groups = [qs for qs in arb.groups.values() if len(qs) > 1]\n",
        "if coll_groups:\n",
        "    qs = coll_groups[0]\n",
        "    print(\"\\nExample shared canonical state group:\", qs)\n",
        "    print(\"Canonical u32:\", int(arb.canonical_state_u32[qs[0]]))\n",
        "    print(\"Unique IDs:\", [int(arb.unique_state_id_u64[q]) for q in qs])\n",
        "else:\n",
        "    print(\"\\nNo shared canonical state groups found in this random sample (this can happen).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XSIm9EpONk3",
        "outputId": "46f64db9-30aa-4096-86fe-192b341164fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ISA STEP OUTPUTS ===\n",
            "primaries: (64, 6, 2)\n",
            "pairs: (64, 30, 2)\n",
            "triplets: (64, 10, 3, 2)\n",
            "collapse_mask: (64, 30) <dtype: 'int32'>\n",
            "parity_mask: (64, 30) <dtype: 'int32'>\n",
            "bits: (64, 30) <dtype: 'int32'>\n",
            "bitmasks_30x_u64: (30,) <dtype: 'uint64'>\n",
            "Total bits per instruction (Q*30): 1920\n",
            "Mask[0] u64: 14272570256839023417\n",
            "Mask[1] u64: 4174173816870528198\n",
            "Mask[29] u64: 2064223497469565654\n",
            "\n",
            "Commitment[0] (hex): 7c215633473d302941487448075d792c120afef8194b5537a836ec3a1a099245\n",
            "spin_vec[0]:\n",
            " [[-0.19449411  0.3380893   0.9207973 ]\n",
            " [-0.33723992  0.19596317  0.9207973 ]]\n",
            "i_vec[0] (norm): 1.0\n",
            "\n",
            "=== GLOBAL STATE ARBITRATION ===\n",
            "Unique address IDs per qubit (first 5): [1538999814548737703, 5393819066989283255, 7360347812077258044, 15690857822044680976, 3367412987148423094]\n",
            "Number of canonical state groups: 46\n",
            "Collision qubits beyond first per group: 18\n",
            "Largest canonical group size: 3\n",
            "Canonical packed state (u32): 735120457 qubits: [4, 20, 32] ...\n",
            "\n",
            "Example shared canonical state group: [4, 20, 32]\n",
            "Canonical u32: 735120457\n",
            "Unique IDs: [3367412987148423094, 14551453295962821185, 14338675291650472399]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab-ready single-cell prototype that implements:\n",
        "# 1) NEC primaries with explicit real/unreal channels: (x,xi,y,yi,z,zi) where x,y,z >=0 and xi,yi,zi <=0.\n",
        "# 2) Base NEC sign pattern controls whether each axis pair is ordered as (real,unreal) or (unreal,real).\n",
        "#    This matches your example: x,-y,z -> (x,xi, yi,y, z,zi) -> 100110 under sign->bit mapping.\n",
        "# 3) Initiator selection per qubit based on *relative position* (frequency of shared axis magnitudes across the array).\n",
        "# 4) Initiator-dependent permutation of the 6 primaries before expansion to pairs/triplets.\n",
        "# 5) Keeps triplet loops + scatter updates (as in your original intent).\n",
        "# 6) Produces:\n",
        "#    - bits_selected: [Q,30] for the chosen initiator per qubit\n",
        "#    - bits_views: [Q,3,30] for initiator x/y/z (simultaneous informational vectors)\n",
        "#    - bit-sliced masks: [3,30] uint64 for Q=64 (3*1920 bits per instruction “view family”)\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import math\n",
        "\n",
        "# -----------------------------\n",
        "# Config / constants\n",
        "# -----------------------------\n",
        "TAU_HI      = 1.0\n",
        "TAU_LOW     = -1.0\n",
        "EPS         = 1e-6\n",
        "R_FOR_RATIO = 64.0\n",
        "\n",
        "PRIME_MASK = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "TRIPLET_IDX = tf.constant(\n",
        "    [[0,1,2],[3,4,5],[6,7,8],[9,10,11],[12,13,14],\n",
        "     [15,16,17],[18,19,20],[21,22,23],[24,25,26],[27,28,29]],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Phase-dual helper ops\n",
        "# -----------------------------\n",
        "def add_pd(a,b): return a+b\n",
        "def mul_pd(a,b): return a*b\n",
        "\n",
        "# -----------------------------\n",
        "# Bit-slicing for Q<=64\n",
        "# -----------------------------\n",
        "def bitslice_30_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    Q = tf.shape(bits30_i32)[0]\n",
        "    weights = tf.bitwise.left_shift(tf.constant(1, tf.uint64), tf.cast(tf.range(Q), tf.uint64))  # [Q]\n",
        "    bits_u64 = tf.cast(bits30_i32, tf.uint64)  # [Q,30]\n",
        "    masks = tf.reduce_sum(tf.transpose(bits_u64, [1,0]) * tf.expand_dims(weights, axis=0), axis=1)  # [30]\n",
        "    return masks\n",
        "\n",
        "# -----------------------------\n",
        "# Core ISA: pairs and triplets (same as your original reduced 30-register)\n",
        "# -----------------------------\n",
        "def compute_pairs(prim: tf.Tensor) -> tf.Tensor:\n",
        "    # prim: [Q,6,2] float32 -> pairs: [Q,30,2]\n",
        "    x, xi, y, yi, z, zi = tf.unstack(prim, axis=1)\n",
        "    pairs = tf.stack([\n",
        "        x, xi, y, yi, z, zi,\n",
        "        add_pd(x, y),   mul_pd(x, y),  add_pd(x, yi),  mul_pd(x, yi),\n",
        "        add_pd(xi, y),  mul_pd(xi, y), add_pd(xi, yi), mul_pd(xi, yi),\n",
        "        add_pd(x, z),   mul_pd(x, z),  add_pd(x, zi),  mul_pd(x, zi),\n",
        "        add_pd(xi, z),  mul_pd(xi, z), add_pd(xi, zi), mul_pd(xi, zi),\n",
        "        add_pd(y, z),   mul_pd(y, z),  add_pd(y, zi),  mul_pd(y, zi),\n",
        "        add_pd(yi, z),  mul_pd(yi, z), add_pd(yi, zi), mul_pd(yi, zi)\n",
        "    ], axis=1)\n",
        "    return pairs\n",
        "\n",
        "def group_triplets(pairs: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.gather(pairs, TRIPLET_IDX, axis=1)\n",
        "\n",
        "# -----------------------------\n",
        "# Collapse: triplet loops + scatter update (kept)\n",
        "# -----------------------------\n",
        "def detect_collapse_triplet_scatter(pairs: tf.Tensor,\n",
        "                                   tau_hi: float = TAU_HI,\n",
        "                                   tau_low: float = TAU_LOW,\n",
        "                                   r_for_ratio: float = R_FOR_RATIO) -> tf.Tensor:\n",
        "    real = pairs[..., 0]    # [Q,30]\n",
        "    unreal = pairs[..., 1]  # [Q,30]\n",
        "    Q = tf.shape(pairs)[0]\n",
        "\n",
        "    cond1 = tf.logical_and(real >= tau_hi, unreal <= tau_low)\n",
        "    ratio = tf.where(tf.abs(unreal) > EPS, real / unreal, tf.zeros_like(real))\n",
        "    cond2 = ratio > r_for_ratio\n",
        "    individual = tf.logical_or(cond1, cond2)  # [Q,30] bool\n",
        "\n",
        "    final_mask = tf.cast(individual, tf.int32)\n",
        "\n",
        "    for t in tf.range(10):\n",
        "        idx3 = TRIPLET_IDX[t]  # [3]\n",
        "        trip_ind = tf.gather(individual, idx3, axis=1)  # [Q,3]\n",
        "\n",
        "        is_uniform = tf.reduce_all(tf.equal(trip_ind, trip_ind[:, 0:1]), axis=1)  # [Q]\n",
        "        uniform_val = tf.cast(trip_ind[:, 0], tf.int32)  # [Q]\n",
        "\n",
        "        updates_for_triplet = tf.where(\n",
        "            tf.expand_dims(is_uniform, axis=1),\n",
        "            tf.tile(tf.expand_dims(uniform_val, axis=1), [1,3]),\n",
        "            tf.cast(trip_ind, tf.int32)\n",
        "        )  # [Q,3]\n",
        "\n",
        "        q_idx = tf.repeat(tf.range(Q), repeats=3)     # [Q*3]\n",
        "        p_idx = tf.tile(idx3, multiples=[Q])          # [Q*3]\n",
        "        scatter_idx = tf.stack([q_idx, p_idx], axis=1)\n",
        "\n",
        "        final_mask = tf.tensor_scatter_nd_update(final_mask, scatter_idx, tf.reshape(updates_for_triplet, [-1]))\n",
        "\n",
        "    return final_mask\n",
        "\n",
        "def apply_parity_rotation(pairs: tf.Tensor, collapse_mask: tf.Tensor, prime_mask: tf.Tensor = PRIME_MASK):\n",
        "    Q = tf.shape(pairs)[0]\n",
        "    prime = tf.broadcast_to(tf.cast(prime_mask, tf.int32)[tf.newaxis, :], [Q, 30])\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32)\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, tf.float32), tf.constant(1.0, tf.float32))\n",
        "    rotated = pairs * sign[..., tf.newaxis]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs: tf.Tensor, eps: float = EPS) -> tf.Tensor:\n",
        "    return tf.cast(rotated_pairs[..., 0] > eps, tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# NEW: NEC construction and initiator logic from your spec\n",
        "# -----------------------------\n",
        "def build_primaries_from_nec(mag_xyz_i32: tf.Tensor, base_sign_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    mag_xyz_i32: [Q,3] int32 magnitudes, >=0\n",
        "    base_sign_xyz_i32: [Q,3] int32 in {-1,+1} giving base NEC sign per axis (unreal/real)\n",
        "\n",
        "    Returns primaries [Q,6,2] float32 with real/unreal channels:\n",
        "      real axis value  = +mag\n",
        "      unreal axis value= -mag\n",
        "    And ordering inside each (axis, axis_i) pair depends on base sign:\n",
        "      if base sign is +1 (real):  emit (real, unreal)\n",
        "      if base sign is -1 (unreal):emit (unreal, real)\n",
        "    The second float component is kept equal to the first (phase-dual placeholder); you can extend later.\n",
        "    \"\"\"\n",
        "    mag = tf.cast(mag_xyz_i32, tf.float32)  # [Q,3]\n",
        "    real = mag\n",
        "    unreal = -mag\n",
        "\n",
        "    # For each axis, choose first/second in the pair based on base sign\n",
        "    # base_sign = +1 => (real, unreal), base_sign = -1 => (unreal, real)\n",
        "    sign_is_unreal = base_sign_xyz_i32 < 0  # [Q,3] bool\n",
        "\n",
        "    first = tf.where(sign_is_unreal, unreal, real)   # [Q,3]\n",
        "    second= tf.where(sign_is_unreal, real, unreal)   # [Q,3]\n",
        "\n",
        "    # Expand to [Q,6] in order x,xi,y,yi,z,zi (before initiator permutation)\n",
        "    # Note: \"xi\" here means the second element of the pair (not always negative); it is \"the dual channel\"\n",
        "    x0,x1 = first[:,0], second[:,0]\n",
        "    y0,y1 = first[:,1], second[:,1]\n",
        "    z0,z1 = first[:,2], second[:,2]\n",
        "\n",
        "    prim_scalar = tf.stack([x0,x1,y0,y1,z0,z1], axis=1)  # [Q,6]\n",
        "\n",
        "    # phase-dual placeholder: [real, unreal] components identical for now\n",
        "    prim = tf.stack([prim_scalar, prim_scalar], axis=2)  # [Q,6,2] float32\n",
        "    return prim\n",
        "\n",
        "def initiator_from_shared_counts(mag_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Implements your initiator rule using axis magnitude sharing across the array.\n",
        "    mag_xyz_i32: [Q,3] magnitudes (abs NEC components)\n",
        "    Returns initiator axis index per qubit: 0=x, 1=y, 2=z\n",
        "\n",
        "    Rule set consistent with your examples:\n",
        "      Let cx,cy,cz be counts of how many qubits share that axis magnitude.\n",
        "      - If exactly one axis is shared (count>1): initiator = that axis (most-shared axis exists uniquely)\n",
        "      - If exactly two axes are shared: initiator = the odd one out (the unshared axis)\n",
        "      - If all three are shared: initiator = axis with max count (most shared)\n",
        "      - If none are shared: initiator = axis with max magnitude (tie-break x>y>z)\n",
        "    \"\"\"\n",
        "    Q = tf.shape(mag_xyz_i32)[0]\n",
        "    mag = mag_xyz_i32  # [Q,3]\n",
        "\n",
        "    # counts per axis via equality matrix (QxQ); Q=64 so OK\n",
        "    # counts_x[q] = sum_{k} [mag[q,0] == mag[k,0]]\n",
        "    eqx = tf.equal(tf.expand_dims(mag[:,0], 1), tf.expand_dims(mag[:,0], 0))\n",
        "    eqy = tf.equal(tf.expand_dims(mag[:,1], 1), tf.expand_dims(mag[:,1], 0))\n",
        "    eqz = tf.equal(tf.expand_dims(mag[:,2], 1), tf.expand_dims(mag[:,2], 0))\n",
        "    cx = tf.reduce_sum(tf.cast(eqx, tf.int32), axis=1)  # [Q]\n",
        "    cy = tf.reduce_sum(tf.cast(eqy, tf.int32), axis=1)\n",
        "    cz = tf.reduce_sum(tf.cast(eqz, tf.int32), axis=1)\n",
        "\n",
        "    shared_mask = tf.stack([cx>1, cy>1, cz>1], axis=1)  # [Q,3] bool\n",
        "    shared_count = tf.reduce_sum(tf.cast(shared_mask, tf.int32), axis=1)  # [Q]\n",
        "\n",
        "    counts = tf.stack([cx,cy,cz], axis=1)  # [Q,3]\n",
        "    mags = mag  # [Q,3]\n",
        "\n",
        "    # Case A: exactly one shared -> argmax(counts)\n",
        "    init_one_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "\n",
        "    # Case B: exactly two shared -> choose unshared axis (where count==1)\n",
        "    # If two are shared, exactly one axis will have count==1.\n",
        "    is_unshared = tf.equal(counts, 1)  # [Q,3] bool\n",
        "    init_two_shared = tf.argmax(tf.cast(is_unshared, tf.int32), axis=1, output_type=tf.int32)\n",
        "\n",
        "    # Case C: three shared -> axis with max count\n",
        "    init_three_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "\n",
        "    # Case D: none shared -> axis with max magnitude; tie-break by preferring lower index\n",
        "    # Implement tie-break by adding small bias: x + 0.002, y + 0.001, z + 0.000\n",
        "    bias = tf.constant([2,1,0], tf.int32)\n",
        "    mags_biased = mags * 1000 + bias  # [Q,3]\n",
        "    init_none_shared = tf.argmax(mags_biased, axis=1, output_type=tf.int32)\n",
        "\n",
        "    initiator = tf.where(shared_count == 1, init_one_shared,\n",
        "                 tf.where(shared_count == 2, init_two_shared,\n",
        "                 tf.where(shared_count == 3, init_three_shared,\n",
        "                          init_none_shared)))\n",
        "    return initiator  # [Q]\n",
        "\n",
        "def permute_primaries_by_initiator(primaries_6: tf.Tensor, initiator_axis: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    primaries_6: [Q,6,2] with axis pair order already set by base NEC sign\n",
        "    initiator_axis: [Q] in {0,1,2} choosing initiator x/y/z\n",
        "\n",
        "    Permutation is cyclic by axis pairs (2-wide):\n",
        "      init x: [x,xi, y,yi, z,zi]  (pairs: X,Y,Z)\n",
        "      init y: [y,yi, z,zi, x,xi]  (pairs: Y,Z,X)\n",
        "      init z: [z,zi, x,xi, y,yi]  (pairs: Z,X,Y)\n",
        "    \"\"\"\n",
        "    Q = tf.shape(primaries_6)[0]\n",
        "\n",
        "    # Build per-qubit indices [6] depending on initiator\n",
        "    idx_x = tf.constant([0,1,2,3,4,5], tf.int32)\n",
        "    idx_y = tf.constant([2,3,4,5,0,1], tf.int32)\n",
        "    idx_z = tf.constant([4,5,0,1,2,3], tf.int32)\n",
        "\n",
        "    # Gather indices per qubit: [Q,6]\n",
        "    idx = tf.where(tf.expand_dims(initiator_axis==0,1), tf.broadcast_to(idx_x, [Q,6]),\n",
        "          tf.where(tf.expand_dims(initiator_axis==1,1), tf.broadcast_to(idx_y, [Q,6]),\n",
        "                                                          tf.broadcast_to(idx_z, [Q,6])))\n",
        "\n",
        "    # Gather along axis=1 with batch dims\n",
        "    batch = tf.expand_dims(tf.range(Q, dtype=tf.int32), axis=1)  # [Q,1]\n",
        "    gather_nd = tf.concat([batch, idx], axis=1)  # WRONG shape for gather_nd; use tf.gather with batch_dims=1\n",
        "    perm = tf.gather(primaries_6, idx, axis=1, batch_dims=1)\n",
        "    return perm\n",
        "\n",
        "# -----------------------------\n",
        "# Compute bits for a given primaries arrangement\n",
        "# -----------------------------\n",
        "def bits_from_primaries(prim: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:\n",
        "    pairs = compute_pairs(prim)\n",
        "    triplets = group_triplets(pairs)\n",
        "    collapse = detect_collapse_triplet_scatter(pairs)\n",
        "    rotated, parity = apply_parity_rotation(pairs, collapse)\n",
        "    bits = bitmap(rotated)\n",
        "    return bits, pairs, triplets, collapse, parity\n",
        "\n",
        "# -----------------------------\n",
        "# Demo setup\n",
        "# -----------------------------\n",
        "tf.random.set_seed(11)\n",
        "np.random.seed(11)\n",
        "\n",
        "Q = 64  # target for 64-lane masks\n",
        "assert Q <= 64\n",
        "\n",
        "# Build magnitudes so sharing actually happens (small range encourages collisions)\n",
        "mag_xyz = tf.random.uniform([Q,3], minval=0, maxval=64, dtype=tf.int32)\n",
        "\n",
        "# Base NEC sign pattern per axis in {-1,+1}\n",
        "# -1 => unreal phase initiated for that axis (pair order swaps)\n",
        "sign_bits = tf.random.uniform([Q,3], minval=0, maxval=2, dtype=tf.int32)\n",
        "base_sign = tf.where(sign_bits>0, tf.constant(1, tf.int32), tf.constant(-1, tf.int32))\n",
        "\n",
        "# Build [Q,6,2] primaries from NEC magnitudes + sign-defined pair ordering\n",
        "prim0 = build_primaries_from_nec(mag_xyz, base_sign)  # [Q,6,2]\n",
        "\n",
        "# Determine per-qubit initiator axis from shared magnitude counts across array\n",
        "initiator = initiator_from_shared_counts(mag_xyz)  # [Q], values 0/1/2\n",
        "\n",
        "# Produce three \"view\" primaries (init=x, init=y, init=z) simultaneously\n",
        "prim_view_x = permute_primaries_by_initiator(prim0, tf.zeros([Q], tf.int32))\n",
        "prim_view_y = permute_primaries_by_initiator(prim0, tf.ones([Q], tf.int32))\n",
        "prim_view_z = permute_primaries_by_initiator(prim0, tf.fill([Q], tf.constant(2, tf.int32)))\n",
        "\n",
        "# Produce selected primaries (per qubit chosen initiator)\n",
        "prim_sel = permute_primaries_by_initiator(prim0, initiator)\n",
        "\n",
        "# Compute 30-bit outputs for each view and selected\n",
        "bits_x, *_ = bits_from_primaries(prim_view_x)\n",
        "bits_y, *_ = bits_from_primaries(prim_view_y)\n",
        "bits_z, *_ = bits_from_primaries(prim_view_z)\n",
        "bits_sel, pairs_sel, trip_sel, coll_sel, par_sel = bits_from_primaries(prim_sel)\n",
        "\n",
        "# Stack views: [Q,3,30]\n",
        "bits_views = tf.stack([bits_x, bits_y, bits_z], axis=1)\n",
        "\n",
        "# Bit-sliced masks per view: [3,30] uint64\n",
        "masks_views = tf.stack([bitslice_30_tf(bits_x), bitslice_30_tf(bits_y), bitslice_30_tf(bits_z)], axis=0)\n",
        "masks_sel = bitslice_30_tf(bits_sel)  # [30] uint64 for selected initiator per qubit\n",
        "\n",
        "# -----------------------------\n",
        "# Print / inspect\n",
        "# -----------------------------\n",
        "print(\"=== NEC / Initiator Prototype ===\")\n",
        "print(\"mag_xyz shape:\", mag_xyz.shape, \"base_sign shape:\", base_sign.shape)\n",
        "print(\"prim0 shape:\", prim0.shape)\n",
        "print(\"initiator axis counts:\", np.bincount(initiator.numpy(), minlength=3), \" (0=x,1=y,2=z)\")\n",
        "\n",
        "print(\"\\n=== Bit outputs ===\")\n",
        "print(\"bits_sel:\", bits_sel.shape, \"bits_views:\", bits_views.shape)\n",
        "print(\"Total bits per view (Q*30):\", Q*30, \"Total bits across 3 initiators:\", 3*Q*30)\n",
        "\n",
        "print(\"\\nSelected initiator masks (30×u64):\")\n",
        "ms = masks_sel.numpy()\n",
        "print(\" mask[0]:\", int(ms[0]))\n",
        "print(\" mask[1]:\", int(ms[1]))\n",
        "print(\" mask[29]:\", int(ms[29]))\n",
        "\n",
        "print(\"\\nView masks shape:\", masks_views.shape, \"dtype:\", masks_views.dtype)\n",
        "print(\"View X mask[0]:\", int(masks_views.numpy()[0,0]))\n",
        "print(\"View Y mask[0]:\", int(masks_views.numpy()[1,0]))\n",
        "print(\"View Z mask[0]:\", int(masks_views.numpy()[2,0]))\n",
        "\n",
        "# Show a few qubits for sanity: NEC, initiator, and 6-bit primary shadow implied by pair ordering\n",
        "# Primary shadow here is simply sign-based bits of the first 6 primaries (positive->1, negative->0)\n",
        "prim6_scalar = prim_sel[...,0]  # [Q,6], since we duplicated channels\n",
        "primary_bits6 = (prim6_scalar > 0).numpy().astype(np.int32)\n",
        "\n",
        "print(\"\\nSample qubits (q, NEC mag, NEC sign, initiator, primary6bits):\")\n",
        "mag_np = mag_xyz.numpy()\n",
        "sign_np = base_sign.numpy()\n",
        "init_np = initiator.numpy()\n",
        "for q in range(8):\n",
        "    print(q, mag_np[q].tolist(), sign_np[q].tolist(), int(init_np[q]), primary_bits6[q].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqygR4xddd9h",
        "outputId": "8cff6daa-d1b6-47d1-e96a-513fa3597ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== NEC / Initiator Prototype ===\n",
            "mag_xyz shape: (64, 3) base_sign shape: (64, 3)\n",
            "prim0 shape: (64, 6, 2)\n",
            "initiator axis counts: [24 22 18]  (0=x,1=y,2=z)\n",
            "\n",
            "=== Bit outputs ===\n",
            "bits_sel: (64, 30) bits_views: (64, 3, 30)\n",
            "Total bits per view (Q*30): 1920 Total bits across 3 initiators: 5760\n",
            "\n",
            "Selected initiator masks (30×u64):\n",
            " mask[0]: 3067302693352695933\n",
            " mask[1]: 6156069068624172930\n",
            " mask[29]: 12857919008426346258\n",
            "\n",
            "View masks shape: (3, 30) dtype: <dtype: 'uint64'>\n",
            "View X mask[0]: 3155114210651005029\n",
            "View Y mask[0]: 14884463583173914205\n",
            "View Z mask[0]: 9059472057987653975\n",
            "\n",
            "Sample qubits (q, NEC mag, NEC sign, initiator, primary6bits):\n",
            "0 [56, 38, 47] [1, 1, 1] 2 [1, 0, 1, 0, 1, 0]\n",
            "1 [44, 2, 2] [-1, -1, 1] 1 [0, 1, 1, 0, 0, 1]\n",
            "2 [8, 57, 40] [1, 1, 1] 0 [1, 0, 1, 0, 1, 0]\n",
            "3 [4, 59, 56] [-1, 1, -1] 1 [1, 0, 0, 1, 0, 1]\n",
            "4 [36, 51, 43] [-1, 1, 1] 1 [1, 0, 1, 0, 0, 1]\n",
            "5 [46, 56, 18] [1, -1, -1] 0 [1, 0, 0, 1, 0, 1]\n",
            "6 [49, 54, 54] [1, 1, 1] 2 [1, 0, 1, 0, 1, 0]\n",
            "7 [46, 28, 62] [-1, -1, -1] 2 [0, 1, 0, 1, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, Dict, List\n",
        "\n",
        "# -----------------------------\n",
        "# Constants / knobs\n",
        "# -----------------------------\n",
        "Q = 64\n",
        "TAU_HI      = 1.0\n",
        "TAU_LOW     = -1.0\n",
        "EPS         = 1e-6\n",
        "R_FOR_RATIO = 64.0\n",
        "\n",
        "PRIME_MASK_30 = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# 10 triplets over 30 slots: [0..2],[3..5],...,[27..29]\n",
        "TRIPLET_IDX = tf.constant([[3*t,3*t+1,3*t+2] for t in range(10)], dtype=tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities: pack/bitslice\n",
        "# -----------------------------\n",
        "def pack30_to_u32_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    # bits30_i32: [Q,30] int32 {0,1} -> [Q] uint32\n",
        "    bits_u32 = tf.cast(bits30_i32, tf.uint32)\n",
        "    shifts = tf.cast(tf.range(30), tf.uint32)\n",
        "    return tf.reduce_sum(tf.bitwise.left_shift(bits_u32, shifts), axis=1)\n",
        "\n",
        "def bitslice_30_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    # [Q,30] -> [30] uint64 lane masks (Q<=64)\n",
        "    weights = tf.bitwise.left_shift(tf.constant(1, tf.uint64), tf.cast(tf.range(tf.shape(bits30_i32)[0]), tf.uint64))\n",
        "    bits_u64 = tf.cast(bits30_i32, tf.uint64)\n",
        "    return tf.reduce_sum(tf.transpose(bits_u64, [1,0]) * tf.expand_dims(weights, axis=0), axis=1)\n",
        "\n",
        "def pack90_from_3x30_u32(packed3_u32: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    packed3_u32: [Q,3] uint32, each holds 30 bits\n",
        "    Returns: [Q,2] uint64 packing 90 bits:\n",
        "      low64  = bits0[0..29] | bits1[0..29]<<30 | bits2[0..3]<<60\n",
        "      high64 = bits2[4..29] in low bits (26 bits)\n",
        "    \"\"\"\n",
        "    Qn = packed3_u32.shape[0]\n",
        "    out = np.zeros((Qn,2), dtype=np.uint64)\n",
        "    for q in range(Qn):\n",
        "        b0 = np.uint64(packed3_u32[q,0] & np.uint32((1<<30)-1))\n",
        "        b1 = np.uint64(packed3_u32[q,1] & np.uint32((1<<30)-1))\n",
        "        b2 = np.uint64(packed3_u32[q,2] & np.uint32((1<<30)-1))\n",
        "        low = b0 | (b1 << np.uint64(30)) | ((b2 & np.uint64(0xF)) << np.uint64(60))\n",
        "        high = (b2 >> np.uint64(4))  # 26 bits\n",
        "        out[q,0] = low\n",
        "        out[q,1] = high\n",
        "    return out\n",
        "\n",
        "# -----------------------------\n",
        "# NEC selectors (true phase-dual) + initiator logic\n",
        "# -----------------------------\n",
        "def sel_real(m: tf.Tensor) -> tf.Tensor:\n",
        "    # m: [Q] float -> [Q,2] = [+m, -m]\n",
        "    return tf.stack([m, -m], axis=1)\n",
        "\n",
        "def sel_unreal(m: tf.Tensor) -> tf.Tensor:\n",
        "    # [Q,2] = [-m, +m]\n",
        "    return tf.stack([-m, m], axis=1)\n",
        "\n",
        "def build_primaries_from_nec(mag_xyz_i32: tf.Tensor, base_sign_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    mag_xyz_i32: [Q,3] int32 magnitudes >=0 (NEC absolute coordinate)\n",
        "    base_sign_xyz_i32: [Q,3] int32 in {-1,+1} giving base NEC sign per axis:\n",
        "      +1 => axis initiated real  => pair order (RealSelector, UnrealSelector)\n",
        "      -1 => axis initiated unreal=> pair order (UnrealSelector, RealSelector)\n",
        "\n",
        "    Returns primaries [Q,6,2] float32 in canonical pair sequence:\n",
        "      [X0, X1, Y0, Y1, Z0, Z1] where each Xi/Yi/Zi is itself a 2-vector [real, unreal].\n",
        "    \"\"\"\n",
        "    mag = tf.cast(mag_xyz_i32, tf.float32)\n",
        "    mX, mY, mZ = mag[:,0], mag[:,1], mag[:,2]\n",
        "    Xr, Xu = sel_real(mX), sel_unreal(mX)\n",
        "    Yr, Yu = sel_real(mY), sel_unreal(mY)\n",
        "    Zr, Zu = sel_real(mZ), sel_unreal(mZ)\n",
        "\n",
        "    sign_is_unreal = base_sign_xyz_i32 < 0  # [Q,3] bool\n",
        "\n",
        "    X0 = tf.where(sign_is_unreal[:,0:1], Xu, Xr)\n",
        "    X1 = tf.where(sign_is_unreal[:,0:1], Xr, Xu)\n",
        "    Y0 = tf.where(sign_is_unreal[:,1:2], Yu, Yr)\n",
        "    Y1 = tf.where(sign_is_unreal[:,1:2], Yr, Yu)\n",
        "    Z0 = tf.where(sign_is_unreal[:,2:3], Zu, Zr)\n",
        "    Z1 = tf.where(sign_is_unreal[:,2:3], Zr, Zu)\n",
        "\n",
        "    prim = tf.stack([X0,X1,Y0,Y1,Z0,Z1], axis=1)  # [Q,6,2]\n",
        "    return prim\n",
        "\n",
        "def initiator_from_shared_counts(mag_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Your initiator rule using shared axis magnitudes across the array.\n",
        "    Returns initiator axis index per qubit: 0=x, 1=y, 2=z\n",
        "    \"\"\"\n",
        "    mag = mag_xyz_i32  # [Q,3], int32\n",
        "    eqx = tf.equal(tf.expand_dims(mag[:,0], 1), tf.expand_dims(mag[:,0], 0))\n",
        "    eqy = tf.equal(tf.expand_dims(mag[:,1], 1), tf.expand_dims(mag[:,1], 0))\n",
        "    eqz = tf.equal(tf.expand_dims(mag[:,2], 1), tf.expand_dims(mag[:,2], 0))\n",
        "    cx = tf.reduce_sum(tf.cast(eqx, tf.int32), axis=1)\n",
        "    cy = tf.reduce_sum(tf.cast(eqy, tf.int32), axis=1)\n",
        "    cz = tf.reduce_sum(tf.cast(eqz, tf.int32), axis=1)\n",
        "\n",
        "    counts = tf.stack([cx,cy,cz], axis=1)  # [Q,3]\n",
        "    shared_mask = counts > 1\n",
        "    shared_count = tf.reduce_sum(tf.cast(shared_mask, tf.int32), axis=1)  # [Q]\n",
        "\n",
        "    init_one_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "    is_unshared = tf.equal(counts, 1)\n",
        "    init_two_shared = tf.argmax(tf.cast(is_unshared, tf.int32), axis=1, output_type=tf.int32)\n",
        "    init_three_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "\n",
        "    # none shared => max magnitude tie-break x>y>z\n",
        "    bias = tf.constant([2,1,0], tf.int32)\n",
        "    mags_biased = mag_xyz_i32 * 1000 + bias\n",
        "    init_none_shared = tf.argmax(mags_biased, axis=1, output_type=tf.int32)\n",
        "\n",
        "    initiator = tf.where(shared_count == 1, init_one_shared,\n",
        "                 tf.where(shared_count == 2, init_two_shared,\n",
        "                 tf.where(shared_count == 3, init_three_shared, init_none_shared)))\n",
        "    return initiator  # [Q]\n",
        "\n",
        "def permute_primaries_by_initiator(prim6: tf.Tensor, initiator_axis: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    prim6: [Q,6,2] ordered as [X0,X1,Y0,Y1,Z0,Z1]\n",
        "    initiator_axis: [Q] in {0,1,2}\n",
        "\n",
        "    Cyclic by axis-pairs (2-wide):\n",
        "      init x: [X0,X1, Y0,Y1, Z0,Z1]\n",
        "      init y: [Y0,Y1, Z0,Z1, X0,X1]\n",
        "      init z: [Z0,Z1, X0,X1, Y0,Y1]\n",
        "    \"\"\"\n",
        "    Qn = tf.shape(prim6)[0]\n",
        "    idx_x = tf.constant([0,1,2,3,4,5], tf.int32)\n",
        "    idx_y = tf.constant([2,3,4,5,0,1], tf.int32)\n",
        "    idx_z = tf.constant([4,5,0,1,2,3], tf.int32)\n",
        "\n",
        "    idx = tf.where(tf.expand_dims(initiator_axis==0,1), tf.broadcast_to(idx_x, [Qn,6]),\n",
        "          tf.where(tf.expand_dims(initiator_axis==1,1), tf.broadcast_to(idx_y, [Qn,6]),\n",
        "                                                          tf.broadcast_to(idx_z, [Qn,6])))\n",
        "\n",
        "    return tf.gather(prim6, idx, axis=1, batch_dims=1)\n",
        "\n",
        "# -----------------------------\n",
        "# 30-register with (+,-,*,/) semantics and add/sub-only reorder (canonicalization)\n",
        "# -----------------------------\n",
        "def div_pd(a: tf.Tensor, b: tf.Tensor) -> tf.Tensor:\n",
        "    # safe component-wise division for phase-dual\n",
        "    return tf.where(tf.abs(b) > EPS, a / b, tf.zeros_like(a))\n",
        "\n",
        "def build_register30(prim6: tf.Tensor,\n",
        "                     canonicalize_addsub: bool = True) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"\n",
        "    prim6: [Q,6,2] in initiator-permuted order [X0,X1,Y0,Y1,Z0,Z1] but \"X,Y,Z\" are just first/second/third axis pairs.\n",
        "    Returns:\n",
        "      reg: [Q,30,2]\n",
        "      swap_flags: [Q,8] int32, whether add/sub swapped in each of the 8 interaction triplets (2..9)\n",
        "    Layout (10 triplets):\n",
        "      Triplet0: [p0, p1, p2]  (primaries)\n",
        "      Triplet1: [p3, p4, p5]  (primaries)\n",
        "      Triplets2..9: 8 interaction triplets:\n",
        "          [ADD(u,v), SUB(u,v), OP3(u,v)]   OP3 fixed (MUL or DIV)\n",
        "    Canonicalization:\n",
        "      If canonicalize_addsub=True: reorder ADD/SUB so the first has >= real component of the second.\n",
        "      Only those two slots reorder; MUL/DIV slot fixed.\n",
        "    \"\"\"\n",
        "    p0,p1,p2,p3,p4,p5 = tf.unstack(prim6, axis=1)  # each [Q,2]\n",
        "    # Interpret axes:\n",
        "    # AxisA = (p0,p1), AxisB=(p2,p3), AxisC=(p4,p5) in this initiator frame\n",
        "    A0,A1 = p0,p1\n",
        "    B0,B1 = p2,p3\n",
        "    C0,C1 = p4,p5\n",
        "\n",
        "    # Choose 8 operand pairs (u,v) deterministically from these six primaries:\n",
        "    # 4 with MUL fixed, 4 with DIV fixed\n",
        "    pairs = [\n",
        "        (A0, B0, \"MUL\"),\n",
        "        (B0, C0, \"MUL\"),\n",
        "        (A0, C0, \"MUL\"),\n",
        "        (A1, B1, \"MUL\"),\n",
        "        (A0, B1, \"DIV\"),\n",
        "        (B0, C1, \"DIV\"),\n",
        "        (A1, C0, \"DIV\"),\n",
        "        (B1, C1, \"DIV\"),\n",
        "    ]\n",
        "\n",
        "    add_list = []\n",
        "    sub_list = []\n",
        "    op3_list = []\n",
        "    swap_flags = []\n",
        "\n",
        "    for (u,v,op3) in pairs:\n",
        "        addv = add_pd(u,v)\n",
        "        subv = u - v\n",
        "        if op3 == \"MUL\":\n",
        "            opv = mul_pd(u,v)\n",
        "        else:\n",
        "            opv = div_pd(u,v)\n",
        "\n",
        "        if canonicalize_addsub:\n",
        "            # swap if subv.real > addv.real (i.e., put the larger-real first)\n",
        "            swap = tf.cast(subv[:,0] > addv[:,0], tf.int32)  # [Q]\n",
        "            addv2 = tf.where(swap[:,None] > 0, subv, addv)\n",
        "            subv2 = tf.where(swap[:,None] > 0, addv, subv)\n",
        "            addv, subv = addv2, subv2\n",
        "            swap_flags.append(swap)\n",
        "        else:\n",
        "            swap_flags.append(tf.zeros([tf.shape(u)[0]], tf.int32))\n",
        "\n",
        "        add_list.append(addv)\n",
        "        sub_list.append(subv)\n",
        "        op3_list.append(opv)\n",
        "\n",
        "    # Assemble 10 triplets = 30 slots\n",
        "    trip0 = [p0,p1,p2]\n",
        "    trip1 = [p3,p4,p5]\n",
        "\n",
        "    reg = [*trip0, *trip1]\n",
        "    for i in range(8):\n",
        "        reg.extend([add_list[i], sub_list[i], op3_list[i]])\n",
        "\n",
        "    reg = tf.stack(reg, axis=1)  # [Q,30,2]\n",
        "    swap_flags = tf.stack(swap_flags, axis=1)  # [Q,8]\n",
        "    return reg, swap_flags\n",
        "\n",
        "# -----------------------------\n",
        "# Collapse/parity/bitmap with triplet loop + scatter update retained\n",
        "# -----------------------------\n",
        "def detect_collapse_triplet_scatter(pairs: tf.Tensor,\n",
        "                                   tau_hi: float = TAU_HI,\n",
        "                                   tau_low: float = TAU_LOW,\n",
        "                                   r_for_ratio: float = R_FOR_RATIO) -> tf.Tensor:\n",
        "    real = pairs[..., 0]    # [Q,30]\n",
        "    unreal = pairs[..., 1]  # [Q,30]\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "\n",
        "    cond1 = tf.logical_and(real >= tau_hi, unreal <= tau_low)\n",
        "    ratio = tf.where(tf.abs(unreal) > EPS, real / unreal, tf.zeros_like(real))\n",
        "    cond2 = ratio > r_for_ratio\n",
        "    individual = tf.logical_or(cond1, cond2)  # [Q,30] bool\n",
        "\n",
        "    final_mask = tf.cast(individual, tf.int32)\n",
        "\n",
        "    for t in tf.range(10):\n",
        "        idx3 = TRIPLET_IDX[t]  # [3]\n",
        "        trip_ind = tf.gather(individual, idx3, axis=1)  # [Q,3]\n",
        "        is_uniform = tf.reduce_all(tf.equal(trip_ind, trip_ind[:, 0:1]), axis=1)  # [Q]\n",
        "        uniform_val = tf.cast(trip_ind[:, 0], tf.int32)  # [Q]\n",
        "\n",
        "        updates_for_triplet = tf.where(\n",
        "            tf.expand_dims(is_uniform, axis=1),\n",
        "            tf.tile(tf.expand_dims(uniform_val, axis=1), [1,3]),\n",
        "            tf.cast(trip_ind, tf.int32)\n",
        "        )  # [Q,3]\n",
        "\n",
        "        q_idx = tf.repeat(tf.range(Qn), repeats=3)\n",
        "        p_idx = tf.tile(idx3, multiples=[Qn])\n",
        "        scatter_idx = tf.stack([q_idx, p_idx], axis=1)\n",
        "        final_mask = tf.tensor_scatter_nd_update(final_mask, scatter_idx, tf.reshape(updates_for_triplet, [-1]))\n",
        "\n",
        "    return final_mask\n",
        "\n",
        "def apply_parity_rotation(pairs: tf.Tensor, collapse_mask: tf.Tensor):\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "    prime = tf.broadcast_to(PRIME_MASK_30[tf.newaxis, :], [Qn, 30])\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32)\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, tf.float32), tf.constant(1.0, tf.float32))\n",
        "    rotated = pairs * sign[..., tf.newaxis]\n",
        "    return rotated, affected\n",
        "\n",
        "def bitmap(rotated_pairs: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.cast(rotated_pairs[..., 0] > EPS, tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# One view compute: prim6 -> reg30 -> collapse/parity -> bits30\n",
        "# -----------------------------\n",
        "def compute_bits_for_view(prim6: tf.Tensor,\n",
        "                          canonicalize_addsub: bool = True) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:\n",
        "    reg30, swap_flags = build_register30(prim6, canonicalize_addsub=canonicalize_addsub)\n",
        "    collapse = detect_collapse_triplet_scatter(reg30)\n",
        "    rotated, parity = apply_parity_rotation(reg30, collapse)\n",
        "    bits = bitmap(rotated)\n",
        "    return bits, swap_flags, collapse, parity\n",
        "\n",
        "# -----------------------------\n",
        "# Commitments keyed off full 3-view payload\n",
        "# -----------------------------\n",
        "def commit_full90(packed_u32_xyz: np.ndarray,\n",
        "                  initiator_axis: np.ndarray,\n",
        "                  swapcount_xyz: np.ndarray,\n",
        "                  domain_sep: bytes = b\"NTHISA90\") -> List[bytes]:\n",
        "    \"\"\"\n",
        "    packed_u32_xyz: [Q,3] uint32 (x/y/z view packed 30-bit)\n",
        "    initiator_axis: [Q] uint8\n",
        "    swapcount_xyz:  [Q,3] uint8 (#swaps in 8 interaction triplets per view; 0..8)\n",
        "    \"\"\"\n",
        "    commits = []\n",
        "    for q in range(packed_u32_xyz.shape[0]):\n",
        "        msg = (\n",
        "            domain_sep +\n",
        "            int(packed_u32_xyz[q,0]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,1]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,2]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(initiator_axis[q]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,0]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,1]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,2]).to_bytes(1,\"little\",signed=False)\n",
        "        )\n",
        "        commits.append(hashlib.blake2s(msg, digest_size=32).digest())\n",
        "    return commits\n",
        "\n",
        "# -----------------------------\n",
        "# Demo run\n",
        "# -----------------------------\n",
        "tf.random.set_seed(11)\n",
        "np.random.seed(11)\n",
        "\n",
        "# NEC magnitudes (small range encourages shared values)\n",
        "mag_xyz = tf.random.uniform([Q,3], minval=0, maxval=64, dtype=tf.int32)\n",
        "\n",
        "# NEC base sign pattern in {-1,+1}\n",
        "sign_bits = tf.random.uniform([Q,3], minval=0, maxval=2, dtype=tf.int32)\n",
        "base_sign = tf.where(sign_bits>0, tf.constant(1, tf.int32), tf.constant(-1, tf.int32))\n",
        "\n",
        "prim0 = build_primaries_from_nec(mag_xyz, base_sign)  # [Q,6,2] canonical pair order X,Y,Z\n",
        "initiator = initiator_from_shared_counts(mag_xyz)     # [Q] axis 0/1/2\n",
        "\n",
        "# Three global views (init=x/y/z) and per-qubit selected init\n",
        "prim_x = permute_primaries_by_initiator(prim0, tf.zeros([Q], tf.int32))\n",
        "prim_y = permute_primaries_by_initiator(prim0, tf.ones([Q], tf.int32))\n",
        "prim_z = permute_primaries_by_initiator(prim0, tf.fill([Q], tf.constant(2, tf.int32)))\n",
        "prim_sel = permute_primaries_by_initiator(prim0, initiator)\n",
        "\n",
        "# Compute bits for each view with add/sub canonicalization enabled\n",
        "bits_x, swaps_x, coll_x, par_x = compute_bits_for_view(prim_x, canonicalize_addsub=True)\n",
        "bits_y, swaps_y, coll_y, par_y = compute_bits_for_view(prim_y, canonicalize_addsub=True)\n",
        "bits_z, swaps_z, coll_z, par_z = compute_bits_for_view(prim_z, canonicalize_addsub=True)\n",
        "bits_sel, swaps_sel, coll_sel, par_sel = compute_bits_for_view(prim_sel, canonicalize_addsub=True)\n",
        "\n",
        "# Stack into [Q,3,30]\n",
        "bits_views = tf.stack([bits_x, bits_y, bits_z], axis=1)\n",
        "\n",
        "# Pack per view: [Q,3] uint32\n",
        "packed_x = pack30_to_u32_tf(bits_x)\n",
        "packed_y = pack30_to_u32_tf(bits_y)\n",
        "packed_z = pack30_to_u32_tf(bits_z)\n",
        "packed_views_u32 = tf.stack([packed_x, packed_y, packed_z], axis=1)\n",
        "\n",
        "packed_views_np = packed_views_u32.numpy().astype(np.uint32)\n",
        "\n",
        "# Pack full 90-bit payload into 2x u64\n",
        "packed90_u64 = pack90_from_3x30_u32(packed_views_np)  # [Q,2] uint64\n",
        "\n",
        "# Swap-counts per view (number of add/sub swaps across the 8 interaction triplets)\n",
        "swapcount_x = tf.reduce_sum(swaps_x, axis=1)  # [Q]\n",
        "swapcount_y = tf.reduce_sum(swaps_y, axis=1)\n",
        "swapcount_z = tf.reduce_sum(swaps_z, axis=1)\n",
        "swapcount_xyz = tf.stack([swapcount_x, swapcount_y, swapcount_z], axis=1).numpy().astype(np.uint8)\n",
        "\n",
        "# Commitments based on full 90-bit payload + initiator selection + swap stats\n",
        "commits = commit_full90(\n",
        "    packed_u32_xyz=packed_views_np,\n",
        "    initiator_axis=initiator.numpy().astype(np.uint8),\n",
        "    swapcount_xyz=swapcount_xyz\n",
        ")\n",
        "\n",
        "# Bit-sliced masks per view: [3,30] uint64\n",
        "masks_views = tf.stack([bitslice_30_tf(bits_x), bitslice_30_tf(bits_y), bitslice_30_tf(bits_z)], axis=0)\n",
        "\n",
        "# Selected initiator masks (30×u64)\n",
        "masks_sel = bitslice_30_tf(bits_sel)\n",
        "\n",
        "# -----------------------------\n",
        "# Display summary\n",
        "# -----------------------------\n",
        "print(\"=== UniversalISA v0.3 Summary ===\")\n",
        "print(\"mag_xyz:\", mag_xyz.shape, \"base_sign:\", base_sign.shape)\n",
        "print(\"prim0:\", prim0.shape, \"initiator:\", initiator.shape)\n",
        "print(\"initiator axis counts:\", np.bincount(initiator.numpy(), minlength=3), \"(0=x,1=y,2=z)\")\n",
        "\n",
        "print(\"\\nPayload shapes:\")\n",
        "print(\"bits_views:\", bits_views.shape, \" (Q,3,30) => 90 bits/qubit\")\n",
        "print(\"packed_views_u32:\", packed_views_u32.shape, packed_views_u32.dtype, \" (3×u32 per qubit)\")\n",
        "print(\"packed90_u64:\", packed90_u64.shape, packed90_u64.dtype, \" (2×u64 per qubit)\")\n",
        "print(\"Total bits per 64-qubit array:\", 64*90)\n",
        "\n",
        "print(\"\\nMasks:\")\n",
        "print(\"masks_views:\", masks_views.shape, masks_views.dtype, \" (3 views × 30 lane-masks)\")\n",
        "print(\"selected masks:\", masks_sel.shape, masks_sel.dtype)\n",
        "\n",
        "print(\"\\nCommitment[0] (hex):\", commits[0].hex())\n",
        "print(\"packed_views_u32[0]:\", packed_views_np[0].tolist())\n",
        "print(\"packed90_u64[0]:\", packed90_u64[0].tolist(), \"(low64, high64)\")\n",
        "print(\"swapcounts per view (q0):\", swapcount_xyz[0].tolist(), \" initiator(q0):\", int(initiator.numpy()[0]))\n",
        "\n",
        "# Show a few qubits: NEC, sign, initiator, primary 6-bit shadow for selected initiator view\n",
        "# Primary bits: 1 if selector.real>0 else 0 for the first 6 slots in the selected primaries\n",
        "prim6_real = prim_sel[...,0].numpy()  # [Q,6]\n",
        "primary6bits = (prim6_real > 0).astype(np.int32)\n",
        "\n",
        "print(\"\\nSample qubits (q, NEC mag, NEC sign, initiator, primary6bits, packedXYZ):\")\n",
        "mag_np = mag_xyz.numpy()\n",
        "sign_np = base_sign.numpy()\n",
        "init_np = initiator.numpy()\n",
        "for q in range(8):\n",
        "    print(q, mag_np[q].tolist(), sign_np[q].tolist(), int(init_np[q]), primary6bits[q].tolist(), packed_views_np[q].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UssTwuP3igW-",
        "outputId": "72294d7d-3c14-4fbf-cbb0-f6de80412943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== UniversalISA v0.3 Summary ===\n",
            "mag_xyz: (64, 3) base_sign: (64, 3)\n",
            "prim0: (64, 6, 2) initiator: (64,)\n",
            "initiator axis counts: [24 22 18] (0=x,1=y,2=z)\n",
            "\n",
            "Payload shapes:\n",
            "bits_views: (64, 3, 30)  (Q,3,30) => 90 bits/qubit\n",
            "packed_views_u32: (64, 3) <dtype: 'uint32'>  (3×u32 per qubit)\n",
            "packed90_u64: (64, 2) uint64  (2×u64 per qubit)\n",
            "Total bits per 64-qubit array: 5760\n",
            "\n",
            "Masks:\n",
            "masks_views: (3, 30) <dtype: 'uint64'>  (3 views × 30 lane-masks)\n",
            "selected masks: (30,) <dtype: 'uint64'>\n",
            "\n",
            "Commitment[0] (hex): 2e161a780261e4e75b64f349284517be142f41fa53a7fe930423e2d929d45760\n",
            "packed_views_u32[0]: [8405288, 8937896, 8929704]\n",
            "packed90_u64[0]: [9232969029616943400, 558106] (low64, high64)\n",
            "swapcounts per view (q0): [4, 4, 4]  initiator(q0): 2\n",
            "\n",
            "Sample qubits (q, NEC mag, NEC sign, initiator, primary6bits, packedXYZ):\n",
            "0 [56, 38, 47] [1, 1, 1] 2 [1, 0, 1, 0, 1, 0] [8405288, 8937896, 8929704]\n",
            "1 [44, 2, 2] [-1, -1, 1] 1 [0, 1, 1, 0, 0, 1] [604514724, 538601608, 77201540]\n",
            "2 [8, 57, 40] [1, 1, 1] 0 [1, 0, 1, 0, 1, 0] [8937896, 8405288, 8413480]\n",
            "3 [4, 59, 56] [-1, 1, -1] 1 [1, 0, 0, 1, 0, 1] [538601608, 76677124, 604514724]\n",
            "4 [36, 51, 43] [-1, 1, 1] 1 [1, 0, 1, 0, 0, 1] [77209768, 603982088, 538077220]\n",
            "5 [46, 56, 18] [1, -1, -1] 0 [1, 0, 0, 1, 0, 1] [77201540, 604514724, 538601608]\n",
            "6 [49, 54, 54] [1, 1, 1] 2 [1, 0, 1, 0, 1, 0] [8937896, 8405288, 8405288]\n",
            "7 [46, 28, 62] [-1, -1, -1] 2 [0, 1, 0, 1, 0, 1] [8937860, 8937860, 8937860]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UniversalISA prototype v0.4 (Colab single-cell)\n",
        "# Adds to v0.3:\n",
        "# - Batch-level DEDUP/ALIAS (state sharing detection) keyed off FULL 90-bit commitment\n",
        "# - Winner selection + alias map + freed qubits list\n",
        "# - Feed-forward state registers (tag_u64, initiator, swap counts)\n",
        "# - Second instruction step that executes only ACTIVE (winner) qubits and fills aliases deterministically\n",
        "# - Mode switch:\n",
        "#     MODE=\"FREE\"      => aliases are reassigned new NEC work states for next instruction\n",
        "#     MODE=\"PAIR_HUNT\" => aliases stay tied to winner state (useful for paired-state hunting)\n",
        "#\n",
        "# Notes:\n",
        "# - This is still a prototype; float32 math is not guaranteed bit-identical across all accelerators.\n",
        "# - The structure (triplet loops + scatter updates) is preserved.\n",
        "# - × and ÷ slots are fixed; only (ADD,SUB) can reorder via canonicalization.\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import hashlib\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "# -----------------------------\n",
        "# Global knobs\n",
        "# -----------------------------\n",
        "Q = 64\n",
        "MODE = \"FREE\"          # \"FREE\" or \"PAIR_HUNT\"\n",
        "INSTR_STEPS = 2        # demonstrate 2 instruction steps\n",
        "\n",
        "TAU_HI      = 1.0\n",
        "TAU_LOW     = -1.0\n",
        "EPS         = 1e-6\n",
        "R_FOR_RATIO = 64.0\n",
        "\n",
        "PRIME_MASK_30 = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "TRIPLET_IDX = tf.constant([[3*t,3*t+1,3*t+2] for t in range(10)], dtype=tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# Pack/bitslice utilities\n",
        "# -----------------------------\n",
        "def pack30_to_u32_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    bits_u32 = tf.cast(bits30_i32, tf.uint32)\n",
        "    shifts = tf.cast(tf.range(30), tf.uint32)\n",
        "    return tf.reduce_sum(tf.bitwise.left_shift(bits_u32, shifts), axis=1)  # [Q] u32\n",
        "\n",
        "def bitslice_30_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    weights = tf.bitwise.left_shift(tf.constant(1, tf.uint64), tf.cast(tf.range(tf.shape(bits30_i32)[0]), tf.uint64))\n",
        "    bits_u64 = tf.cast(bits30_i32, tf.uint64)\n",
        "    return tf.reduce_sum(tf.transpose(bits_u64, [1,0]) * tf.expand_dims(weights, axis=0), axis=1)  # [30] u64\n",
        "\n",
        "def pack90_from_3x30_u32(packed3_u32: np.ndarray) -> np.ndarray:\n",
        "    # packed3_u32: [Q,3] uint32 -> [Q,2] uint64\n",
        "    out = np.zeros((packed3_u32.shape[0],2), dtype=np.uint64)\n",
        "    for q in range(packed3_u32.shape[0]):\n",
        "        b0 = np.uint64(packed3_u32[q,0] & np.uint32((1<<30)-1))\n",
        "        b1 = np.uint64(packed3_u32[q,1] & np.uint32((1<<30)-1))\n",
        "        b2 = np.uint64(packed3_u32[q,2] & np.uint32((1<<30)-1))\n",
        "        low = b0 | (b1 << np.uint64(30)) | ((b2 & np.uint64(0xF)) << np.uint64(60))\n",
        "        high = (b2 >> np.uint64(4))\n",
        "        out[q,0] = low\n",
        "        out[q,1] = high\n",
        "    return out\n",
        "\n",
        "# -----------------------------\n",
        "# Phase-dual core ops\n",
        "# -----------------------------\n",
        "def add_pd(a,b): return a+b\n",
        "def mul_pd(a,b): return a*b\n",
        "def div_pd(a,b): return tf.where(tf.abs(b) > EPS, a/b, tf.zeros_like(a))\n",
        "\n",
        "# -----------------------------\n",
        "# NEC selectors (true phase-dual) + initiator logic\n",
        "# -----------------------------\n",
        "def sel_real(m: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.stack([m, -m], axis=1)  # [+m,-m]\n",
        "\n",
        "def sel_unreal(m: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.stack([-m, m], axis=1)  # [-m,+m]\n",
        "\n",
        "def build_primaries_from_nec(mag_xyz_i32: tf.Tensor, base_sign_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    mag = tf.cast(mag_xyz_i32, tf.float32)\n",
        "    mX, mY, mZ = mag[:,0], mag[:,1], mag[:,2]\n",
        "    Xr, Xu = sel_real(mX), sel_unreal(mX)\n",
        "    Yr, Yu = sel_real(mY), sel_unreal(mY)\n",
        "    Zr, Zu = sel_real(mZ), sel_unreal(mZ)\n",
        "\n",
        "    sign_is_unreal = base_sign_xyz_i32 < 0  # [Q,3]\n",
        "\n",
        "    X0 = tf.where(sign_is_unreal[:,0:1], Xu, Xr)\n",
        "    X1 = tf.where(sign_is_unreal[:,0:1], Xr, Xu)\n",
        "    Y0 = tf.where(sign_is_unreal[:,1:2], Yu, Yr)\n",
        "    Y1 = tf.where(sign_is_unreal[:,1:2], Yr, Yu)\n",
        "    Z0 = tf.where(sign_is_unreal[:,2:3], Zu, Zr)\n",
        "    Z1 = tf.where(sign_is_unreal[:,2:3], Zr, Zu)\n",
        "\n",
        "    return tf.stack([X0,X1,Y0,Y1,Z0,Z1], axis=1)  # [Q,6,2]\n",
        "\n",
        "def initiator_from_shared_counts(mag_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    mag = mag_xyz_i32\n",
        "    eqx = tf.equal(tf.expand_dims(mag[:,0], 1), tf.expand_dims(mag[:,0], 0))\n",
        "    eqy = tf.equal(tf.expand_dims(mag[:,1], 1), tf.expand_dims(mag[:,1], 0))\n",
        "    eqz = tf.equal(tf.expand_dims(mag[:,2], 1), tf.expand_dims(mag[:,2], 0))\n",
        "    cx = tf.reduce_sum(tf.cast(eqx, tf.int32), axis=1)\n",
        "    cy = tf.reduce_sum(tf.cast(eqy, tf.int32), axis=1)\n",
        "    cz = tf.reduce_sum(tf.cast(eqz, tf.int32), axis=1)\n",
        "\n",
        "    counts = tf.stack([cx,cy,cz], axis=1)  # [Q,3]\n",
        "    shared_mask = counts > 1\n",
        "    shared_count = tf.reduce_sum(tf.cast(shared_mask, tf.int32), axis=1)  # [Q]\n",
        "\n",
        "    init_one_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "    is_unshared = tf.equal(counts, 1)\n",
        "    init_two_shared = tf.argmax(tf.cast(is_unshared, tf.int32), axis=1, output_type=tf.int32)\n",
        "    init_three_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "\n",
        "    bias = tf.constant([2,1,0], tf.int32)\n",
        "    mags_biased = mag_xyz_i32 * 1000 + bias\n",
        "    init_none_shared = tf.argmax(mags_biased, axis=1, output_type=tf.int32)\n",
        "\n",
        "    initiator = tf.where(shared_count == 1, init_one_shared,\n",
        "                 tf.where(shared_count == 2, init_two_shared,\n",
        "                 tf.where(shared_count == 3, init_three_shared, init_none_shared)))\n",
        "    return initiator\n",
        "\n",
        "def permute_primaries_by_initiator(prim6: tf.Tensor, initiator_axis: tf.Tensor) -> tf.Tensor:\n",
        "    Qn = tf.shape(prim6)[0]\n",
        "    idx_x = tf.constant([0,1,2,3,4,5], tf.int32)\n",
        "    idx_y = tf.constant([2,3,4,5,0,1], tf.int32)\n",
        "    idx_z = tf.constant([4,5,0,1,2,3], tf.int32)\n",
        "\n",
        "    idx = tf.where(tf.expand_dims(initiator_axis==0,1), tf.broadcast_to(idx_x, [Qn,6]),\n",
        "          tf.where(tf.expand_dims(initiator_axis==1,1), tf.broadcast_to(idx_y, [Qn,6]),\n",
        "                                                          tf.broadcast_to(idx_z, [Qn,6])))\n",
        "    return tf.gather(prim6, idx, axis=1, batch_dims=1)\n",
        "\n",
        "# -----------------------------\n",
        "# 30-register builder: 10 triplets, add/sub reorderable, mul/div fixed\n",
        "# -----------------------------\n",
        "def build_register30(prim6: tf.Tensor, canonicalize_addsub: bool = True) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    p0,p1,p2,p3,p4,p5 = tf.unstack(prim6, axis=1)\n",
        "\n",
        "    A0,A1 = p0,p1\n",
        "    B0,B1 = p2,p3\n",
        "    C0,C1 = p4,p5\n",
        "\n",
        "    # 8 interaction triplets (2..9), each is [ADD,SUB,OP3] with OP3 fixed as MUL or DIV\n",
        "    spec = [\n",
        "        (A0, B0, \"MUL\"),\n",
        "        (B0, C0, \"MUL\"),\n",
        "        (A0, C0, \"MUL\"),\n",
        "        (A1, B1, \"MUL\"),\n",
        "        (A0, B1, \"DIV\"),\n",
        "        (B0, C1, \"DIV\"),\n",
        "        (A1, C0, \"DIV\"),\n",
        "        (B1, C1, \"DIV\"),\n",
        "    ]\n",
        "\n",
        "    add_list, sub_list, op3_list, swap_flags = [], [], [], []\n",
        "    for (u,v,op3) in spec:\n",
        "        addv = add_pd(u,v)\n",
        "        subv = u - v\n",
        "        opv  = mul_pd(u,v) if op3==\"MUL\" else div_pd(u,v)\n",
        "\n",
        "        if canonicalize_addsub:\n",
        "            swap = tf.cast(subv[:,0] > addv[:,0], tf.int32)  # [Q]\n",
        "            addv2 = tf.where(swap[:,None] > 0, subv, addv)\n",
        "            subv2 = tf.where(swap[:,None] > 0, addv, subv)\n",
        "            addv, subv = addv2, subv2\n",
        "        else:\n",
        "            swap = tf.zeros([tf.shape(u)[0]], tf.int32)\n",
        "\n",
        "        add_list.append(addv); sub_list.append(subv); op3_list.append(opv); swap_flags.append(swap)\n",
        "\n",
        "    reg = [p0,p1,p2, p3,p4,p5]\n",
        "    for i in range(8):\n",
        "        reg.extend([add_list[i], sub_list[i], op3_list[i]])\n",
        "    reg = tf.stack(reg, axis=1)                  # [Q,30,2]\n",
        "    swap_flags = tf.stack(swap_flags, axis=1)    # [Q,8]\n",
        "    return reg, swap_flags\n",
        "\n",
        "# -----------------------------\n",
        "# Collapse / parity / bitmap (triplet loops + scatter update retained)\n",
        "# -----------------------------\n",
        "def detect_collapse_triplet_scatter(pairs: tf.Tensor,\n",
        "                                   tau_hi: float = TAU_HI,\n",
        "                                   tau_low: float = TAU_LOW,\n",
        "                                   r_for_ratio: float = R_FOR_RATIO) -> tf.Tensor:\n",
        "    real = pairs[..., 0]\n",
        "    unreal = pairs[..., 1]\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "\n",
        "    cond1 = tf.logical_and(real >= tau_hi, unreal <= tau_low)\n",
        "    ratio = tf.where(tf.abs(unreal) > EPS, real / unreal, tf.zeros_like(real))\n",
        "    cond2 = ratio > r_for_ratio\n",
        "    individual = tf.logical_or(cond1, cond2)\n",
        "\n",
        "    final_mask = tf.cast(individual, tf.int32)\n",
        "\n",
        "    for t in tf.range(10):\n",
        "        idx3 = TRIPLET_IDX[t]\n",
        "        trip_ind = tf.gather(individual, idx3, axis=1)\n",
        "        is_uniform = tf.reduce_all(tf.equal(trip_ind, trip_ind[:,0:1]), axis=1)\n",
        "        uniform_val = tf.cast(trip_ind[:,0], tf.int32)\n",
        "\n",
        "        updates = tf.where(\n",
        "            tf.expand_dims(is_uniform, axis=1),\n",
        "            tf.tile(tf.expand_dims(uniform_val, axis=1), [1,3]),\n",
        "            tf.cast(trip_ind, tf.int32)\n",
        "        )\n",
        "\n",
        "        q_idx = tf.repeat(tf.range(Qn), repeats=3)\n",
        "        p_idx = tf.tile(idx3, multiples=[Qn])\n",
        "        scatter_idx = tf.stack([q_idx, p_idx], axis=1)\n",
        "        final_mask = tf.tensor_scatter_nd_update(final_mask, scatter_idx, tf.reshape(updates, [-1]))\n",
        "\n",
        "    return final_mask\n",
        "\n",
        "def apply_parity_rotation(pairs: tf.Tensor, collapse_mask: tf.Tensor):\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "    prime = tf.broadcast_to(PRIME_MASK_30[tf.newaxis,:], [Qn,30])\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32)\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, tf.float32), tf.constant(1.0, tf.float32))\n",
        "    return pairs * sign[...,None], affected\n",
        "\n",
        "def bitmap(rotated_pairs: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.cast(rotated_pairs[...,0] > EPS, tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# One view: prim6 -> bits30 + swap flags + collapse/parity\n",
        "# -----------------------------\n",
        "def compute_bits_for_view(prim6: tf.Tensor, canonicalize_addsub: bool = True):\n",
        "    reg30, swap_flags = build_register30(prim6, canonicalize_addsub=canonicalize_addsub)\n",
        "    collapse = detect_collapse_triplet_scatter(reg30)\n",
        "    rotated, parity = apply_parity_rotation(reg30, collapse)\n",
        "    bits = bitmap(rotated)\n",
        "    return bits, swap_flags, collapse, parity\n",
        "\n",
        "# -----------------------------\n",
        "# Commitment and tag\n",
        "# -----------------------------\n",
        "def commit_full90(packed_u32_xyz: np.ndarray,\n",
        "                  initiator_axis: np.ndarray,\n",
        "                  swapcount_xyz: np.ndarray,\n",
        "                  instr_counter: int,\n",
        "                  domain_sep: bytes = b\"NTHISA90\") -> List[bytes]:\n",
        "    commits = []\n",
        "    for q in range(packed_u32_xyz.shape[0]):\n",
        "        msg = (\n",
        "            domain_sep +\n",
        "            int(instr_counter).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,0]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,1]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,2]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(initiator_axis[q]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,0]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,1]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,2]).to_bytes(1,\"little\",signed=False)\n",
        "        )\n",
        "        commits.append(hashlib.blake2s(msg, digest_size=32).digest())\n",
        "    return commits\n",
        "\n",
        "def tag_u64_from_commit(commit32: bytes, q_idx: int, instr_counter: int) -> np.uint64:\n",
        "    msg = b\"NTH_TAG0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    h = hashlib.blake2s(msg, digest_size=8).digest()\n",
        "    return np.uint64(int.from_bytes(h, \"little\", signed=False))\n",
        "\n",
        "# -----------------------------\n",
        "# Dedup/Alias (batch-level)\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class DedupResult:\n",
        "    winner_of: np.ndarray       # [Q] int32: winner index for each qubit\n",
        "    active_mask: np.ndarray     # [Q] bool: True for winners\n",
        "    groups: Dict[bytes, List[int]]\n",
        "    freed: List[int]            # indices of qubits freed (aliases) when MODE=\"FREE\"\n",
        "    collision_qubits: int\n",
        "\n",
        "def dedup_by_commit(commits: List[bytes],\n",
        "                    efficiency_score: np.ndarray) -> DedupResult:\n",
        "    # Group by commit bytes\n",
        "    groups: Dict[bytes, List[int]] = {}\n",
        "    for q,c in enumerate(commits):\n",
        "        groups.setdefault(c, []).append(q)\n",
        "\n",
        "    winner_of = np.arange(len(commits), dtype=np.int32)\n",
        "    active_mask = np.ones(len(commits), dtype=bool)\n",
        "    freed = []\n",
        "    collision_qubits = 0\n",
        "\n",
        "    for c, qs in groups.items():\n",
        "        if len(qs) > 1:\n",
        "            collision_qubits += (len(qs) - 1)\n",
        "\n",
        "        # Pick winner: minimal efficiency_score, then minimal q_idx\n",
        "        qs_sorted = sorted(qs, key=lambda q: (int(efficiency_score[q]), q))\n",
        "        w = qs_sorted[0]\n",
        "        for q in qs:\n",
        "            winner_of[q] = w\n",
        "            if q != w:\n",
        "                active_mask[q] = False\n",
        "                if MODE == \"FREE\":\n",
        "                    freed.append(q)\n",
        "\n",
        "    return DedupResult(winner_of=winner_of, active_mask=active_mask, groups=groups,\n",
        "                      freed=freed, collision_qubits=collision_qubits)\n",
        "\n",
        "# -----------------------------\n",
        "# Deterministic reassignment of freed qubits to new NEC work states (MODE=\"FREE\")\n",
        "# -----------------------------\n",
        "def derive_new_nec_for_freed(commit32: bytes, q_idx: int, instr_counter: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Deterministically produce new magnitudes/signs for a freed qubit.\n",
        "    Output:\n",
        "      mag_xyz: [3] int32 in [0,63]\n",
        "      sign_xyz: [3] int32 in {-1,+1}\n",
        "    \"\"\"\n",
        "    msg = b\"NTH_FREE0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    raw = hashlib.blake2s(msg, digest_size=16).digest()  # 16 bytes\n",
        "    # 3 mags from bytes 0..2, 3 signs from byte 3 bits, etc.\n",
        "    mags = np.array([raw[0] % 64, raw[1] % 64, raw[2] % 64], dtype=np.int32)\n",
        "    sb = raw[3]\n",
        "    signs = np.array([1 if (sb & 1) else -1, 1 if (sb & 2) else -1, 1 if (sb & 4) else -1], dtype=np.int32)\n",
        "    return mags, signs\n",
        "\n",
        "# -----------------------------\n",
        "# ISA step execution\n",
        "# - Can execute on all qubits, or only on a subset of active indices (for dedup demonstration)\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class StepOut:\n",
        "    instr_counter: int\n",
        "    mag_xyz: np.ndarray                 # [Q,3] int32\n",
        "    base_sign: np.ndarray               # [Q,3] int32\n",
        "    initiator: np.ndarray               # [Q] int32\n",
        "    bits_views: np.ndarray              # [Q,3,30] int32\n",
        "    packed_views_u32: np.ndarray        # [Q,3] uint32\n",
        "    packed90_u64: np.ndarray            # [Q,2] uint64\n",
        "    swapcount_xyz: np.ndarray           # [Q,3] uint8\n",
        "    commits: List[bytes]                # len Q\n",
        "    tags_u64: np.ndarray                # [Q] uint64\n",
        "    masks_views: np.ndarray             # [3,30] uint64 (lane masks)\n",
        "    masks_selected: np.ndarray          # [30] uint64 (selected initiator)\n",
        "    dedup: DedupResult\n",
        "\n",
        "def execute_step(mag_xyz: np.ndarray,\n",
        "                 base_sign: np.ndarray,\n",
        "                 prev_tags: np.ndarray,\n",
        "                 instr_counter: int,\n",
        "                 active_indices: np.ndarray = None) -> StepOut:\n",
        "    \"\"\"\n",
        "    If active_indices is provided, compute heavy pipeline only for those qubits.\n",
        "    Others will be filled later (either by alias copy or by reassignment in the caller).\n",
        "    For v0.4 demonstration, we still compute views for all at step 1 (no active_indices),\n",
        "    and at step 2 we compute only active winners and then fill alias qubits.\n",
        "    \"\"\"\n",
        "    Qn = mag_xyz.shape[0]\n",
        "    assert Qn == Q\n",
        "\n",
        "    # Convert to TF tensors\n",
        "    mag_tf = tf.constant(mag_xyz, dtype=tf.int32)\n",
        "    sign_tf = tf.constant(base_sign, dtype=tf.int32)\n",
        "\n",
        "    # If active subset requested, gather active state\n",
        "    if active_indices is not None:\n",
        "        ai_tf = tf.constant(active_indices, dtype=tf.int32)\n",
        "        mag_tf_a = tf.gather(mag_tf, ai_tf, axis=0)\n",
        "        sign_tf_a = tf.gather(sign_tf, ai_tf, axis=0)\n",
        "        # Build primaries for active\n",
        "        prim0_a = build_primaries_from_nec(mag_tf_a, sign_tf_a)\n",
        "        initiator_a = initiator_from_shared_counts(mag_tf_a)  # NOTE: initiator computed on active subset only\n",
        "        # Views\n",
        "        Qa = int(active_indices.shape[0])\n",
        "        prim_x = permute_primaries_by_initiator(prim0_a, tf.zeros([Qa], tf.int32))\n",
        "        prim_y = permute_primaries_by_initiator(prim0_a, tf.ones([Qa], tf.int32))\n",
        "        prim_z = permute_primaries_by_initiator(prim0_a, tf.fill([Qa], tf.constant(2, tf.int32)))\n",
        "        prim_sel = permute_primaries_by_initiator(prim0_a, initiator_a)\n",
        "\n",
        "        bits_x, swaps_x, _, _ = compute_bits_for_view(prim_x, True)\n",
        "        bits_y, swaps_y, _, _ = compute_bits_for_view(prim_y, True)\n",
        "        bits_z, swaps_z, _, _ = compute_bits_for_view(prim_z, True)\n",
        "        bits_sel, _, _, _ = compute_bits_for_view(prim_sel, True)\n",
        "\n",
        "        packed_x = pack30_to_u32_tf(bits_x)\n",
        "        packed_y = pack30_to_u32_tf(bits_y)\n",
        "        packed_z = pack30_to_u32_tf(bits_z)\n",
        "        packed_xyz = tf.stack([packed_x, packed_y, packed_z], axis=1).numpy().astype(np.uint32)\n",
        "\n",
        "        swapcount_x = tf.reduce_sum(swaps_x, axis=1).numpy().astype(np.uint8)\n",
        "        swapcount_y = tf.reduce_sum(swaps_y, axis=1).numpy().astype(np.uint8)\n",
        "        swapcount_z = tf.reduce_sum(swaps_z, axis=1).numpy().astype(np.uint8)\n",
        "        swapcount_xyz = np.stack([swapcount_x, swapcount_y, swapcount_z], axis=1).astype(np.uint8)\n",
        "\n",
        "        bits_views = np.stack([bits_x.numpy().astype(np.int32),\n",
        "                               bits_y.numpy().astype(np.int32),\n",
        "                               bits_z.numpy().astype(np.int32)], axis=1)\n",
        "\n",
        "        masks_views = np.stack([bitslice_30_tf(bits_x).numpy(),\n",
        "                                bitslice_30_tf(bits_y).numpy(),\n",
        "                                bitslice_30_tf(bits_z).numpy()], axis=0).astype(np.uint64)\n",
        "        masks_sel = bitslice_30_tf(bits_sel).numpy().astype(np.uint64)\n",
        "\n",
        "        # Commitments for active subset only (caller will expand)\n",
        "        commits = commit_full90(packed_xyz, initiator_a.numpy().astype(np.uint8), swapcount_xyz, instr_counter)\n",
        "        tags = np.array([tag_u64_from_commit(commits[i], int(active_indices[i]), instr_counter) for i in range(len(active_indices))], dtype=np.uint64)\n",
        "\n",
        "        # Return a partial StepOut-like structure for active subset; caller will merge\n",
        "        # Use placeholder arrays for full Q in caller\n",
        "        return StepOut(\n",
        "            instr_counter=instr_counter,\n",
        "            mag_xyz=mag_xyz,\n",
        "            base_sign=base_sign,\n",
        "            initiator=np.full((Q,), -1, dtype=np.int32),\n",
        "            bits_views=np.zeros((Q,3,30), dtype=np.int32),\n",
        "            packed_views_u32=np.zeros((Q,3), dtype=np.uint32),\n",
        "            packed90_u64=np.zeros((Q,2), dtype=np.uint64),\n",
        "            swapcount_xyz=np.zeros((Q,3), dtype=np.uint8),\n",
        "            commits=[b\"\"]*Q,\n",
        "            tags_u64=np.zeros((Q,), dtype=np.uint64),\n",
        "            masks_views=np.zeros((3,30), dtype=np.uint64),\n",
        "            masks_selected=np.zeros((30,), dtype=np.uint64),\n",
        "            dedup=DedupResult(np.arange(Q,dtype=np.int32), np.ones(Q,dtype=bool), {}, [], 0)\n",
        "        ), (active_indices, packed_xyz, swapcount_xyz, bits_views, masks_views, masks_sel, commits, tags, initiator_a.numpy().astype(np.int32))\n",
        "\n",
        "    # Full execution path (no active subset)\n",
        "    prim0 = build_primaries_from_nec(mag_tf, sign_tf)\n",
        "    initiator = initiator_from_shared_counts(mag_tf)\n",
        "\n",
        "    prim_x = permute_primaries_by_initiator(prim0, tf.zeros([Q], tf.int32))\n",
        "    prim_y = permute_primaries_by_initiator(prim0, tf.ones([Q], tf.int32))\n",
        "    prim_z = permute_primaries_by_initiator(prim0, tf.fill([Q], tf.constant(2, tf.int32)))\n",
        "    prim_sel = permute_primaries_by_initiator(prim0, initiator)\n",
        "\n",
        "    bits_x, swaps_x, _, _ = compute_bits_for_view(prim_x, True)\n",
        "    bits_y, swaps_y, _, _ = compute_bits_for_view(prim_y, True)\n",
        "    bits_z, swaps_z, _, _ = compute_bits_for_view(prim_z, True)\n",
        "    bits_sel, _, _, _ = compute_bits_for_view(prim_sel, True)\n",
        "\n",
        "    packed_x = pack30_to_u32_tf(bits_x)\n",
        "    packed_y = pack30_to_u32_tf(bits_y)\n",
        "    packed_z = pack30_to_u32_tf(bits_z)\n",
        "    packed_views_u32 = tf.stack([packed_x, packed_y, packed_z], axis=1).numpy().astype(np.uint32)\n",
        "\n",
        "    packed90_u64 = pack90_from_3x30_u32(packed_views_u32)\n",
        "\n",
        "    swapcount_x = tf.reduce_sum(swaps_x, axis=1).numpy().astype(np.uint8)\n",
        "    swapcount_y = tf.reduce_sum(swaps_y, axis=1).numpy().astype(np.uint8)\n",
        "    swapcount_z = tf.reduce_sum(swaps_z, axis=1).numpy().astype(np.uint8)\n",
        "    swapcount_xyz = np.stack([swapcount_x, swapcount_y, swapcount_z], axis=1).astype(np.uint8)\n",
        "\n",
        "    commits = commit_full90(packed_views_u32, initiator.numpy().astype(np.uint8), swapcount_xyz, instr_counter)\n",
        "    tags_u64 = np.array([tag_u64_from_commit(commits[q], q, instr_counter) for q in range(Q)], dtype=np.uint64)\n",
        "\n",
        "    bits_views = np.stack([bits_x.numpy().astype(np.int32),\n",
        "                           bits_y.numpy().astype(np.int32),\n",
        "                           bits_z.numpy().astype(np.int32)], axis=1)\n",
        "\n",
        "    masks_views = np.stack([bitslice_30_tf(bits_x).numpy(),\n",
        "                            bitslice_30_tf(bits_y).numpy(),\n",
        "                            bitslice_30_tf(bits_z).numpy()], axis=0).astype(np.uint64)\n",
        "    masks_selected = bitslice_30_tf(bits_sel).numpy().astype(np.uint64)\n",
        "\n",
        "    # Efficiency score for winner selection (prototype): fewer add/sub swaps = \"cheaper\"\n",
        "    efficiency_score = swapcount_xyz.sum(axis=1).astype(np.int32)\n",
        "    dedup = dedup_by_commit(commits, efficiency_score)\n",
        "\n",
        "    return StepOut(\n",
        "        instr_counter=instr_counter,\n",
        "        mag_xyz=mag_xyz,\n",
        "        base_sign=base_sign,\n",
        "        initiator=initiator.numpy().astype(np.int32),\n",
        "        bits_views=bits_views,\n",
        "        packed_views_u32=packed_views_u32,\n",
        "        packed90_u64=packed90_u64,\n",
        "        swapcount_xyz=swapcount_xyz,\n",
        "        commits=commits,\n",
        "        tags_u64=tags_u64,\n",
        "        masks_views=masks_views,\n",
        "        masks_selected=masks_selected,\n",
        "        dedup=dedup\n",
        "    )\n",
        "\n",
        "# -----------------------------\n",
        "# Run v0.4 demonstration: Step 0 full compute -> dedup -> produce next state -> Step 1 active-only compute\n",
        "# -----------------------------\n",
        "tf.random.set_seed(11)\n",
        "np.random.seed(11)\n",
        "\n",
        "# Initial NEC state (encourage shared magnitudes)\n",
        "mag_xyz0 = np.random.randint(0, 64, size=(Q,3), dtype=np.int32)\n",
        "sign_bits = np.random.randint(0, 2, size=(Q,3), dtype=np.int32)\n",
        "base_sign0 = np.where(sign_bits>0, 1, -1).astype(np.int32)\n",
        "\n",
        "tags0 = np.zeros((Q,), dtype=np.uint64)\n",
        "\n",
        "print(\"=== UniversalISA v0.4 ===\")\n",
        "print(\"MODE:\", MODE)\n",
        "\n",
        "# Step 0: full compute\n",
        "step0 = execute_step(mag_xyz0, base_sign0, tags0, instr_counter=0)\n",
        "print(\"\\n--- STEP 0 ---\")\n",
        "print(\"bits_views:\", step0.bits_views.shape, \"packed_views_u32:\", step0.packed_views_u32.shape, \"packed90_u64:\", step0.packed90_u64.shape)\n",
        "print(\"initiator axis counts:\", np.bincount(step0.initiator, minlength=3))\n",
        "print(\"collision_qubits:\", step0.dedup.collision_qubits, \"num_groups:\", len(step0.dedup.groups), \"freed:\", len(step0.dedup.freed))\n",
        "\n",
        "# Build next-state (Step 1 state) using dedup policy\n",
        "mag_xyz1 = step0.mag_xyz.copy()\n",
        "base_sign1 = step0.base_sign.copy()\n",
        "tags1 = step0.tags_u64.copy()\n",
        "\n",
        "winner_of = step0.dedup.winner_of\n",
        "active_mask = step0.dedup.active_mask\n",
        "active_indices = np.where(active_mask)[0].astype(np.int32)\n",
        "alias_indices = np.where(~active_mask)[0].astype(np.int32)\n",
        "\n",
        "if MODE == \"PAIR_HUNT\":\n",
        "    # aliases inherit winner NEC directly (stay in shared state)\n",
        "    for q in alias_indices:\n",
        "        w = winner_of[q]\n",
        "        mag_xyz1[q] = mag_xyz1[w]\n",
        "        base_sign1[q] = base_sign1[w]\n",
        "else:\n",
        "    # MODE == \"FREE\": aliases get deterministic new NEC states derived from commitment\n",
        "    for q in alias_indices:\n",
        "        mags, signs = derive_new_nec_for_freed(step0.commits[q], q, instr_counter=1)\n",
        "        mag_xyz1[q] = mags\n",
        "        base_sign1[q] = signs\n",
        "        # tag also changes when they take new work:\n",
        "        tags1[q] = tag_u64_from_commit(step0.commits[q], q, instr_counter=1)\n",
        "\n",
        "print(\"active indices:\", len(active_indices), \"alias indices:\", len(alias_indices))\n",
        "\n",
        "# Step 1: compute only for ACTIVE (winners), then fill aliases\n",
        "partial_shell, partial = execute_step(mag_xyz1, base_sign1, tags1, instr_counter=1, active_indices=active_indices)\n",
        "(ai, packed_xyz_a, swapcount_xyz_a, bits_views_a, masks_views_a, masks_sel_a, commits_a, tags_a, initiator_a) = partial\n",
        "\n",
        "# Build full Step1 outputs by scattering active results, then filling aliases\n",
        "packed_views_u32_1 = np.zeros((Q,3), dtype=np.uint32)\n",
        "swapcount_xyz_1 = np.zeros((Q,3), dtype=np.uint8)\n",
        "bits_views_1 = np.zeros((Q,3,30), dtype=np.int32)\n",
        "commits1 = [b\"\"]*Q\n",
        "tags_u64_1 = np.zeros((Q,), dtype=np.uint64)\n",
        "initiator1 = np.full((Q,), -1, dtype=np.int32)\n",
        "\n",
        "for i,q in enumerate(ai):\n",
        "    packed_views_u32_1[q] = packed_xyz_a[i]\n",
        "    swapcount_xyz_1[q] = swapcount_xyz_a[i]\n",
        "    bits_views_1[q] = bits_views_a[i]\n",
        "    commits1[q] = commits_a[i]\n",
        "    tags_u64_1[q] = tags_a[i]\n",
        "    initiator1[q] = initiator_a[i]\n",
        "\n",
        "# Fill alias qubits depending on mode:\n",
        "if MODE == \"PAIR_HUNT\":\n",
        "    # Copy winner's computed payload/commit/tag for aliases\n",
        "    for q in alias_indices:\n",
        "        w = winner_of[q]\n",
        "        packed_views_u32_1[q] = packed_views_u32_1[w]\n",
        "        swapcount_xyz_1[q] = swapcount_xyz_1[w]\n",
        "        bits_views_1[q] = bits_views_1[w]\n",
        "        commits1[q] = commits1[w]\n",
        "        # keep unique per-qubit tag even in pair-hunt (addressable):\n",
        "        tags_u64_1[q] = tag_u64_from_commit(commits1[w], int(q), 1)\n",
        "        initiator1[q] = initiator1[w]\n",
        "else:\n",
        "    # MODE FREE: aliases computed nothing here (freed); for demo we still need a payload object.\n",
        "    # We set their payload to zeros and mark commitment as empty.\n",
        "    for q in alias_indices:\n",
        "        packed_views_u32_1[q] = np.array([0,0,0], dtype=np.uint32)\n",
        "        swapcount_xyz_1[q] = np.array([0,0,0], dtype=np.uint8)\n",
        "        bits_views_1[q] = np.zeros((3,30), dtype=np.int32)\n",
        "        commits1[q] = b\"\"\n",
        "        # tag already set by deterministic reassignment above\n",
        "        initiator1[q] = -1\n",
        "\n",
        "packed90_u64_1 = pack90_from_3x30_u32(packed_views_u32_1)\n",
        "\n",
        "# Dedup for step1 (only meaningful for active qubits; if MODE FREE, freed are intentionally different jobs)\n",
        "# We compute dedup on non-empty commitments only:\n",
        "efficiency_score_1 = swapcount_xyz_1.sum(axis=1).astype(np.int32)\n",
        "valid = np.array([len(c)==32 for c in commits1], dtype=bool)\n",
        "commits1_valid = [commits1[q] if valid[q] else (b\"\\x00\"*32 + q.to_bytes(2,\"little\")) for q in range(Q)]\n",
        "dedup1 = dedup_by_commit(commits1_valid, efficiency_score_1)\n",
        "\n",
        "print(\"\\n--- STEP 1 (active-only compute) ---\")\n",
        "print(\"computed winners:\", len(active_indices), \"aliases:\", len(alias_indices), \"MODE:\", MODE)\n",
        "print(\"step1 collision_qubits:\", dedup1.collision_qubits, \"num_groups:\", len(dedup1.groups))\n",
        "print(\"packed90_u64[0]:\", packed90_u64_1[0].tolist(), \"tag[0]:\", int(tags_u64_1[0]))\n",
        "\n",
        "# Show a few qubits\n",
        "print(\"\\nSample qubits (q, mag, sign, winner, active, packedXYZ_step0, packedXYZ_step1):\")\n",
        "for q in range(8):\n",
        "    print(q,\n",
        "          mag_xyz0[q].tolist(),\n",
        "          base_sign0[q].tolist(),\n",
        "          int(winner_of[q]),\n",
        "          bool(active_mask[q]),\n",
        "          step0.packed_views_u32[q].tolist(),\n",
        "          packed_views_u32_1[q].tolist())\n",
        "\n",
        "# Summarize reclaimed compute\n",
        "print(\"\\n=== Reclaimed compute estimate ===\")\n",
        "print(\"Step0 executed on:\", Q, \"qubits\")\n",
        "print(\"Step1 executed on:\", len(active_indices), \"qubits (winners only)\")\n",
        "print(\"Saved executions:\", Q - len(active_indices))\n",
        "print(\"If MODE=FREE, those saved qubits are available for new work in the next scheduling epoch.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2LUV4tnk8WG",
        "outputId": "d4156b1e-0ccd-4ed1-bbd2-26da4abf20ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== UniversalISA v0.4 ===\n",
            "MODE: FREE\n",
            "\n",
            "--- STEP 0 ---\n",
            "bits_views: (64, 3, 30) packed_views_u32: (64, 3) packed90_u64: (64, 2)\n",
            "initiator axis counts: [32 17 15]\n",
            "collision_qubits: 11 num_groups: 53 freed: 11\n",
            "active indices: 53 alias indices: 11\n",
            "\n",
            "--- STEP 1 (active-only compute) ---\n",
            "computed winners: 53 aliases: 11 MODE: FREE\n",
            "step1 collision_qubits: 3 num_groups: 61\n",
            "packed90_u64[0]: [5190005092015155620, 4825608] tag[0]: 6328507439259414915\n",
            "\n",
            "Sample qubits (q, mag, sign, winner, active, packedXYZ_step0, packedXYZ_step1):\n",
            "0 [25, 63, 16] [-1, -1, 1] 0 True [604514724, 538601608, 77209732] [604514724, 538601608, 77209732]\n",
            "1 [27, 17, 55] [1, -1, -1] 1 True [76685316, 604514724, 538601608] [76685316, 604514724, 538601608]\n",
            "2 [13, 12, 33] [1, 1, -1] 2 True [603990280, 538601636, 77209768] [603990280, 538601636, 77209768]\n",
            "3 [7, 18, 24] [-1, 1, 1] 3 True [77209768, 604506504, 538069028] [77209768, 604506504, 538069028]\n",
            "4 [45, 28, 48] [-1, -1, 1] 4 True [604514724, 538601608, 76677124] [604514724, 538601608, 76677124]\n",
            "5 [61, 32, 45] [1, 1, -1] 5 True [603982088, 538601636, 77209768] [603982088, 538601636, 77209768]\n",
            "6 [44, 61, 4] [1, 1, 1] 6 True [8929704, 8405288, 8937896] [8929704, 8405288, 8937896]\n",
            "7 [34, 12, 1] [-1, -1, 1] 7 True [604514724, 538601608, 77209732] [604514724, 538601608, 77209732]\n",
            "\n",
            "=== Reclaimed compute estimate ===\n",
            "Step0 executed on: 64 qubits\n",
            "Step1 executed on: 53 qubits (winners only)\n",
            "Saved executions: 11\n",
            "If MODE=FREE, those saved qubits are available for new work in the next scheduling epoch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UniversalISA v0.5 (Colab single-cell)\n",
        "# - Defines a minimal IR/opcode format for one ISA cycle.\n",
        "# - Implements a small interpreter that executes an instruction stream.\n",
        "# - Preserves triplet loops + scatter updates.\n",
        "# - Supports DEDUP + FREE/ALIAS and an \"EXEC_ACTIVE_ONLY\" optimization that skips redundant qubits.\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "# -----------------------------\n",
        "# Global constants / fixed geometry\n",
        "# -----------------------------\n",
        "Q = 64\n",
        "TAU_HI      = 1.0\n",
        "TAU_LOW     = -1.0\n",
        "EPS         = 1e-6\n",
        "R_FOR_RATIO = 64.0\n",
        "\n",
        "PRIME_MASK_30 = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# 10 triplets over 30 slots: [0..2],[3..5],...,[27..29]\n",
        "TRIPLET_IDX = tf.constant([[3*t,3*t+1,3*t+2] for t in range(10)], dtype=tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# IR / Opcode model\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Instr:\n",
        "    op: str\n",
        "    args: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities: pack/bitslice\n",
        "# -----------------------------\n",
        "def pack30_to_u32_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    bits_u32 = tf.cast(bits30_i32, tf.uint32)               # [Q,30]\n",
        "    shifts = tf.cast(tf.range(30), tf.uint32)               # [30]\n",
        "    return tf.reduce_sum(tf.bitwise.left_shift(bits_u32, shifts), axis=1)  # [Q] u32\n",
        "\n",
        "def bitslice_30_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    # [Q,30] -> [30] uint64 lane masks (Q<=64)\n",
        "    weights = tf.bitwise.left_shift(tf.constant(1, tf.uint64), tf.cast(tf.range(tf.shape(bits30_i32)[0]), tf.uint64))\n",
        "    bits_u64 = tf.cast(bits30_i32, tf.uint64)\n",
        "    return tf.reduce_sum(tf.transpose(bits_u64, [1,0]) * tf.expand_dims(weights, axis=0), axis=1)\n",
        "\n",
        "def pack90_from_3x30_u32(packed3_u32: np.ndarray) -> np.ndarray:\n",
        "    # packed3_u32: [Q,3] uint32 -> [Q,2] uint64 (90 bits packed)\n",
        "    out = np.zeros((packed3_u32.shape[0],2), dtype=np.uint64)\n",
        "    for q in range(packed3_u32.shape[0]):\n",
        "        b0 = np.uint64(packed3_u32[q,0] & np.uint32((1<<30)-1))\n",
        "        b1 = np.uint64(packed3_u32[q,1] & np.uint32((1<<30)-1))\n",
        "        b2 = np.uint64(packed3_u32[q,2] & np.uint32((1<<30)-1))\n",
        "        low = b0 | (b1 << np.uint64(30)) | ((b2 & np.uint64(0xF)) << np.uint64(60))\n",
        "        high = (b2 >> np.uint64(4))\n",
        "        out[q,0] = low\n",
        "        out[q,1] = high\n",
        "    return out\n",
        "\n",
        "# -----------------------------\n",
        "# Phase-dual core ops\n",
        "# -----------------------------\n",
        "def add_pd(a,b): return a+b\n",
        "def mul_pd(a,b): return a*b\n",
        "def div_pd(a,b): return tf.where(tf.abs(b) > EPS, a/b, tf.zeros_like(a))\n",
        "\n",
        "# -----------------------------\n",
        "# NEC selectors (true phase-dual) + initiator logic\n",
        "# -----------------------------\n",
        "def sel_real(m: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.stack([m, -m], axis=1)  # [+m,-m]\n",
        "\n",
        "def sel_unreal(m: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.stack([-m, m], axis=1)  # [-m,+m]\n",
        "\n",
        "def build_primaries_from_nec(mag_xyz_i32: tf.Tensor, base_sign_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    mag = tf.cast(mag_xyz_i32, tf.float32)\n",
        "    mX, mY, mZ = mag[:,0], mag[:,1], mag[:,2]\n",
        "    Xr, Xu = sel_real(mX), sel_unreal(mX)\n",
        "    Yr, Yu = sel_real(mY), sel_unreal(mY)\n",
        "    Zr, Zu = sel_real(mZ), sel_unreal(mZ)\n",
        "\n",
        "    sign_is_unreal = base_sign_xyz_i32 < 0  # [Q,3]\n",
        "    X0 = tf.where(sign_is_unreal[:,0:1], Xu, Xr)\n",
        "    X1 = tf.where(sign_is_unreal[:,0:1], Xr, Xu)\n",
        "    Y0 = tf.where(sign_is_unreal[:,1:2], Yu, Yr)\n",
        "    Y1 = tf.where(sign_is_unreal[:,1:2], Yr, Yu)\n",
        "    Z0 = tf.where(sign_is_unreal[:,2:3], Zu, Zr)\n",
        "    Z1 = tf.where(sign_is_unreal[:,2:3], Zr, Zu)\n",
        "    return tf.stack([X0,X1,Y0,Y1,Z0,Z1], axis=1)  # [Q,6,2]\n",
        "\n",
        "def initiator_from_shared_counts(mag_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    mag = mag_xyz_i32\n",
        "    eqx = tf.equal(tf.expand_dims(mag[:,0], 1), tf.expand_dims(mag[:,0], 0))\n",
        "    eqy = tf.equal(tf.expand_dims(mag[:,1], 1), tf.expand_dims(mag[:,1], 0))\n",
        "    eqz = tf.equal(tf.expand_dims(mag[:,2], 1), tf.expand_dims(mag[:,2], 0))\n",
        "    cx = tf.reduce_sum(tf.cast(eqx, tf.int32), axis=1)\n",
        "    cy = tf.reduce_sum(tf.cast(eqy, tf.int32), axis=1)\n",
        "    cz = tf.reduce_sum(tf.cast(eqz, tf.int32), axis=1)\n",
        "\n",
        "    counts = tf.stack([cx,cy,cz], axis=1)  # [Q,3]\n",
        "    shared_mask = counts > 1\n",
        "    shared_count = tf.reduce_sum(tf.cast(shared_mask, tf.int32), axis=1)\n",
        "\n",
        "    init_one_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "    is_unshared = tf.equal(counts, 1)\n",
        "    init_two_shared = tf.argmax(tf.cast(is_unshared, tf.int32), axis=1, output_type=tf.int32)\n",
        "    init_three_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "\n",
        "    bias = tf.constant([2,1,0], tf.int32)\n",
        "    mags_biased = mag_xyz_i32 * 1000 + bias\n",
        "    init_none_shared = tf.argmax(mags_biased, axis=1, output_type=tf.int32)\n",
        "\n",
        "    initiator = tf.where(shared_count == 1, init_one_shared,\n",
        "                 tf.where(shared_count == 2, init_two_shared,\n",
        "                 tf.where(shared_count == 3, init_three_shared, init_none_shared)))\n",
        "    return initiator\n",
        "\n",
        "def permute_primaries_by_initiator(prim6: tf.Tensor, initiator_axis: tf.Tensor) -> tf.Tensor:\n",
        "    Qn = tf.shape(prim6)[0]\n",
        "    idx_x = tf.constant([0,1,2,3,4,5], tf.int32)\n",
        "    idx_y = tf.constant([2,3,4,5,0,1], tf.int32)\n",
        "    idx_z = tf.constant([4,5,0,1,2,3], tf.int32)\n",
        "\n",
        "    idx = tf.where(tf.expand_dims(initiator_axis==0,1), tf.broadcast_to(idx_x, [Qn,6]),\n",
        "          tf.where(tf.expand_dims(initiator_axis==1,1), tf.broadcast_to(idx_y, [Qn,6]),\n",
        "                                                          tf.broadcast_to(idx_z, [Qn,6])))\n",
        "    return tf.gather(prim6, idx, axis=1, batch_dims=1)\n",
        "\n",
        "# -----------------------------\n",
        "# REG30 build: 10 triplets, (+,-) reorderable; (*,/) fixed\n",
        "# -----------------------------\n",
        "def build_register30(prim6: tf.Tensor, canonicalize_addsub: bool = True) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    p0,p1,p2,p3,p4,p5 = tf.unstack(prim6, axis=1)\n",
        "    A0,A1 = p0,p1\n",
        "    B0,B1 = p2,p3\n",
        "    C0,C1 = p4,p5\n",
        "\n",
        "    spec = [\n",
        "        (A0, B0, \"MUL\"),\n",
        "        (B0, C0, \"MUL\"),\n",
        "        (A0, C0, \"MUL\"),\n",
        "        (A1, B1, \"MUL\"),\n",
        "        (A0, B1, \"DIV\"),\n",
        "        (B0, C1, \"DIV\"),\n",
        "        (A1, C0, \"DIV\"),\n",
        "        (B1, C1, \"DIV\"),\n",
        "    ]\n",
        "\n",
        "    add_list, sub_list, op3_list, swap_flags = [], [], [], []\n",
        "    for (u,v,op3) in spec:\n",
        "        addv = add_pd(u,v)\n",
        "        subv = u - v\n",
        "        opv  = mul_pd(u,v) if op3==\"MUL\" else div_pd(u,v)\n",
        "\n",
        "        if canonicalize_addsub:\n",
        "            swap = tf.cast(subv[:,0] > addv[:,0], tf.int32)  # [Q]\n",
        "            addv2 = tf.where(swap[:,None] > 0, subv, addv)\n",
        "            subv2 = tf.where(swap[:,None] > 0, addv, subv)\n",
        "            addv, subv = addv2, subv2\n",
        "        else:\n",
        "            swap = tf.zeros([tf.shape(u)[0]], tf.int32)\n",
        "\n",
        "        add_list.append(addv); sub_list.append(subv); op3_list.append(opv); swap_flags.append(swap)\n",
        "\n",
        "    reg = [p0,p1,p2, p3,p4,p5]\n",
        "    for i in range(8):\n",
        "        reg.extend([add_list[i], sub_list[i], op3_list[i]])\n",
        "    reg = tf.stack(reg, axis=1)               # [Q,30,2]\n",
        "    swap_flags = tf.stack(swap_flags, axis=1) # [Q,8]\n",
        "    return reg, swap_flags\n",
        "\n",
        "# -----------------------------\n",
        "# COLLAPSE (triplet loops + scatter updates preserved)\n",
        "# -----------------------------\n",
        "def detect_collapse_triplet_scatter(pairs: tf.Tensor,\n",
        "                                   tau_hi: float = TAU_HI,\n",
        "                                   tau_low: float = TAU_LOW,\n",
        "                                   r_for_ratio: float = R_FOR_RATIO) -> tf.Tensor:\n",
        "    real = pairs[..., 0]\n",
        "    unreal = pairs[..., 1]\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "\n",
        "    cond1 = tf.logical_and(real >= tau_hi, unreal <= tau_low)\n",
        "    ratio = tf.where(tf.abs(unreal) > EPS, real / unreal, tf.zeros_like(real))\n",
        "    cond2 = ratio > r_for_ratio\n",
        "    individual = tf.logical_or(cond1, cond2)\n",
        "\n",
        "    final_mask = tf.cast(individual, tf.int32)\n",
        "\n",
        "    for t in tf.range(10):\n",
        "        idx3 = TRIPLET_IDX[t]\n",
        "        trip_ind = tf.gather(individual, idx3, axis=1)\n",
        "        is_uniform = tf.reduce_all(tf.equal(trip_ind, trip_ind[:,0:1]), axis=1)\n",
        "        uniform_val = tf.cast(trip_ind[:,0], tf.int32)\n",
        "\n",
        "        updates = tf.where(\n",
        "            tf.expand_dims(is_uniform, axis=1),\n",
        "            tf.tile(tf.expand_dims(uniform_val, axis=1), [1,3]),\n",
        "            tf.cast(trip_ind, tf.int32)\n",
        "        )\n",
        "\n",
        "        q_idx = tf.repeat(tf.range(Qn), repeats=3)\n",
        "        p_idx = tf.tile(idx3, multiples=[Qn])\n",
        "        scatter_idx = tf.stack([q_idx, p_idx], axis=1)\n",
        "        final_mask = tf.tensor_scatter_nd_update(final_mask, scatter_idx, tf.reshape(updates, [-1]))\n",
        "\n",
        "    return final_mask\n",
        "\n",
        "# -----------------------------\n",
        "# PARITY + BITMAP\n",
        "# -----------------------------\n",
        "def apply_parity_rotation(pairs: tf.Tensor, collapse_mask: tf.Tensor):\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "    prime = tf.broadcast_to(PRIME_MASK_30[tf.newaxis,:], [Qn,30])\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32)\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, tf.float32), tf.constant(1.0, tf.float32))\n",
        "    return pairs * sign[...,None], affected\n",
        "\n",
        "def bitmap(rotated_pairs: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.cast(rotated_pairs[...,0] > EPS, tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# Commit/tag/dedup/free\n",
        "# -----------------------------\n",
        "def commit_full90(packed_u32_xyz: np.ndarray,\n",
        "                  initiator_axis: np.ndarray,\n",
        "                  swapcount_xyz: np.ndarray,\n",
        "                  instr_counter: int,\n",
        "                  domain_sep: bytes = b\"NTHISA90\") -> List[bytes]:\n",
        "    commits = []\n",
        "    for q in range(packed_u32_xyz.shape[0]):\n",
        "        msg = (\n",
        "            domain_sep +\n",
        "            int(instr_counter).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,0]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,1]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,2]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(initiator_axis[q]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,0]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,1]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,2]).to_bytes(1,\"little\",signed=False)\n",
        "        )\n",
        "        commits.append(hashlib.blake2s(msg, digest_size=32).digest())\n",
        "    return commits\n",
        "\n",
        "def tag_u64_from_commit(commit32: bytes, q_idx: int, instr_counter: int) -> np.uint64:\n",
        "    msg = b\"NTH_TAG0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    h = hashlib.blake2s(msg, digest_size=8).digest()\n",
        "    return np.uint64(int.from_bytes(h, \"little\", signed=False))\n",
        "\n",
        "@dataclass\n",
        "class DedupResult:\n",
        "    winner_of: np.ndarray\n",
        "    active_mask: np.ndarray\n",
        "    groups: Dict[bytes, List[int]]\n",
        "    freed: List[int]\n",
        "    collision_qubits: int\n",
        "\n",
        "def dedup_by_commit(commits: List[bytes], efficiency_score: np.ndarray, mode: str) -> DedupResult:\n",
        "    groups: Dict[bytes, List[int]] = {}\n",
        "    for q,c in enumerate(commits):\n",
        "        groups.setdefault(c, []).append(q)\n",
        "\n",
        "    winner_of = np.arange(len(commits), dtype=np.int32)\n",
        "    active_mask = np.ones(len(commits), dtype=bool)\n",
        "    freed: List[int] = []\n",
        "    collision_qubits = 0\n",
        "\n",
        "    for c, qs in groups.items():\n",
        "        if len(qs) > 1:\n",
        "            collision_qubits += (len(qs) - 1)\n",
        "\n",
        "        # winner = min efficiency_score, tie -> min q index\n",
        "        qs_sorted = sorted(qs, key=lambda q: (int(efficiency_score[q]), q))\n",
        "        w = qs_sorted[0]\n",
        "        for q in qs:\n",
        "            winner_of[q] = w\n",
        "            if q != w:\n",
        "                active_mask[q] = False\n",
        "                if mode == \"FREE\":\n",
        "                    freed.append(q)\n",
        "\n",
        "    return DedupResult(winner_of, active_mask, groups, freed, collision_qubits)\n",
        "\n",
        "def derive_new_nec_for_freed(commit32: bytes, q_idx: int, instr_counter: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    msg = b\"NTH_FREE0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    raw = hashlib.blake2s(msg, digest_size=16).digest()\n",
        "    mags = np.array([raw[0] % 64, raw[1] % 64, raw[2] % 64], dtype=np.int32)\n",
        "    sb = raw[3]\n",
        "    signs = np.array([1 if (sb & 1) else -1, 1 if (sb & 2) else -1, 1 if (sb & 4) else -1], dtype=np.int32)\n",
        "    return mags, signs\n",
        "\n",
        "# -----------------------------\n",
        "# Interpreter state\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class ISAState:\n",
        "    instr_counter: int = 0\n",
        "    mode: str = \"FREE\"                  # FREE or PAIR_HUNT\n",
        "    exec_active_only: bool = False      # if True, heavy ops run only on active winners\n",
        "\n",
        "    # NEC state\n",
        "    mag_xyz: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.int32))\n",
        "    base_sign: np.ndarray = field(default_factory=lambda: np.ones((Q,3), dtype=np.int32))\n",
        "\n",
        "    # Derived registers\n",
        "    initiator: np.ndarray = field(default_factory=lambda: np.zeros((Q,), dtype=np.int32))\n",
        "    packed_views_u32: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.uint32))\n",
        "    packed90_u64: np.ndarray = field(default_factory=lambda: np.zeros((Q,2), dtype=np.uint64))\n",
        "    bits_views: np.ndarray = field(default_factory=lambda: np.zeros((Q,3,30), dtype=np.int32))\n",
        "    swapcount_xyz: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.uint8))\n",
        "    commits: List[bytes] = field(default_factory=lambda: [b\"\"]*Q)\n",
        "    tags_u64: np.ndarray = field(default_factory=lambda: np.zeros((Q,), dtype=np.uint64))\n",
        "\n",
        "    # Dedup scheduling\n",
        "    dedup: Optional[DedupResult] = None\n",
        "    active_mask: np.ndarray = field(default_factory=lambda: np.ones((Q,), dtype=bool))\n",
        "    winner_of: np.ndarray = field(default_factory=lambda: np.arange(Q, dtype=np.int32))\n",
        "\n",
        "# -----------------------------\n",
        "# Interpreter core: ops\n",
        "# -----------------------------\n",
        "def op_NEC_LOAD(st: ISAState, seed: int = 11, mag_range: int = 64):\n",
        "    rng = np.random.default_rng(seed + st.instr_counter)\n",
        "    st.mag_xyz = rng.integers(0, mag_range, size=(Q,3), dtype=np.int32)\n",
        "    sign_bits = rng.integers(0, 2, size=(Q,3), dtype=np.int32)\n",
        "    st.base_sign = np.where(sign_bits > 0, 1, -1).astype(np.int32)\n",
        "\n",
        "def op_INIT_SELECT(st: ISAState):\n",
        "    mag_tf = tf.constant(st.mag_xyz, dtype=tf.int32)\n",
        "    st.initiator = initiator_from_shared_counts(mag_tf).numpy().astype(np.int32)\n",
        "\n",
        "def _compute_views_full(st: ISAState):\n",
        "    mag_tf  = tf.constant(st.mag_xyz, dtype=tf.int32)\n",
        "    sign_tf = tf.constant(st.base_sign, dtype=tf.int32)\n",
        "\n",
        "    prim0 = build_primaries_from_nec(mag_tf, sign_tf)  # [Q,6,2]\n",
        "    init_tf = tf.constant(st.initiator, dtype=tf.int32)\n",
        "\n",
        "    prim_x = permute_primaries_by_initiator(prim0, tf.zeros([Q], tf.int32))\n",
        "    prim_y = permute_primaries_by_initiator(prim0, tf.ones([Q], tf.int32))\n",
        "    prim_z = permute_primaries_by_initiator(prim0, tf.fill([Q], tf.constant(2, tf.int32)))\n",
        "\n",
        "    def eval_view(prim6):\n",
        "        reg30, swaps = build_register30(prim6, canonicalize_addsub=True)\n",
        "        collapse = detect_collapse_triplet_scatter(reg30)\n",
        "        rotated, _ = apply_parity_rotation(reg30, collapse)\n",
        "        bits = bitmap(rotated)\n",
        "        packed = pack30_to_u32_tf(bits)\n",
        "        swapcount = tf.reduce_sum(swaps, axis=1)\n",
        "        return bits, packed, swapcount\n",
        "\n",
        "    bits_x, packed_x, swap_x = eval_view(prim_x)\n",
        "    bits_y, packed_y, swap_y = eval_view(prim_y)\n",
        "    bits_z, packed_z, swap_z = eval_view(prim_z)\n",
        "\n",
        "    st.bits_views = np.stack([bits_x.numpy().astype(np.int32),\n",
        "                              bits_y.numpy().astype(np.int32),\n",
        "                              bits_z.numpy().astype(np.int32)], axis=1)\n",
        "    st.packed_views_u32 = tf.stack([packed_x, packed_y, packed_z], axis=1).numpy().astype(np.uint32)\n",
        "    st.swapcount_xyz = np.stack([swap_x.numpy().astype(np.uint8),\n",
        "                                 swap_y.numpy().astype(np.uint8),\n",
        "                                 swap_z.numpy().astype(np.uint8)], axis=1).astype(np.uint8)\n",
        "    st.packed90_u64 = pack90_from_3x30_u32(st.packed_views_u32)\n",
        "\n",
        "def _compute_views_active_only(st: ISAState):\n",
        "    # Compute heavy pipeline only for active winners, then fill aliases based on mode\n",
        "    active_idx = np.where(st.active_mask)[0].astype(np.int32)\n",
        "    alias_idx = np.where(~st.active_mask)[0].astype(np.int32)\n",
        "    Qa = int(active_idx.shape[0])\n",
        "\n",
        "    if Qa == 0:\n",
        "        # nothing active; clear outputs\n",
        "        st.bits_views[:] = 0\n",
        "        st.packed_views_u32[:] = 0\n",
        "        st.swapcount_xyz[:] = 0\n",
        "        st.packed90_u64[:] = 0\n",
        "        st.commits = [b\"\"]*Q\n",
        "        st.tags_u64[:] = 0\n",
        "        return\n",
        "\n",
        "    mag_a  = tf.constant(st.mag_xyz[active_idx], dtype=tf.int32)\n",
        "    sign_a = tf.constant(st.base_sign[active_idx], dtype=tf.int32)\n",
        "\n",
        "    prim0_a = build_primaries_from_nec(mag_a, sign_a)\n",
        "    # initiator for active subset only (optimization)\n",
        "    init_a = initiator_from_shared_counts(mag_a)\n",
        "\n",
        "    prim_x = permute_primaries_by_initiator(prim0_a, tf.zeros([Qa], tf.int32))\n",
        "    prim_y = permute_primaries_by_initiator(prim0_a, tf.ones([Qa], tf.int32))\n",
        "    prim_z = permute_primaries_by_initiator(prim0_a, tf.fill([Qa], tf.constant(2, tf.int32)))\n",
        "\n",
        "    def eval_view(prim6):\n",
        "        reg30, swaps = build_register30(prim6, canonicalize_addsub=True)\n",
        "        collapse = detect_collapse_triplet_scatter(reg30)\n",
        "        rotated, _ = apply_parity_rotation(reg30, collapse)\n",
        "        bits = bitmap(rotated)\n",
        "        packed = pack30_to_u32_tf(bits)\n",
        "        swapcount = tf.reduce_sum(swaps, axis=1)\n",
        "        return bits, packed, swapcount\n",
        "\n",
        "    bits_x, packed_x, swap_x = eval_view(prim_x)\n",
        "    bits_y, packed_y, swap_y = eval_view(prim_y)\n",
        "    bits_z, packed_z, swap_z = eval_view(prim_z)\n",
        "\n",
        "    bits_views_a = np.stack([bits_x.numpy().astype(np.int32),\n",
        "                             bits_y.numpy().astype(np.int32),\n",
        "                             bits_z.numpy().astype(np.int32)], axis=1)\n",
        "    packed_a = tf.stack([packed_x, packed_y, packed_z], axis=1).numpy().astype(np.uint32)\n",
        "    swapcount_a = np.stack([swap_x.numpy().astype(np.uint8),\n",
        "                            swap_y.numpy().astype(np.uint8),\n",
        "                            swap_z.numpy().astype(np.uint8)], axis=1).astype(np.uint8)\n",
        "\n",
        "    # Scatter active results into full arrays\n",
        "    st.bits_views[:] = 0\n",
        "    st.packed_views_u32[:] = 0\n",
        "    st.swapcount_xyz[:] = 0\n",
        "    for i,q in enumerate(active_idx):\n",
        "        st.bits_views[q] = bits_views_a[i]\n",
        "        st.packed_views_u32[q] = packed_a[i]\n",
        "        st.swapcount_xyz[q] = swapcount_a[i]\n",
        "\n",
        "    # Fill aliases\n",
        "    if st.mode == \"PAIR_HUNT\":\n",
        "        # aliases copy winner payload\n",
        "        for q in alias_idx:\n",
        "            w = st.winner_of[q]\n",
        "            st.bits_views[q] = st.bits_views[w]\n",
        "            st.packed_views_u32[q] = st.packed_views_u32[w]\n",
        "            st.swapcount_xyz[q] = st.swapcount_xyz[w]\n",
        "    else:\n",
        "        # FREE: freed qubits may be doing new work later; for now keep payload=0 (uncomputed this cycle)\n",
        "        pass\n",
        "\n",
        "    st.packed90_u64 = pack90_from_3x30_u32(st.packed_views_u32)\n",
        "\n",
        "def op_REG30_BUILD_BITMAP_PACK(st: ISAState):\n",
        "    # This op is a fused execution of: REG30_BUILD + COLLAPSE + PARITY + BITMAP + PACK\n",
        "    # It exists because a real backend would fuse these kernels, but the IR still names the primitives.\n",
        "    if st.exec_active_only and st.dedup is not None:\n",
        "        _compute_views_active_only(st)\n",
        "    else:\n",
        "        _compute_views_full(st)\n",
        "\n",
        "def op_COMMIT(st: ISAState):\n",
        "    st.commits = commit_full90(st.packed_views_u32,\n",
        "                              st.initiator.astype(np.uint8),\n",
        "                              st.swapcount_xyz.astype(np.uint8),\n",
        "                              st.instr_counter)\n",
        "    st.tags_u64 = np.array([tag_u64_from_commit(st.commits[q], q, st.instr_counter) for q in range(Q)], dtype=np.uint64)\n",
        "\n",
        "def op_DEDUP(st: ISAState):\n",
        "    # Efficiency score prototype: fewer swaps => cheaper\n",
        "    eff = st.swapcount_xyz.sum(axis=1).astype(np.int32)\n",
        "    st.dedup = dedup_by_commit(st.commits, eff, st.mode)\n",
        "    st.active_mask = st.dedup.active_mask.copy()\n",
        "    st.winner_of = st.dedup.winner_of.copy()\n",
        "\n",
        "def op_FREE_ALIAS(st: ISAState):\n",
        "    if st.dedup is None:\n",
        "        return\n",
        "    alias_idx = np.where(~st.active_mask)[0].astype(np.int32)\n",
        "\n",
        "    if st.mode == \"PAIR_HUNT\":\n",
        "        # aliases inherit winner NEC as well (remain paired)\n",
        "        for q in alias_idx:\n",
        "            w = st.winner_of[q]\n",
        "            st.mag_xyz[q] = st.mag_xyz[w]\n",
        "            st.base_sign[q] = st.base_sign[w]\n",
        "    else:\n",
        "        # FREE: reassign alias qubits to new NEC states deterministically from their own commit\n",
        "        for q in alias_idx:\n",
        "            mags, signs = derive_new_nec_for_freed(st.commits[q], q, st.instr_counter + 1)\n",
        "            st.mag_xyz[q] = mags\n",
        "            st.base_sign[q] = signs\n",
        "\n",
        "def op_EXEC_ACTIVE_ONLY(st: ISAState, enabled: bool = True):\n",
        "    st.exec_active_only = bool(enabled)\n",
        "\n",
        "def op_NEXT(st: ISAState):\n",
        "    st.instr_counter += 1\n",
        "\n",
        "# -----------------------------\n",
        "# Interpreter runner\n",
        "# -----------------------------\n",
        "OP_TABLE = {\n",
        "    \"NEC_LOAD\": op_NEC_LOAD,\n",
        "    \"INIT_SELECT\": op_INIT_SELECT,\n",
        "    \"REG30_BUILD\": op_REG30_BUILD_BITMAP_PACK,    # fused for now\n",
        "    \"COLLAPSE\": lambda st, **k: None,             # named primitive; fused in REG30_BUILD\n",
        "    \"PARITY\":   lambda st, **k: None,             # named primitive; fused in REG30_BUILD\n",
        "    \"BITMAP\":   lambda st, **k: None,             # named primitive; fused in REG30_BUILD\n",
        "    \"PACK\":     lambda st, **k: None,             # named primitive; fused in REG30_BUILD\n",
        "    \"COMMIT\": op_COMMIT,\n",
        "    \"DEDUP\": op_DEDUP,\n",
        "    \"FREE_ALIAS\": op_FREE_ALIAS,\n",
        "    \"EXEC_ACTIVE_ONLY\": op_EXEC_ACTIVE_ONLY,\n",
        "    \"NEXT\": op_NEXT,\n",
        "}\n",
        "\n",
        "def run_program(st: ISAState, program: List[Instr], verbose: bool = True):\n",
        "    for ins in program:\n",
        "        fn = OP_TABLE.get(ins.op)\n",
        "        if fn is None:\n",
        "            raise ValueError(f\"Unknown opcode: {ins.op}\")\n",
        "        fn(st, **ins.args)\n",
        "        if verbose and ins.op in (\"REG30_BUILD\",\"COMMIT\",\"DEDUP\",\"FREE_ALIAS\",\"NEXT\"):\n",
        "            if ins.op == \"REG30_BUILD\":\n",
        "                print(f\"[t={st.instr_counter}] REG30_BUILD done. packed90_u64[0]={st.packed90_u64[0].tolist()}\")\n",
        "            elif ins.op == \"COMMIT\":\n",
        "                print(f\"[t={st.instr_counter}] COMMIT done. commit0={st.commits[0].hex()[:16]}...\")\n",
        "            elif ins.op == \"DEDUP\":\n",
        "                print(f\"[t={st.instr_counter}] DEDUP done. collisions={st.dedup.collision_qubits} groups={len(st.dedup.groups)} active={int(st.active_mask.sum())}\")\n",
        "            elif ins.op == \"FREE_ALIAS\":\n",
        "                print(f\"[t={st.instr_counter}] FREE/ALIAS applied. mode={st.mode} aliases={Q-int(st.active_mask.sum())}\")\n",
        "            elif ins.op == \"NEXT\":\n",
        "                print(f\"--- NEXT instr_counter={st.instr_counter} ---\")\n",
        "\n",
        "# -----------------------------\n",
        "# Demo microprogram: two instruction cycles with DEDUP + FREE/ALIAS + EXEC_ACTIVE_ONLY\n",
        "# -----------------------------\n",
        "st = ISAState(mode=\"FREE\", instr_counter=0)\n",
        "np.random.seed(11)\n",
        "tf.random.set_seed(11)\n",
        "\n",
        "program = [\n",
        "    Instr(\"NEC_LOAD\", {\"seed\": 11}),\n",
        "    Instr(\"INIT_SELECT\"),\n",
        "    Instr(\"REG30_BUILD\"),\n",
        "    Instr(\"COMMIT\"),\n",
        "    Instr(\"DEDUP\"),\n",
        "    Instr(\"FREE_ALIAS\"),\n",
        "    Instr(\"EXEC_ACTIVE_ONLY\", {\"enabled\": True}),\n",
        "    Instr(\"NEXT\"),\n",
        "\n",
        "    # second cycle (will compute heavy ops only for active winners if exec_active_only=True)\n",
        "    Instr(\"INIT_SELECT\"),\n",
        "    Instr(\"REG30_BUILD\"),\n",
        "    Instr(\"COMMIT\"),\n",
        "    Instr(\"DEDUP\"),\n",
        "    Instr(\"FREE_ALIAS\"),\n",
        "    Instr(\"NEXT\"),\n",
        "]\n",
        "\n",
        "print(\"=== UniversalISA v0.5 Interpreter Demo ===\")\n",
        "print(\"MODE:\", st.mode, \"EXEC_ACTIVE_ONLY initially:\", st.exec_active_only)\n",
        "run_program(st, program, verbose=True)\n",
        "\n",
        "print(\"\\n=== Final State Snapshot ===\")\n",
        "print(\"instr_counter:\", st.instr_counter)\n",
        "print(\"initiator axis counts:\", np.bincount(st.initiator, minlength=3).tolist(), \"(0=x,1=y,2=z)\")\n",
        "print(\"packed_views_u32[0]:\", st.packed_views_u32[0].tolist())\n",
        "print(\"packed90_u64[0]:\", st.packed90_u64[0].tolist())\n",
        "print(\"active qubits:\", int(st.active_mask.sum()), \"aliases:\", Q-int(st.active_mask.sum()))\n",
        "print(\"tag[0]:\", int(st.tags_u64[0]))\n",
        "print(\"Sample qubits (q, mag, sign, winner, active):\")\n",
        "for q in range(8):\n",
        "    print(q, st.mag_xyz[q].tolist(), st.base_sign[q].tolist(), int(st.winner_of[q]), bool(st.active_mask[q]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekVEDBLPmiYP",
        "outputId": "9da0c256-ec33-4c6c-95b6-5726754c6d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== UniversalISA v0.5 Interpreter Demo ===\n",
            "MODE: FREE EXEC_ACTIVE_ONLY initially: False\n",
            "[t=0] REG30_BUILD done. packed90_u64[0]=[9232960233523929384, 525330]\n",
            "[t=0] COMMIT done. commit0=7ee6f4f8306e0b3f...\n",
            "[t=0] DEDUP done. collisions=15 groups=49 active=49\n",
            "[t=0] FREE/ALIAS applied. mode=FREE aliases=15\n",
            "--- NEXT instr_counter=1 ---\n",
            "[t=1] REG30_BUILD done. packed90_u64[0]=[9232960233523929384, 525330]\n",
            "[t=1] COMMIT done. commit0=c1596df8c9ec1a9c...\n",
            "[t=1] DEDUP done. collisions=15 groups=49 active=49\n",
            "[t=1] FREE/ALIAS applied. mode=FREE aliases=15\n",
            "--- NEXT instr_counter=2 ---\n",
            "\n",
            "=== Final State Snapshot ===\n",
            "instr_counter: 2\n",
            "initiator axis counts: [21, 18, 25] (0=x,1=y,2=z)\n",
            "packed_views_u32[0]: [8413480, 8929704, 8405288]\n",
            "packed90_u64[0]: [9232960233523929384, 525330]\n",
            "active qubits: 49 aliases: 15\n",
            "tag[0]: 15683781815185925009\n",
            "Sample qubits (q, mag, sign, winner, active):\n",
            "0 [8, 8, 51] [1, 1, 1] 0 True\n",
            "1 [31, 37, 38] [1, -1, -1] 1 True\n",
            "2 [45, 1, 31] [1, 1, -1] 2 True\n",
            "3 [9, 25, 59] [-1, 1, -1] 3 True\n",
            "4 [35, 4, 34] [-1, 1, 1] 4 True\n",
            "5 [8, 48, 60] [1, -1, 1] 5 True\n",
            "6 [62, 39, 55] [1, -1, -1] 6 True\n",
            "7 [23, 9, 32] [-1, 1, -1] 7 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V0.5.1 Patch"
      ],
      "metadata": {
        "id": "q_Ipn31YnxbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UniversalISA prototype v0.5.1 (Colab single-cell)\n",
        "# Patch: Switched Commit domain_sep for commit_full90 to include Q to address collision\n",
        "# Adds to v0.3:\n",
        "# - Batch-level DEDUP/ALIAS (state sharing detection) keyed off FULL 90-bit commitment\n",
        "# - Winner selection + alias map + freed qubits list\n",
        "# - Feed-forward state registers (tag_u64, initiator, swap counts)\n",
        "# - Second instruction step that executes only ACTIVE (winner) qubits and fills aliases deterministically\n",
        "# - Mode switch:\n",
        "#     MODE=\"FREE\"      => aliases are reassigned new NEC work states for next instruction\n",
        "#     MODE=\"PAIR_HUNT\" => aliases stay tied to winner state (useful for paired-state hunting)\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "# -----------------------------\n",
        "# Global constants / fixed geometry\n",
        "# -----------------------------\n",
        "Q = 64\n",
        "TAU_HI      = 1.0\n",
        "TAU_LOW     = -1.0\n",
        "EPS         = 1e-6\n",
        "R_FOR_RATIO = 64.0\n",
        "\n",
        "PRIME_MASK_30 = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# 10 triplets over 30 slots: [0..2],[3..5],...,[27..29]\n",
        "TRIPLET_IDX = tf.constant([[3*t,3*t+1,3*t+2] for t in range(10)], dtype=tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# Pack/bitslice utilities\n",
        "# -----------------------------\n",
        "def pack30_to_u32_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    bits_u32 = tf.cast(bits30_i32, tf.uint32)\n",
        "    shifts = tf.cast(tf.range(30), tf.uint32)\n",
        "    return tf.reduce_sum(tf.bitwise.left_shift(bits_u32, shifts), axis=1)  # [Q] u32\n",
        "\n",
        "def bitslice_30_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    weights = tf.bitwise.left_shift(tf.constant(1, tf.uint64), tf.cast(tf.range(tf.shape(bits30_i32)[0]), tf.uint64))\n",
        "    bits_u64 = tf.cast(bits30_i32, tf.uint64)\n",
        "    return tf.reduce_sum(tf.transpose(bits_u64, [1,0]) * tf.expand_dims(weights, axis=0), axis=1)\n",
        "\n",
        "def pack90_from_3x30_u32(packed3_u32: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    packed3_u32: [Q,3] uint32, each holds 30 bits\n",
        "    Returns: [Q,2] uint64 (90 bits packed)\n",
        "    \"\"\"\n",
        "    out = np.zeros((packed3_u32.shape[0],2), dtype=np.uint64)\n",
        "    for q in range(packed3_u32.shape[0]):\n",
        "        b0 = np.uint64(packed3_u32[q,0] & np.uint32((1<<30)-1))\n",
        "        b1 = np.uint64(packed3_u32[q,1] & np.uint32((1<<30)-1))\n",
        "        b2 = np.uint64(packed3_u32[q,2] & np.uint32((1<<30)-1))\n",
        "        low = b0 | (b1 << np.uint64(30)) | ((b2 & np.uint64(0xF)) << np.uint64(60))\n",
        "        high = (b2 >> np.uint64(4))\n",
        "        out[q,0] = low\n",
        "        out[q,1] = high\n",
        "    return out\n",
        "\n",
        "# -----------------------------\n",
        "# Phase-dual core ops\n",
        "# -----------------------------\n",
        "def add_pd(a,b): return a+b\n",
        "def mul_pd(a,b): return a*b\n",
        "def div_pd(a,b): return tf.where(tf.abs(b) > EPS, a/b, tf.zeros_like(a))\n",
        "\n",
        "# -----------------------------\n",
        "# NEC selectors (true phase-dual) + initiator logic\n",
        "# -----------------------------\n",
        "def sel_real(m: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.stack([m, -m], axis=1)  # [+m,-m]\n",
        "\n",
        "def sel_unreal(m: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.stack([-m, m], axis=1)  # [-m,+m]\n",
        "\n",
        "def build_primaries_from_nec(mag_xyz_i32: tf.Tensor, base_sign_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    mag_xyz_i32: [Q,3] int32 magnitudes >=0 (NEC absolute coordinate)\n",
        "    base_sign_xyz_i32: [Q,3] int32 in {-1,+1} giving base NEC sign per axis:\n",
        "      +1 => axis initiated real  => pair order (RealSelector, UnrealSelector)\n",
        "      -1 => axis initiated unreal=> pair order (UnrealSelector, RealSelector)\n",
        "\n",
        "    Returns primaries [Q,6,2] float32 in canonical pair sequence:\n",
        "      [X0, X1, Y0, Y1, Z0, Z1] where each Xi/Yi/Zi is itself a 2-vector [real, unreal].\n",
        "    \"\"\"\n",
        "    mag = tf.cast(mag_xyz_i32, tf.float32)\n",
        "    mX, mY, mZ = mag[:,0], mag[:,1], mag[:,2]\n",
        "    Xr, Xu = sel_real(mX), sel_unreal(mX)\n",
        "    Yr, Yu = sel_real(mY), sel_unreal(mY)\n",
        "    Zr, Zu = sel_real(mZ), sel_unreal(mZ)\n",
        "\n",
        "    sign_is_unreal = base_sign_xyz_i32 < 0  # [Q,3]\n",
        "    X0 = tf.where(sign_is_unreal[:,0:1], Xu, Xr)\n",
        "    X1 = tf.where(sign_is_unreal[:,0:1], Xr, Xu)\n",
        "    Y0 = tf.where(sign_is_unreal[:,1:2], Yu, Yr)\n",
        "    Y1 = tf.where(sign_is_unreal[:,1:2], Yr, Yu)\n",
        "    Z0 = tf.where(sign_is_unreal[:,2:3], Zu, Zr)\n",
        "    Z1 = tf.where(sign_is_unreal[:,2:3], Zr, Zu)\n",
        "    return tf.stack([X0,X1,Y0,Y1,Z0,Z1], axis=1)  # [Q,6,2]\n",
        "\n",
        "def initiator_from_shared_counts(mag_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Your initiator rule using shared axis magnitudes across the array.\n",
        "    Returns initiator axis index per qubit: 0=x, 1=y, 2=z\n",
        "    \"\"\"\n",
        "    mag = mag_xyz_i32  # [Q,3], int32\n",
        "    eqx = tf.equal(tf.expand_dims(mag[:,0], 1), tf.expand_dims(mag[:,0], 0))\n",
        "    eqy = tf.equal(tf.expand_dims(mag[:,1], 1), tf.expand_dims(mag[:,1], 0))\n",
        "    eqz = tf.equal(tf.expand_dims(mag[:,2], 1), tf.expand_dims(mag[:,2], 0))\n",
        "    cx = tf.reduce_sum(tf.cast(eqx, tf.int32), axis=1)\n",
        "    cy = tf.reduce_sum(tf.cast(eqy, tf.int32), axis=1)\n",
        "    cz = tf.reduce_sum(tf.cast(eqz, tf.int32), axis=1)\n",
        "\n",
        "    counts = tf.stack([cx,cy,cz], axis=1)  # [Q,3]\n",
        "    shared_mask = counts > 1\n",
        "    shared_count = tf.reduce_sum(tf.cast(shared_mask, tf.int32), axis=1)  # [Q]\n",
        "\n",
        "    init_one_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "    is_unshared = tf.equal(counts, 1)\n",
        "    init_two_shared = tf.argmax(tf.cast(is_unshared, tf.int32), axis=1, output_type=tf.int32)\n",
        "    init_three_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "\n",
        "    bias = tf.constant([2,1,0], tf.int32)\n",
        "    mags_biased = mag_xyz_i32 * 1000 + bias\n",
        "    init_none_shared = tf.argmax(mags_biased, axis=1, output_type=tf.int32)\n",
        "\n",
        "    initiator = tf.where(shared_count == 1, init_one_shared,\n",
        "                 tf.where(shared_count == 2, init_two_shared,\n",
        "                 tf.where(shared_count == 3, init_three_shared, init_none_shared)))\n",
        "    return initiator  # [Q]\n",
        "\n",
        "def permute_primaries_by_initiator(prim6: tf.Tensor, initiator_axis: tf.Tensor) -> tf.Tensor:\n",
        "    Qn = tf.shape(prim6)[0]\n",
        "    idx_x = tf.constant([0,1,2,3,4,5], tf.int32)\n",
        "    idx_y = tf.constant([2,3,4,5,0,1], tf.int32)\n",
        "    idx_z = tf.constant([4,5,0,1,2,3], tf.int32)\n",
        "\n",
        "    idx = tf.where(tf.expand_dims(initiator_axis==0,1), tf.broadcast_to(idx_x, [Qn,6]),\n",
        "          tf.where(tf.expand_dims(initiator_axis==1,1), tf.broadcast_to(idx_y, [Qn,6]),\n",
        "                                                          tf.broadcast_to(idx_z, [Qn,6])))\n",
        "\n",
        "    return tf.gather(prim6, idx, axis=1, batch_dims=1)\n",
        "\n",
        "# -----------------------------\n",
        "# 30-register with (+,-,*,/) semantics and add/sub-only reorder (canonicalization)\n",
        "# -----------------------------\n",
        "def build_register30(prim6: tf.Tensor,\n",
        "                     canonicalize_addsub: bool = True) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    p0,p1,p2,p3,p4,p5 = tf.unstack(prim6, axis=1)\n",
        "    A0,A1 = p0,p1\n",
        "    B0,B1 = p2,p3\n",
        "    C0,C1 = p4,p5\n",
        "\n",
        "    spec = [\n",
        "        (A0, B0, \"MUL\"),\n",
        "        (B0, C0, \"MUL\"),\n",
        "        (A0, C0, \"MUL\"),\n",
        "        (A1, B1, \"MUL\"),\n",
        "        (A0, B1, \"DIV\"),\n",
        "        (B0, C1, \"DIV\"),\n",
        "        (A1, C0, \"DIV\"),\n",
        "        (B1, C1, \"DIV\"),\n",
        "    ]\n",
        "\n",
        "    add_list = []\n",
        "    sub_list = []\n",
        "    op3_list = []\n",
        "    swap_flags = []\n",
        "\n",
        "    for (u,v,op3) in spec:\n",
        "        addv = add_pd(u,v)\n",
        "        subv = u - v\n",
        "        opv  = mul_pd(u,v) if op3==\"MUL\" else div_pd(u,v)\n",
        "\n",
        "        if canonicalize_addsub:\n",
        "            swap = tf.cast(subv[:,0] > addv[:,0], tf.int32)  # [Q]\n",
        "            addv2 = tf.where(swap[:,None] > 0, subv, addv)\n",
        "            subv2 = tf.where(swap[:,None] > 0, addv, subv)\n",
        "            addv, subv = addv2, subv2\n",
        "        else:\n",
        "            swap = tf.zeros([tf.shape(u)[0]], tf.int32)\n",
        "\n",
        "        # Patch v0.5.1: Ensure swap is always appended\n",
        "        swap_flags.append(swap)\n",
        "\n",
        "        add_list.append(addv)\n",
        "        sub_list.append(subv)\n",
        "        op3_list.append(opv)\n",
        "\n",
        "    reg = [p0,p1,p2, p3,p4,p5]\n",
        "    for i in range(8):\n",
        "        reg.extend([add_list[i], sub_list[i], op3_list[i]])\n",
        "\n",
        "    reg = tf.stack(reg, axis=1)  # [Q,30,2]\n",
        "    swap_flags = tf.stack(swap_flags, axis=1)  # [Q,8]\n",
        "    return reg, swap_flags\n",
        "\n",
        "# -----------------------------\n",
        "# Collapse/parity/bitmap with triplet loop + scatter update retained\n",
        "# -----------------------------\n",
        "def detect_collapse_triplet_scatter(pairs: tf.Tensor,\n",
        "                                   tau_hi: float = TAU_HI,\n",
        "                                   tau_low: float = TAU_LOW,\n",
        "                                   r_for_ratio: float = R_FOR_RATIO) -> tf.Tensor:\n",
        "    real = pairs[..., 0]\n",
        "    unreal = pairs[..., 1]\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "\n",
        "    cond1 = tf.logical_and(real >= tau_hi, unreal <= tau_low)\n",
        "    ratio = tf.where(tf.abs(unreal) > EPS, real / unreal, tf.zeros_like(real))\n",
        "    cond2 = ratio > r_for_ratio\n",
        "    individual = tf.logical_or(cond1, cond2)\n",
        "\n",
        "    final_mask = tf.cast(individual, tf.int32)\n",
        "\n",
        "    for t in tf.range(10):\n",
        "        idx3 = TRIPLET_IDX[t]\n",
        "        trip_ind = tf.gather(individual, idx3, axis=1)\n",
        "        is_uniform = tf.reduce_all(tf.equal(trip_ind, trip_ind[:, 0:1]), axis=1)\n",
        "        uniform_val = tf.cast(trip_ind[:, 0], tf.int32)\n",
        "\n",
        "        updates = tf.where(\n",
        "            tf.expand_dims(is_uniform, axis=1),\n",
        "            tf.tile(tf.expand_dims(uniform_val, axis=1), [1,3]),\n",
        "            tf.cast(trip_ind, tf.int32)\n",
        "        )\n",
        "\n",
        "        q_idx = tf.repeat(tf.range(Qn), repeats=3)\n",
        "        p_idx = tf.tile(idx3, multiples=[Qn])\n",
        "        scatter_idx = tf.stack([q_idx, p_idx], axis=1)\n",
        "        final_mask = tf.tensor_scatter_nd_update(final_mask, scatter_idx, tf.reshape(updates, [-1]))\n",
        "\n",
        "    return final_mask\n",
        "\n",
        "def apply_parity_rotation(pairs: tf.Tensor, collapse_mask: tf.Tensor):\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "    prime = tf.broadcast_to(PRIME_MASK_30[tf.newaxis,:], [Qn,30])\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32)\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, tf.float32), tf.constant(1.0, tf.float32))\n",
        "    return pairs * sign[...,None], affected\n",
        "\n",
        "def bitmap(rotated_pairs: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.cast(rotated_pairs[...,0] > EPS, tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# One view compute: prim6 -> reg30 -> collapse/parity -> bits30\n",
        "# -----------------------------\n",
        "def compute_bits_for_view(prim6: tf.Tensor,\n",
        "                          canonicalize_addsub: bool = True) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, tf.Tensor]:\n",
        "    reg30, swap_flags = build_register30(prim6, canonicalize_addsub=canonicalize_addsub)\n",
        "    collapse = detect_collapse_triplet_scatter(reg30)\n",
        "    rotated, parity = apply_parity_rotation(reg30, collapse)\n",
        "    bits = bitmap(rotated)\n",
        "    return bits, swap_flags, collapse, parity\n",
        "\n",
        "# -----------------------------\n",
        "# Commitments keyed off full 3-view payload\n",
        "# -----------------------------\n",
        "def commit_full90(packed_u32_xyz: np.ndarray,\n",
        "                  initiator_axis: np.ndarray,\n",
        "                  swapcount_xyz: np.ndarray,\n",
        "                  instr_counter: int,\n",
        "                  domain_sep: bytes = b\"NTHISA90\") -> List[bytes]:\n",
        "    \"\"\"\n",
        "    packed_u32_xyz: [Q,3] uint32 (x/y/z view packed 30-bit)\n",
        "    initiator_axis: [Q] uint8\n",
        "    swapcount_xyz:  [Q,3] uint8 (#swaps in 8 interaction triplets per view; 0..8)\n",
        "    \"\"\"\n",
        "    commits = []\n",
        "    # Patch v0.5.1: include Q in domain_sep for commit_full90 to address collision\n",
        "    domain_sep_patched = domain_sep + Q.to_bytes(2, \"little\", signed=False)\n",
        "    for q in range(packed_u32_xyz.shape[0]):\n",
        "        msg = (\n",
        "            domain_sep_patched +\n",
        "            int(instr_counter).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,0]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,1]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,2]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(initiator_axis[q]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,0]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,1]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,2]).to_bytes(1,\"little\",signed=False)\n",
        "        )\n",
        "        commits.append(hashlib.blake2s(msg, digest_size=32).digest())\n",
        "    return commits\n",
        "\n",
        "def tag_u64_from_commit(commit32: bytes, q_idx: int, instr_counter: int) -> np.uint64:\n",
        "    msg = b\"NTH_TAG0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    h = hashlib.blake2s(msg, digest_size=8).digest()\n",
        "    return np.uint64(int.from_bytes(h, \"little\", signed=False))\n",
        "\n",
        "@dataclass\n",
        "class DedupResult:\n",
        "    winner_of: np.ndarray\n",
        "    active_mask: np.ndarray\n",
        "    groups: Dict[bytes, List[int]] = field(default_factory=dict)\n",
        "    freed: List[int] = field(default_factory=list)\n",
        "    collision_qubits: int\n",
        "\n",
        "def dedup_by_commit(commits: List[bytes], efficiency_score: np.ndarray, mode: str) -> DedupResult:\n",
        "    groups: Dict[bytes, List[int]] = {}\n",
        "    for q,c in enumerate(commits):\n",
        "        groups.setdefault(c, []).append(q)\n",
        "\n",
        "    winner_of = np.arange(len(commits), dtype=np.int32)\n",
        "    active_mask = np.ones(len(commits), dtype=bool)\n",
        "    freed: List[int] = []\n",
        "    collision_qubits = 0\n",
        "\n",
        "    for c, qs in groups.items():\n",
        "        if len(qs) > 1:\n",
        "            collision_qubits += (len(qs) - 1)\n",
        "\n",
        "        # winner = min efficiency_score, tie -> min q index\n",
        "        qs_sorted = sorted(qs, key=lambda q: (int(efficiency_score[q]), q))\n",
        "        w = qs_sorted[0]\n",
        "        for q in qs:\n",
        "            winner_of[q] = w\n",
        "            if q != w:\n",
        "                active_mask[q] = False\n",
        "                if mode == \"FREE\":\n",
        "                    freed.append(q)\n",
        "\n",
        "    return DedupResult(winner_of, active_mask, groups, freed, collision_qubits)\n",
        "\n",
        "def derive_new_nec_for_freed(commit32: bytes, q_idx: int, instr_counter: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    msg = b\"NTH_FREE0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    raw = hashlib.blake2s(msg, digest_size=16).digest()\n",
        "    mags = np.array([raw[0] % 64, raw[1] % 64, raw[2] % 64], dtype=np.int32)\n",
        "    sb = raw[3]\n",
        "    signs = np.array([1 if (sb & 1) else -1, 1 if (sb & 2) else -1, 1 if (sb & 4) else -1], dtype=np.int32)\n",
        "    return mags, signs\n",
        "\n",
        "# -----------------------------\n",
        "# Interpreter state\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class ISAState:\n",
        "    instr_counter: int = 0\n",
        "    mode: str = \"FREE\"                  # FREE or PAIR_HUNT\n",
        "    exec_active_only: bool = False      # if True, heavy ops run only on active winners\n",
        "\n",
        "    # NEC state\n",
        "    mag_xyz: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.int32))\n",
        "    base_sign: np.ndarray = field(default_factory=lambda: np.ones((Q,3), dtype=np.int32))\n",
        "\n",
        "    # Derived registers\n",
        "    initiator: np.ndarray = field(default_factory=lambda: np.zeros((Q,), dtype=np.int32))\n",
        "    packed_views_u32: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.uint32))\n",
        "    packed90_u64: np.ndarray = field(default_factory=lambda: np.zeros((Q,2), dtype=np.uint64))\n",
        "    bits_views: np.ndarray = field(default_factory=lambda: np.zeros((Q,3,30), dtype=np.int32))\n",
        "    swapcount_xyz: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.uint8))\n",
        "    commits: List[bytes] = field(default_factory=lambda: [b\"\"]*Q)\n",
        "    tags_u64: np.ndarray = field(default_factory=lambda: np.zeros((Q,), dtype=np.uint64))\n",
        "\n",
        "    # Dedup scheduling\n",
        "    dedup: Optional[DedupResult] = None\n",
        "    active_mask: np.ndarray = field(default_factory=lambda: np.ones((Q,), dtype=bool))\n",
        "    winner_of: np.ndarray = field(default_factory=lambda: np.arange(Q, dtype=np.int32))\n",
        "\n",
        "# -----------------------------\n",
        "# Interpreter core: ops\n",
        "# -----------------------------\n",
        "def op_NEC_LOAD(st: ISAState, seed: int = 11, mag_range: int = 64):\n",
        "    rng = np.random.default_rng(seed + st.instr_counter)\n",
        "    st.mag_xyz = rng.integers(0, mag_range, size=(Q,3), dtype=np.int32)\n",
        "    sign_bits = rng.integers(0, 2, size=(Q,3), dtype=np.int32)\n",
        "    st.base_sign = np.where(sign_bits > 0, 1, -1).astype(np.int32)\n",
        "\n",
        "def op_INIT_SELECT(st: ISAState):\n",
        "    mag_tf = tf.constant(st.mag_xyz, dtype=tf.int32)\n",
        "    st.initiator = initiator_from_shared_counts(mag_tf).numpy().astype(np.int32)\n",
        "\n",
        "def _compute_views_full(st: ISAState):\n",
        "    mag_tf  = tf.constant(st.mag_xyz, dtype=tf.int32)\n",
        "    sign_tf = tf.constant(st.base_sign, dtype=tf.int32)\n",
        "\n",
        "    prim0 = build_primaries_from_nec(mag_tf, sign_tf)  # [Q,6,2]\n",
        "    # init_tf = tf.constant(st.initiator, dtype=tf.int32) # Not used in full compute, so commented out\n",
        "\n",
        "    prim_x = permute_primaries_by_initiator(prim0, tf.zeros([Q], tf.int32))\n",
        "    prim_y = permute_primaries_by_initiator(prim0, tf.ones([Q], tf.int32))\n",
        "    prim_z = permute_primaries_by_initiator(prim0, tf.fill([Q], tf.constant(2, tf.int32)))\n",
        "\n",
        "    def eval_view(prim6):\n",
        "        reg30, swaps = build_register30(prim6, canonicalize_addsub=True)\n",
        "        collapse = detect_collapse_triplet_scatter(reg30)\n",
        "        rotated, _ = apply_parity_rotation(reg30, collapse)\n",
        "        bits = bitmap(rotated)\n",
        "        packed = pack30_to_u32_tf(bits)\n",
        "        swapcount = tf.reduce_sum(swaps, axis=1)\n",
        "        return bits, packed, swapcount\n",
        "\n",
        "    bits_x, packed_x, swap_x = eval_view(prim_x)\n",
        "    bits_y, packed_y, swap_y = eval_view(prim_y)\n",
        "    bits_z, packed_z, swap_z = eval_view(prim_z)\n",
        "\n",
        "    st.bits_views = np.stack([bits_x.numpy().astype(np.int32),\n",
        "                              bits_y.numpy().astype(np.int32),\n",
        "                              bits_z.numpy().astype(np.int32)], axis=1)\n",
        "    st.packed_views_u32 = tf.stack([packed_x, packed_y, packed_z], axis=1).numpy().astype(np.uint32)\n",
        "    st.swapcount_xyz = np.stack([swap_x.numpy().astype(np.uint8),\n",
        "                                 swap_y.numpy().astype(np.uint8),\n",
        "                                 swap_z.numpy().astype(np.uint8)], axis=1).astype(np.uint8)\n",
        "    st.packed90_u64 = pack90_from_3x30_u32(st.packed_views_u32)\n",
        "\n",
        "def _compute_views_active_only(st: ISAState):\n",
        "    # Compute heavy pipeline only for active winners, then fill aliases based on mode\n",
        "    active_idx = np.where(st.active_mask)[0].astype(np.int32)\n",
        "    alias_idx = np.where(~st.active_mask)[0].astype(np.int32)\n",
        "    Qa = int(active_idx.shape[0])\n",
        "\n",
        "    if Qa == 0:\n",
        "        # nothing active; clear outputs\n",
        "        st.bits_views[:] = 0\n",
        "        st.packed_views_u32[:] = 0\n",
        "        st.swapcount_xyz[:] = 0\n",
        "        st.packed90_u64[:] = 0\n",
        "        st.commits = [b\"\"]*Q\n",
        "        st.tags_u64[:] = 0\n",
        "        return\n",
        "\n",
        "    mag_a  = tf.constant(st.mag_xyz[active_idx], dtype=tf.int32)\n",
        "    sign_a = tf.constant(st.base_sign[active_idx], dtype=tf.int32)\n",
        "\n",
        "    prim0_a = build_primaries_from_nec(mag_a, sign_a)\n",
        "    # initiator for active subset only (optimization)\n",
        "    init_a = initiator_from_shared_counts(mag_a)\n",
        "\n",
        "    prim_x = permute_primaries_by_initiator(prim0_a, tf.zeros([Qa], tf.int32))\n",
        "    prim_y = permute_primaries_by_initiator(prim0_a, tf.ones([Qa], tf.int32))\n",
        "    prim_z = permute_primaries_by_initiator(prim0_a, tf.fill([Qa], tf.constant(2, tf.int32)))\n",
        "\n",
        "    def eval_view(prim6):\n",
        "        reg30, swaps = build_register30(prim6, canonicalize_addsub=True)\n",
        "        collapse = detect_collapse_triplet_scatter(reg30)\n",
        "        rotated, _ = apply_parity_rotation(reg30, collapse)\n",
        "        bits = bitmap(rotated)\n",
        "        packed = pack30_to_u32_tf(bits)\n",
        "        swapcount = tf.reduce_sum(swaps, axis=1)\n",
        "        return bits, packed, swapcount\n",
        "\n",
        "    bits_x, packed_x, swap_x = eval_view(prim_x)\n",
        "    bits_y, packed_y, swap_y = eval_view(prim_y)\n",
        "    bits_z, packed_z, swap_z = eval_view(prim_z)\n",
        "\n",
        "    bits_views_a = np.stack([bits_x.numpy().astype(np.int32),\n",
        "                             bits_y.numpy().astype(np.int32),\n",
        "                             bits_z.numpy().astype(np.int32)], axis=1)\n",
        "    packed_a = tf.stack([packed_x, packed_y, packed_z], axis=1).numpy().astype(np.uint32)\n",
        "    swapcount_a = np.stack([swap_x.numpy().astype(np.uint8),\n",
        "                            swap_y.numpy().astype(np.uint8),\n",
        "                            swap_z.numpy().astype(np.uint8)], axis=1).astype(np.uint8)\n",
        "\n",
        "    # Scatter active results into full arrays\n",
        "    st.bits_views[:] = 0\n",
        "    st.packed_views_u32[:] = 0\n",
        "    st.swapcount_xyz[:] = 0\n",
        "    for i,q in enumerate(active_idx):\n",
        "        st.bits_views[q] = bits_views_a[i]\n",
        "        st.packed_views_u32[q] = packed_a[i]\n",
        "        st.swapcount_xyz[q] = swapcount_a[i]\n",
        "\n",
        "    # Fill aliases\n",
        "    if st.mode == \"PAIR_HUNT\":\n",
        "        # aliases copy winner payload\n",
        "        for q in alias_idx:\n",
        "            w = st.winner_of[q]\n",
        "            st.bits_views[q] = st.bits_views[w]\n",
        "            st.packed_views_u32[q] = st.packed_views_u32[w]\n",
        "            st.swapcount_xyz[q] = st.swapcount_xyz[w]\n",
        "    else:\n",
        "        # FREE: freed qubits may be doing new work later; for now keep payload=0 (uncomputed this cycle)\n",
        "        pass\n",
        "\n",
        "    st.packed90_u64 = pack90_from_3x30_u32(st.packed_views_u32)\n",
        "\n",
        "def op_REG30_BUILD_BITMAP_PACK(st: ISAState):\n",
        "    # This op is a fused execution of: REG30_BUILD + COLLAPSE + PARITY + BITMAP + PACK\n",
        "    # It exists because a real backend would fuse these kernels, but the IR still names the primitives.\n",
        "    if st.exec_active_only and st.dedup is not None:\n",
        "        _compute_views_active_only(st)\n",
        "    else:\n",
        "        _compute_views_full(st)\n",
        "\n",
        "def op_COMMIT(st: ISAState):\n",
        "    st.commits = commit_full90(st.packed_views_u32,\n",
        "                              st.initiator.astype(np.uint8),\n",
        "                              st.swapcount_xyz.astype(np.uint8),\n",
        "                              st.instr_counter)\n",
        "    st.tags_u64 = np.array([tag_u64_from_commit(st.commits[q], q, st.instr_counter) for q in range(Q)], dtype=np.uint64)\n",
        "\n",
        "def op_DEDUP(st: ISAState):\n",
        "    # Efficiency score prototype: fewer swaps => cheaper\n",
        "    eff = st.swapcount_xyz.sum(axis=1).astype(np.int32)\n",
        "    st.dedup = dedup_by_commit(st.commits, eff, st.mode)\n",
        "    st.active_mask = st.dedup.active_mask.copy()\n",
        "    st.winner_of = st.dedup.winner_of.copy()\n",
        "\n",
        "def op_FREE_ALIAS(st: ISAState):\n",
        "    if st.dedup is None:\n",
        "        return\n",
        "    alias_idx = np.where(~st.active_mask)[0].astype(np.int32)\n",
        "\n",
        "    if st.mode == \"PAIR_HUNT\":\n",
        "        # aliases inherit winner NEC as well (remain paired)\n",
        "        for q in alias_idx:\n",
        "            w = st.winner_of[q]\n",
        "            st.mag_xyz[q] = st.mag_xyz[w]\n",
        "            st.base_sign[q] = st.base_sign[w]\n",
        "    else:\n",
        "        # FREE: reassign alias qubits to new NEC states deterministically from their own commit\n",
        "        for q in alias_idx:\n",
        "            mags, signs = derive_new_nec_for_freed(st.commits[q], q, st.instr_counter + 1)\n",
        "            st.mag_xyz[q] = mags\n",
        "            st.base_sign[q] = signs\n",
        "\n",
        "def op_EXEC_ACTIVE_ONLY(st: ISAState, enabled: bool = True):\n",
        "    st.exec_active_only = bool(enabled)\n",
        "\n",
        "def op_NEXT(st: ISAState):\n",
        "    st.instr_counter += 1\n",
        "\n",
        "# -----------------------------\n",
        "# Interpreter runner\n",
        "# -----------------------------\n",
        "OP_TABLE = {\n",
        "    \"NEC_LOAD\": op_NEC_LOAD,\n",
        "    \"INIT_SELECT\": op_INIT_SELECT,\n",
        "    \"REG30_BUILD\": op_REG30_BUILD_BITMAP_PACK,    # fused for now\n",
        "    \"COLLAPSE\": lambda st, **k: None,             # named primitive; fused in REG30_BUILD\n",
        "    \"PARITY\":   lambda st, **k: None,             # named primitive; fused in REG30_BUILD\n",
        "    \"BITMAP\":   lambda st, **k: None,             # named primitive; fused in REG30_BUILD\n",
        "    \"PACK\":     lambda st, **k: None,             # named primitive; fused in REG30_BUILD\n",
        "    \"COMMIT\": op_COMMIT,\n",
        "    \"DEDUP\": op_DEDUP,\n",
        "    \"FREE_ALIAS\": op_FREE_ALIAS,\n",
        "    \"EXEC_ACTIVE_ONLY\": op_EXEC_ACTIVE_ONLY,\n",
        "    \"NEXT\": op_NEXT,\n",
        "}\n",
        "\n",
        "def run_program(st: ISAState, program: List[Instr], verbose: bool = True):\n",
        "    for ins in program:\n",
        "        fn = OP_TABLE.get(ins.op)\n",
        "        if fn is None:\n",
        "            raise ValueError(f\"Unknown opcode: {ins.op}\")\n",
        "        fn(st, **ins.args)\n",
        "        if verbose and ins.op in (\"REG30_BUILD\",\"COMMIT\",\"DEDUP\",\"FREE_ALIAS\",\"NEXT\"):\n",
        "            if ins.op == \"REG30_BUILD\":\n",
        "                print(f\"[t={st.instr_counter}] REG30_BUILD done. packed90_u64[0]={st.packed90_u64[0].tolist()}\")\n",
        "            elif ins.op == \"COMMIT\":\n",
        "                print(f\"[t={st.instr_counter}] COMMIT done. commit0={st.commits[0].hex()[:16]}...\")\n",
        "            elif ins.op == \"DEDUP\":\n",
        "                print(f\"[t={st.instr_counter}] DEDUP done. collisions={st.dedup.collision_qubits} groups={len(st.dedup.groups)} active={int(st.active_mask.sum())}\")\n",
        "            elif ins.op == \"FREE_ALIAS\":\n",
        "                print(f\"[t={st.instr_counter}] FREE/ALIAS applied. mode={st.mode} aliases={Q-int(st.active_mask.sum())}\")\n",
        "            elif ins.op == \"NEXT\":\n",
        "                print(f\"--- NEXT instr_counter={st.instr_counter} ---\")\n",
        "\n",
        "# -----------------------------\n",
        "# Demo microprogram: two instruction cycles with DEDUP + FREE/ALIAS + EXEC_ACTIVE_ONLY\n",
        "# -----------------------------\n",
        "st = ISAState(mode=\"FREE\", instr_counter=0)\n",
        "np.random.seed(11)\n",
        "tf.random.set_seed(11)\n",
        "\n",
        "program = [\n",
        "    Instr(\"NEC_LOAD\", {\"seed\": 11}),\n",
        "    Instr(\"INIT_SELECT\"),\n",
        "    Instr(\"REG30_BUILD\"),\n",
        "    Instr(\"COMMIT\"),\n",
        "    Instr(\"DEDUP\"),\n",
        "    Instr(\"FREE_ALIAS\"),\n",
        "    Instr(\"EXEC_ACTIVE_ONLY\", {\"enabled\": True}),\n",
        "    Instr(\"NEXT\"),\n",
        "\n",
        "    # second cycle (will compute heavy ops only for active winners if exec_active_only=True)\n",
        "    Instr(\"INIT_SELECT\"),\n",
        "    Instr(\"REG30_BUILD\"),\n",
        "    Instr(\"COMMIT\"),\n",
        "    Instr(\"DEDUP\"),\n",
        "    Instr(\"FREE_ALIAS\"),\n",
        "    Instr(\"NEXT\"),\n",
        "]\n",
        "\n",
        "print(\"=== UniversalISA v0.5 Interpreter Demo ===\")\n",
        "print(\"MODE:\", st.mode, \"EXEC_ACTIVE_ONLY initially:\", st.exec_active_only)\n",
        "run_program(st, program, verbose=True)\n",
        "\n",
        "print(\"\\n=== Final State Snapshot ===\")\n",
        "print(\"instr_counter:\", st.instr_counter)\n",
        "print(\"initiator axis counts:\", np.bincount(st.initiator, minlength=3).tolist(), \"(0=x,1=y,2=z)\")\n",
        "print(\"packed_views_u32[0]:\", st.packed_views_u32[0].tolist())\n",
        "print(\"packed90_u64[0]:\", st.packed90_u64[0].tolist())\n",
        "print(\"active qubits:\", int(st.active_mask.sum()), \"aliases:\", Q-int(st.active_mask.sum()))\n",
        "print(\"tag[0]:\", int(st.tags_u64[0]))\n",
        "print(\"Sample qubits (q, mag, sign, winner, active):\")\n",
        "for q in range(8):\n",
        "    print(q, st.mag_xyz[q].tolist(), st.base_sign[q].tolist(), int(st.winner_of[q]), bool(st.active_mask[q]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWIyA_pfn0ux",
        "outputId": "ddaaae81-c6a8-45dc-c748-e3d82704faa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== UniversalISA v0.5 Interpreter Demo ===\n",
            "MODE: FREE EXEC_ACTIVE_ONLY initially: False\n",
            "[t=0] REG30_BUILD done. packed90_u64[0]=[9232960233523929384, 525330]\n",
            "[t=0] COMMIT done. commit0=bcf249254eb62024...\n",
            "[t=0] DEDUP done. collisions=15 groups=49 active=49\n",
            "[t=0] FREE/ALIAS applied. mode=FREE aliases=15\n",
            "--- NEXT instr_counter=1 ---\n",
            "[t=1] REG30_BUILD done. packed90_u64[0]=[9232960233523929384, 525330]\n",
            "[t=1] COMMIT done. commit0=dc0ec393d083aac7...\n",
            "[t=1] DEDUP done. collisions=23 groups=41 active=41\n",
            "[t=1] FREE/ALIAS applied. mode=FREE aliases=23\n",
            "--- NEXT instr_counter=2 ---\n",
            "\n",
            "=== Final State Snapshot ===\n",
            "instr_counter: 2\n",
            "initiator axis counts: [28, 20, 16] (0=x,1=y,2=z)\n",
            "packed_views_u32[0]: [8413480, 8929704, 8405288]\n",
            "packed90_u64[0]: [9232960233523929384, 525330]\n",
            "active qubits: 41 aliases: 23\n",
            "tag[0]: 8100722577479211034\n",
            "Sample qubits (q, mag, sign, winner, active):\n",
            "0 [8, 8, 51] [1, 1, 1] 0 True\n",
            "1 [31, 37, 38] [1, -1, -1] 1 True\n",
            "2 [45, 1, 31] [1, 1, -1] 2 True\n",
            "3 [9, 25, 59] [-1, 1, -1] 3 True\n",
            "4 [35, 4, 34] [-1, 1, 1] 4 True\n",
            "5 [8, 48, 60] [1, -1, 1] 5 True\n",
            "6 [62, 39, 55] [1, -1, -1] 6 True\n",
            "7 [23, 9, 32] [-1, 1, -1] 7 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UniversalISA v0.6 (Colab single-cell, full corrected code)\n",
        "# Goals:\n",
        "#  - Minimal IR/opcode format + interpreter that runs instruction streams\n",
        "#  - Explicit stage opcodes: NEC_LOAD, INIT_SELECT, REG30_BUILD, COLLAPSE, PARITY, BITMAP, PACK, COMMIT, DEDUP, FREE_ALIAS, EXEC_ACTIVE_ONLY, NEXT\n",
        "#  - Preserves triplet loops + scatter updates in COLLAPSE\n",
        "#  - True NEC phase-dual selectors (Real=[+m,-m], Unreal=[-m,+m])\n",
        "#  - 3 initiator views => 90-bit payload per qubit (3×30-bit)\n",
        "#  - Add/Sub-only reorder canonicalization; MUL/DIV fixed\n",
        "#  - Batch-level DEDUP keyed off full 90-bit commitment\n",
        "#  - Correct FREE semantics: freed qubits are reassigned new NEC and become ACTIVE next epoch\n",
        "#  - Correct initiator semantics: initiator always computed from FULL 64-qubit array (even if later stages are active-only)\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "# -----------------------------\n",
        "# Global constants / fixed geometry\n",
        "# -----------------------------\n",
        "Q = 64\n",
        "TAU_HI      = 1.0\n",
        "TAU_LOW     = -1.0\n",
        "EPS         = 1e-6\n",
        "R_FOR_RATIO = 64.0\n",
        "\n",
        "PRIME_MASK_30 = tf.constant(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=tf.int32\n",
        ")\n",
        "\n",
        "# 10 triplets over 30 slots: [0..2],[3..5],...,[27..29]\n",
        "TRIPLET_IDX = tf.constant([[3*t,3*t+1,3*t+2] for t in range(10)], dtype=tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# IR / Opcode model\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Instr:\n",
        "    op: str\n",
        "    args: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities: pack/bitslice\n",
        "# -----------------------------\n",
        "def pack30_to_u32_tf(bits30_i32: tf.Tensor) -> tf.Tensor:\n",
        "    bits_u32 = tf.cast(bits30_i32, tf.uint32)               # [Q,30]\n",
        "    shifts = tf.cast(tf.range(30), tf.uint32)               # [30]\n",
        "    return tf.reduce_sum(tf.bitwise.left_shift(bits_u32, shifts), axis=1)  # [Q] u32\n",
        "\n",
        "def pack90_from_3x30_u32(packed3_u32: np.ndarray) -> np.ndarray:\n",
        "    # packed3_u32: [Q,3] uint32 -> [Q,2] uint64 (90 bits packed)\n",
        "    out = np.zeros((packed3_u32.shape[0],2), dtype=np.uint64)\n",
        "    for q in range(packed3_u32.shape[0]):\n",
        "        b0 = np.uint64(packed3_u32[q,0] & np.uint32((1<<30)-1))\n",
        "        b1 = np.uint64(packed3_u32[q,1] & np.uint32((1<<30)-1))\n",
        "        b2 = np.uint64(packed3_u32[q,2] & np.uint32((1<<30)-1))\n",
        "        low = b0 | (b1 << np.uint64(30)) | ((b2 & np.uint64(0xF)) << np.uint64(60))\n",
        "        high = (b2 >> np.uint64(4))\n",
        "        out[q,0] = low\n",
        "        out[q,1] = high\n",
        "    return out\n",
        "\n",
        "# -----------------------------\n",
        "# Phase-dual core ops\n",
        "# -----------------------------\n",
        "def add_pd(a,b): return a+b\n",
        "def mul_pd(a,b): return a*b\n",
        "def div_pd(a,b): return tf.where(tf.abs(b) > EPS, a/b, tf.zeros_like(a))\n",
        "\n",
        "# -----------------------------\n",
        "# NEC selectors (true phase-dual) + initiator logic\n",
        "# -----------------------------\n",
        "def sel_real(m: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.stack([m, -m], axis=1)  # [+m,-m]\n",
        "\n",
        "def sel_unreal(m: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.stack([-m, m], axis=1)  # [-m,+m]\n",
        "\n",
        "def build_primaries_from_nec(mag_xyz_i32: tf.Tensor, base_sign_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    mag_xyz_i32: [Q,3] int32 magnitudes >=0\n",
        "    base_sign_xyz_i32: [Q,3] int32 in {-1,+1}\n",
        "      +1 => axis initiated real   => (RealSelector, UnrealSelector)\n",
        "      -1 => axis initiated unreal => (UnrealSelector, RealSelector)\n",
        "    Returns: [Q,6,2] float32 in canonical axis-pair order [X0,X1,Y0,Y1,Z0,Z1]\n",
        "    \"\"\"\n",
        "    mag = tf.cast(mag_xyz_i32, tf.float32)\n",
        "    mX, mY, mZ = mag[:,0], mag[:,1], mag[:,2]\n",
        "    Xr, Xu = sel_real(mX), sel_unreal(mX)\n",
        "    Yr, Yu = sel_real(mY), sel_unreal(mY)\n",
        "    Zr, Zu = sel_real(mZ), sel_unreal(mZ)\n",
        "\n",
        "    sign_is_unreal = base_sign_xyz_i32 < 0  # [Q,3]\n",
        "    X0 = tf.where(sign_is_unreal[:,0:1], Xu, Xr)\n",
        "    X1 = tf.where(sign_is_unreal[:,0:1], Xr, Xu)\n",
        "    Y0 = tf.where(sign_is_unreal[:,1:2], Yu, Yr)\n",
        "    Y1 = tf.where(sign_is_unreal[:,1:2], Yr, Yu)\n",
        "    Z0 = tf.where(sign_is_unreal[:,2:3], Zu, Zr)\n",
        "    Z1 = tf.where(sign_is_unreal[:,2:3], Zr, Zu)\n",
        "\n",
        "    return tf.stack([X0,X1,Y0,Y1,Z0,Z1], axis=1)\n",
        "\n",
        "def initiator_from_shared_counts(mag_xyz_i32: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Initiator axis selection based on shared axis magnitudes across the full array.\n",
        "    Returns: [Q] int32 in {0,1,2} for (x,y,z)\n",
        "    \"\"\"\n",
        "    mag = mag_xyz_i32\n",
        "    eqx = tf.equal(tf.expand_dims(mag[:,0], 1), tf.expand_dims(mag[:,0], 0))\n",
        "    eqy = tf.equal(tf.expand_dims(mag[:,1], 1), tf.expand_dims(mag[:,1], 0))\n",
        "    eqz = tf.equal(tf.expand_dims(mag[:,2], 1), tf.expand_dims(mag[:,2], 0))\n",
        "    cx = tf.reduce_sum(tf.cast(eqx, tf.int32), axis=1)\n",
        "    cy = tf.reduce_sum(tf.cast(eqy, tf.int32), axis=1)\n",
        "    cz = tf.reduce_sum(tf.cast(eqz, tf.int32), axis=1)\n",
        "\n",
        "    counts = tf.stack([cx,cy,cz], axis=1)  # [Q,3]\n",
        "    shared_mask = counts > 1\n",
        "    shared_count = tf.reduce_sum(tf.cast(shared_mask, tf.int32), axis=1)\n",
        "\n",
        "    init_one_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "    is_unshared = tf.equal(counts, 1)\n",
        "    init_two_shared = tf.argmax(tf.cast(is_unshared, tf.int32), axis=1, output_type=tf.int32)\n",
        "    init_three_shared = tf.argmax(counts, axis=1, output_type=tf.int32)\n",
        "\n",
        "    bias = tf.constant([2,1,0], tf.int32)  # tie-break: prefer x>y>z\n",
        "    mags_biased = mag_xyz_i32 * 1000 + bias\n",
        "    init_none_shared = tf.argmax(mags_biased, axis=1, output_type=tf.int32)\n",
        "\n",
        "    initiator = tf.where(shared_count == 1, init_one_shared,\n",
        "                 tf.where(shared_count == 2, init_two_shared,\n",
        "                 tf.where(shared_count == 3, init_three_shared, init_none_shared)))\n",
        "    return initiator\n",
        "\n",
        "def permute_primaries_by_initiator(prim6: tf.Tensor, initiator_axis: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    prim6: [Q,6,2] in [X0,X1,Y0,Y1,Z0,Z1]\n",
        "    initiator_axis: [Q] in {0,1,2}\n",
        "    cyclic pairs:\n",
        "      x: [X0,X1, Y0,Y1, Z0,Z1]\n",
        "      y: [Y0,Y1, Z0,Z1, X0,X1]\n",
        "      z: [Z0,Z1, X0,X1, Y0,Y1]\n",
        "    \"\"\"\n",
        "    Qn = tf.shape(prim6)[0]\n",
        "    idx_x = tf.constant([0,1,2,3,4,5], tf.int32)\n",
        "    idx_y = tf.constant([2,3,4,5,0,1], tf.int32)\n",
        "    idx_z = tf.constant([4,5,0,1,2,3], tf.int32)\n",
        "\n",
        "    idx = tf.where(tf.expand_dims(initiator_axis==0,1), tf.broadcast_to(idx_x, [Qn,6]),\n",
        "          tf.where(tf.expand_dims(initiator_axis==1,1), tf.broadcast_to(idx_y, [Qn,6]),\n",
        "                                                          tf.broadcast_to(idx_z, [Qn,6])))\n",
        "    return tf.gather(prim6, idx, axis=1, batch_dims=1)\n",
        "\n",
        "# -----------------------------\n",
        "# REG30 build: 10 triplets, (+,-) reorderable; (*,/) fixed\n",
        "# -----------------------------\n",
        "def build_register30(prim6: tf.Tensor, canonicalize_addsub: bool = True) -> Tuple[tf.Tensor, tf.Tensor]:\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      reg30: [Q,30,2]\n",
        "      swap_flags: [Q,8] int32, swap decisions per interaction triplet (2..9)\n",
        "    \"\"\"\n",
        "    p0,p1,p2,p3,p4,p5 = tf.unstack(prim6, axis=1)\n",
        "    A0,A1 = p0,p1\n",
        "    B0,B1 = p2,p3\n",
        "    C0,C1 = p4,p5\n",
        "\n",
        "    # 8 interaction triplets: [ADD,SUB,OP3] with OP3 fixed as MUL or DIV\n",
        "    spec = [\n",
        "        (A0, B0, \"MUL\"),\n",
        "        (B0, C0, \"MUL\"),\n",
        "        (A0, C0, \"MUL\"),\n",
        "        (A1, B1, \"MUL\"),\n",
        "        (A0, B1, \"DIV\"),\n",
        "        (B0, C1, \"DIV\"),\n",
        "        (A1, C0, \"DIV\"),\n",
        "        (B1, C1, \"DIV\"),\n",
        "    ]\n",
        "\n",
        "    add_list, sub_list, op3_list, swap_flags = [], [], [], []\n",
        "    for (u,v,op3) in spec:\n",
        "        addv = add_pd(u,v)\n",
        "        subv = u - v\n",
        "        opv  = mul_pd(u,v) if op3==\"MUL\" else div_pd(u,v)\n",
        "\n",
        "        # canonicalize only ADD/SUB: swap if SUB.real > ADD.real\n",
        "        if canonicalize_addsub:\n",
        "            swap = tf.cast(subv[:,0] > addv[:,0], tf.int32)  # [Q]\n",
        "            addv2 = tf.where(swap[:,None] > 0, subv, addv)\n",
        "            subv2 = tf.where(swap[:,None] > 0, addv, subv)\n",
        "            addv, subv = addv2, subv2\n",
        "        else:\n",
        "            swap = tf.zeros([tf.shape(u)[0]], tf.int32)\n",
        "\n",
        "        add_list.append(addv); sub_list.append(subv); op3_list.append(opv); swap_flags.append(swap)\n",
        "\n",
        "    reg = [p0,p1,p2, p3,p4,p5]\n",
        "    for i in range(8):\n",
        "        reg.extend([add_list[i], sub_list[i], op3_list[i]])\n",
        "    reg = tf.stack(reg, axis=1)               # [Q,30,2]\n",
        "    swap_flags = tf.stack(swap_flags, axis=1) # [Q,8]\n",
        "    return reg, swap_flags\n",
        "\n",
        "# -----------------------------\n",
        "# COLLAPSE (triplet loops + scatter updates preserved)\n",
        "# -----------------------------\n",
        "def detect_collapse_triplet_scatter(pairs: tf.Tensor,\n",
        "                                   tau_hi: float = TAU_HI,\n",
        "                                   tau_low: float = TAU_LOW,\n",
        "                                   r_for_ratio: float = R_FOR_RATIO) -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    pairs: [Q,30,2] -> collapse_mask: [Q,30] int32\n",
        "    Keeps per-triplet loop + scatter update semantics.\n",
        "    \"\"\"\n",
        "    real = pairs[..., 0]\n",
        "    unreal = pairs[..., 1]\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "\n",
        "    cond1 = tf.logical_and(real >= tau_hi, unreal <= tau_low)\n",
        "    ratio = tf.where(tf.abs(unreal) > EPS, real / unreal, tf.zeros_like(real))\n",
        "    cond2 = ratio > r_for_ratio\n",
        "    individual = tf.logical_or(cond1, cond2)\n",
        "\n",
        "    final_mask = tf.cast(individual, tf.int32)\n",
        "\n",
        "    for t in tf.range(10):\n",
        "        idx3 = TRIPLET_IDX[t]\n",
        "        trip_ind = tf.gather(individual, idx3, axis=1)\n",
        "        is_uniform = tf.reduce_all(tf.equal(trip_ind, trip_ind[:,0:1]), axis=1)\n",
        "        uniform_val = tf.cast(trip_ind[:,0], tf.int32)\n",
        "\n",
        "        updates = tf.where(\n",
        "            tf.expand_dims(is_uniform, axis=1),\n",
        "            tf.tile(tf.expand_dims(uniform_val, axis=1), [1,3]),\n",
        "            tf.cast(trip_ind, tf.int32)\n",
        "        )\n",
        "\n",
        "        q_idx = tf.repeat(tf.range(Qn), repeats=3)\n",
        "        p_idx = tf.tile(idx3, multiples=[Qn])\n",
        "        scatter_idx = tf.stack([q_idx, p_idx], axis=1)\n",
        "        final_mask = tf.tensor_scatter_nd_update(final_mask, scatter_idx, tf.reshape(updates, [-1]))\n",
        "\n",
        "    return final_mask\n",
        "\n",
        "# -----------------------------\n",
        "# PARITY + BITMAP\n",
        "# -----------------------------\n",
        "def apply_parity_rotation(pairs: tf.Tensor, collapse_mask: tf.Tensor):\n",
        "    Qn = tf.shape(pairs)[0]\n",
        "    prime = tf.broadcast_to(PRIME_MASK_30[tf.newaxis,:], [Qn,30])\n",
        "    affected = tf.cast(tf.logical_or(prime > 0, collapse_mask > 0), tf.int32)\n",
        "    sign = tf.where(affected > 0, tf.constant(-1.0, tf.float32), tf.constant(1.0, tf.float32))\n",
        "    return pairs * sign[...,None], affected\n",
        "\n",
        "def bitmap(rotated_pairs: tf.Tensor) -> tf.Tensor:\n",
        "    return tf.cast(rotated_pairs[...,0] > EPS, tf.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# Commit/tag/dedup/free\n",
        "# -----------------------------\n",
        "def commit_full90(packed_u32_xyz: np.ndarray,\n",
        "                  initiator_axis: np.ndarray,\n",
        "                  swapcount_xyz: np.ndarray,\n",
        "                  instr_counter: int,\n",
        "                  domain_sep: bytes = b\"NTHISA90\") -> List[bytes]:\n",
        "    commits = []\n",
        "    for q in range(packed_u32_xyz.shape[0]):\n",
        "        msg = (\n",
        "            domain_sep +\n",
        "            int(instr_counter).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,0]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,1]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,2]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(initiator_axis[q]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,0]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,1]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,2]).to_bytes(1,\"little\",signed=False)\n",
        "        )\n",
        "        commits.append(hashlib.blake2s(msg, digest_size=32).digest())\n",
        "    return commits\n",
        "\n",
        "def tag_u64_from_commit(commit32: bytes, q_idx: int, instr_counter: int) -> np.uint64:\n",
        "    msg = b\"NTH_TAG0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    h = hashlib.blake2s(msg, digest_size=8).digest()\n",
        "    return np.uint64(int.from_bytes(h, \"little\", signed=False))\n",
        "\n",
        "@dataclass\n",
        "class DedupResult:\n",
        "    winner_of: np.ndarray\n",
        "    active_mask: np.ndarray\n",
        "    groups: Dict[bytes, List[int]]\n",
        "    freed: List[int]\n",
        "    collision_qubits: int\n",
        "\n",
        "def dedup_by_commit(commits: List[bytes], efficiency_score: np.ndarray, mode: str) -> DedupResult:\n",
        "    groups: Dict[bytes, List[int]] = {}\n",
        "    for q,c in enumerate(commits):\n",
        "        groups.setdefault(c, []).append(q)\n",
        "\n",
        "    winner_of = np.arange(len(commits), dtype=np.int32)\n",
        "    active_mask = np.ones(len(commits), dtype=bool)\n",
        "    freed: List[int] = []\n",
        "    collision_qubits = 0\n",
        "\n",
        "    for c, qs in groups.items():\n",
        "        if len(qs) > 1:\n",
        "            collision_qubits += (len(qs) - 1)\n",
        "\n",
        "        qs_sorted = sorted(qs, key=lambda q: (int(efficiency_score[q]), q))  # min score, tie min q\n",
        "        w = qs_sorted[0]\n",
        "        for q in qs:\n",
        "            winner_of[q] = w\n",
        "            if q != w:\n",
        "                active_mask[q] = False\n",
        "                if mode == \"FREE\":\n",
        "                    freed.append(q)\n",
        "\n",
        "    return DedupResult(winner_of, active_mask, groups, freed, collision_qubits)\n",
        "\n",
        "def derive_new_nec_for_freed(commit32: bytes, q_idx: int, instr_counter: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    msg = b\"NTH_FREE0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    raw = hashlib.blake2s(msg, digest_size=16).digest()\n",
        "    mags = np.array([raw[0] % 64, raw[1] % 64, raw[2] % 64], dtype=np.int32)\n",
        "    sb = raw[3]\n",
        "    signs = np.array([1 if (sb & 1) else -1, 1 if (sb & 2) else -1, 1 if (sb & 4) else -1], dtype=np.int32)\n",
        "    return mags, signs\n",
        "\n",
        "# -----------------------------\n",
        "# Interpreter state (register file)\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class ISAState:\n",
        "    instr_counter: int = 0\n",
        "    mode: str = \"PAIR_HUNT\"                  # FREE or PAIR_HUNT\n",
        "    exec_active_only: bool = False      # if True, stages run only on active winners when dedup exists & PAIR_HUNT\n",
        "\n",
        "    # NEC state registers\n",
        "    mag_xyz: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.int32))\n",
        "    base_sign: np.ndarray = field(default_factory=lambda: np.ones((Q,3), dtype=np.int32))\n",
        "\n",
        "    # scheduling registers\n",
        "    dedup: Optional[DedupResult] = None\n",
        "    active_mask: np.ndarray = field(default_factory=lambda: np.ones((Q,), dtype=bool))\n",
        "    winner_of: np.ndarray = field(default_factory=lambda: np.arange(Q, dtype=np.int32))\n",
        "\n",
        "    # derived registers\n",
        "    initiator: np.ndarray = field(default_factory=lambda: np.zeros((Q,), dtype=np.int32))            # [Q]\n",
        "    reg30_views: Optional[np.ndarray] = None                                                         # [Q,3,30,2] float32\n",
        "    swapflags_views: Optional[np.ndarray] = None                                                      # [Q,3,8] int32\n",
        "    collapse_views: Optional[np.ndarray] = None                                                       # [Q,3,30] int32\n",
        "    parity_views: Optional[np.ndarray] = None                                                         # [Q,3,30] int32\n",
        "    rotated_views: Optional[np.ndarray] = None                                                        # [Q,3,30,2] float32\n",
        "    bits_views: Optional[np.ndarray] = None                                                           # [Q,3,30] int32\n",
        "    packed_views_u32: Optional[np.ndarray] = None                                                     # [Q,3] uint32\n",
        "    packed90_u64: Optional[np.ndarray] = None                                                         # [Q,2] uint64\n",
        "    swapcount_xyz: Optional[np.ndarray] = None                                                        # [Q,3] uint8\n",
        "    commits: List[bytes] = field(default_factory=lambda: [b\"\"]*Q)\n",
        "    tags_u64: np.ndarray = field(default_factory=lambda: np.zeros((Q,), dtype=np.uint64))\n",
        "\n",
        "# -----------------------------\n",
        "# Stage helpers (full vs active-only execution)\n",
        "# -----------------------------\n",
        "def _get_active_indices_for_compute(st: ISAState) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    active_idx = np.where(st.active_mask)[0].astype(np.int32)\n",
        "    alias_idx = np.where(~st.active_mask)[0].astype(np.int32)\n",
        "    return active_idx, alias_idx\n",
        "\n",
        "def _should_active_only(st: ISAState) -> bool:\n",
        "    # active-only compute is only valid when:\n",
        "    # - exec_active_only enabled\n",
        "    # - dedup exists\n",
        "    # - mode is PAIR_HUNT (aliases can be safely copied)\n",
        "    return st.exec_active_only and (st.dedup is not None) and (st.mode == \"PAIR_HUNT\")\n",
        "\n",
        "# -----------------------------\n",
        "# Opcode implementations\n",
        "# -----------------------------\n",
        "def op_NEC_LOAD(st: ISAState, seed: int = 11, mag_range: int = 64):\n",
        "    rng = np.random.default_rng(seed + st.instr_counter)\n",
        "    st.mag_xyz = rng.integers(0, mag_range, size=(Q,3), dtype=np.int32)\n",
        "    sign_bits = rng.integers(0, 2, size=(Q,3), dtype=np.int32)\n",
        "    st.base_sign = np.where(sign_bits > 0, 1, -1).astype(np.int32)\n",
        "    # fresh epoch: all active\n",
        "    st.active_mask[:] = True\n",
        "    st.winner_of[:] = np.arange(Q, dtype=np.int32)\n",
        "    st.dedup = None\n",
        "\n",
        "def op_INIT_SELECT(st: ISAState):\n",
        "    # initiator MUST be computed on full array per spec (relative position)\n",
        "    mag_tf = tf.constant(st.mag_xyz, dtype=tf.int32)\n",
        "    st.initiator = initiator_from_shared_counts(mag_tf).numpy().astype(np.int32)\n",
        "\n",
        "def op_REG30_BUILD(st: ISAState):\n",
        "    \"\"\"\n",
        "    Builds reg30 for each of the three initiator views (x/y/z) and stores reg30_views and swapflags_views.\n",
        "    If active-only mode is enabled (PAIR_HUNT + dedup exists), compute only for active winners and leave aliases empty here.\n",
        "    Aliases will be filled at BITMAP stage by copying winner results.\n",
        "    \"\"\"\n",
        "    # Prepare buffers\n",
        "    st.reg30_views = np.zeros((Q,3,30,2), dtype=np.float32)\n",
        "    st.swapflags_views = np.zeros((Q,3,8), dtype=np.int32)\n",
        "\n",
        "    mag_tf = tf.constant(st.mag_xyz, dtype=tf.int32)\n",
        "    sign_tf = tf.constant(st.base_sign, dtype=tf.int32)\n",
        "    prim0 = build_primaries_from_nec(mag_tf, sign_tf)  # full [Q,6,2]\n",
        "\n",
        "    if _should_active_only(st):\n",
        "        active_idx, _ = _get_active_indices_for_compute(st)\n",
        "        prim0_a = tf.gather(prim0, active_idx, axis=0)\n",
        "\n",
        "        Qa = int(active_idx.shape[0])\n",
        "        prim_x = permute_primaries_by_initiator(prim0_a, tf.zeros([Qa], tf.int32))\n",
        "        prim_y = permute_primaries_by_initiator(prim0_a, tf.ones([Qa], tf.int32))\n",
        "        prim_z = permute_primaries_by_initiator(prim0_a, tf.fill([Qa], tf.constant(2, tf.int32)))\n",
        "\n",
        "        reg_x, sw_x = build_register30(prim_x, canonicalize_addsub=True)\n",
        "        reg_y, sw_y = build_register30(prim_y, canonicalize_addsub=True)\n",
        "        reg_z, sw_z = build_register30(prim_z, canonicalize_addsub=True)\n",
        "\n",
        "        reg_x = reg_x.numpy(); reg_y = reg_y.numpy(); reg_z = reg_z.numpy()\n",
        "        sw_x = sw_x.numpy();   sw_y = sw_y.numpy();   sw_z = sw_z.numpy()\n",
        "\n",
        "        for i,q in enumerate(active_idx):\n",
        "            st.reg30_views[q,0] = reg_x[i]\n",
        "            st.reg30_views[q,1] = reg_y[i]\n",
        "            st.reg30_views[q,2] = reg_z[i]\n",
        "            st.swapflags_views[q,0] = sw_x[i]\n",
        "            st.swapflags_views[q,1] = sw_y[i]\n",
        "            st.swapflags_views[q,2] = sw_z[i]\n",
        "    else:\n",
        "        prim_x = permute_primaries_by_initiator(prim0, tf.zeros([Q], tf.int32))\n",
        "        prim_y = permute_primaries_by_initiator(prim0, tf.ones([Q], tf.int32))\n",
        "        prim_z = permute_primaries_by_initiator(prim0, tf.fill([Q], tf.constant(2, tf.int32)))\n",
        "\n",
        "        reg_x, sw_x = build_register30(prim_x, canonicalize_addsub=True)\n",
        "        reg_y, sw_y = build_register30(prim_y, canonicalize_addsub=True)\n",
        "        reg_z, sw_z = build_register30(prim_z, canonicalize_addsub=True)\n",
        "\n",
        "        st.reg30_views[:,0] = reg_x.numpy()\n",
        "        st.reg30_views[:,1] = reg_y.numpy()\n",
        "        st.reg30_views[:,2] = reg_z.numpy()\n",
        "        st.swapflags_views[:,0] = sw_x.numpy()\n",
        "        st.swapflags_views[:,1] = sw_y.numpy()\n",
        "        st.swapflags_views[:,2] = sw_z.numpy()\n",
        "\n",
        "    # swap counts (used for efficiency score and commitments)\n",
        "    st.swapcount_xyz = np.sum(st.swapflags_views, axis=2).astype(np.uint8)  # [Q,3]\n",
        "\n",
        "def op_COLLAPSE(st: ISAState):\n",
        "    assert st.reg30_views is not None, \"REG30_BUILD must run before COLLAPSE\"\n",
        "    st.collapse_views = np.zeros((Q,3,30), dtype=np.int32)\n",
        "\n",
        "    if _should_active_only(st):\n",
        "        active_idx, _ = _get_active_indices_for_compute(st)\n",
        "        for v in range(3):\n",
        "            reg_a = tf.constant(st.reg30_views[active_idx, v], dtype=tf.float32)  # [Qa,30,2]\n",
        "            coll_a = detect_collapse_triplet_scatter(reg_a).numpy().astype(np.int32)\n",
        "            for i,q in enumerate(active_idx):\n",
        "                st.collapse_views[q,v] = coll_a[i]\n",
        "    else:\n",
        "        for v in range(3):\n",
        "            reg = tf.constant(st.reg30_views[:,v], dtype=tf.float32)\n",
        "            st.collapse_views[:,v] = detect_collapse_triplet_scatter(reg).numpy().astype(np.int32)\n",
        "\n",
        "def op_PARITY(st: ISAState):\n",
        "    assert st.reg30_views is not None and st.collapse_views is not None, \"Need REG30_BUILD and COLLAPSE\"\n",
        "    st.rotated_views = np.zeros((Q,3,30,2), dtype=np.float32)\n",
        "    st.parity_views = np.zeros((Q,3,30), dtype=np.int32)\n",
        "\n",
        "    if _should_active_only(st):\n",
        "        active_idx, _ = _get_active_indices_for_compute(st)\n",
        "        for v in range(3):\n",
        "            reg_a = tf.constant(st.reg30_views[active_idx, v], dtype=tf.float32)\n",
        "            coll_a = tf.constant(st.collapse_views[active_idx, v], dtype=tf.int32)\n",
        "            rot_a, par_a = apply_parity_rotation(reg_a, coll_a)\n",
        "            rot_a = rot_a.numpy().astype(np.float32)\n",
        "            par_a = par_a.numpy().astype(np.int32)\n",
        "            for i,q in enumerate(active_idx):\n",
        "                st.rotated_views[q,v] = rot_a[i]\n",
        "                st.parity_views[q,v] = par_a[i]\n",
        "    else:\n",
        "        for v in range(3):\n",
        "            reg = tf.constant(st.reg30_views[:,v], dtype=tf.float32)\n",
        "            coll = tf.constant(st.collapse_views[:,v], dtype=tf.int32)\n",
        "            rot, par = apply_parity_rotation(reg, coll)\n",
        "            st.rotated_views[:,v] = rot.numpy().astype(np.float32)\n",
        "            st.parity_views[:,v] = par.numpy().astype(np.int32)\n",
        "\n",
        "def op_BITMAP(st: ISAState):\n",
        "    assert st.rotated_views is not None, \"Need PARITY before BITMAP\"\n",
        "    st.bits_views = np.zeros((Q,3,30), dtype=np.int32)\n",
        "\n",
        "    if _should_active_only(st):\n",
        "        active_idx, alias_idx = _get_active_indices_for_compute(st)\n",
        "        # compute for active\n",
        "        for v in range(3):\n",
        "            rot_a = tf.constant(st.rotated_views[active_idx, v], dtype=tf.float32)\n",
        "            bits_a = bitmap(rot_a).numpy().astype(np.int32)\n",
        "            for i,q in enumerate(active_idx):\n",
        "                st.bits_views[q,v] = bits_a[i]\n",
        "        # fill aliases by copying winner bits\n",
        "        for q in alias_idx:\n",
        "            w = st.winner_of[q]\n",
        "            st.bits_views[q,:,:] = st.bits_views[w,:,:]\n",
        "    else:\n",
        "        for v in range(3):\n",
        "            rot = tf.constant(st.rotated_views[:,v], dtype=tf.float32)\n",
        "            st.bits_views[:,v] = bitmap(rot).numpy().astype(np.int32)\n",
        "\n",
        "def op_PACK(st: ISAState):\n",
        "    assert st.bits_views is not None, \"Need BITMAP before PACK\"\n",
        "    st.packed_views_u32 = np.zeros((Q,3), dtype=np.uint32)\n",
        "    for v in range(3):\n",
        "        st.packed_views_u32[:,v] = pack30_to_u32_tf(tf.constant(st.bits_views[:,v], dtype=tf.int32)).numpy().astype(np.uint32)\n",
        "    st.packed90_u64 = pack90_from_3x30_u32(st.packed_views_u32)\n",
        "\n",
        "def op_COMMIT(st: ISAState):\n",
        "    assert st.packed_views_u32 is not None and st.swapcount_xyz is not None, \"Need PACK and REG30_BUILD before COMMIT\"\n",
        "    st.commits = commit_full90(st.packed_views_u32,\n",
        "                              st.initiator.astype(np.uint8),\n",
        "                              st.swapcount_xyz.astype(np.uint8),\n",
        "                              st.instr_counter)\n",
        "    st.tags_u64 = np.array([tag_u64_from_commit(st.commits[q], q, st.instr_counter) for q in range(Q)], dtype=np.uint64)\n",
        "\n",
        "def op_DEDUP(st: ISAState):\n",
        "    assert st.commits is not None and len(st.commits) == Q, \"Need COMMIT before DEDUP\"\n",
        "    eff = st.swapcount_xyz.sum(axis=1).astype(np.int32)  # prototype efficiency\n",
        "    st.dedup = dedup_by_commit(st.commits, eff, st.mode)\n",
        "    st.active_mask = st.dedup.active_mask.copy()\n",
        "    st.winner_of = st.dedup.winner_of.copy()\n",
        "\n",
        "def op_FREE_ALIAS(st: ISAState):\n",
        "    \"\"\"\n",
        "    Correct semantics:\n",
        "      - PAIR_HUNT: aliases remain aliases (inactive) and inherit winner NEC state\n",
        "      - FREE: aliases are reassigned new NEC work AND become ACTIVE next epoch (dedup epoch resets)\n",
        "    \"\"\"\n",
        "    if st.dedup is None:\n",
        "        return\n",
        "\n",
        "    active_idx, alias_idx = _get_active_indices_for_compute(st)\n",
        "\n",
        "    if st.mode == \"PAIR_HUNT\":\n",
        "        for q in alias_idx:\n",
        "            w = st.winner_of[q]\n",
        "            st.mag_xyz[q] = st.mag_xyz[w]\n",
        "            st.base_sign[q] = st.base_sign[w]\n",
        "        # remain inactive\n",
        "    else:\n",
        "        # FREE: deterministically assign new NEC to alias qubits for next instruction and RE-ACTIVATE them\n",
        "        for q in alias_idx:\n",
        "            mags, signs = derive_new_nec_for_freed(st.commits[q], q, st.instr_counter + 1)\n",
        "            st.mag_xyz[q] = mags\n",
        "            st.base_sign[q] = signs\n",
        "\n",
        "        # reset dedup epoch: everyone active for new work next instruction\n",
        "        st.active_mask[:] = True\n",
        "        st.winner_of[:] = np.arange(Q, dtype=np.int32)\n",
        "        st.dedup = None\n",
        "\n",
        "def op_EXEC_ACTIVE_ONLY(st: ISAState, enabled: bool = True):\n",
        "    st.exec_active_only = bool(enabled)\n",
        "\n",
        "def op_NEXT(st: ISAState):\n",
        "    st.instr_counter += 1\n",
        "\n",
        "# -----------------------------\n",
        "# Interpreter dispatch\n",
        "# -----------------------------\n",
        "OP_TABLE = {\n",
        "    \"NEC_LOAD\": op_NEC_LOAD,\n",
        "    \"INIT_SELECT\": op_INIT_SELECT,\n",
        "    \"REG30_BUILD\": op_REG30_BUILD,\n",
        "    \"COLLAPSE\": op_COLLAPSE,\n",
        "    \"PARITY\": op_PARITY,\n",
        "    \"BITMAP\": op_BITMAP,\n",
        "    \"PACK\": op_PACK,\n",
        "    \"COMMIT\": op_COMMIT,\n",
        "    \"DEDUP\": op_DEDUP,\n",
        "    \"FREE_ALIAS\": op_FREE_ALIAS,\n",
        "    \"EXEC_ACTIVE_ONLY\": op_EXEC_ACTIVE_ONLY,\n",
        "    \"NEXT\": op_NEXT,\n",
        "}\n",
        "\n",
        "def run_program(st: ISAState, program: List[Instr], verbose: bool = True):\n",
        "    for ins in program:\n",
        "        fn = OP_TABLE.get(ins.op)\n",
        "        if fn is None:\n",
        "            raise ValueError(f\"Unknown opcode: {ins.op}\")\n",
        "        fn(st, **ins.args)\n",
        "\n",
        "        if verbose and ins.op in (\"REG30_BUILD\",\"PACK\",\"COMMIT\",\"DEDUP\",\"FREE_ALIAS\",\"NEXT\"):\n",
        "            if ins.op == \"REG30_BUILD\":\n",
        "                act = int(np.sum(st.active_mask))\n",
        "                print(f\"[t={st.instr_counter}] REG30_BUILD done. active={act} exec_active_only={st.exec_active_only} mode={st.mode}\")\n",
        "            elif ins.op == \"PACK\":\n",
        "                print(f\"[t={st.instr_counter}] PACK done. packed90_u64[0]={st.packed90_u64[0].tolist()}\")\n",
        "            elif ins.op == \"COMMIT\":\n",
        "                print(f\"[t={st.instr_counter}] COMMIT done. commit0={st.commits[0].hex()[:16]}...\")\n",
        "            elif ins.op == \"DEDUP\":\n",
        "                print(f\"[t={st.instr_counter}] DEDUP done. collisions={st.dedup.collision_qubits} groups={len(st.dedup.groups)} active={int(np.sum(st.active_mask))}\")\n",
        "            elif ins.op == \"FREE_ALIAS\":\n",
        "                aliases = Q - int(np.sum(st.active_mask))\n",
        "                print(f\"[t={st.instr_counter}] FREE/ALIAS applied. mode={st.mode} aliases_now={aliases} (FREE resets to 0 aliases next epoch)\")\n",
        "            elif ins.op == \"NEXT\":\n",
        "                print(f\"--- NEXT instr_counter={st.instr_counter} ---\")\n",
        "\n",
        "# -----------------------------\n",
        "# Demo program: 2 cycles\n",
        "# -----------------------------\n",
        "np.random.seed(11)\n",
        "tf.random.set_seed(11)\n",
        "\n",
        "st = ISAState(mode=\"PAIR_HUNT\", instr_counter=0, exec_active_only=True)  # exec_active_only only takes effect in PAIR_HUNT\n",
        "program = [\n",
        "    Instr(\"NEC_LOAD\", {\"seed\": 11}),\n",
        "    # cycle 0\n",
        "    Instr(\"INIT_SELECT\"),\n",
        "    Instr(\"REG30_BUILD\"),\n",
        "    Instr(\"COLLAPSE\"),\n",
        "    Instr(\"PARITY\"),\n",
        "    Instr(\"BITMAP\"),\n",
        "    Instr(\"PACK\"),\n",
        "    Instr(\"COMMIT\"),\n",
        "    Instr(\"DEDUP\"),\n",
        "    Instr(\"FREE_ALIAS\"),\n",
        "    Instr(\"NEXT\"),\n",
        "    # cycle 1\n",
        "    Instr(\"INIT_SELECT\"),\n",
        "    Instr(\"REG30_BUILD\"),\n",
        "    Instr(\"COLLAPSE\"),\n",
        "    Instr(\"PARITY\"),\n",
        "    Instr(\"BITMAP\"),\n",
        "    Instr(\"PACK\"),\n",
        "    Instr(\"COMMIT\"),\n",
        "    Instr(\"DEDUP\"),\n",
        "    Instr(\"FREE_ALIAS\"),\n",
        "    Instr(\"NEXT\"),\n",
        "]\n",
        "\n",
        "print(\"=== UniversalISA v0.6 Interpreter Demo ===\")\n",
        "print(\"MODE:\", st.mode, \"EXEC_ACTIVE_ONLY:\", st.exec_active_only, \"(only effective in PAIR_HUNT)\")\n",
        "run_program(st, program, verbose=True)\n",
        "\n",
        "print(\"\\n=== Final State Snapshot ===\")\n",
        "print(\"instr_counter:\", st.instr_counter)\n",
        "print(\"initiator axis counts:\", np.bincount(st.initiator, minlength=3).tolist(), \"(0=x,1=y,2=z)\")\n",
        "print(\"packed_views_u32[0]:\", st.packed_views_u32[0].tolist())\n",
        "print(\"packed90_u64[0]:\", st.packed90_u64[0].tolist())\n",
        "print(\"active qubits:\", int(np.sum(st.active_mask)), \"aliases:\", Q-int(np.sum(st.active_mask)))\n",
        "print(\"tag[0]:\", int(st.tags_u64[0]))\n",
        "print(\"Sample qubits (q, mag, sign, winner, active):\")\n",
        "for q in range(8):\n",
        "    print(q, st.mag_xyz[q].tolist(), st.base_sign[q].tolist(), int(st.winner_of[q]), bool(st.active_mask[q]))\n",
        "\n",
        "print(\"\\n--- If you want to see active-only savings, switch MODE to 'PAIR_HUNT' and rerun. ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOowgYR3sW-w",
        "outputId": "940db459-c6b3-4176-82eb-91f002cd6c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== UniversalISA v0.6 Interpreter Demo ===\n",
            "MODE: PAIR_HUNT EXEC_ACTIVE_ONLY: True (only effective in PAIR_HUNT)\n",
            "[t=0] REG30_BUILD done. active=64 exec_active_only=True mode=PAIR_HUNT\n",
            "[t=0] PACK done. packed90_u64[0]=[9232960233523929384, 525330]\n",
            "[t=0] COMMIT done. commit0=7ee6f4f8306e0b3f...\n",
            "[t=0] DEDUP done. collisions=15 groups=49 active=49\n",
            "[t=0] FREE/ALIAS applied. mode=PAIR_HUNT aliases_now=15 (FREE resets to 0 aliases next epoch)\n",
            "--- NEXT instr_counter=1 ---\n",
            "[t=1] REG30_BUILD done. active=49 exec_active_only=True mode=PAIR_HUNT\n",
            "[t=1] PACK done. packed90_u64[0]=[9232960233523929384, 525330]\n",
            "[t=1] COMMIT done. commit0=c1596df8c9ec1a9c...\n",
            "[t=1] DEDUP done. collisions=12 groups=52 active=52\n",
            "[t=1] FREE/ALIAS applied. mode=PAIR_HUNT aliases_now=12 (FREE resets to 0 aliases next epoch)\n",
            "--- NEXT instr_counter=2 ---\n",
            "\n",
            "=== Final State Snapshot ===\n",
            "instr_counter: 2\n",
            "initiator axis counts: [29, 12, 23] (0=x,1=y,2=z)\n",
            "packed_views_u32[0]: [8413480, 8929704, 8405288]\n",
            "packed90_u64[0]: [9232960233523929384, 525330]\n",
            "active qubits: 52 aliases: 12\n",
            "tag[0]: 15683781815185925009\n",
            "Sample qubits (q, mag, sign, winner, active):\n",
            "0 [8, 8, 51] [1, 1, 1] 0 True\n",
            "1 [31, 37, 38] [1, -1, -1] 1 True\n",
            "2 [45, 1, 31] [1, 1, -1] 2 True\n",
            "3 [9, 25, 59] [-1, 1, -1] 3 True\n",
            "4 [35, 4, 34] [-1, 1, 1] 4 True\n",
            "5 [8, 48, 60] [1, -1, 1] 5 True\n",
            "6 [62, 39, 55] [1, -1, -1] 6 True\n",
            "7 [23, 9, 32] [-1, 1, -1] 7 True\n",
            "\n",
            "--- If you want to see active-only savings, switch MODE to 'PAIR_HUNT' and rerun. ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UniversalISA v0.7 (Colab single-cell)\n",
        "# Major step toward v1.0 / Rust:\n",
        "#   - Removes TensorFlow entirely; uses only NumPy + Python stdlib (hashlib).\n",
        "#   - Keeps fixed shapes and explicit loops that map cleanly to Rust arrays/SIMD kernels.\n",
        "#   - Defines a minimal IR/opcode format + interpreter running an instruction stream.\n",
        "#   - Adds NEC-transforming \"work\" opcodes (NEC_ALU / PHASE_FLIP / ROT_AXES / XOR_SIGN / SHIFT_MAG).\n",
        "#   - Preserves: 3 initiator views => 90-bit payload per qubit (3×30-bit), commitments, DEDUP, FREE/ALIAS, PAIR_HUNT.\n",
        "#   - Preserves: triplet loops + scatter-style updates in COLLAPSE.\n",
        "#   - Preserves: add/sub-only reorderable (canonicalized); mul/div fixed.\n",
        "#\n",
        "# NOTE: This is still a prototype. Deterministic cross-CPU/GPU parity will require fixed-point or strict FP mode by v1.0.\n",
        "\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "# -----------------------------\n",
        "# Fixed ISA geometry (v1.0 target constants)\n",
        "# -----------------------------\n",
        "Q = 64\n",
        "AXES = 3\n",
        "VIEWS = 3\n",
        "SLOTS = 30\n",
        "TRIPLETS = 10\n",
        "EPS = 1e-6\n",
        "\n",
        "TAU_HI = 1.0\n",
        "TAU_LOW = -1.0\n",
        "R_FOR_RATIO = 64.0\n",
        "\n",
        "PRIME_MASK_30 = np.array(\n",
        "    [0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1],\n",
        "    dtype=np.uint8\n",
        ")\n",
        "\n",
        "TRIPLET_IDX = np.array([[3*t, 3*t+1, 3*t+2] for t in range(TRIPLETS)], dtype=np.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# IR / Instruction model\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class Instr:\n",
        "    op: str\n",
        "    args: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "# -----------------------------\n",
        "# Numpy helpers: packing\n",
        "# -----------------------------\n",
        "def pack30_to_u32_np(bits30_u8: np.ndarray) -> np.ndarray:\n",
        "    # bits30_u8: [Q,30] uint8 {0,1} -> [Q] uint32\n",
        "    shifts = (np.uint32(1) << np.arange(30, dtype=np.uint32))  # [30]\n",
        "    return (bits30_u8.astype(np.uint32) * shifts[None, :]).sum(axis=1).astype(np.uint32)\n",
        "\n",
        "def pack90_from_3x30_u32(packed3_u32: np.ndarray) -> np.ndarray:\n",
        "    # packed3_u32: [Q,3] uint32 -> [Q,2] uint64 (90 bits packed)\n",
        "    out = np.zeros((packed3_u32.shape[0], 2), dtype=np.uint64)\n",
        "    for q in range(packed3_u32.shape[0]):\n",
        "        b0 = np.uint64(packed3_u32[q,0] & np.uint32((1<<30)-1))\n",
        "        b1 = np.uint64(packed3_u32[q,1] & np.uint32((1<<30)-1))\n",
        "        b2 = np.uint64(packed3_u32[q,2] & np.uint32((1<<30)-1))\n",
        "        low = b0 | (b1 << np.uint64(30)) | ((b2 & np.uint64(0xF)) << np.uint64(60))\n",
        "        high = (b2 >> np.uint64(4))\n",
        "        out[q,0] = low\n",
        "        out[q,1] = high\n",
        "    return out\n",
        "\n",
        "def bitslice_30_np(bits30_u8: np.ndarray) -> np.ndarray:\n",
        "    # bits30_u8: [Q,30] -> [30] uint64 lane masks (Q<=64)\n",
        "    weights = (np.uint64(1) << np.arange(bits30_u8.shape[0], dtype=np.uint64))  # [Q]\n",
        "    return (bits30_u8.astype(np.uint64).T * weights[None,:]).sum(axis=1).astype(np.uint64)\n",
        "\n",
        "# -----------------------------\n",
        "# Phase-dual selector ops (component-wise)\n",
        "# -----------------------------\n",
        "def add_pd(a, b): return a + b\n",
        "def sub_pd(a, b): return a - b\n",
        "def mul_pd(a, b): return a * b\n",
        "def div_pd(a, b):\n",
        "    out = np.zeros_like(a, dtype=np.float32)\n",
        "    mask = np.abs(b) > EPS\n",
        "    out[mask] = a[mask] / b[mask]\n",
        "    return out\n",
        "\n",
        "# -----------------------------\n",
        "# NEC -> primaries (true phase-dual)\n",
        "# Each axis magnitude m yields:\n",
        "#   Real selector  = [+m, -m]\n",
        "#   Unreal selector= [-m, +m]\n",
        "# base_sign +1 => (Real, Unreal)\n",
        "# base_sign -1 => (Unreal, Real)\n",
        "# Output prim6: [Q,6,2] in canonical axis-pair order [X0,X1,Y0,Y1,Z0,Z1]\n",
        "# -----------------------------\n",
        "def build_primaries_from_nec(mag_xyz: np.ndarray, base_sign: np.ndarray) -> np.ndarray:\n",
        "    mag = mag_xyz.astype(np.float32)  # [Q,3]\n",
        "    # selectors per axis:\n",
        "    # real:  [+m, -m], unreal: [-m, +m]\n",
        "    real_sel = np.stack([mag, -mag], axis=2)   # [Q,3,2]\n",
        "    unrl_sel = np.stack([-mag, mag], axis=2)   # [Q,3,2]\n",
        "    sign_is_unreal = (base_sign < 0)           # [Q,3] bool\n",
        "\n",
        "    first = np.where(sign_is_unreal[:,:,None], unrl_sel, real_sel)   # [Q,3,2]\n",
        "    second= np.where(sign_is_unreal[:,:,None], real_sel, unrl_sel)   # [Q,3,2]\n",
        "\n",
        "    X0,X1 = first[:,0,:], second[:,0,:]\n",
        "    Y0,Y1 = first[:,1,:], second[:,1,:]\n",
        "    Z0,Z1 = first[:,2,:], second[:,2,:]\n",
        "\n",
        "    prim6 = np.stack([X0,X1,Y0,Y1,Z0,Z1], axis=1).astype(np.float32)  # [Q,6,2]\n",
        "    return prim6\n",
        "\n",
        "# -----------------------------\n",
        "# Initiator selection from shared magnitude counts (full-array rule)\n",
        "# Returns initiator axis per qubit in {0,1,2} for x,y,z\n",
        "# -----------------------------\n",
        "def initiator_from_shared_counts(mag_xyz: np.ndarray) -> np.ndarray:\n",
        "    mag = mag_xyz.astype(np.int32)  # [Q,3]\n",
        "    Qn = mag.shape[0]\n",
        "    counts = np.zeros((Qn,3), dtype=np.int32)\n",
        "    for ax in range(3):\n",
        "        v = mag[:,ax]\n",
        "        eq = (v[:,None] == v[None,:])\n",
        "        counts[:,ax] = eq.sum(axis=1)\n",
        "\n",
        "    shared = counts > 1\n",
        "    shared_count = shared.sum(axis=1)  # [Q]\n",
        "\n",
        "    # tie-break none-shared via bias x>y>z\n",
        "    bias = np.array([2,1,0], dtype=np.int32)\n",
        "    mags_biased = mag * 1000 + bias[None,:]\n",
        "\n",
        "    initiator = np.zeros((Qn,), dtype=np.int32)\n",
        "    for q in range(Qn):\n",
        "        if shared_count[q] == 1:\n",
        "            initiator[q] = int(np.argmax(counts[q]))\n",
        "        elif shared_count[q] == 2:\n",
        "            initiator[q] = int(np.argmax((counts[q] == 1).astype(np.int32)))\n",
        "        elif shared_count[q] == 3:\n",
        "            initiator[q] = int(np.argmax(counts[q]))\n",
        "        else:\n",
        "            initiator[q] = int(np.argmax(mags_biased[q]))\n",
        "    return initiator\n",
        "\n",
        "# -----------------------------\n",
        "# Primaries permutation by initiator (cyclic pairs)\n",
        "# prim6: [Q,6,2] in [X0,X1,Y0,Y1,Z0,Z1]\n",
        "# init x => [X0,X1,Y0,Y1,Z0,Z1]\n",
        "# init y => [Y0,Y1,Z0,Z1,X0,X1]\n",
        "# init z => [Z0,Z1,X0,X1,Y0,Y1]\n",
        "# -----------------------------\n",
        "def permute_primaries_by_initiator(prim6: np.ndarray, initiator_axis: np.ndarray) -> np.ndarray:\n",
        "    Qn = prim6.shape[0]\n",
        "    idx_x = np.array([0,1,2,3,4,5], dtype=np.int32)\n",
        "    idx_y = np.array([2,3,4,5,0,1], dtype=np.int32)\n",
        "    idx_z = np.array([4,5,0,1,2,3], dtype=np.int32)\n",
        "    out = np.empty_like(prim6)\n",
        "    for q in range(Qn):\n",
        "        a = initiator_axis[q]\n",
        "        if a == 0:\n",
        "            out[q] = prim6[q, idx_x]\n",
        "        elif a == 1:\n",
        "            out[q] = prim6[q, idx_y]\n",
        "        else:\n",
        "            out[q] = prim6[q, idx_z]\n",
        "    return out\n",
        "\n",
        "# -----------------------------\n",
        "# REG30 build (10 triplets):\n",
        "# Triplet0 = p0,p1,p2\n",
        "# Triplet1 = p3,p4,p5\n",
        "# Triplets2..9: [ADD(u,v), SUB(u,v), OP3(u,v)] where OP3 fixed MUL or DIV\n",
        "# Canonicalize: only ADD/SUB reorder (swap if SUB.real > ADD.real). MUL/DIV fixed.\n",
        "# Returns reg30 [Q,30,2], swap_flags [Q,8] uint8\n",
        "# -----------------------------\n",
        "def build_register30(prim6: np.ndarray, canonicalize_addsub: bool = True) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    p0,p1,p2,p3,p4,p5 = prim6[:,0],prim6[:,1],prim6[:,2],prim6[:,3],prim6[:,4],prim6[:,5]\n",
        "    A0,A1 = p0,p1\n",
        "    B0,B1 = p2,p3\n",
        "    C0,C1 = p4,p5\n",
        "\n",
        "    spec = [\n",
        "        (A0, B0, \"MUL\"),\n",
        "        (B0, C0, \"MUL\"),\n",
        "        (A0, C0, \"MUL\"),\n",
        "        (A1, B1, \"MUL\"),\n",
        "        (A0, B1, \"DIV\"),\n",
        "        (B0, C1, \"DIV\"),\n",
        "        (A1, C0, \"DIV\"),\n",
        "        (B1, C1, \"DIV\"),\n",
        "    ]\n",
        "\n",
        "    reg = np.empty((prim6.shape[0], 30, 2), dtype=np.float32)\n",
        "    swap_flags = np.zeros((prim6.shape[0], 8), dtype=np.uint8)\n",
        "\n",
        "    # primaries\n",
        "    reg[:,0:6,:] = np.stack([p0,p1,p2,p3,p4,p5], axis=1)\n",
        "\n",
        "    # interactions\n",
        "    cursor = 6\n",
        "    for i,(u,v,op3) in enumerate(spec):\n",
        "        addv = add_pd(u,v)\n",
        "        subv = sub_pd(u,v)\n",
        "        opv = mul_pd(u,v) if op3==\"MUL\" else div_pd(u,v)\n",
        "\n",
        "        if canonicalize_addsub:\n",
        "            swap = (subv[:,0] > addv[:,0])  # [Q] bool\n",
        "            swap_flags[:,i] = swap.astype(np.uint8)\n",
        "            add2 = np.where(swap[:,None], subv, addv)\n",
        "            sub2 = np.where(swap[:,None], addv, subv)\n",
        "            addv, subv = add2, sub2\n",
        "\n",
        "        reg[:,cursor+0,:] = addv\n",
        "        reg[:,cursor+1,:] = subv\n",
        "        reg[:,cursor+2,:] = opv\n",
        "        cursor += 3\n",
        "\n",
        "    return reg, swap_flags\n",
        "\n",
        "# -----------------------------\n",
        "# COLLAPSE (triplet loop + scatter-style update)\n",
        "# individual collapse predicate per slot:\n",
        "#   cond1 = real >= TAU_HI AND unreal <= TAU_LOW\n",
        "#   cond2 = (real/unreal) > R_FOR_RATIO (guarding near-zero unreal)\n",
        "# per triplet: if uniform, enforce uniform across that triplet; else keep individual\n",
        "# Returns collapse_mask [Q,30] uint8\n",
        "# -----------------------------\n",
        "def detect_collapse_triplet_scatter(pairs: np.ndarray) -> np.ndarray:\n",
        "    real = pairs[...,0]    # [Q,30]\n",
        "    unreal = pairs[...,1]  # [Q,30]\n",
        "    cond1 = (real >= TAU_HI) & (unreal <= TAU_LOW)\n",
        "\n",
        "    ratio = np.zeros_like(real, dtype=np.float32)\n",
        "    safe = np.abs(unreal) > EPS\n",
        "    ratio[safe] = real[safe] / unreal[safe]\n",
        "    cond2 = ratio > R_FOR_RATIO\n",
        "\n",
        "    individual = (cond1 | cond2)  # [Q,30] bool\n",
        "    final_mask = individual.astype(np.uint8).copy()\n",
        "\n",
        "    # triplet loop + scatter update\n",
        "    for t in range(TRIPLETS):\n",
        "        idx3 = TRIPLET_IDX[t]  # [3]\n",
        "        trip = individual[:, idx3]  # [Q,3] bool\n",
        "        is_uniform = np.all(trip == trip[:,0:1], axis=1)  # [Q] bool\n",
        "        uniform_val = trip[:,0].astype(np.uint8)          # [Q]\n",
        "\n",
        "        updates = np.where(is_uniform[:,None], np.tile(uniform_val[:,None], (1,3)), trip.astype(np.uint8))  # [Q,3]\n",
        "\n",
        "        q_idx = np.repeat(np.arange(individual.shape[0], dtype=np.int32), 3)\n",
        "        p_idx = np.tile(idx3.astype(np.int32), individual.shape[0])\n",
        "        final_mask[q_idx, p_idx] = updates.reshape(-1)\n",
        "\n",
        "    return final_mask\n",
        "\n",
        "# -----------------------------\n",
        "# PARITY + BITMAP\n",
        "# affected = prime OR collapse; sign flip on both components\n",
        "# bitmap bit=1 if rotated.real > EPS else 0\n",
        "# -----------------------------\n",
        "def apply_parity_rotation(pairs: np.ndarray, collapse: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    prime = np.broadcast_to(PRIME_MASK_30[None,:], collapse.shape).astype(np.uint8)\n",
        "    affected = ((prime > 0) | (collapse > 0)).astype(np.uint8)\n",
        "    sign = np.where(affected > 0, -1.0, 1.0).astype(np.float32)  # [Q,30]\n",
        "    rotated = pairs * sign[...,None]\n",
        "    return rotated.astype(np.float32), affected.astype(np.uint8)\n",
        "\n",
        "def bitmap(rotated_pairs: np.ndarray) -> np.ndarray:\n",
        "    return (rotated_pairs[...,0] > EPS).astype(np.uint8)  # [Q,30]\n",
        "\n",
        "# -----------------------------\n",
        "# Commit/tag/dedup/free\n",
        "# Commit includes: instr_counter + 3 view words + initiator + swapcounts\n",
        "# -----------------------------\n",
        "def commit_full90(packed_u32_xyz: np.ndarray,\n",
        "                  initiator_axis: np.ndarray,\n",
        "                  swapcount_xyz: np.ndarray,\n",
        "                  instr_counter: int,\n",
        "                  domain_sep: bytes = b\"NTHISA90\") -> List[bytes]:\n",
        "    commits = []\n",
        "    for q in range(packed_u32_xyz.shape[0]):\n",
        "        msg = (\n",
        "            domain_sep +\n",
        "            int(instr_counter).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,0]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,1]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(packed_u32_xyz[q,2]).to_bytes(4,\"little\",signed=False) +\n",
        "            int(initiator_axis[q]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,0]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,1]).to_bytes(1,\"little\",signed=False) +\n",
        "            int(swapcount_xyz[q,2]).to_bytes(1,\"little\",signed=False)\n",
        "        )\n",
        "        commits.append(hashlib.blake2s(msg, digest_size=32).digest())\n",
        "    return commits\n",
        "\n",
        "def tag_u64_from_commit(commit32: bytes, q_idx: int, instr_counter: int) -> np.uint64:\n",
        "    msg = b\"NTH_TAG0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    h = hashlib.blake2s(msg, digest_size=8).digest()\n",
        "    return np.uint64(int.from_bytes(h, \"little\", signed=False))\n",
        "\n",
        "@dataclass\n",
        "class DedupResult:\n",
        "    winner_of: np.ndarray\n",
        "    active_mask: np.ndarray\n",
        "    groups: Dict[bytes, List[int]]\n",
        "    freed: List[int]\n",
        "    collision_qubits: int\n",
        "\n",
        "def dedup_by_commit(commits: List[bytes], efficiency_score: np.ndarray, mode: str) -> DedupResult:\n",
        "    groups: Dict[bytes, List[int]] = {}\n",
        "    for q,c in enumerate(commits):\n",
        "        groups.setdefault(c, []).append(q)\n",
        "\n",
        "    winner_of = np.arange(len(commits), dtype=np.int32)\n",
        "    active_mask = np.ones(len(commits), dtype=bool)\n",
        "    freed: List[int] = []\n",
        "    collision_qubits = 0\n",
        "\n",
        "    for c, qs in groups.items():\n",
        "        if len(qs) > 1:\n",
        "            collision_qubits += (len(qs) - 1)\n",
        "        qs_sorted = sorted(qs, key=lambda q: (int(efficiency_score[q]), q))\n",
        "        w = qs_sorted[0]\n",
        "        for q in qs:\n",
        "            winner_of[q] = w\n",
        "            if q != w:\n",
        "                active_mask[q] = False\n",
        "                if mode == \"FREE\":\n",
        "                    freed.append(q)\n",
        "\n",
        "    return DedupResult(winner_of, active_mask, groups, freed, collision_qubits)\n",
        "\n",
        "def derive_new_nec_for_freed(commit32: bytes, q_idx: int, instr_counter: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    msg = b\"NTH_FREE0\" + commit32 + int(q_idx).to_bytes(2,\"little\",signed=False) + int(instr_counter).to_bytes(4,\"little\",signed=False)\n",
        "    raw = hashlib.blake2s(msg, digest_size=16).digest()\n",
        "    mags = np.array([raw[0] % 64, raw[1] % 64, raw[2] % 64], dtype=np.int32)\n",
        "    sb = raw[3]\n",
        "    signs = np.array([1 if (sb & 1) else -1, 1 if (sb & 2) else -1, 1 if (sb & 4) else -1], dtype=np.int32)\n",
        "    return mags, signs\n",
        "\n",
        "# -----------------------------\n",
        "# Interpreter state (Rust-friendly register file)\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class ISAState:\n",
        "    instr_counter: int = 0\n",
        "    mode: str = \"FREE\"                 # \"FREE\" or \"PAIR_HUNT\"\n",
        "    exec_active_only: bool = False     # only meaningful in PAIR_HUNT after DEDUP\n",
        "\n",
        "    # NEC registers\n",
        "    mag_xyz: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.int32))\n",
        "    base_sign: np.ndarray = field(default_factory=lambda: np.ones((Q,3), dtype=np.int32))\n",
        "\n",
        "    # Scheduling registers\n",
        "    dedup: Optional[DedupResult] = None\n",
        "    active_mask: np.ndarray = field(default_factory=lambda: np.ones((Q,), dtype=bool))\n",
        "    winner_of: np.ndarray = field(default_factory=lambda: np.arange(Q, dtype=np.int32))\n",
        "\n",
        "    # Derived registers (pipeline)\n",
        "    initiator: np.ndarray = field(default_factory=lambda: np.zeros((Q,), dtype=np.int32))             # [Q]\n",
        "    reg30_views: np.ndarray = field(default_factory=lambda: np.zeros((Q,3,30,2), dtype=np.float32))   # [Q,3,30,2]\n",
        "    swapflags_views: np.ndarray = field(default_factory=lambda: np.zeros((Q,3,8), dtype=np.uint8))    # [Q,3,8]\n",
        "    collapse_views: np.ndarray = field(default_factory=lambda: np.zeros((Q,3,30), dtype=np.uint8))    # [Q,3,30]\n",
        "    parity_views: np.ndarray = field(default_factory=lambda: np.zeros((Q,3,30), dtype=np.uint8))      # [Q,3,30]\n",
        "    rotated_views: np.ndarray = field(default_factory=lambda: np.zeros((Q,3,30,2), dtype=np.float32)) # [Q,3,30,2]\n",
        "    bits_views: np.ndarray = field(default_factory=lambda: np.zeros((Q,3,30), dtype=np.uint8))        # [Q,3,30]\n",
        "    packed_views_u32: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.uint32))    # [Q,3]\n",
        "    packed90_u64: np.ndarray = field(default_factory=lambda: np.zeros((Q,2), dtype=np.uint64))        # [Q,2]\n",
        "    swapcount_xyz: np.ndarray = field(default_factory=lambda: np.zeros((Q,3), dtype=np.uint8))        # [Q,3]\n",
        "    commits: List[bytes] = field(default_factory=lambda: [b\"\"]*Q)\n",
        "    tags_u64: np.ndarray = field(default_factory=lambda: np.zeros((Q,), dtype=np.uint64))\n",
        "\n",
        "    # Side-effect barrier: if True, forbid DEDUP optimization for this epoch\n",
        "    barrier: bool = False\n",
        "\n",
        "# -----------------------------\n",
        "# Helper: decide active-only compute\n",
        "# -----------------------------\n",
        "def should_active_only(st: ISAState) -> bool:\n",
        "    return st.exec_active_only and (st.dedup is not None) and (st.mode == \"PAIR_HUNT\") and (not st.barrier)\n",
        "\n",
        "# -----------------------------\n",
        "# Work opcodes (NEC-transforming)\n",
        "# These are the beginning of conventional ISA mapping.\n",
        "# They operate directly on NEC state (mag_xyz/base_sign), and are deterministic.\n",
        "# -----------------------------\n",
        "def nec_alu_mag(mag_xyz: np.ndarray, op: str, dst: int, src: int, imm: Optional[int] = None, mod: int = 64):\n",
        "    # op in {\"ADD\",\"SUB\",\"MUL\",\"DIV\",\"XOR\"} on magnitudes only\n",
        "    if imm is not None:\n",
        "        rhs = int(imm)\n",
        "        vec = mag_xyz[:,dst].astype(np.int32)\n",
        "        if op == \"ADD\":\n",
        "            mag_xyz[:,dst] = (vec + rhs) % mod\n",
        "        elif op == \"SUB\":\n",
        "            mag_xyz[:,dst] = (vec - rhs) % mod\n",
        "        elif op == \"MUL\":\n",
        "            mag_xyz[:,dst] = (vec * rhs) % mod\n",
        "        elif op == \"DIV\":\n",
        "            mag_xyz[:,dst] = (vec // max(rhs,1)) % mod\n",
        "        elif op == \"XOR\":\n",
        "            mag_xyz[:,dst] = (vec ^ rhs) % mod\n",
        "        else:\n",
        "            raise ValueError(op)\n",
        "        return\n",
        "\n",
        "    a = mag_xyz[:,dst].astype(np.int32)\n",
        "    b = mag_xyz[:,src].astype(np.int32)\n",
        "    if op == \"ADD\":\n",
        "        mag_xyz[:,dst] = (a + b) % mod\n",
        "    elif op == \"SUB\":\n",
        "        mag_xyz[:,dst] = (a - b) % mod\n",
        "    elif op == \"MUL\":\n",
        "        mag_xyz[:,dst] = (a * b) % mod\n",
        "    elif op == \"DIV\":\n",
        "        mag_xyz[:,dst] = (a // np.maximum(b,1)) % mod\n",
        "    elif op == \"XOR\":\n",
        "        mag_xyz[:,dst] = (a ^ b) % mod\n",
        "    else:\n",
        "        raise ValueError(op)\n",
        "\n",
        "def nec_phase_flip(base_sign: np.ndarray, axis: int):\n",
        "    base_sign[:,axis] *= -1\n",
        "\n",
        "def nec_rot_axes(mag_xyz: np.ndarray, base_sign: np.ndarray, direction: str = \"R\"):\n",
        "    # rotate (x,y,z) as a structural operation: shifts both mag and sign\n",
        "    if direction == \"R\":  # (x,y,z)->(z,x,y)\n",
        "        mag_xyz[:] = mag_xyz[:,[2,0,1]]\n",
        "        base_sign[:] = base_sign[:,[2,0,1]]\n",
        "    else:                # \"L\": (x,y,z)->(y,z,x)\n",
        "        mag_xyz[:] = mag_xyz[:,[1,2,0]]\n",
        "        base_sign[:] = base_sign[:,[1,2,0]]\n",
        "\n",
        "def nec_shift_mag(mag_xyz: np.ndarray, axis: int, sh: int, mod: int = 64):\n",
        "    # logical shift on magnitude (wrap mod); useful as prototype for SHL/SHR\n",
        "    if sh >= 0:\n",
        "        mag_xyz[:,axis] = ((mag_xyz[:,axis].astype(np.int32) << sh) % mod).astype(np.int32)\n",
        "    else:\n",
        "        mag_xyz[:,axis] = ((mag_xyz[:,axis].astype(np.int32) >> (-sh)) % mod).astype(np.int32)\n",
        "\n",
        "# -----------------------------\n",
        "# Pipeline stage ops (views + transcode)\n",
        "# -----------------------------\n",
        "def stage_INIT_SELECT(st: ISAState):\n",
        "    st.initiator = initiator_from_shared_counts(st.mag_xyz)\n",
        "\n",
        "def stage_REG30_BUILD(st: ISAState):\n",
        "    # Always compute initiator from full array before building views\n",
        "    stage_INIT_SELECT(st)\n",
        "\n",
        "    prim0 = build_primaries_from_nec(st.mag_xyz, st.base_sign)  # [Q,6,2]\n",
        "\n",
        "    # views always: x/y/z initiators (global)\n",
        "    init_x = np.zeros((Q,), dtype=np.int32)\n",
        "    init_y = np.ones((Q,), dtype=np.int32)\n",
        "    init_z = np.full((Q,), 2, dtype=np.int32)\n",
        "\n",
        "    active_only = should_active_only(st)\n",
        "    if active_only:\n",
        "        active_idx = np.where(st.active_mask)[0].astype(np.int32)\n",
        "        alias_idx = np.where(~st.active_mask)[0].astype(np.int32)\n",
        "\n",
        "        # Build only for active indices\n",
        "        prim0_a = prim0[active_idx]\n",
        "\n",
        "        for v,(initv) in enumerate([init_x, init_y, init_z]):\n",
        "            prim_v = permute_primaries_by_initiator(prim0_a, initv[active_idx])\n",
        "            reg30, swaps = build_register30(prim_v, canonicalize_addsub=True)\n",
        "            st.reg30_views[active_idx, v] = reg30\n",
        "            st.swapflags_views[active_idx, v] = swaps\n",
        "\n",
        "        # aliases left as zeros; will be filled later (PAIR_HUNT copies)\n",
        "    else:\n",
        "        for v,(initv) in enumerate([init_x, init_y, init_z]):\n",
        "            prim_v = permute_primaries_by_initiator(prim0, initv)\n",
        "            reg30, swaps = build_register30(prim_v, canonicalize_addsub=True)\n",
        "            st.reg30_views[:,v] = reg30\n",
        "            st.swapflags_views[:,v] = swaps\n",
        "\n",
        "    st.swapcount_xyz = st.swapflags_views.sum(axis=2).astype(np.uint8)  # [Q,3]\n",
        "\n",
        "def stage_COLLAPSE(st: ISAState):\n",
        "    active_only = should_active_only(st)\n",
        "    if active_only:\n",
        "        active_idx = np.where(st.active_mask)[0].astype(np.int32)\n",
        "        for v in range(3):\n",
        "            st.collapse_views[active_idx, v] = detect_collapse_triplet_scatter(st.reg30_views[active_idx, v])\n",
        "    else:\n",
        "        for v in range(3):\n",
        "            st.collapse_views[:, v] = detect_collapse_triplet_scatter(st.reg30_views[:, v])\n",
        "\n",
        "def stage_PARITY(st: ISAState):\n",
        "    active_only = should_active_only(st)\n",
        "    if active_only:\n",
        "        active_idx = np.where(st.active_mask)[0].astype(np.int32)\n",
        "        for v in range(3):\n",
        "            rot, par = apply_parity_rotation(st.reg30_views[active_idx, v], st.collapse_views[active_idx, v])\n",
        "            st.rotated_views[active_idx, v] = rot\n",
        "            st.parity_views[active_idx, v] = par\n",
        "    else:\n",
        "        for v in range(3):\n",
        "            rot, par = apply_parity_rotation(st.reg30_views[:, v], st.collapse_views[:, v])\n",
        "            st.rotated_views[:, v] = rot\n",
        "            st.parity_views[:, v] = par\n",
        "\n",
        "def stage_BITMAP(st: ISAState):\n",
        "    active_only = should_active_only(st)\n",
        "    if active_only:\n",
        "        active_idx = np.where(st.active_mask)[0].astype(np.int32)\n",
        "        alias_idx = np.where(~st.active_mask)[0].astype(np.int32)\n",
        "\n",
        "        for v in range(3):\n",
        "            st.bits_views[active_idx, v] = bitmap(st.rotated_views[active_idx, v])\n",
        "\n",
        "        # copy to aliases (PAIR_HUNT)\n",
        "        for q in alias_idx:\n",
        "            w = st.winner_of[q]\n",
        "            st.bits_views[q,:,:] = st.bits_views[w,:,:]\n",
        "    else:\n",
        "        for v in range(3):\n",
        "            st.bits_views[:, v] = bitmap(st.rotated_views[:, v])\n",
        "\n",
        "def stage_PACK(st: ISAState):\n",
        "    for v in range(3):\n",
        "        st.packed_views_u32[:,v] = pack30_to_u32_np(st.bits_views[:,v])\n",
        "    st.packed90_u64 = pack90_from_3x30_u32(st.packed_views_u32)\n",
        "\n",
        "def stage_COMMIT(st: ISAState):\n",
        "    st.commits = commit_full90(st.packed_views_u32,\n",
        "                              st.initiator.astype(np.uint8),\n",
        "                              st.swapcount_xyz.astype(np.uint8),\n",
        "                              st.instr_counter)\n",
        "    st.tags_u64 = np.array([tag_u64_from_commit(st.commits[q], q, st.instr_counter) for q in range(Q)], dtype=np.uint64)\n",
        "\n",
        "def stage_DEDUP(st: ISAState):\n",
        "    if st.barrier:\n",
        "        # If a side-effect barrier is active, do not dedup this epoch\n",
        "        st.dedup = None\n",
        "        st.active_mask[:] = True\n",
        "        st.winner_of[:] = np.arange(Q, dtype=np.int32)\n",
        "        return\n",
        "    eff = st.swapcount_xyz.sum(axis=1).astype(np.int32)\n",
        "    st.dedup = dedup_by_commit(st.commits, eff, st.mode)\n",
        "    st.active_mask = st.dedup.active_mask.copy()\n",
        "    st.winner_of = st.dedup.winner_of.copy()\n",
        "\n",
        "def stage_FREE_ALIAS(st: ISAState):\n",
        "    if st.dedup is None:\n",
        "        return\n",
        "\n",
        "    alias_idx = np.where(~st.active_mask)[0].astype(np.int32)\n",
        "    if st.mode == \"PAIR_HUNT\":\n",
        "        # aliases remain inactive and inherit winner NEC (stay paired)\n",
        "        for q in alias_idx:\n",
        "            w = st.winner_of[q]\n",
        "            st.mag_xyz[q] = st.mag_xyz[w]\n",
        "            st.base_sign[q] = st.base_sign[w]\n",
        "    else:\n",
        "        # FREE: assign new NEC work to aliases and reset epoch (everyone active next instruction)\n",
        "        for q in alias_idx:\n",
        "            mags, signs = derive_new_nec_for_freed(st.commits[q], q, st.instr_counter + 1)\n",
        "            st.mag_xyz[q] = mags\n",
        "            st.base_sign[q] = signs\n",
        "        st.active_mask[:] = True\n",
        "        st.winner_of[:] = np.arange(Q, dtype=np.int32)\n",
        "        st.dedup = None\n",
        "\n",
        "def stage_NEXT(st: ISAState):\n",
        "    st.instr_counter += 1\n",
        "    st.barrier = False  # barrier is per-epoch\n",
        "\n",
        "# -----------------------------\n",
        "# Opcode dispatch\n",
        "# -----------------------------\n",
        "def op_NEC_LOAD(st: ISAState, seed: int = 11, mag_range: int = 64):\n",
        "    rng = np.random.default_rng(seed + st.instr_counter)\n",
        "    st.mag_xyz[:] = rng.integers(0, mag_range, size=(Q,3), dtype=np.int32)\n",
        "    sb = rng.integers(0, 2, size=(Q,3), dtype=np.int32)\n",
        "    st.base_sign[:] = np.where(sb > 0, 1, -1).astype(np.int32)\n",
        "    st.active_mask[:] = True\n",
        "    st.winner_of[:] = np.arange(Q, dtype=np.int32)\n",
        "    st.dedup = None\n",
        "\n",
        "def op_NEC_ALU(st: ISAState, op: str, dst: int, src: Optional[int] = None, imm: Optional[int] = None, mod: int = 64):\n",
        "    if src is None and imm is None:\n",
        "        raise ValueError(\"NEC_ALU requires src or imm\")\n",
        "    nec_alu_mag(st.mag_xyz, op=op, dst=int(dst), src=int(src) if src is not None else 0, imm=imm, mod=mod)\n",
        "\n",
        "def op_PHASE_FLIP(st: ISAState, axis: int):\n",
        "    nec_phase_flip(st.base_sign, int(axis))\n",
        "\n",
        "def op_ROT_AXES(st: ISAState, direction: str = \"R\"):\n",
        "    nec_rot_axes(st.mag_xyz, st.base_sign, direction=direction)\n",
        "\n",
        "def op_SHIFT_MAG(st: ISAState, axis: int, sh: int):\n",
        "    nec_shift_mag(st.mag_xyz, axis=int(axis), sh=int(sh), mod=64)\n",
        "\n",
        "def op_BARRIER(st: ISAState):\n",
        "    # Side-effect barrier placeholder: forbids DEDUP optimization for this epoch.\n",
        "    st.barrier = True\n",
        "\n",
        "# Pipeline ops:\n",
        "def op_INIT_SELECT(st: ISAState): stage_INIT_SELECT(st)\n",
        "def op_REG30_BUILD(st: ISAState): stage_REG30_BUILD(st)\n",
        "def op_COLLAPSE(st: ISAState): stage_COLLAPSE(st)\n",
        "def op_PARITY(st: ISAState): stage_PARITY(st)\n",
        "def op_BITMAP(st: ISAState): stage_BITMAP(st)\n",
        "def op_PACK(st: ISAState): stage_PACK(st)\n",
        "def op_COMMIT(st: ISAState): stage_COMMIT(st)\n",
        "def op_DEDUP(st: ISAState): stage_DEDUP(st)\n",
        "def op_FREE_ALIAS(st: ISAState): stage_FREE_ALIAS(st)\n",
        "def op_EXEC_ACTIVE_ONLY(st: ISAState, enabled: bool = True): st.exec_active_only = bool(enabled)\n",
        "def op_NEXT(st: ISAState): stage_NEXT(st)\n",
        "\n",
        "OP_TABLE = {\n",
        "    \"NEC_LOAD\": op_NEC_LOAD,\n",
        "    \"NEC_ALU\": op_NEC_ALU,\n",
        "    \"PHASE_FLIP\": op_PHASE_FLIP,\n",
        "    \"ROT_AXES\": op_ROT_AXES,\n",
        "    \"SHIFT_MAG\": op_SHIFT_MAG,\n",
        "    \"BARRIER\": op_BARRIER,\n",
        "\n",
        "    \"INIT_SELECT\": op_INIT_SELECT,\n",
        "    \"REG30_BUILD\": op_REG30_BUILD,\n",
        "    \"COLLAPSE\": op_COLLAPSE,\n",
        "    \"PARITY\": op_PARITY,\n",
        "    \"BITMAP\": op_BITMAP,\n",
        "    \"PACK\": op_PACK,\n",
        "    \"COMMIT\": op_COMMIT,\n",
        "    \"DEDUP\": op_DEDUP,\n",
        "    \"FREE_ALIAS\": op_FREE_ALIAS,\n",
        "    \"EXEC_ACTIVE_ONLY\": op_EXEC_ACTIVE_ONLY,\n",
        "    \"NEXT\": op_NEXT,\n",
        "}\n",
        "\n",
        "def run_program(st: ISAState, program: List[Instr], verbose: bool = True):\n",
        "    for ins in program:\n",
        "        fn = OP_TABLE.get(ins.op)\n",
        "        if fn is None:\n",
        "            raise ValueError(f\"Unknown opcode: {ins.op}\")\n",
        "        fn(st, **ins.args)\n",
        "\n",
        "        if verbose and ins.op in (\"NEC_ALU\",\"PHASE_FLIP\",\"ROT_AXES\",\"SHIFT_MAG\",\"PACK\",\"COMMIT\",\"DEDUP\",\"FREE_ALIAS\",\"NEXT\"):\n",
        "            if ins.op in (\"NEC_ALU\",\"PHASE_FLIP\",\"ROT_AXES\",\"SHIFT_MAG\"):\n",
        "                print(f\"[t={st.instr_counter}] {ins.op} {ins.args}\")\n",
        "            elif ins.op == \"PACK\":\n",
        "                print(f\"[t={st.instr_counter}] PACK packed90[0]={st.packed90_u64[0].tolist()}\")\n",
        "            elif ins.op == \"COMMIT\":\n",
        "                print(f\"[t={st.instr_counter}] COMMIT commit0={st.commits[0].hex()[:16]}...\")\n",
        "            elif ins.op == \"DEDUP\":\n",
        "                if st.dedup is None:\n",
        "                    print(f\"[t={st.instr_counter}] DEDUP skipped (barrier). active={int(st.active_mask.sum())}\")\n",
        "                else:\n",
        "                    print(f\"[t={st.instr_counter}] DEDUP collisions={st.dedup.collision_qubits} groups={len(st.dedup.groups)} active={int(st.active_mask.sum())}\")\n",
        "            elif ins.op == \"FREE_ALIAS\":\n",
        "                aliases = Q - int(st.active_mask.sum())\n",
        "                print(f\"[t={st.instr_counter}] FREE_ALIAS mode={st.mode} aliases_now={aliases}\")\n",
        "            elif ins.op == \"NEXT\":\n",
        "                print(f\"--- NEXT instr_counter={st.instr_counter} ---\")\n",
        "\n",
        "# -----------------------------\n",
        "# Demo microprograms\n",
        "# -----------------------------\n",
        "def make_measurement_block() -> List[Instr]:\n",
        "    return [\n",
        "        Instr(\"REG30_BUILD\"),\n",
        "        Instr(\"COLLAPSE\"),\n",
        "        Instr(\"PARITY\"),\n",
        "        Instr(\"BITMAP\"),\n",
        "        Instr(\"PACK\"),\n",
        "        Instr(\"COMMIT\"),\n",
        "        Instr(\"DEDUP\"),\n",
        "        Instr(\"FREE_ALIAS\"),\n",
        "    ]\n",
        "\n",
        "# Example: \"x86-like\" ALU microprogram sketch (pure NEC ops)\n",
        "# We'll do:\n",
        "#   - LOAD NEC\n",
        "#   - (pretend) ADD x += y, XOR z ^= x, SHIFT y << 1, PHASE_FLIP x, ROT axes\n",
        "#   - measurement/transcode + dedup\n",
        "#   - next epoch, repeat with exec_active_only depending on mode\n",
        "program = [\n",
        "    Instr(\"NEC_LOAD\", {\"seed\": 11}),\n",
        "    Instr(\"EXEC_ACTIVE_ONLY\", {\"enabled\": True}),  # only impacts PAIR_HUNT mode after dedup\n",
        "    # instruction 0 \"work\":\n",
        "    Instr(\"NEC_ALU\", {\"op\":\"ADD\", \"dst\":0, \"src\":1}),     # x = x + y\n",
        "    Instr(\"NEC_ALU\", {\"op\":\"XOR\", \"dst\":2, \"src\":0}),     # z = z XOR x\n",
        "    Instr(\"SHIFT_MAG\", {\"axis\":1, \"sh\":1}),               # y <<= 1\n",
        "    Instr(\"PHASE_FLIP\", {\"axis\":0}),                      # flip x phase initiation\n",
        "    Instr(\"ROT_AXES\", {\"direction\":\"R\"}),                 # rotate axes (z,x,y)\n",
        "    *make_measurement_block(),\n",
        "    Instr(\"NEXT\"),\n",
        "\n",
        "    # instruction 1 \"work\": include a barrier to demonstrate dedup suppression\n",
        "    Instr(\"NEC_ALU\", {\"op\":\"MUL\", \"dst\":0, \"src\":2}),     # x = x * z (mod 64)\n",
        "    Instr(\"BARRIER\"),                                     # emulate a side-effectful op: skip dedup this epoch\n",
        "    *make_measurement_block(),\n",
        "    Instr(\"NEXT\"),\n",
        "]\n",
        "\n",
        "# -----------------------------\n",
        "# Run demo in FREE then in PAIR_HUNT\n",
        "# -----------------------------\n",
        "for mode in (\"FREE\", \"PAIR_HUNT\"):\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"UniversalISA v0.7 DEMO | MODE:\", mode)\n",
        "    st = ISAState(mode=mode, exec_active_only=True, instr_counter=0)\n",
        "    np.random.seed(11)\n",
        "    run_program(st, program, verbose=True)\n",
        "\n",
        "    print(\"\\n--- Final Snapshot ---\")\n",
        "    print(\"instr_counter:\", st.instr_counter, \"mode:\", st.mode, \"exec_active_only:\", st.exec_active_only)\n",
        "    print(\"initiator counts:\", np.bincount(st.initiator, minlength=3).tolist(), \"(0=x,1=y,2=z)\")\n",
        "    print(\"active:\", int(st.active_mask.sum()), \"aliases:\", Q-int(st.active_mask.sum()))\n",
        "    print(\"packed_views_u32[0]:\", st.packed_views_u32[0].tolist())\n",
        "    print(\"packed90_u64[0]:\", st.packed90_u64[0].tolist())\n",
        "    print(\"tag[0]:\", int(st.tags_u64[0]))\n",
        "    print(\"commit0:\", st.commits[0].hex()[:32], \"...\")\n",
        "    print(\"sample NEC (q0): mag\", st.mag_xyz[0].tolist(), \"sign\", st.base_sign[0].tolist(), \"winner\", int(st.winner_of[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IF-b6F2vvDy",
        "outputId": "5d854d16-fc96-48dd-a02b-df7fe647a43b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================\n",
            "UniversalISA v0.7 DEMO | MODE: FREE\n",
            "[t=0] NEC_ALU {'op': 'ADD', 'dst': 0, 'src': 1}\n",
            "[t=0] NEC_ALU {'op': 'XOR', 'dst': 2, 'src': 0}\n",
            "[t=0] SHIFT_MAG {'axis': 1, 'sh': 1}\n",
            "[t=0] PHASE_FLIP {'axis': 0}\n",
            "[t=0] ROT_AXES {'direction': 'R'}\n",
            "[t=0] PACK packed90[0]=[9306275394515781668, 37781656]\n",
            "[t=0] COMMIT commit0=d7dc49e8fdfca611...\n",
            "[t=0] DEDUP collisions=21 groups=43 active=43\n",
            "[t=0] FREE_ALIAS mode=FREE aliases_now=0\n",
            "--- NEXT instr_counter=1 ---\n",
            "[t=1] NEC_ALU {'op': 'MUL', 'dst': 0, 'src': 2}\n",
            "[t=1] PACK packed90[0]=[9306275394515781668, 37781656]\n",
            "[t=1] COMMIT commit0=dfc5fc05d1326fdc...\n",
            "[t=1] DEDUP skipped (barrier). active=64\n",
            "[t=1] FREE_ALIAS mode=FREE aliases_now=0\n",
            "--- NEXT instr_counter=2 ---\n",
            "\n",
            "--- Final Snapshot ---\n",
            "instr_counter: 2 mode: FREE exec_active_only: True\n",
            "initiator counts: [21, 26, 17] (0=x,1=y,2=z)\n",
            "active: 64 aliases: 0\n",
            "packed_views_u32[0]: [538069028, 77209768, 604506504]\n",
            "packed90_u64[0]: [9306275394515781668, 37781656]\n",
            "tag[0]: 2288642141128177132\n",
            "commit0: dfc5fc05d1326fdcd33a4b23383a27d2 ...\n",
            "sample NEC (q0): mag [48, 16, 16] sign [1, -1, 1] winner 0\n",
            "\n",
            "==============================\n",
            "UniversalISA v0.7 DEMO | MODE: PAIR_HUNT\n",
            "[t=0] NEC_ALU {'op': 'ADD', 'dst': 0, 'src': 1}\n",
            "[t=0] NEC_ALU {'op': 'XOR', 'dst': 2, 'src': 0}\n",
            "[t=0] SHIFT_MAG {'axis': 1, 'sh': 1}\n",
            "[t=0] PHASE_FLIP {'axis': 0}\n",
            "[t=0] ROT_AXES {'direction': 'R'}\n",
            "[t=0] PACK packed90[0]=[9306275394515781668, 37781656]\n",
            "[t=0] COMMIT commit0=d7dc49e8fdfca611...\n",
            "[t=0] DEDUP collisions=21 groups=43 active=43\n",
            "[t=0] FREE_ALIAS mode=PAIR_HUNT aliases_now=21\n",
            "--- NEXT instr_counter=1 ---\n",
            "[t=1] NEC_ALU {'op': 'MUL', 'dst': 0, 'src': 2}\n",
            "[t=1] PACK packed90[0]=[9306275394515781668, 37781656]\n",
            "[t=1] COMMIT commit0=dfc5fc05d1326fdc...\n",
            "[t=1] DEDUP skipped (barrier). active=64\n",
            "[t=1] FREE_ALIAS mode=PAIR_HUNT aliases_now=0\n",
            "--- NEXT instr_counter=2 ---\n",
            "\n",
            "--- Final Snapshot ---\n",
            "instr_counter: 2 mode: PAIR_HUNT exec_active_only: True\n",
            "initiator counts: [40, 11, 13] (0=x,1=y,2=z)\n",
            "active: 64 aliases: 0\n",
            "packed_views_u32[0]: [538069028, 77209768, 604506504]\n",
            "packed90_u64[0]: [9306275394515781668, 37781656]\n",
            "tag[0]: 2288642141128177132\n",
            "commit0: dfc5fc05d1326fdcd33a4b23383a27d2 ...\n",
            "sample NEC (q0): mag [48, 16, 16] sign [1, -1, 1] winner 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v0.8 Rust Refactor"
      ],
      "metadata": {
        "id": "7AyEdN0gznfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "```bash\n",
        "%%bash\n",
        "set -e\n",
        "\n",
        "# Ensure Rust toolchain\n",
        "if ! command -v cargo >/dev/null 2>&1; then\n",
        "  curl https://sh.rustup.rs -sSf | sh -s -- -y\n",
        "  source $HOME/.cargo/env\n",
        "fi\n",
        "\n",
        "rm -rf uisa_v08\n",
        "mkdir -p uisa_v08/src\n",
        "\n",
        "cat > uisa_v08/Cargo.toml <<'TOML'\n",
        "[package]\n",
        "name = \"uisa_v08\"\n",
        "version = \"0.8.1\"\n",
        "edition = \"2021\"\n",
        "\n",
        "[dependencies]\n",
        "blake2 = \"0.10\"\n",
        "TOML\n",
        "\n",
        "cat > uisa_v08/src/main.rs <<'RS'\n",
        "use blake2::{Blake2s256, Digest};\n",
        "use std::collections::HashMap;\n",
        "\n",
        "// ===========================\n",
        "// UniversalISA v0.8.1 Constants\n",
        "// ===========================\n",
        "const Q: usize = 64;\n",
        "const SLOTS: usize = 30;\n",
        "const VIEWS: usize = 3;\n",
        "const TRIPLETS: usize = 10;\n",
        "\n",
        "const EPS: f32 = 1e-6;\n",
        "const TAU_HI: f32 = 1.0;\n",
        "const TAU_LOW: f32 = -1.0;\n",
        "const R_FOR_RATIO: f32 = 64.0;\n",
        "\n",
        "const PRIME_MASK_30: [u8; 30] = [\n",
        "    0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1\n",
        "];\n",
        "\n",
        "fn triplet_idx(t: usize) -> [usize;3] { [3*t, 3*t+1, 3*t+2] }\n",
        "\n",
        "// ===========================\n",
        "// Typed GPR model: QubitMask\n",
        "// ===========================\n",
        "#[derive(Clone, Copy, Debug)]\n",
        "struct QubitMask(u64);\n",
        "\n",
        "impl QubitMask {\n",
        "    fn all() -> Self { QubitMask(!0u64) }\n",
        "    fn only(q: usize) -> Self { QubitMask(1u64 << q) }\n",
        "    fn contains(&self, q: usize) -> bool { ((self.0 >> q) & 1) != 0 }\n",
        "}\n",
        "\n",
        "// ===========================\n",
        "// Memory model (simulated + real controller skeleton)\n",
        "// ===========================\n",
        "struct SimMemory { buf: Vec<u8> }\n",
        "impl SimMemory {\n",
        "    fn new(size: usize) -> Self { Self { buf: vec![0u8; size] } }\n",
        "    fn read_u32(&self, addr: usize) -> u32 {\n",
        "        let b = &self.buf[addr..addr+4];\n",
        "        u32::from_le_bytes([b[0],b[1],b[2],b[3]])\n",
        "    }\n",
        "    fn write_u32(&mut self, addr: usize, v: u32) {\n",
        "        let b = v.to_le_bytes();\n",
        "        self.buf[addr..addr+4].copy_from_slice(&b);\n",
        "    }\n",
        "}\n",
        "\n",
        "trait MemoryController {\n",
        "    fn read(&self, addr: u64, len: usize) -> Vec<u8>;\n",
        "    fn write(&mut self, addr: u64, data: &[u8]);\n",
        "}\n",
        "struct PlaceholderMemController;\n",
        "impl MemoryController for PlaceholderMemController {\n",
        "    fn read(&self, _addr: u64, len: usize) -> Vec<u8> { vec![0u8; len] }\n",
        "    fn write(&mut self, _addr: u64, _data: &[u8]) {}\n",
        "}\n",
        "\n",
        "// ===========================\n",
        "// Canonical 16-byte Bytecode\n",
        "// ===========================\n",
        "#[repr(u8)]\n",
        "#[derive(Clone, Copy, Debug)]\n",
        "enum Opcode {\n",
        "    NecLoad = 0x01,\n",
        "    NecAlu  = 0x02,     // imm8: ADD=0,SUB=1,MUL=2,DIV=3,XOR=4, ADDI=5 uses imm32\n",
        "    PhaseFlip = 0x03,\n",
        "    RotAxes   = 0x04,   // imm8: 0=R,1=L\n",
        "    ShiftMag  = 0x05,   // imm32 shift signed\n",
        "    Barrier   = 0x06,\n",
        "\n",
        "    Pack       = 0x15,  // triggers fused stage_measure_transcode\n",
        "    Dedup      = 0x17,\n",
        "    FreeAlias  = 0x18,\n",
        "    Next       = 0x19,\n",
        "\n",
        "    LoadMemU32 = 0x20,  // aux32=addr, XOR into x magnitudes\n",
        "    StoreMemU32= 0x21,  // aux32=addr, store packed_views_u32[q,0] from first masked qubit\n",
        "}\n",
        "\n",
        "#[derive(Clone, Copy)]\n",
        "struct DecodedInstr {\n",
        "    op: Opcode,\n",
        "    flags: u8,\n",
        "    gpr_mask: usize,\n",
        "    dst_axis: u8,\n",
        "    src_axis: u8,\n",
        "    imm8: u8,\n",
        "    imm32: i32,\n",
        "    aux32: u32,\n",
        "}\n",
        "\n",
        "fn decode16(bytes: &[u8]) -> DecodedInstr {\n",
        "    assert!(bytes.len() == 16);\n",
        "    let op = match bytes[0] {\n",
        "        0x01 => Opcode::NecLoad,\n",
        "        0x02 => Opcode::NecAlu,\n",
        "        0x03 => Opcode::PhaseFlip,\n",
        "        0x04 => Opcode::RotAxes,\n",
        "        0x05 => Opcode::ShiftMag,\n",
        "        0x06 => Opcode::Barrier,\n",
        "        0x15 => Opcode::Pack,\n",
        "        0x17 => Opcode::Dedup,\n",
        "        0x18 => Opcode::FreeAlias,\n",
        "        0x19 => Opcode::Next,\n",
        "        0x20 => Opcode::LoadMemU32,\n",
        "        0x21 => Opcode::StoreMemU32,\n",
        "        _ => panic!(\"unknown opcode {}\", bytes[0]),\n",
        "    };\n",
        "    let flags = bytes[1];\n",
        "    let gpr_mask = bytes[2] as usize;\n",
        "    let dst_axis = bytes[3];\n",
        "    let src_axis = bytes[4];\n",
        "    let imm8 = bytes[5];\n",
        "    let imm32 = i32::from_le_bytes([bytes[8],bytes[9],bytes[10],bytes[11]]);\n",
        "    let aux32 = u32::from_le_bytes([bytes[12],bytes[13],bytes[14],bytes[15]]);\n",
        "    DecodedInstr { op, flags, gpr_mask, dst_axis, src_axis, imm8, imm32, aux32 }\n",
        "}\n",
        "\n",
        "fn emit(op: Opcode, flags: u8, gpr: u8, dst: u8, src: u8, imm8: u8, imm32: i32, aux32: u32) -> [u8;16] {\n",
        "    let mut b = [0u8;16];\n",
        "    b[0] = op as u8;\n",
        "    b[1] = flags;\n",
        "    b[2] = gpr;\n",
        "    b[3] = dst;\n",
        "    b[4] = src;\n",
        "    b[5] = imm8;\n",
        "    b[8..12].copy_from_slice(&imm32.to_le_bytes());\n",
        "    b[12..16].copy_from_slice(&aux32.to_le_bytes());\n",
        "    b\n",
        "}\n",
        "\n",
        "// ===========================\n",
        "// ISA State\n",
        "// ===========================\n",
        "#[derive(Clone)]\n",
        "struct ISAState {\n",
        "    instr_counter: u32,\n",
        "    mode_pair_hunt: bool,\n",
        "    exec_active_only: bool,\n",
        "    barrier: bool,\n",
        "\n",
        "    gpr_masks: [QubitMask; 8],\n",
        "\n",
        "    mag_xyz: [[i32;3]; Q],\n",
        "    base_sign: [[i32;3]; Q],\n",
        "\n",
        "    active_mask: [bool; Q],\n",
        "    winner_of: [usize; Q],\n",
        "\n",
        "    initiator: [u8; Q],\n",
        "\n",
        "    reg30_views: [[[[f32;2]; SLOTS]; VIEWS]; Q],\n",
        "    swapcount_xyz: [[u8;3]; Q],\n",
        "\n",
        "    collapse_views: [[[u8; SLOTS]; VIEWS]; Q],\n",
        "    parity_views:  [[[u8; SLOTS]; VIEWS]; Q],\n",
        "    rotated_views: [[[[f32;2]; SLOTS]; VIEWS]; Q],\n",
        "    bits_views:    [[[u8; SLOTS]; VIEWS]; Q],\n",
        "\n",
        "    packed_views_u32: [[u32;3]; Q],\n",
        "    packed90_u64: [[u64;2]; Q],\n",
        "\n",
        "    commits: [[u8;32]; Q],\n",
        "    tags_u64: [u64; Q],\n",
        "}\n",
        "\n",
        "impl ISAState {\n",
        "    fn new() -> Self {\n",
        "        ISAState {\n",
        "            instr_counter: 0,\n",
        "            mode_pair_hunt: false,\n",
        "            exec_active_only: false,\n",
        "            barrier: false,\n",
        "            gpr_masks: [QubitMask(0); 8],\n",
        "            mag_xyz: [[0;3]; Q],\n",
        "            base_sign: [[1;3]; Q],\n",
        "            active_mask: [true; Q],\n",
        "            winner_of: core::array::from_fn(|i| i),\n",
        "            initiator: [0u8; Q],\n",
        "            reg30_views: [[[[0.0;2]; SLOTS]; VIEWS]; Q],\n",
        "            swapcount_xyz: [[0u8;3]; Q],\n",
        "            collapse_views: [[[0u8; SLOTS]; VIEWS]; Q],\n",
        "            parity_views:  [[[0u8; SLOTS]; VIEWS]; Q],\n",
        "            rotated_views: [[[[0.0;2]; SLOTS]; VIEWS]; Q],\n",
        "            bits_views:    [[[0u8; SLOTS]; VIEWS]; Q],\n",
        "            packed_views_u32: [[0u32;3]; Q],\n",
        "            packed90_u64: [[0u64;2]; Q],\n",
        "            commits: [[0u8;32]; Q],\n",
        "            tags_u64: [0u64; Q],\n",
        "        }\n",
        "    }\n",
        "    fn active_only_allowed(&self) -> bool {\n",
        "        self.exec_active_only && self.mode_pair_hunt && !self.barrier\n",
        "    }\n",
        "}\n",
        "\n",
        "// ===========================\n",
        "// Core functions (subset of v0.7 in Rust)\n",
        "// ===========================\n",
        "fn initiator_from_shared_counts(mag: &[[i32;3]; Q], mask: QubitMask) -> [u8; Q] {\n",
        "    let mut init = [0u8; Q];\n",
        "    let mut counts = [[0i32;3]; Q];\n",
        "\n",
        "    for axis in 0..3 {\n",
        "        for q in 0..Q {\n",
        "            if !mask.contains(q) { continue; }\n",
        "            let v = mag[q][axis];\n",
        "            let mut c = 0i32;\n",
        "            for k in 0..Q {\n",
        "                if !mask.contains(k) { continue; }\n",
        "                if mag[k][axis] == v { c += 1; }\n",
        "            }\n",
        "            counts[q][axis] = c;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for q in 0..Q {\n",
        "        if !mask.contains(q) { continue; }\n",
        "        let cx = counts[q][0];\n",
        "        let cy = counts[q][1];\n",
        "        let cz = counts[q][2];\n",
        "        let shared = [cx>1, cy>1, cz>1];\n",
        "        let shared_count = shared.iter().filter(|&&b| b).count();\n",
        "\n",
        "        let argmax_counts = {\n",
        "            let mut best = 0usize;\n",
        "            let mut bestv = counts[q][0];\n",
        "            for a in 1..3 {\n",
        "                if counts[q][a] > bestv { best=a; bestv=counts[q][a]; }\n",
        "            }\n",
        "            best as u8\n",
        "        };\n",
        "\n",
        "        if shared_count == 1 {\n",
        "            init[q] = argmax_counts;\n",
        "        } else if shared_count == 2 {\n",
        "            let mut odd = 0usize;\n",
        "            for a in 0..3 {\n",
        "                if counts[q][a] == 1 { odd=a; break; }\n",
        "            }\n",
        "            init[q] = odd as u8;\n",
        "        } else if shared_count == 3 {\n",
        "            init[q] = argmax_counts;\n",
        "        } else {\n",
        "            // none shared: max magnitude tie-break x>y>z via bias (x=2,y=1,z=0)\n",
        "            let v0 = mag[q][0]*1000 + 2;\n",
        "            let v1 = mag[q][1]*1000 + 1;\n",
        "            let v2 = mag[q][2]*1000 + 0;\n",
        "            let mut best = 0usize;\n",
        "            let mut bestv = v0;\n",
        "            if v1 > bestv { best=1; bestv=v1; }\n",
        "            if v2 > bestv { best=2; bestv=v2; }\n",
        "            init[q] = best as u8;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    init\n",
        "}\n",
        "\n",
        "fn build_primaries_from_nec_for_qubit(mag: [i32;3], sign: [i32;3]) -> [[f32;2]; 6] {\n",
        "    let mut out = [[0.0f32;2]; 6];\n",
        "    for axis in 0..3 {\n",
        "        let m = mag[axis] as f32;\n",
        "        let real = [ m, -m];\n",
        "        let unrl = [-m,  m];\n",
        "        let (first, second) = if sign[axis] < 0 { (unrl, real) } else { (real, unrl) };\n",
        "        out[2*axis + 0] = first;\n",
        "        out[2*axis + 1] = second;\n",
        "    }\n",
        "    out\n",
        "}\n",
        "\n",
        "fn permute_primaries_by_initiator(prim6: [[f32;2];6], init_axis: u8) -> [[f32;2];6] {\n",
        "    let idx_x = [0usize,1,2,3,4,5];\n",
        "    let idx_y = [2usize,3,4,5,0,1];\n",
        "    let idx_z = [4usize,5,0,1,2,3];\n",
        "    let idx = match init_axis { 0 => idx_x, 1 => idx_y, _ => idx_z };\n",
        "    let mut out = [[0.0f32;2];6];\n",
        "    for i in 0..6 { out[i] = prim6[idx[i]]; }\n",
        "    out\n",
        "}\n",
        "\n",
        "fn add_pd(a: [f32;2], b: [f32;2]) -> [f32;2] { [a[0]+b[0], a[1]+b[1]] }\n",
        "fn sub_pd(a: [f32;2], b: [f32;2]) -> [f32;2] { [a[0]-b[0], a[1]-b[1]] }\n",
        "fn mul_pd(a: [f32;2], b: [f32;2]) -> [f32;2] { [a[0]*b[0], a[1]*b[1]] }\n",
        "fn div_pd(a: [f32;2], b: [f32;2]) -> [f32;2] {\n",
        "    let mut out = [0.0f32;2];\n",
        "    for i in 0..2 {\n",
        "        if b[i].abs() > EPS { out[i] = a[i] / b[i]; }\n",
        "    }\n",
        "    out\n",
        "}\n",
        "\n",
        "fn build_register30_for_qubit(prim6: [[f32;2];6], swap_sum_out: &mut u8) -> [[f32;2]; SLOTS] {\n",
        "    let (p0,p1,p2,p3,p4,p5) = (prim6[0],prim6[1],prim6[2],prim6[3],prim6[4],prim6[5]);\n",
        "    let (a0,a1) = (p0,p1);\n",
        "    let (b0,b1) = (p2,p3);\n",
        "    let (c0,c1) = (p4,p5);\n",
        "\n",
        "    let spec: [([f32;2],[f32;2],u8);8] = [\n",
        "        (a0,b0,0), (b0,c0,0), (a0,c0,0), (a1,b1,0),\n",
        "        (a0,b1,1), (b0,c1,1), (a1,c0,1), (b1,c1,1),\n",
        "    ];\n",
        "\n",
        "    let mut reg = [[0.0f32;2]; SLOTS];\n",
        "    reg[0]=p0; reg[1]=p1; reg[2]=p2; reg[3]=p3; reg[4]=p4; reg[5]=p5;\n",
        "\n",
        "    let mut cursor = 6usize;\n",
        "    let mut swap_sum = 0u8;\n",
        "    for (u,v,op3) in spec {\n",
        "        let addv = add_pd(u,v);\n",
        "        let subv = sub_pd(u,v);\n",
        "        let opv  = if op3==0 { mul_pd(u,v) } else { div_pd(u,v) };\n",
        "        let (first, second, swap) = if subv[0] > addv[0] { (subv, addv, 1u8) } else { (addv, subv, 0u8) };\n",
        "        swap_sum += swap;\n",
        "        reg[cursor+0] = first;\n",
        "        reg[cursor+1] = second;\n",
        "        reg[cursor+2] = opv;\n",
        "        cursor += 3;\n",
        "    }\n",
        "    *swap_sum_out = swap_sum;\n",
        "    reg\n",
        "}\n",
        "\n",
        "fn detect_collapse_triplet_scatter(pairs: &[[f32;2]; SLOTS]) -> [u8; SLOTS] {\n",
        "    let mut individual = [0u8; SLOTS];\n",
        "\n",
        "    for i in 0..SLOTS {\n",
        "        let real = pairs[i][0];\n",
        "        let unreal = pairs[i][1];\n",
        "        let cond1 = (real >= TAU_HI) && (unreal <= TAU_LOW);\n",
        "        let ratio = if unreal.abs() > EPS { real / unreal } else { 0.0 };\n",
        "        let cond2 = ratio > R_FOR_RATIO;\n",
        "        individual[i] = if cond1 || cond2 { 1 } else { 0 };\n",
        "    }\n",
        "\n",
        "    let mut final_mask = individual;\n",
        "    for t in 0..TRIPLETS {\n",
        "        let idx = triplet_idx(t);\n",
        "        let a = individual[idx[0]];\n",
        "        let b = individual[idx[1]];\n",
        "        let c = individual[idx[2]];\n",
        "        let uniform = (a==b) && (b==c);\n",
        "        if uniform {\n",
        "            final_mask[idx[0]] = a;\n",
        "            final_mask[idx[1]] = a;\n",
        "            final_mask[idx[2]] = a;\n",
        "        } else {\n",
        "            final_mask[idx[0]] = a;\n",
        "            final_mask[idx[1]] = b;\n",
        "            final_mask[idx[2]] = c;\n",
        "        }\n",
        "    }\n",
        "    final_mask\n",
        "}\n",
        "\n",
        "fn apply_parity_rotation(pairs: &[[f32;2]; SLOTS], collapse: &[u8; SLOTS]) -> ([[f32;2]; SLOTS], [u8; SLOTS]) {\n",
        "    let mut rotated = [[0.0f32;2]; SLOTS];\n",
        "    let mut parity = [0u8; SLOTS];\n",
        "    for i in 0..SLOTS {\n",
        "        let affected = (PRIME_MASK_30[i] > 0) || (collapse[i] > 0);\n",
        "        parity[i] = if affected { 1 } else { 0 };\n",
        "        let s = if affected { -1.0f32 } else { 1.0f32 };\n",
        "        rotated[i] = [pairs[i][0]*s, pairs[i][1]*s];\n",
        "    }\n",
        "    (rotated, parity)\n",
        "}\n",
        "\n",
        "fn bitmap(rotated: &[[f32;2]; SLOTS]) -> [u8; SLOTS] {\n",
        "    let mut bits = [0u8; SLOTS];\n",
        "    for i in 0..SLOTS { bits[i] = if rotated[i][0] > EPS { 1 } else { 0 }; }\n",
        "    bits\n",
        "}\n",
        "\n",
        "fn pack30_to_u32(bits: &[u8; SLOTS]) -> u32 {\n",
        "    let mut x = 0u32;\n",
        "    for i in 0..30 { x |= (bits[i] as u32) << i; }\n",
        "    x\n",
        "}\n",
        "\n",
        "fn pack90(b0: u32, b1: u32, b2: u32) -> (u64,u64) {\n",
        "    let b0 = (b0 & ((1u32<<30)-1)) as u64;\n",
        "    let b1 = (b1 & ((1u32<<30)-1)) as u64;\n",
        "    let b2 = (b2 & ((1u32<<30)-1)) as u64;\n",
        "    let low = b0 | (b1<<30) | ((b2 & 0xF)<<60);\n",
        "    let high = (b2 >> 4);\n",
        "    (low, high)\n",
        "}\n",
        "\n",
        "fn commit_full90(instr_counter: u32, w0: u32, w1: u32, w2: u32, initiator: u8, scx: u8, scy: u8, scz: u8) -> [u8;32] {\n",
        "    let mut h = Blake2s256::new();\n",
        "    h.update(b\"NTHISA90\");\n",
        "    h.update(&instr_counter.to_le_bytes());\n",
        "    h.update(&w0.to_le_bytes());\n",
        "    h.update(&w1.to_le_bytes());\n",
        "    h.update(&w2.to_le_bytes());\n",
        "    h.update(&[initiator, scx, scy, scz]);\n",
        "    let out = h.finalize();\n",
        "    let mut a = [0u8;32];\n",
        "    a.copy_from_slice(&out[..]);\n",
        "    a\n",
        "}\n",
        "\n",
        "fn tag_u64(commit: &[u8;32], q: usize, instr_counter: u32) -> u64 {\n",
        "    let mut h = Blake2s256::new();\n",
        "    h.update(b\"NTH_TAG0\");\n",
        "    h.update(commit);\n",
        "    h.update(&(q as u16).to_le_bytes());\n",
        "    h.update(&instr_counter.to_le_bytes());\n",
        "    let out = h.finalize();\n",
        "    u64::from_le_bytes(out[0..8].try_into().unwrap())\n",
        "}\n",
        "\n",
        "#[derive(Clone, Debug)]\n",
        "struct DedupInfo { collision_qubits: u32, groups: u32, active: u32, freed: u32 }\n",
        "\n",
        "fn dedup(commits: &[[u8;32]; Q], efficiency: &[u32; Q], mode_pair_hunt: bool, barrier: bool)\n",
        "    -> (Option<DedupInfo>, [bool; Q], [usize; Q])\n",
        "{\n",
        "    if barrier {\n",
        "        return (None, [true; Q], core::array::from_fn(|i| i));\n",
        "    }\n",
        "\n",
        "    let mut map: HashMap<[u8;32], Vec<usize>> = HashMap::new();\n",
        "    for q in 0..Q { map.entry(commits[q]).or_insert_with(Vec::new).push(q); }\n",
        "\n",
        "    let mut winner_of = core::array::from_fn(|i| i);\n",
        "    let mut active_mask = [true; Q];\n",
        "    let mut freed_count = 0u32;\n",
        "    let mut collision_qubits = 0u32;\n",
        "\n",
        "    for (_k, qs) in map.iter() {\n",
        "        if qs.len() > 1 { collision_qubits += (qs.len() as u32) - 1; }\n",
        "        let mut best = qs[0];\n",
        "        for &q in qs.iter() {\n",
        "            let eb = efficiency[best];\n",
        "            let eq = efficiency[q];\n",
        "            if (eq < eb) || (eq == eb && q < best) { best = q; }\n",
        "        }\n",
        "        for &q in qs.iter() {\n",
        "            winner_of[q] = best;\n",
        "            if q != best {\n",
        "                active_mask[q] = false;\n",
        "                if !mode_pair_hunt { freed_count += 1; }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    let info = DedupInfo {\n",
        "        collision_qubits,\n",
        "        groups: map.len() as u32,\n",
        "        active: active_mask.iter().filter(|&&b| b).count() as u32,\n",
        "        freed: freed_count,\n",
        "    };\n",
        "    (Some(info), active_mask, winner_of)\n",
        "}\n",
        "\n",
        "fn free_alias(st: &mut ISAState) {\n",
        "    if st.dedup.is_none() { return; }\n",
        "    if st.mode_pair_hunt {\n",
        "        for q in 0..Q {\n",
        "            if !st.active_mask[q] {\n",
        "                let w = st.winner_of[q];\n",
        "                st.mag_xyz[q] = st.mag_xyz[w];\n",
        "                st.base_sign[q] = st.base_sign[w];\n",
        "            }\n",
        "        }\n",
        "    } else {\n",
        "        for q in 0..Q {\n",
        "            if !st.active_mask[q] {\n",
        "                // derive new NEC from commit (deterministic)\n",
        "                let mut h = Blake2s256::new();\n",
        "                h.update(b\"NTH_FREE0\");\n",
        "                h.update(&st.commits[q]);\n",
        "                h.update(&(q as u16).to_le_bytes());\n",
        "                h.update(&(st.instr_counter + 1).to_le_bytes());\n",
        "                let out = h.finalize();\n",
        "                let m0 = (out[0] as i32) & 63;\n",
        "                let m1 = (out[1] as i32) & 63;\n",
        "                let m2 = (out[2] as i32) & 63;\n",
        "                let sb = out[3];\n",
        "                let s0 = if (sb & 1) != 0 { 1 } else { -1 };\n",
        "                let s1 = if (sb & 2) != 0 { 1 } else { -1 };\n",
        "                let s2 = if (sb & 4) != 0 { 1 } else { -1 };\n",
        "                st.mag_xyz[q] = [m0,m1,m2];\n",
        "                st.base_sign[q] = [s0,s1,s2];\n",
        "            }\n",
        "        }\n",
        "        st.active_mask = [true; Q];\n",
        "        st.winner_of = core::array::from_fn(|i| i);\n",
        "        st.dedup = None;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Fused stage triggered by PACK in bytecode\n",
        "fn stage_measure_transcode(st: &mut ISAState, mask: QubitMask) {\n",
        "    st.initiator = initiator_from_shared_counts(&st.mag_xyz, mask);\n",
        "\n",
        "    let active_only = st.active_only_allowed() && st.dedup.is_some();\n",
        "    let mut do_q = [true; Q];\n",
        "    if active_only {\n",
        "        for q in 0..Q { do_q[q] = st.active_mask[q] && mask.contains(q); }\n",
        "    } else {\n",
        "        for q in 0..Q { do_q[q] = mask.contains(q); }\n",
        "    }\n",
        "\n",
        "    for q in 0..Q {\n",
        "        if !do_q[q] { continue; }\n",
        "\n",
        "        let prim6 = build_primaries_from_nec_for_qubit(st.mag_xyz[q], st.base_sign[q]);\n",
        "\n",
        "        for v in 0..3 {\n",
        "            let prim_v = permute_primaries_by_initiator(prim6, v as u8);\n",
        "\n",
        "            let mut swap_sum = 0u8;\n",
        "            let reg30 = build_register30_for_qubit(prim_v, &mut swap_sum);\n",
        "            st.reg30_views[q][v] = reg30;\n",
        "            st.swapcount_xyz[q][v] = swap_sum;\n",
        "\n",
        "            let coll = detect_collapse_triplet_scatter(&st.reg30_views[q][v]);\n",
        "            st.collapse_views[q][v] = coll;\n",
        "\n",
        "            let (rot, par) = apply_parity_rotation(&st.reg30_views[q][v], &st.collapse_views[q][v]);\n",
        "            st.rotated_views[q][v] = rot;\n",
        "            st.parity_views[q][v] = par;\n",
        "\n",
        "            let bits = bitmap(&st.rotated_views[q][v]);\n",
        "            st.bits_views[q][v] = bits;\n",
        "\n",
        "            let w = pack30_to_u32(&st.bits_views[q][v]);\n",
        "            st.packed_views_u32[q][v] = w;\n",
        "        }\n",
        "\n",
        "        let (lo, hi) = pack90(st.packed_views_u32[q][0], st.packed_views_u32[q][1], st.packed_views_u32[q][2]);\n",
        "        st.packed90_u64[q] = [lo, hi];\n",
        "\n",
        "        let c = commit_full90(\n",
        "            st.instr_counter,\n",
        "            st.packed_views_u32[q][0], st.packed_views_u32[q][1], st.packed_views_u32[q][2],\n",
        "            st.initiator[q],\n",
        "            st.swapcount_xyz[q][0], st.swapcount_xyz[q][1], st.swapcount_xyz[q][2]\n",
        "        );\n",
        "        st.commits[q] = c;\n",
        "        st.tags_u64[q] = tag_u64(&st.commits[q], q, st.instr_counter);\n",
        "    }\n",
        "\n",
        "    // Fill aliases in PAIR_HUNT\n",
        "    if active_only && st.mode_pair_hunt {\n",
        "        for q in 0..Q {\n",
        "            if mask.contains(q) && !st.active_mask[q] {\n",
        "                let w = st.winner_of[q];\n",
        "                st.reg30_views[q] = st.reg30_views[w];\n",
        "                st.swapcount_xyz[q] = st.swapcount_xyz[w];\n",
        "                st.collapse_views[q] = st.collapse_views[w];\n",
        "                st.parity_views[q] = st.parity_views[w];\n",
        "                st.rotated_views[q] = st.rotated_views[w];\n",
        "                st.bits_views[q] = st.bits_views[w];\n",
        "                st.packed_views_u32[q] = st.packed_views_u32[w];\n",
        "                st.packed90_u64[q] = st.packed90_u64[w];\n",
        "                st.commits[q] = st.commits[w];\n",
        "                st.tags_u64[q] = tag_u64(&st.commits[w], q, st.instr_counter);\n",
        "                st.initiator[q] = st.initiator[w];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "fn exec_one(st: &mut ISAState, mem: &mut SimMemory, ins: DecodedInstr) {\n",
        "    let mask = st.gpr_masks[ins.gpr_mask.min(7)];\n",
        "    match ins.op {\n",
        "        Opcode::NecLoad => {\n",
        "            // deterministic load using aux32 seed\n",
        "            let mut x = (st.instr_counter as u64) ^ (ins.aux32 as u64) ^ 0x9E3779B97F4A7C15u64;\n",
        "            for q in 0..Q {\n",
        "                if !mask.contains(q) { continue; }\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                st.mag_xyz[q][0] = (x as i32) & 63;\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                st.mag_xyz[q][1] = (x as i32) & 63;\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                st.mag_xyz[q][2] = (x as i32) & 63;\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                let sb = (x as u8) & 7;\n",
        "                st.base_sign[q][0] = if (sb & 1)!=0 { 1 } else { -1 };\n",
        "                st.base_sign[q][1] = if (sb & 2)!=0 { 1 } else { -1 };\n",
        "                st.base_sign[q][2] = if (sb & 4)!=0 { 1 } else { -1 };\n",
        "            }\n",
        "            st.active_mask = [true; Q];\n",
        "            st.winner_of = core::array::from_fn(|i| i);\n",
        "            st.dedup = None;\n",
        "            st.barrier = false;\n",
        "        }\n",
        "        Opcode::NecAlu => {\n",
        "            let subop = ins.imm8;\n",
        "            let dst = (ins.dst_axis as usize).min(2);\n",
        "            let src = (ins.src_axis as usize).min(2);\n",
        "            let imm = ins.imm32;\n",
        "            for q in 0..Q {\n",
        "                if !mask.contains(q) { continue; }\n",
        "                let a = st.mag_xyz[q][dst];\n",
        "                let b = st.mag_xyz[q][src];\n",
        "                let v = match subop {\n",
        "                    0 => (a + b) & 63,\n",
        "                    1 => (a - b) & 63,\n",
        "                    2 => (a * b) & 63,\n",
        "                    3 => if b==0 { a } else { (a / b) & 63 },\n",
        "                    4 => (a ^ b) & 63,\n",
        "                    5 => (a + imm) & 63,\n",
        "                    _ => a,\n",
        "                };\n",
        "                st.mag_xyz[q][dst] = v;\n",
        "            }\n",
        "        }\n",
        "        Opcode::PhaseFlip => {\n",
        "            let axis = (ins.dst_axis as usize).min(2);\n",
        "            for q in 0..Q {\n",
        "                if !mask.contains(q) { continue; }\n",
        "                st.base_sign[q][axis] *= -1;\n",
        "            }\n",
        "        }\n",
        "        Opcode::RotAxes => {\n",
        "            let dir = ins.imm8;\n",
        "            for q in 0..Q {\n",
        "                if !mask.contains(q) { continue; }\n",
        "                if dir == 0 {\n",
        "                    let m = st.mag_xyz[q];\n",
        "                    let s = st.base_sign[q];\n",
        "                    st.mag_xyz[q] = [m[2], m[0], m[1]];\n",
        "                    st.base_sign[q] = [s[2], s[0], s[1]];\n",
        "                } else {\n",
        "                    let m = st.mag_xyz[q];\n",
        "                    let s = st.base_sign[q];\n",
        "                    st.mag_xyz[q] = [m[1], m[2], m[0]];\n",
        "                    st.base_sign[q] = [s[1], s[2], s[0]];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        Opcode::ShiftMag => {\n",
        "            let axis = (ins.dst_axis as usize).min(2);\n",
        "            let sh = ins.imm32;\n",
        "            for q in 0..Q {\n",
        "                if !mask.contains(q) { continue; }\n",
        "                let a = st.mag_xyz[q][axis];\n",
        "                let v = if sh >= 0 { (a << sh) & 63 } else { (a >> (-sh)) & 63 };\n",
        "                st.mag_xyz[q][axis] = v;\n",
        "            }\n",
        "        }\n",
        "        Opcode::Barrier => {\n",
        "            st.barrier = true;\n",
        "        }\n",
        "        Opcode::Pack => {\n",
        "            stage_measure_transcode(st, mask);\n",
        "        }\n",
        "        Opcode::Dedup => {\n",
        "            let mut eff = [0u32; Q];\n",
        "            for q in 0..Q {\n",
        "                eff[q] = (st.swapcount_xyz[q][0] as u32)\n",
        "                       + (st.swapcount_xyz[q][1] as u32)\n",
        "                       + (st.swapcount_xyz[q][2] as u32);\n",
        "            }\n",
        "            let (d, am, wo) = dedup(&st.commits, &eff, st.mode_pair_hunt, st.barrier);\n",
        "            st.dedup = d;\n",
        "            st.active_mask = am;\n",
        "            st.winner_of = wo;\n",
        "        }\n",
        "        Opcode::FreeAlias => free_alias(st),\n",
        "        Opcode::Next => {\n",
        "            st.instr_counter += 1;\n",
        "            st.barrier = false;\n",
        "        }\n",
        "        Opcode::LoadMemU32 => {\n",
        "            let addr = ins.aux32 as usize;\n",
        "            let v = mem.read_u32(addr) as i32;\n",
        "            for q in 0..Q {\n",
        "                if !mask.contains(q) { continue; }\n",
        "                st.mag_xyz[q][0] = (st.mag_xyz[q][0] ^ v) & 63;\n",
        "            }\n",
        "        }\n",
        "        Opcode::StoreMemU32 => {\n",
        "            let addr = ins.aux32 as usize;\n",
        "            let mut q0 = None;\n",
        "            for q in 0..Q {\n",
        "                if mask.contains(q) { q0 = Some(q); break; }\n",
        "            }\n",
        "            if let Some(qi) = q0 {\n",
        "                mem.write_u32(addr, st.packed_views_u32[qi][0]);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "fn exec_program(st: &mut ISAState, mem: &mut SimMemory, bytecode: &[u8]) {\n",
        "    assert!(bytecode.len() % 16 == 0);\n",
        "    for i in 0..(bytecode.len()/16) {\n",
        "        let ins = decode16(&bytecode[i*16..i*16+16]);\n",
        "        exec_one(st, mem, ins);\n",
        "    }\n",
        "}\n",
        "\n",
        "fn build_state_map(commits: &[[u8;32]; Q]) -> HashMap<[u8;32], Vec<usize>> {\n",
        "    let mut m: HashMap<[u8;32], Vec<usize>> = HashMap::new();\n",
        "    for q in 0..Q {\n",
        "        m.entry(commits[q]).or_insert_with(Vec::new).push(q);\n",
        "    }\n",
        "    m\n",
        "}\n",
        "\n",
        "fn main() {\n",
        "    let mut st = ISAState::new();\n",
        "    let mut mem = SimMemory::new(1024);\n",
        "\n",
        "    // Mode: FREE by default\n",
        "    st.mode_pair_hunt = false;\n",
        "    st.exec_active_only = true;\n",
        "\n",
        "    // GPR masks\n",
        "    st.gpr_masks[0] = QubitMask::all();\n",
        "    st.gpr_masks[1] = QubitMask::only(0);\n",
        "\n",
        "    // Build bytecode program\n",
        "    let mut bc: Vec<u8> = Vec::new();\n",
        "    bc.extend_from_slice(&emit(Opcode::NecLoad, 0, 0, 0,0,0, 0, 11));\n",
        "    bc.extend_from_slice(&emit(Opcode::NecAlu,  0, 0, 0,1,0, 0, 0));     // x += y\n",
        "    bc.extend_from_slice(&emit(Opcode::NecAlu,  0, 0, 2,0,4, 0, 0));     // z ^= x\n",
        "    bc.extend_from_slice(&emit(Opcode::ShiftMag,0, 0, 1,0,0,  1, 0));    // y <<= 1\n",
        "    bc.extend_from_slice(&emit(Opcode::PhaseFlip,0,0,0,0,0, 0, 0));      // flip x\n",
        "    bc.extend_from_slice(&emit(Opcode::RotAxes, 0, 0, 0,0,0, 0, 0));     // rotate R\n",
        "    bc.extend_from_slice(&emit(Opcode::Pack,    0, 0, 0,0,0, 0, 0));     // measure/transcode\n",
        "    bc.extend_from_slice(&emit(Opcode::Dedup,   0, 0, 0,0,0, 0, 0));\n",
        "    bc.extend_from_slice(&emit(Opcode::FreeAlias,0,0,0,0,0, 0, 0));\n",
        "    bc.extend_from_slice(&emit(Opcode::Next,    0, 0, 0,0,0, 0, 0));\n",
        "\n",
        "    bc.extend_from_slice(&emit(Opcode::NecAlu,  0, 0, 0,2,2, 0, 0));     // x *= z\n",
        "    bc.extend_from_slice(&emit(Opcode::Barrier, 0, 0, 0,0,0, 0, 0));     // barrier\n",
        "    bc.extend_from_slice(&emit(Opcode::Pack,    0, 0, 0,0,0, 0, 0));\n",
        "    bc.extend_from_slice(&emit(Opcode::Dedup,   0, 0, 0,0,0, 0, 0));\n",
        "    bc.extend_from_slice(&emit(Opcode::Next,    0, 0, 0,0,0, 0, 0));\n",
        "\n",
        "    exec_program(&mut st, &mut mem, &bc);\n",
        "\n",
        "    println!(\"=== UniversalISA v0.8.1 Rust Demo ===\");\n",
        "    println!(\"instr_counter: {}\", st.instr_counter);\n",
        "    println!(\"mode_pair_hunt: {} exec_active_only: {} barrier: {}\", st.mode_pair_hunt, st.exec_active_only, st.barrier);\n",
        "    println!(\"q0 NEC mag={:?} sign={:?}\", st.mag_xyz[0], st.base_sign[0]);\n",
        "    println!(\"q0 packed_views_u32={:?}\", st.packed_views_u32[0]);\n",
        "    println!(\"q0 packed90_u64={:?}\", st.packed90_u64[0]);\n",
        "    println!(\"q0 tag_u64={}\", st.tags_u64[0]);\n",
        "\n",
        "    let sm = build_state_map(&st.commits);\n",
        "    println!(\"state_groups: {}\", sm.len());\n",
        "    let mut best_len = 0usize;\n",
        "    let mut best_members: Vec<usize> = vec![];\n",
        "    for (_k, v) in sm.iter() {\n",
        "        if v.len() > best_len {\n",
        "            best_len = v.len();\n",
        "            best_members = v.clone();\n",
        "        }\n",
        "    }\n",
        "    println!(\"largest_group_size: {} members(sample)={:?}\", best_len, &best_members[..best_members.len().min(10)]);\n",
        "\n",
        "    let active_count = st.active_mask.iter().filter(|&&b| b).count();\n",
        "    println!(\"active_qubits: {} aliases: {}\", active_count, Q - active_count);\n",
        "}\n",
        "RS\n",
        "\n",
        "cd uisa_v08\n",
        "source $HOME/.cargo/env\n",
        "cargo run --release"
      ],
      "metadata": {
        "id": "mCuNK41z43kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two Cell Python Wrapped Rust Code for Test"
      ],
      "metadata": {
        "id": "qjBDlRyXLuPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 1 — Build + install the Rust Python module (uisa_v09)"
      ],
      "metadata": {
        "id": "UWE1jd1LLz4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "# ---- 0) toolchain prerequisites ----\n",
        "apt-get update -y >/dev/null\n",
        "apt-get install -y build-essential pkg-config >/dev/null\n",
        "\n",
        "# ---- 1) install rust if missing ----\n",
        "if ! command -v cargo >/dev/null 2>&1; then\n",
        "  curl https://sh.rustup.rs -sSf | sh -s -- -y\n",
        "fi\n",
        "source $HOME/.cargo/env\n",
        "\n",
        "# ---- 2) install maturin ----\n",
        "python3 -m pip -q install --upgrade pip\n",
        "python3 -m pip -q install maturin\n",
        "\n",
        "# ---- 3) write Rust project ----\n",
        "rm -rf uisa_v09\n",
        "mkdir -p uisa_v09/src\n",
        "\n",
        "cat > uisa_v09/Cargo.toml <<'TOML'\n",
        "[package]\n",
        "name = \"uisa_v09\"\n",
        "version = \"0.9.0\"\n",
        "edition = \"2021\"\n",
        "\n",
        "[lib]\n",
        "name = \"uisa_v09\"\n",
        "crate-type = [\"cdylib\"]\n",
        "\n",
        "[dependencies]\n",
        "pyo3 = { version = \"0.21\", features = [\"extension-module\"] }\n",
        "blake2 = \"0.10\"\n",
        "TOML\n",
        "\n",
        "cat > uisa_v09/src/lib.rs <<'RS'\n",
        "use blake2::{Blake2s256, Digest};\n",
        "use pyo3::prelude::*;\n",
        "use std::collections::HashMap;\n",
        "\n",
        "const Q: usize = 64;\n",
        "const SLOTS: usize = 30;\n",
        "const VIEWS: usize = 3;\n",
        "const TRIPLETS: usize = 10;\n",
        "\n",
        "const EPS: f32 = 1e-6;\n",
        "const TAU_HI: f32 = 1.0;\n",
        "const TAU_LOW: f32 = -1.0;\n",
        "const R_FOR_RATIO: f32 = 64.0;\n",
        "\n",
        "const PRIME_MASK_30: [u8; 30] = [\n",
        "    0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1\n",
        "];\n",
        "\n",
        "fn triplet_idx(t: usize) -> [usize;3] { [3*t, 3*t+1, 3*t+2] }\n",
        "\n",
        "// 16-byte instruction decode\n",
        "#[repr(u8)]\n",
        "#[derive(Clone, Copy, Debug)]\n",
        "enum Opcode {\n",
        "    NecLoad = 0x01,\n",
        "    NecAlu  = 0x02,     // imm8: ADD=0,SUB=1,MUL=2,DIV=3,XOR=4, ADDI=5 uses imm32\n",
        "    PhaseFlip = 0x03,\n",
        "    RotAxes   = 0x04,   // imm8: 0=R,1=L\n",
        "    ShiftMag  = 0x05,   // imm32 signed shift\n",
        "    Barrier   = 0x06,\n",
        "\n",
        "    Pack       = 0x15,  // fused measure/transcode\n",
        "    Dedup      = 0x17,\n",
        "    FreeAlias  = 0x18,\n",
        "    Next       = 0x19,\n",
        "\n",
        "    MemLoadU32 = 0x20,  // aux32=addr, XOR into x magnitudes\n",
        "    MemStoreU32= 0x21,  // aux32=addr, store packed_views_u32[q,0] from first qubit\n",
        "}\n",
        "\n",
        "#[derive(Clone, Copy)]\n",
        "struct DecodedInstr {\n",
        "    op: Opcode,\n",
        "    gpr_mask: u8,       // reserved for v1.0 masks; v0.9 uses mask=all\n",
        "    dst_axis: u8,\n",
        "    src_axis: u8,\n",
        "    imm8: u8,\n",
        "    imm32: i32,\n",
        "    aux32: u32,\n",
        "}\n",
        "\n",
        "fn decode16(bytes: &[u8]) -> DecodedInstr {\n",
        "    assert!(bytes.len() == 16);\n",
        "    let op = match bytes[0] {\n",
        "        0x01 => Opcode::NecLoad,\n",
        "        0x02 => Opcode::NecAlu,\n",
        "        0x03 => Opcode::PhaseFlip,\n",
        "        0x04 => Opcode::RotAxes,\n",
        "        0x05 => Opcode::ShiftMag,\n",
        "        0x06 => Opcode::Barrier,\n",
        "        0x15 => Opcode::Pack,\n",
        "        0x17 => Opcode::Dedup,\n",
        "        0x18 => Opcode::FreeAlias,\n",
        "        0x19 => Opcode::Next,\n",
        "        0x20 => Opcode::MemLoadU32,\n",
        "        0x21 => Opcode::MemStoreU32,\n",
        "        _ => panic!(\"unknown opcode {}\", bytes[0]),\n",
        "    };\n",
        "    let gpr_mask = bytes[2];\n",
        "    let dst_axis = bytes[3];\n",
        "    let src_axis = bytes[4];\n",
        "    let imm8 = bytes[5];\n",
        "    let imm32 = i32::from_le_bytes([bytes[8],bytes[9],bytes[10],bytes[11]]);\n",
        "    let aux32 = u32::from_le_bytes([bytes[12],bytes[13],bytes[14],bytes[15]]);\n",
        "    DecodedInstr { op, gpr_mask, dst_axis, src_axis, imm8, imm32, aux32 }\n",
        "}\n",
        "\n",
        "// ===========================\n",
        "// SimMemory (used in Colab tests)\n",
        "// ===========================\n",
        "#[derive(Clone)]\n",
        "struct SimMemory { buf: Vec<u8> }\n",
        "impl SimMemory {\n",
        "    fn new(size: usize) -> Self { Self { buf: vec![0u8; size] } }\n",
        "    fn read_u32(&self, addr: usize) -> u32 {\n",
        "        let b = &self.buf[addr..addr+4];\n",
        "        u32::from_le_bytes([b[0],b[1],b[2],b[3]])\n",
        "    }\n",
        "    fn write_u32(&mut self, addr: usize, v: u32) {\n",
        "        let b = v.to_le_bytes();\n",
        "        self.buf[addr..addr+4].copy_from_slice(&b);\n",
        "    }\n",
        "}\n",
        "\n",
        "// ===========================\n",
        "// ISA core state (Rust-native)\n",
        "// ===========================\n",
        "#[derive(Clone)]\n",
        "struct ISA {\n",
        "    instr_counter: u32,\n",
        "    mode_pair_hunt: bool,\n",
        "    exec_active_only: bool,\n",
        "    barrier: bool,\n",
        "\n",
        "    // NEC state\n",
        "    mag_xyz: [[i32;3]; Q],\n",
        "    base_sign: [[i32;3]; Q],\n",
        "\n",
        "    // scheduling\n",
        "    active_mask: [bool; Q],\n",
        "    winner_of: [usize; Q],\n",
        "\n",
        "    // derived\n",
        "    initiator: [u8; Q],\n",
        "    swapcount_xyz: [[u8;3]; Q],\n",
        "    packed_views_u32: [[u32;3]; Q],\n",
        "    packed90_u64: [[u64;2]; Q],\n",
        "    commits: [[u8;32]; Q],\n",
        "}\n",
        "\n",
        "impl ISA {\n",
        "    fn new(mode_pair_hunt: bool, exec_active_only: bool) -> Self {\n",
        "        Self {\n",
        "            instr_counter: 0,\n",
        "            mode_pair_hunt,\n",
        "            exec_active_only,\n",
        "            barrier: false,\n",
        "            mag_xyz: [[0;3]; Q],\n",
        "            base_sign: [[1;3]; Q],\n",
        "            active_mask: [true; Q],\n",
        "            winner_of: core::array::from_fn(|i| i),\n",
        "            initiator: [0u8; Q],\n",
        "            swapcount_xyz: [[0u8;3]; Q],\n",
        "            packed_views_u32: [[0u32;3]; Q],\n",
        "            packed90_u64: [[0u64;2]; Q],\n",
        "            commits: [[0u8;32]; Q],\n",
        "        }\n",
        "    }\n",
        "\n",
        "    fn active_only_allowed(&self) -> bool {\n",
        "        self.exec_active_only && self.mode_pair_hunt && !self.barrier\n",
        "    }\n",
        "}\n",
        "\n",
        "// ===========================\n",
        "// Math / Nth pipeline primitives\n",
        "// ===========================\n",
        "fn initiator_from_shared_counts(mag: &[[i32;3]; Q]) -> [u8; Q] {\n",
        "    let mut init = [0u8; Q];\n",
        "    let mut counts = [[0i32;3]; Q];\n",
        "\n",
        "    for axis in 0..3 {\n",
        "        for q in 0..Q {\n",
        "            let v = mag[q][axis];\n",
        "            let mut c = 0i32;\n",
        "            for k in 0..Q {\n",
        "                if mag[k][axis] == v { c += 1; }\n",
        "            }\n",
        "            counts[q][axis] = c;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for q in 0..Q {\n",
        "        let cx = counts[q][0];\n",
        "        let cy = counts[q][1];\n",
        "        let cz = counts[q][2];\n",
        "        let shared = [cx>1, cy>1, cz>1];\n",
        "        let shared_count = shared.iter().filter(|&&b| b).count();\n",
        "\n",
        "        let argmax_counts = {\n",
        "            let mut best = 0usize;\n",
        "            let mut bestv = counts[q][0];\n",
        "            for a in 1..3 {\n",
        "                if counts[q][a] > bestv { best=a; bestv=counts[q][a]; }\n",
        "            }\n",
        "            best as u8\n",
        "        };\n",
        "\n",
        "        if shared_count == 1 {\n",
        "            init[q] = argmax_counts;\n",
        "        } else if shared_count == 2 {\n",
        "            let mut odd = 0usize;\n",
        "            for a in 0..3 { if counts[q][a] == 1 { odd=a; break; } }\n",
        "            init[q] = odd as u8;\n",
        "        } else if shared_count == 3 {\n",
        "            init[q] = argmax_counts;\n",
        "        } else {\n",
        "            let v0 = mag[q][0]*1000 + 2;\n",
        "            let v1 = mag[q][1]*1000 + 1;\n",
        "            let v2 = mag[q][2]*1000 + 0;\n",
        "            let mut best = 0usize;\n",
        "            let mut bestv = v0;\n",
        "            if v1 > bestv { best=1; bestv=v1; }\n",
        "            if v2 > bestv { best=2; bestv=v2; }\n",
        "            init[q] = best as u8;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    init\n",
        "}\n",
        "\n",
        "fn build_primaries_from_nec_for_qubit(mag: [i32;3], sign: [i32;3]) -> [[f32;2]; 6] {\n",
        "    let mut out = [[0.0f32;2]; 6];\n",
        "    for axis in 0..3 {\n",
        "        let m = mag[axis] as f32;\n",
        "        let real = [ m, -m];\n",
        "        let unrl = [-m,  m];\n",
        "        let (first, second) = if sign[axis] < 0 { (unrl, real) } else { (real, unrl) };\n",
        "        out[2*axis + 0] = first;\n",
        "        out[2*axis + 1] = second;\n",
        "    }\n",
        "    out\n",
        "}\n",
        "\n",
        "fn permute_primaries_by_initiator(prim6: [[f32;2];6], init_axis: u8) -> [[f32;2];6] {\n",
        "    let idx_x = [0usize,1,2,3,4,5];\n",
        "    let idx_y = [2usize,3,4,5,0,1];\n",
        "    let idx_z = [4usize,5,0,1,2,3];\n",
        "    let idx = match init_axis { 0 => idx_x, 1 => idx_y, _ => idx_z };\n",
        "    let mut out = [[0.0f32;2];6];\n",
        "    for i in 0..6 { out[i] = prim6[idx[i]]; }\n",
        "    out\n",
        "}\n",
        "\n",
        "fn add_pd(a: [f32;2], b: [f32;2]) -> [f32;2] { [a[0]+b[0], a[1]+b[1]] }\n",
        "fn sub_pd(a: [f32;2], b: [f32;2]) -> [f32;2] { [a[0]-b[0], a[1]-b[1]] }\n",
        "fn mul_pd(a: [f32;2], b: [f32;2]) -> [f32;2] { [a[0]*b[0], a[1]*b[1]] }\n",
        "fn div_pd(a: [f32;2], b: [f32;2]) -> [f32;2] {\n",
        "    let mut out = [0.0f32;2];\n",
        "    for i in 0..2 { if b[i].abs() > EPS { out[i] = a[i] / b[i]; } }\n",
        "    out\n",
        "}\n",
        "\n",
        "// REG30 build (10 triplets) with add/sub-only canonicalization\n",
        "fn build_register30_for_qubit(prim6: [[f32;2];6], swap_sum_out: &mut u8) -> [[f32;2]; SLOTS] {\n",
        "    let (p0,p1,p2,p3,p4,p5) = (prim6[0],prim6[1],prim6[2],prim6[3],prim6[4],prim6[5]);\n",
        "    let (a0,a1) = (p0,p1);\n",
        "    let (b0,b1) = (p2,p3);\n",
        "    let (c0,c1) = (p4,p5);\n",
        "\n",
        "    let spec: [([f32;2],[f32;2],u8);8] = [\n",
        "        (a0,b0,0), (b0,c0,0), (a0,c0,0), (a1,b1,0),\n",
        "        (a0,b1,1), (b0,c1,1), (a1,c0,1), (b1,c1,1),\n",
        "    ];\n",
        "\n",
        "    let mut reg = [[0.0f32;2]; SLOTS];\n",
        "    reg[0]=p0; reg[1]=p1; reg[2]=p2; reg[3]=p3; reg[4]=p4; reg[5]=p5;\n",
        "\n",
        "    let mut cursor = 6usize;\n",
        "    let mut swap_sum = 0u8;\n",
        "    for (u,v,op3) in spec {\n",
        "        let addv = add_pd(u,v);\n",
        "        let subv = sub_pd(u,v);\n",
        "        let opv  = if op3==0 { mul_pd(u,v) } else { div_pd(u,v) };\n",
        "        let (first, second, swap) = if subv[0] > addv[0] { (subv, addv, 1u8) } else { (addv, subv, 0u8) };\n",
        "        swap_sum += swap;\n",
        "        reg[cursor+0] = first;\n",
        "        reg[cursor+1] = second;\n",
        "        reg[cursor+2] = opv;\n",
        "        cursor += 3;\n",
        "    }\n",
        "    *swap_sum_out = swap_sum;\n",
        "    reg\n",
        "}\n",
        "\n",
        "fn detect_collapse_triplet_scatter(pairs: &[[f32;2]; SLOTS]) -> [u8; SLOTS] {\n",
        "    let mut individual = [0u8; SLOTS];\n",
        "    for i in 0..SLOTS {\n",
        "        let real = pairs[i][0];\n",
        "        let unreal = pairs[i][1];\n",
        "        let cond1 = (real >= TAU_HI) && (unreal <= TAU_LOW);\n",
        "        let ratio = if unreal.abs() > EPS { real / unreal } else { 0.0 };\n",
        "        let cond2 = ratio > R_FOR_RATIO;\n",
        "        individual[i] = if cond1 || cond2 { 1 } else { 0 };\n",
        "    }\n",
        "\n",
        "    let mut final_mask = individual;\n",
        "    for t in 0..TRIPLETS {\n",
        "        let idx = triplet_idx(t);\n",
        "        let a = individual[idx[0]];\n",
        "        let b = individual[idx[1]];\n",
        "        let c = individual[idx[2]];\n",
        "        let uniform = (a==b) && (b==c);\n",
        "        if uniform {\n",
        "            final_mask[idx[0]] = a;\n",
        "            final_mask[idx[1]] = a;\n",
        "            final_mask[idx[2]] = a;\n",
        "        } else {\n",
        "            final_mask[idx[0]] = a;\n",
        "            final_mask[idx[1]] = b;\n",
        "            final_mask[idx[2]] = c;\n",
        "        }\n",
        "    }\n",
        "    final_mask\n",
        "}\n",
        "\n",
        "fn apply_parity_rotation(pairs: &[[f32;2]; SLOTS], collapse: &[u8; SLOTS]) -> ([[f32;2]; SLOTS], [u8; SLOTS]) {\n",
        "    let mut rotated = [[0.0f32;2]; SLOTS];\n",
        "    let mut parity = [0u8; SLOTS];\n",
        "    for i in 0..SLOTS {\n",
        "        let affected = (PRIME_MASK_30[i] > 0) || (collapse[i] > 0);\n",
        "        parity[i] = if affected { 1 } else { 0 };\n",
        "        let s = if affected { -1.0f32 } else { 1.0f32 };\n",
        "        rotated[i] = [pairs[i][0]*s, pairs[i][1]*s];\n",
        "    }\n",
        "    (rotated, parity)\n",
        "}\n",
        "\n",
        "fn bitmap(rotated: &[[f32;2]; SLOTS]) -> [u8; SLOTS] {\n",
        "    let mut bits = [0u8; SLOTS];\n",
        "    for i in 0..SLOTS { bits[i] = if rotated[i][0] > EPS { 1 } else { 0 }; }\n",
        "    bits\n",
        "}\n",
        "\n",
        "fn pack30_to_u32(bits: &[u8; SLOTS]) -> u32 {\n",
        "    let mut x = 0u32;\n",
        "    for i in 0..30 { x |= (bits[i] as u32) << i; }\n",
        "    x\n",
        "}\n",
        "\n",
        "fn pack90(b0: u32, b1: u32, b2: u32) -> (u64,u64) {\n",
        "    let b0 = (b0 & ((1u32<<30)-1)) as u64;\n",
        "    let b1 = (b1 & ((1u32<<30)-1)) as u64;\n",
        "    let b2 = (b2 & ((1u32<<30)-1)) as u64;\n",
        "    let low = b0 | (b1<<30) | ((b2 & 0xF)<<60);\n",
        "    let high = (b2 >> 4);\n",
        "    (low, high)\n",
        "}\n",
        "\n",
        "fn commit_full90(instr_counter: u32, w0: u32, w1: u32, w2: u32, initiator: u8, scx: u8, scy: u8, scz: u8) -> [u8;32] {\n",
        "    let mut h = Blake2s256::new();\n",
        "    h.update(b\"NTHISA90\");\n",
        "    h.update(&instr_counter.to_le_bytes());\n",
        "    h.update(&w0.to_le_bytes());\n",
        "    h.update(&w1.to_le_bytes());\n",
        "    h.update(&w2.to_le_bytes());\n",
        "    h.update(&[initiator, scx, scy, scz]);\n",
        "    let out = h.finalize();\n",
        "    let mut a = [0u8;32];\n",
        "    a.copy_from_slice(&out[..]);\n",
        "    a\n",
        "}\n",
        "\n",
        "fn tag_u64(commit: &[u8;32], q: usize, instr_counter: u32) -> u64 {\n",
        "    let mut h = Blake2s256::new();\n",
        "    h.update(b\"NTH_TAG0\");\n",
        "    h.update(commit);\n",
        "    h.update(&(q as u16).to_le_bytes());\n",
        "    h.update(&instr_counter.to_le_bytes());\n",
        "    let out = h.finalize();\n",
        "    u64::from_le_bytes(out[0..8].try_into().unwrap())\n",
        "}\n",
        "\n",
        "#[derive(Clone, Debug)]\n",
        "struct DedupInfo { collision_qubits: u32, groups: u32, active: u32, freed: u32 }\n",
        "\n",
        "fn dedup(commits: &[[u8;32]; Q], efficiency: &[u32; Q], mode_pair_hunt: bool, barrier: bool)\n",
        "    -> (Option<DedupInfo>, [bool; Q], [usize; Q])\n",
        "{\n",
        "    if barrier {\n",
        "        return (None, [true; Q], core::array::from_fn(|i| i));\n",
        "    }\n",
        "\n",
        "    let mut map: HashMap<[u8;32], Vec<usize>> = HashMap::new();\n",
        "    for q in 0..Q { map.entry(commits[q]).or_insert_with(Vec::new).push(q); }\n",
        "\n",
        "    let mut winner_of = core::array::from_fn(|i| i);\n",
        "    let mut active_mask = [true; Q];\n",
        "    let mut freed_count = 0u32;\n",
        "    let mut collision_qubits = 0u32;\n",
        "\n",
        "    for (_k, qs) in map.iter() {\n",
        "        if qs.len() > 1 { collision_qubits += (qs.len() as u32) - 1; }\n",
        "        let mut best = qs[0];\n",
        "        for &q in qs.iter() {\n",
        "            let eb = efficiency[best];\n",
        "            let eq = efficiency[q];\n",
        "            if (eq < eb) || (eq == eb && q < best) { best = q; }\n",
        "        }\n",
        "        for &q in qs.iter() {\n",
        "            winner_of[q] = best;\n",
        "            if q != best {\n",
        "                active_mask[q] = false;\n",
        "                if !mode_pair_hunt { freed_count += 1; }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    let info = DedupInfo {\n",
        "        collision_qubits,\n",
        "        groups: map.len() as u32,\n",
        "        active: active_mask.iter().filter(|&&b| b).count() as u32,\n",
        "        freed: freed_count,\n",
        "    };\n",
        "    (Some(info), active_mask, winner_of)\n",
        "}\n",
        "\n",
        "fn free_alias(st: &mut ISA) {\n",
        "    if st.mode_pair_hunt {\n",
        "        for q in 0..Q {\n",
        "            if !st.active_mask[q] {\n",
        "                let w = st.winner_of[q];\n",
        "                st.mag_xyz[q] = st.mag_xyz[w];\n",
        "                st.base_sign[q] = st.base_sign[w];\n",
        "            }\n",
        "        }\n",
        "    } else {\n",
        "        for q in 0..Q {\n",
        "            if !st.active_mask[q] {\n",
        "                let mut h = Blake2s256::new();\n",
        "                h.update(b\"NTH_FREE0\");\n",
        "                h.update(&st.commits[q]);\n",
        "                h.update(&(q as u16).to_le_bytes());\n",
        "                h.update(&(st.instr_counter + 1).to_le_bytes());\n",
        "                let out = h.finalize();\n",
        "                let m0 = (out[0] as i32) & 63;\n",
        "                let m1 = (out[1] as i32) & 63;\n",
        "                let m2 = (out[2] as i32) & 63;\n",
        "                let sb = out[3];\n",
        "                let s0 = if (sb & 1) != 0 { 1 } else { -1 };\n",
        "                let s1 = if (sb & 2) != 0 { 1 } else { -1 };\n",
        "                let s2 = if (sb & 4) != 0 { 1 } else { -1 };\n",
        "                st.mag_xyz[q] = [m0,m1,m2];\n",
        "                st.base_sign[q] = [s0,s1,s2];\n",
        "            }\n",
        "        }\n",
        "        // reset epoch to all active\n",
        "        st.active_mask = [true; Q];\n",
        "        st.winner_of = core::array::from_fn(|i| i);\n",
        "    }\n",
        "}\n",
        "\n",
        "// Fused measurement/transcode stage (called by PACK)\n",
        "fn stage_measure_transcode(st: &mut ISA) {\n",
        "    st.initiator = initiator_from_shared_counts(&st.mag_xyz);\n",
        "\n",
        "    let active_only = st.active_only_allowed();\n",
        "    let mut do_q = [true; Q];\n",
        "    if active_only {\n",
        "        for q in 0..Q { do_q[q] = st.active_mask[q]; }\n",
        "    }\n",
        "\n",
        "    for q in 0..Q {\n",
        "        if !do_q[q] { continue; }\n",
        "        let prim6 = build_primaries_from_nec_for_qubit(st.mag_xyz[q], st.base_sign[q]);\n",
        "\n",
        "        for v in 0..3 {\n",
        "            let prim_v = permute_primaries_by_initiator(prim6, v as u8);\n",
        "            let mut swap_sum = 0u8;\n",
        "            let reg30 = build_register30_for_qubit(prim_v, &mut swap_sum);\n",
        "            st.swapcount_xyz[q][v] = swap_sum;\n",
        "\n",
        "            let coll = detect_collapse_triplet_scatter(&reg30);\n",
        "            let (rot, _par) = apply_parity_rotation(&reg30, &coll);\n",
        "            let bits = bitmap(&rot);\n",
        "            st.packed_views_u32[q][v] = pack30_to_u32(&bits);\n",
        "        }\n",
        "\n",
        "        let (lo, hi) = pack90(st.packed_views_u32[q][0], st.packed_views_u32[q][1], st.packed_views_u32[q][2]);\n",
        "        st.packed90_u64[q] = [lo, hi];\n",
        "\n",
        "        st.commits[q] = commit_full90(\n",
        "            st.instr_counter,\n",
        "            st.packed_views_u32[q][0], st.packed_views_u32[q][1], st.packed_views_u32[q][2],\n",
        "            st.initiator[q],\n",
        "            st.swapcount_xyz[q][0], st.swapcount_xyz[q][1], st.swapcount_xyz[q][2]\n",
        "        );\n",
        "    }\n",
        "\n",
        "    // Fill aliases in PAIR_HUNT if active-only compute\n",
        "    if active_only && st.mode_pair_hunt {\n",
        "        for q in 0..Q {\n",
        "            if !st.active_mask[q] {\n",
        "                let w = st.winner_of[q];\n",
        "                st.packed_views_u32[q] = st.packed_views_u32[w];\n",
        "                st.packed90_u64[q] = st.packed90_u64[w];\n",
        "                st.swapcount_xyz[q] = st.swapcount_xyz[w];\n",
        "                st.commits[q] = st.commits[w];\n",
        "                st.initiator[q] = st.initiator[w];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// ===========================\n",
        "// Execution\n",
        "// ===========================\n",
        "fn exec_one(st: &mut ISA, mem: &mut SimMemory, ins: DecodedInstr) {\n",
        "    match ins.op {\n",
        "        Opcode::NecLoad => {\n",
        "            // deterministic NEC fill based on aux32 + instr_counter\n",
        "            let mut x = (st.instr_counter as u64) ^ (ins.aux32 as u64) ^ 0x9E3779B97F4A7C15u64;\n",
        "            for q in 0..Q {\n",
        "                // xorshift-like\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                st.mag_xyz[q][0] = (x as i32) & 63;\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                st.mag_xyz[q][1] = (x as i32) & 63;\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                st.mag_xyz[q][2] = (x as i32) & 63;\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                let sb = (x as u8) & 7;\n",
        "                st.base_sign[q][0] = if (sb & 1)!=0 { 1 } else { -1 };\n",
        "                st.base_sign[q][1] = if (sb & 2)!=0 { 1 } else { -1 };\n",
        "                st.base_sign[q][2] = if (sb & 4)!=0 { 1 } else { -1 };\n",
        "            }\n",
        "            st.active_mask = [true; Q];\n",
        "            st.winner_of = core::array::from_fn(|i| i);\n",
        "            st.barrier = false;\n",
        "        }\n",
        "        Opcode::NecAlu => {\n",
        "            let subop = ins.imm8;\n",
        "            let dst = (ins.dst_axis as usize).min(2);\n",
        "            let src = (ins.src_axis as usize).min(2);\n",
        "            let imm = ins.imm32;\n",
        "            for q in 0..Q {\n",
        "                let a = st.mag_xyz[q][dst];\n",
        "                let b = st.mag_xyz[q][src];\n",
        "                let v = match subop {\n",
        "                    0 => (a + b) & 63,\n",
        "                    1 => (a - b) & 63,\n",
        "                    2 => (a * b) & 63,\n",
        "                    3 => if b==0 { a } else { (a / b) & 63 },\n",
        "                    4 => (a ^ b) & 63,\n",
        "                    5 => (a + imm) & 63,\n",
        "                    _ => a,\n",
        "                };\n",
        "                st.mag_xyz[q][dst] = v;\n",
        "            }\n",
        "        }\n",
        "        Opcode::PhaseFlip => {\n",
        "            let axis = (ins.dst_axis as usize).min(2);\n",
        "            for q in 0..Q { st.base_sign[q][axis] *= -1; }\n",
        "        }\n",
        "        Opcode::RotAxes => {\n",
        "            let dir = ins.imm8;\n",
        "            for q in 0..Q {\n",
        "                if dir == 0 {\n",
        "                    let m = st.mag_xyz[q];\n",
        "                    let s = st.base_sign[q];\n",
        "                    st.mag_xyz[q] = [m[2], m[0], m[1]];\n",
        "                    st.base_sign[q] = [s[2], s[0], s[1]];\n",
        "                } else {\n",
        "                    let m = st.mag_xyz[q];\n",
        "                    let s = st.base_sign[q];\n",
        "                    st.mag_xyz[q] = [m[1], m[2], m[0]];\n",
        "                    st.base_sign[q] = [s[1], s[2], s[0]];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        Opcode::ShiftMag => {\n",
        "            let axis = (ins.dst_axis as usize).min(2);\n",
        "            let sh = ins.imm32;\n",
        "            for q in 0..Q {\n",
        "                let a = st.mag_xyz[q][axis];\n",
        "                let v = if sh >= 0 { (a << sh) & 63 } else { (a >> (-sh)) & 63 };\n",
        "                st.mag_xyz[q][axis] = v;\n",
        "            }\n",
        "        }\n",
        "        Opcode::Barrier => st.barrier = true,\n",
        "        Opcode::Pack => stage_measure_transcode(st),\n",
        "        Opcode::Dedup => {\n",
        "            if st.barrier {\n",
        "                st.active_mask = [true; Q];\n",
        "                st.winner_of = core::array::from_fn(|i| i);\n",
        "            } else {\n",
        "                let mut eff = [0u32; Q];\n",
        "                for q in 0..Q {\n",
        "                    eff[q] = (st.swapcount_xyz[q][0] as u32) + (st.swapcount_xyz[q][1] as u32) + (st.swapcount_xyz[q][2] as u32);\n",
        "                }\n",
        "                let (_info, am, wo) = dedup(&st.commits, &eff, st.mode_pair_hunt, st.barrier);\n",
        "                st.active_mask = am;\n",
        "                st.winner_of = wo;\n",
        "            }\n",
        "        }\n",
        "        Opcode::FreeAlias => free_alias(st),\n",
        "        Opcode::Next => { st.instr_counter += 1; st.barrier = false; }\n",
        "        Opcode::MemLoadU32 => {\n",
        "            let addr = ins.aux32 as usize;\n",
        "            let v = mem.read_u32(addr) as i32;\n",
        "            for q in 0..Q { st.mag_xyz[q][0] = (st.mag_xyz[q][0] ^ v) & 63; }\n",
        "        }\n",
        "        Opcode::MemStoreU32 => {\n",
        "            let addr = ins.aux32 as usize;\n",
        "            mem.write_u32(addr, st.packed_views_u32[0][0]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "fn exec_program(st: &mut ISA, mem: &mut SimMemory, bytecode: &[u8]) {\n",
        "    assert!(bytecode.len() % 16 == 0);\n",
        "    for i in 0..(bytecode.len()/16) {\n",
        "        let ins = decode16(&bytecode[i*16..i*16+16]);\n",
        "        exec_one(st, mem, ins);\n",
        "    }\n",
        "}\n",
        "\n",
        "fn state_map(commits: &[[u8;32]; Q]) -> usize {\n",
        "    let mut m: HashMap<[u8;32], u32> = HashMap::new();\n",
        "    for q in 0..Q {\n",
        "        *m.entry(commits[q]).or_insert(0) += 1;\n",
        "    }\n",
        "    m.len()\n",
        "}\n",
        "\n",
        "// ===========================\n",
        "// Python-exposed API\n",
        "// ===========================\n",
        "#[pyfunction]\n",
        "fn run_uisa(bytecode: Vec<u8>, mode: &str, exec_active_only: bool, mem_size: usize) -> PyResult<PyObject> {\n",
        "    if bytecode.len() % 16 != 0 {\n",
        "        return Err(pyo3::exceptions::PyValueError::new_err(\"bytecode length must be multiple of 16\"));\n",
        "    }\n",
        "    let mode_pair_hunt = match mode {\n",
        "        \"FREE\" => false,\n",
        "        \"PAIR_HUNT\" => true,\n",
        "        _ => return Err(pyo3::exceptions::PyValueError::new_err(\"mode must be 'FREE' or 'PAIR_HUNT'\")),\n",
        "    };\n",
        "\n",
        "    let mut st = ISA::new(mode_pair_hunt, exec_active_only);\n",
        "    let mut mem = SimMemory::new(mem_size.max(64));\n",
        "\n",
        "    exec_program(&mut st, &mut mem, &bytecode);\n",
        "\n",
        "    // Flatten outputs into Python-friendly vectors\n",
        "    let mut packed_views: Vec<u32> = Vec::with_capacity(Q*3);\n",
        "    let mut packed90: Vec<u64> = Vec::with_capacity(Q*2);\n",
        "    let mut initiator: Vec<u8> = Vec::with_capacity(Q);\n",
        "    let mut active: Vec<u8> = Vec::with_capacity(Q);\n",
        "    let mut winner_of: Vec<u32> = Vec::with_capacity(Q);\n",
        "    let mut commits: Vec<u8> = Vec::with_capacity(Q*32);\n",
        "\n",
        "    for q in 0..Q {\n",
        "        packed_views.push(st.packed_views_u32[q][0]);\n",
        "        packed_views.push(st.packed_views_u32[q][1]);\n",
        "        packed_views.push(st.packed_views_u32[q][2]);\n",
        "\n",
        "        packed90.push(st.packed90_u64[q][0]);\n",
        "        packed90.push(st.packed90_u64[q][1]);\n",
        "\n",
        "        initiator.push(initiator_from_shared_counts(&st.mag_xyz)[q]); // recompute for return stability\n",
        "        active.push(if st.active_mask[q] { 1 } else { 0 });\n",
        "        winner_of.push(st.winner_of[q] as u32);\n",
        "\n",
        "        commits.extend_from_slice(&st.commits[q]);\n",
        "    }\n",
        "\n",
        "    let groups = state_map(&st.commits);\n",
        "\n",
        "    Python::with_gil(|py| {\n",
        "        let dict = pyo3::types::PyDict::new(py);\n",
        "        dict.set_item(\"instr_counter\", st.instr_counter)?;\n",
        "        dict.set_item(\"mode_pair_hunt\", st.mode_pair_hunt)?;\n",
        "        dict.set_item(\"barrier\", st.barrier)?;\n",
        "        dict.set_item(\"state_groups\", groups)?;\n",
        "\n",
        "        dict.set_item(\"packed_views_u32_flat\", packed_views)?;\n",
        "        dict.set_item(\"packed90_u64_flat\", packed90)?;\n",
        "        dict.set_item(\"initiator\", initiator)?;\n",
        "        dict.set_item(\"active_mask\", active)?;\n",
        "        dict.set_item(\"winner_of\", winner_of)?;\n",
        "        dict.set_item(\"commits_bytes\", commits)?;\n",
        "\n",
        "        // also return a small memory readback for debugging\n",
        "        dict.set_item(\"mem_u32_0\", mem.read_u32(0))?;\n",
        "        Ok(dict.into())\n",
        "    })\n",
        "}\n",
        "\n",
        "#[pymodule]\n",
        "fn uisa_v09(_py: Python, m: &PyModule) -> PyResult<()> {\n",
        "    m.add_function(wrap_pyfunction!(run_uisa, m)?)?;\n",
        "    Ok(())\n",
        "}\n",
        "RS\n",
        "\n",
        "# ---- 4) build wheel and install ----\n",
        "cd uisa_v09\n",
        "source $HOME/.cargo/env\n",
        "maturin build -q --release\n",
        "python3 -m pip -q install target/wheels/uisa_v09-*.whl\n",
        "echo \"Built and installed uisa_v09.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SysIs9SGLyga",
        "outputId": "e922a368-b12f-4540-cedb-8a619625e0f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  stable-x86_64-unknown-linux-gnu installed - rustc 1.92.0 (ded5c06cf 2025-12-08)\n",
            "\n",
            "\n",
            "Rust is installed now. Great!\n",
            "\n",
            "To get started you may need to restart your current shell.\n",
            "This would reload your PATH environment variable to include\n",
            "Cargo's bin directory ($HOME/.cargo/bin).\n",
            "\n",
            "To configure your current shell, you need to source\n",
            "the corresponding env file under $HOME/.cargo.\n",
            "\n",
            "This is usually done by running one of the following (note the leading DOT):\n",
            ". \"$HOME/.cargo/env\"            # For sh/bash/zsh/ash/dash/pdksh\n",
            "source \"$HOME/.cargo/env.fish\"  # For fish\n",
            "source $\"($nu.home-path)/.cargo/env.nu\"  # For nushell\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 17.2 MB/s eta 0:00:00\n",
            "Built and installed uisa_v09.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "info: downloading installer\n",
            "info: profile set to 'default'\n",
            "info: default host triple is x86_64-unknown-linux-gnu\n",
            "info: syncing channel updates for 'stable-x86_64-unknown-linux-gnu'\n",
            "info: latest update on 2025-12-11, rust version 1.92.0 (ded5c06cf 2025-12-08)\n",
            "info: downloading component 'cargo'\n",
            "info: downloading component 'clippy'\n",
            "info: downloading component 'rust-docs'\n",
            "info: downloading component 'rust-std'\n",
            "info: downloading component 'rustc'\n",
            "info: downloading component 'rustfmt'\n",
            "info: installing component 'cargo'\n",
            "info: installing component 'clippy'\n",
            "info: installing component 'rust-docs'\n",
            "info: installing component 'rust-std'\n",
            "info: installing component 'rustc'\n",
            "info: installing component 'rustfmt'\n",
            "info: default toolchain set to 'stable-x86_64-unknown-linux-gnu'\n",
            "    Updating crates.io index\n",
            "     Locking 36 packages to latest compatible versions\n",
            "      Adding generic-array v0.14.7 (available: v0.14.9)\n",
            "      Adding pyo3 v0.21.2 (available: v0.27.2)\n",
            " Downloading crates ...\n",
            "  Downloaded heck v0.4.1\n",
            "  Downloaded digest v0.10.7\n",
            "  Downloaded pyo3-macros v0.21.2\n",
            "  Downloaded windows-link v0.2.1\n",
            "  Downloaded unindent v0.2.4\n",
            "  Downloaded cfg-if v1.0.4\n",
            "  Downloaded crypto-common v0.1.7\n",
            "  Downloaded scopeguard v1.2.0\n",
            "  Downloaded version_check v0.9.5\n",
            "  Downloaded parking_lot v0.12.5\n",
            "  Downloaded unicode-ident v1.0.22\n",
            "  Downloaded subtle v2.6.1\n",
            "  Downloaded rustversion v1.0.22\n",
            "  Downloaded typenum v1.19.0\n",
            "  Downloaded redox_syscall v0.5.18\n",
            "  Downloaded pyo3-macros-backend v0.21.2\n",
            "  Downloaded pyo3-ffi v0.21.2\n",
            "  Downloaded portable-atomic v1.11.1\n",
            "  Downloaded proc-macro2 v1.0.103\n",
            "  Downloaded target-lexicon v0.12.16\n",
            "  Downloaded smallvec v1.15.1\n",
            "  Downloaded quote v1.0.42\n",
            "  Downloaded bitflags v2.10.0\n",
            "  Downloaded once_cell v1.21.3\n",
            "  Downloaded syn v2.0.111\n",
            "  Downloaded memoffset v0.9.1\n",
            "  Downloaded pyo3-build-config v0.21.2\n",
            "  Downloaded parking_lot_core v0.9.12\n",
            "  Downloaded lock_api v0.4.14\n",
            "  Downloaded blake2 v0.10.6\n",
            "  Downloaded indoc v2.0.7\n",
            "  Downloaded autocfg v1.5.0\n",
            "  Downloaded pyo3 v0.21.2\n",
            "  Downloaded generic-array v0.14.7\n",
            "  Downloaded block-buffer v0.10.4\n",
            "  Downloaded libc v0.2.178\n",
            "🔗 Found pyo3 bindings\n",
            "🐍 Found CPython 3.12 at /usr/bin/python3\n",
            "warning: unnecessary parentheses around assigned value\n",
            "   --> src/lib.rs:326:16\n",
            "    |\n",
            "326 |     let high = (b2 >> 4);\n",
            "    |                ^       ^\n",
            "    |\n",
            "    = note: `#[warn(unused_parens)]` (part of `#[warn(unused)]`) on by default\n",
            "help: remove these parentheses\n",
            "    |\n",
            "326 -     let high = (b2 >> 4);\n",
            "326 +     let high = b2 >> 4 ;\n",
            "    |\n",
            "\n",
            "warning: use of deprecated associated function `pyo3::types::PyDict::new`: `PyDict::new` will be replaced by `PyDict::new_bound` in a future PyO3 version\n",
            "   --> src/lib.rs:651:41\n",
            "    |\n",
            "651 |         let dict = pyo3::types::PyDict::new(py);\n",
            "    |                                         ^^^\n",
            "    |\n",
            "    = note: `#[warn(deprecated)]` on by default\n",
            "\n",
            "warning: use of deprecated method `pyo3::deprecations::GilRefs::<T>::function_arg`: use `&Bound<'_, T>` instead for this function argument\n",
            "   --> src/lib.rs:671:26\n",
            "    |\n",
            "671 | fn uisa_v09(_py: Python, m: &PyModule) -> PyResult<()> {\n",
            "    |                          ^\n",
            "\n",
            "warning: value assigned to `bestv` is never read\n",
            "   --> src/lib.rs:194:37\n",
            "    |\n",
            "194 |             if v2 > bestv { best=2; bestv=v2; }\n",
            "    |                                     ^^^^^^^^\n",
            "    |\n",
            "    = help: maybe it is overwritten before being read?\n",
            "    = note: `#[warn(unused_assignments)]` (part of `#[warn(unused)]`) on by default\n",
            "\n",
            "warning: constant `VIEWS` is never used\n",
            " --> src/lib.rs:7:7\n",
            "  |\n",
            "7 | const VIEWS: usize = 3;\n",
            "  |       ^^^^^\n",
            "  |\n",
            "  = note: `#[warn(dead_code)]` (part of `#[warn(unused)]`) on by default\n",
            "\n",
            "warning: field `gpr_mask` is never read\n",
            "  --> src/lib.rs:44:5\n",
            "   |\n",
            "42 | struct DecodedInstr {\n",
            "   |        ------------ field in this struct\n",
            "43 |     op: Opcode,\n",
            "44 |     gpr_mask: u8,       // reserved for v1.0 masks; v0.9 uses mask=all\n",
            "   |     ^^^^^^^^\n",
            "   |\n",
            "   = note: `DecodedInstr` has a derived impl for the trait `Clone`, but this is intentionally ignored during dead code analysis\n",
            "\n",
            "warning: function `tag_u64` is never used\n",
            "   --> src/lib.rs:344:4\n",
            "    |\n",
            "344 | fn tag_u64(commit: &[u8;32], q: usize, instr_counter: u32) -> u64 {\n",
            "    |    ^^^^^^^\n",
            "\n",
            "warning: fields `collision_qubits`, `groups`, `active`, and `freed` are never read\n",
            "   --> src/lib.rs:355:20\n",
            "    |\n",
            "355 | struct DedupInfo { collision_qubits: u32, groups: u32, active: u32, freed: u32 }\n",
            "    |        ---------   ^^^^^^^^^^^^^^^^       ^^^^^^       ^^^^^^       ^^^^^\n",
            "    |        |\n",
            "    |        fields in this struct\n",
            "    |\n",
            "    = note: `DedupInfo` has derived impls for the traits `Debug` and `Clone`, but these are intentionally ignored during dead code analysis\n",
            "\n",
            "📦 Built wheel for CPython 3.12 to /content/uisa_v09/target/wheels/uisa_v09-0.9.0-cp312-cp312-manylinux_2_34_x86_64.whl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CELL 2 — Python harness: assemble bytecode, run FREE and PAIR_HUNT, inspect outputs"
      ],
      "metadata": {
        "id": "q2oBQdsbL2H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "import uisa_v09\n",
        "\n",
        "# canonical 16-byte encoding (must match Rust decode16 layout)\n",
        "def emit(op, flags=0, gpr_mask=0, dst=0, src=0, imm8=0, imm32=0, aux32=0):\n",
        "    b = bytearray(16)\n",
        "    b[0] = op\n",
        "    b[1] = flags\n",
        "    b[2] = gpr_mask\n",
        "    b[3] = dst\n",
        "    b[4] = src\n",
        "    b[5] = imm8\n",
        "    b[8:12] = struct.pack(\"<i\", imm32)\n",
        "    b[12:16] = struct.pack(\"<I\", aux32)\n",
        "    return bytes(b)\n",
        "\n",
        "# opcodes (match Rust enum values)\n",
        "OP_NEC_LOAD   = 0x01\n",
        "OP_NEC_ALU    = 0x02\n",
        "OP_PHASE_FLIP = 0x03\n",
        "OP_ROT_AXES   = 0x04\n",
        "OP_SHIFT_MAG  = 0x05\n",
        "OP_BARRIER    = 0x06\n",
        "OP_PACK       = 0x15\n",
        "OP_DEDUP      = 0x17\n",
        "OP_FREE_ALIAS = 0x18\n",
        "OP_NEXT       = 0x19\n",
        "\n",
        "OP_MEM_LOAD_U32  = 0x20\n",
        "OP_MEM_STORE_U32 = 0x21\n",
        "\n",
        "# subops for NEC_ALU (imm8)\n",
        "ALU_ADD = 0\n",
        "ALU_SUB = 1\n",
        "ALU_MUL = 2\n",
        "ALU_DIV = 3\n",
        "ALU_XOR = 4\n",
        "ALU_ADDI= 5\n",
        "\n",
        "# Build a demo bytecode program similar to v0.7\n",
        "bc = b\"\".join([\n",
        "    emit(OP_NEC_LOAD, aux32=11),\n",
        "\n",
        "    emit(OP_NEC_ALU, dst=0, src=1, imm8=ALU_ADD),   # x += y\n",
        "    emit(OP_NEC_ALU, dst=2, src=0, imm8=ALU_XOR),   # z ^= x\n",
        "    emit(OP_SHIFT_MAG, dst=1, imm32=1),             # y <<= 1\n",
        "    emit(OP_PHASE_FLIP, dst=0),                     # flip x\n",
        "    emit(OP_ROT_AXES, imm8=0),                      # rotate R\n",
        "\n",
        "    emit(OP_PACK),\n",
        "    emit(OP_DEDUP),\n",
        "    emit(OP_FREE_ALIAS),\n",
        "    emit(OP_NEXT),\n",
        "\n",
        "    emit(OP_NEC_ALU, dst=0, src=2, imm8=ALU_MUL),   # x *= z\n",
        "    emit(OP_BARRIER),                               # suppress dedup this epoch\n",
        "    emit(OP_PACK),\n",
        "    emit(OP_DEDUP),\n",
        "    emit(OP_NEXT),\n",
        "])\n",
        "\n",
        "def reshape_outputs(out):\n",
        "    packed_views = np.array(out[\"packed_views_u32_flat\"], dtype=np.uint32).reshape(64,3)\n",
        "    packed90 = np.array(out[\"packed90_u64_flat\"], dtype=np.uint64).reshape(64,2)\n",
        "    initiator = np.array(out[\"initiator\"], dtype=np.uint8)\n",
        "    active = np.array(out[\"active_mask\"], dtype=np.uint8)\n",
        "    winner = np.array(out[\"winner_of\"], dtype=np.uint32)\n",
        "    commits = bytes(out[\"commits_bytes\"])\n",
        "    commits = [commits[i*32:(i+1)*32] for i in range(64)]\n",
        "    return packed_views, packed90, initiator, active, winner, commits\n",
        "\n",
        "for mode in [\"FREE\", \"PAIR_HUNT\"]:\n",
        "    out = uisa_v09.run_uisa(bytecode=list(bc), mode=mode, exec_active_only=True, mem_size=1024)\n",
        "    packed_views, packed90, initiator, active, winner, commits = reshape_outputs(out)\n",
        "\n",
        "    print(\"\\n=== v0.9 Rust module run ===\")\n",
        "    print(\"mode:\", mode, \"instr_counter:\", out[\"instr_counter\"], \"barrier:\", out[\"barrier\"], \"state_groups:\", out[\"state_groups\"])\n",
        "    print(\"packed_views_u32[0]:\", packed_views[0].tolist())\n",
        "    print(\"packed90_u64[0]:\", packed90[0].tolist())\n",
        "    print(\"initiator counts:\", np.bincount(initiator, minlength=3).tolist())\n",
        "    print(\"active count:\", int(active.sum()), \"aliases:\", 64 - int(active.sum()))\n",
        "    print(\"winner_of[0..7]:\", winner[:8].tolist())\n",
        "    print(\"commit0 hex:\", commits[0].hex()[:32], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOe3dxbjL9gA",
        "outputId": "a71936e9-763c-4514-965a-7749167566a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== v0.9 Rust module run ===\n",
            "mode: FREE instr_counter: 2 barrier: False state_groups: 50\n",
            "packed_views_u32[0]: [604514724, 538601608, 76677124]\n",
            "packed90_u64[0]: [5190005092015155620, 4792320]\n",
            "initiator counts: [27, 16, 21]\n",
            "active count: 64 aliases: 0\n",
            "winner_of[0..7]: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "commit0 hex: 4701ea597a1aaeab36b00f0627b396b1 ...\n",
            "\n",
            "=== v0.9 Rust module run ===\n",
            "mode: PAIR_HUNT instr_counter: 2 barrier: False state_groups: 44\n",
            "packed_views_u32[0]: [604514724, 538601608, 76677124]\n",
            "packed90_u64[0]: [5190005092015155620, 4792320]\n",
            "initiator counts: [17, 20, 27]\n",
            "active count: 64 aliases: 0\n",
            "winner_of[0..7]: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "commit0 hex: 4701ea597a1aaeab36b00f0627b396b1 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v0.1.0 split cell build and run."
      ],
      "metadata": {
        "id": "ljAjrqVzPsZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1: Build"
      ],
      "metadata": {
        "id": "m_pUIeSvP0MJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "apt-get update -y >/dev/null\n",
        "apt-get install -y build-essential pkg-config >/dev/null\n",
        "\n",
        "# Rust exists already; just load env\n",
        "if [ -f \"$HOME/.cargo/env\" ]; then\n",
        "  source \"$HOME/.cargo/env\"\n",
        "fi\n",
        "\n",
        "python3 -m pip -q install --upgrade pip\n",
        "python3 -m pip -q install maturin\n",
        "\n",
        "rm -rf uisa_v10\n",
        "mkdir -p uisa_v10/src\n",
        "\n",
        "cat > uisa_v10/Cargo.toml <<'TOML'\n",
        "[package]\n",
        "name = \"uisa_v10\"\n",
        "version = \"0.10.1\"\n",
        "edition = \"2021\"\n",
        "\n",
        "[lib]\n",
        "name = \"uisa_v10\"\n",
        "crate-type = [\"cdylib\"]\n",
        "\n",
        "[dependencies]\n",
        "pyo3 = { version = \"0.21\", features = [\"extension-module\"] }\n",
        "blake2 = \"0.10\"\n",
        "TOML\n",
        "\n",
        "cat > uisa_v10/src/lib.rs <<'RS'\n",
        "use blake2::{Blake2s256, Digest};\n",
        "use pyo3::prelude::*;\n",
        "use pyo3::types::PyDict;\n",
        "use std::collections::HashMap;\n",
        "\n",
        "const Q: usize = 64;\n",
        "const SLOTS: usize = 30;\n",
        "const TRIPLETS: usize = 10;\n",
        "\n",
        "const EPS: f32 = 1e-6;\n",
        "const TAU_HI: f32 = 1.0;\n",
        "const TAU_LOW: f32 = -1.0;\n",
        "const R_FOR_RATIO: f32 = 64.0;\n",
        "\n",
        "const PRIME_MASK_30: [u8; 30] = [\n",
        "    0,0,1,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,1,0,0,0,1,0,0,0,0,0,1\n",
        "];\n",
        "\n",
        "fn triplet_idx(t: usize) -> [usize;3] { [3*t, 3*t+1, 3*t+2] }\n",
        "\n",
        "#[repr(u8)]\n",
        "#[derive(Clone, Copy, Debug)]\n",
        "enum Opcode {\n",
        "    NecLoad = 0x01,\n",
        "    NecAlu  = 0x02,\n",
        "    PhaseFlip = 0x03,\n",
        "    RotAxes   = 0x04,\n",
        "    ShiftMag  = 0x05,\n",
        "    BarrierDedup = 0x06,\n",
        "    BarrierAll   = 0x07,\n",
        "\n",
        "    Pack       = 0x15,\n",
        "    Dedup      = 0x17,\n",
        "    FreeAlias  = 0x18,\n",
        "    Next       = 0x19,\n",
        "}\n",
        "\n",
        "#[derive(Clone, Copy)]\n",
        "struct DecodedInstr {\n",
        "    op: Opcode,\n",
        "    dst_axis: u8,\n",
        "    src_axis: u8,\n",
        "    imm8: u8,\n",
        "    imm32: i32,\n",
        "    aux32: u32,\n",
        "}\n",
        "\n",
        "fn decode16(bytes: &[u8]) -> DecodedInstr {\n",
        "    assert!(bytes.len() == 16);\n",
        "    let op = match bytes[0] {\n",
        "        0x01 => Opcode::NecLoad,\n",
        "        0x02 => Opcode::NecAlu,\n",
        "        0x03 => Opcode::PhaseFlip,\n",
        "        0x04 => Opcode::RotAxes,\n",
        "        0x05 => Opcode::ShiftMag,\n",
        "        0x06 => Opcode::BarrierDedup,\n",
        "        0x07 => Opcode::BarrierAll,\n",
        "        0x15 => Opcode::Pack,\n",
        "        0x17 => Opcode::Dedup,\n",
        "        0x18 => Opcode::FreeAlias,\n",
        "        0x19 => Opcode::Next,\n",
        "        _ => panic!(\"unknown opcode {}\", bytes[0]),\n",
        "    };\n",
        "    let dst_axis = bytes[3];\n",
        "    let src_axis = bytes[4];\n",
        "    let imm8 = bytes[5];\n",
        "    let imm32 = i32::from_le_bytes([bytes[8],bytes[9],bytes[10],bytes[11]]);\n",
        "    let aux32 = u32::from_le_bytes([bytes[12],bytes[13],bytes[14],bytes[15]]);\n",
        "    DecodedInstr { op, dst_axis, src_axis, imm8, imm32, aux32 }\n",
        "}\n",
        "\n",
        "#[derive(Clone)]\n",
        "struct ISA {\n",
        "    instr_counter: u32,\n",
        "    mode_pair_hunt: bool,\n",
        "    exec_active_only: bool,\n",
        "\n",
        "    barrier_dedup: bool,\n",
        "    barrier_all: bool,\n",
        "\n",
        "    has_schedule: bool,\n",
        "\n",
        "    mag_xyz: [[i32;3]; Q],\n",
        "    base_sign: [[i32;3]; Q],\n",
        "\n",
        "    active_mask: [bool; Q],\n",
        "    winner_of: [usize; Q],\n",
        "\n",
        "    initiator: [u8; Q],\n",
        "    swapcount_xyz: [[u8;3]; Q],\n",
        "    packed_views_u32: [[u32;3]; Q],\n",
        "    packed90_u64: [[u64;2]; Q],\n",
        "    commits: [[u8;32]; Q],\n",
        "    tags_u64: [u64; Q],\n",
        "\n",
        "    epoch_log: Vec<(u32,u8,u32,u32,u32)>, // (t, barrier_mode, groups, collisions, active)\n",
        "}\n",
        "\n",
        "impl ISA {\n",
        "    fn new(mode_pair_hunt: bool, exec_active_only: bool) -> Self {\n",
        "        ISA {\n",
        "            instr_counter: 0,\n",
        "            mode_pair_hunt,\n",
        "            exec_active_only,\n",
        "            barrier_dedup: false,\n",
        "            barrier_all: false,\n",
        "            has_schedule: false,\n",
        "            mag_xyz: [[0;3]; Q],\n",
        "            base_sign: [[1;3]; Q],\n",
        "            active_mask: [true; Q],\n",
        "            winner_of: core::array::from_fn(|i| i),\n",
        "            initiator: [0u8; Q],\n",
        "            swapcount_xyz: [[0u8;3]; Q],\n",
        "            packed_views_u32: [[0u32;3]; Q],\n",
        "            packed90_u64: [[0u64;2]; Q],\n",
        "            commits: [[0u8;32]; Q],\n",
        "            tags_u64: [0u64; Q],\n",
        "            epoch_log: Vec::new(),\n",
        "        }\n",
        "    }\n",
        "\n",
        "    fn active_only_allowed(&self) -> bool {\n",
        "        self.mode_pair_hunt && self.exec_active_only && self.has_schedule && !self.barrier_all && !self.barrier_dedup\n",
        "    }\n",
        "}\n",
        "\n",
        "// ---- initiator (full array) ----\n",
        "fn initiator_from_shared_counts(mag: &[[i32;3]; Q]) -> [u8; Q] {\n",
        "    let mut init = [0u8; Q];\n",
        "    let mut counts = [[0i32;3]; Q];\n",
        "\n",
        "    for axis in 0..3 {\n",
        "        for q in 0..Q {\n",
        "            let v = mag[q][axis];\n",
        "            let mut c = 0i32;\n",
        "            for k in 0..Q {\n",
        "                if mag[k][axis] == v { c += 1; }\n",
        "            }\n",
        "            counts[q][axis] = c;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for q in 0..Q {\n",
        "        let cx = counts[q][0];\n",
        "        let cy = counts[q][1];\n",
        "        let cz = counts[q][2];\n",
        "        let shared = [cx>1, cy>1, cz>1];\n",
        "        let shared_count = shared.iter().filter(|&&b| b).count();\n",
        "\n",
        "        let argmax_counts = {\n",
        "            let mut best = 0usize;\n",
        "            let mut bestv = counts[q][0];\n",
        "            for a in 1..3 {\n",
        "                if counts[q][a] > bestv { best=a; bestv=counts[q][a]; }\n",
        "            }\n",
        "            best as u8\n",
        "        };\n",
        "\n",
        "        if shared_count == 1 {\n",
        "            init[q] = argmax_counts;\n",
        "        } else if shared_count == 2 {\n",
        "            let mut odd = 0usize;\n",
        "            for a in 0..3 { if counts[q][a] == 1 { odd=a; break; } }\n",
        "            init[q] = odd as u8;\n",
        "        } else if shared_count == 3 {\n",
        "            init[q] = argmax_counts;\n",
        "        } else {\n",
        "            let v0 = mag[q][0]*1000 + 2;\n",
        "            let v1 = mag[q][1]*1000 + 1;\n",
        "            let v2 = mag[q][2]*1000 + 0;\n",
        "            let mut best = 0usize;\n",
        "            let mut bestv = v0;\n",
        "            if v1 > bestv { best=1; bestv=v1; }\n",
        "            if v2 > bestv { best=2; }\n",
        "            init[q] = best as u8;\n",
        "        }\n",
        "    }\n",
        "    init\n",
        "}\n",
        "\n",
        "// ---- NEC -> primaries ----\n",
        "fn build_primaries_from_nec_for_qubit(mag: [i32;3], sign: [i32;3]) -> [[f32;2]; 6] {\n",
        "    let mut out = [[0.0f32;2]; 6];\n",
        "    for axis in 0..3 {\n",
        "        let m = mag[axis] as f32;\n",
        "        let real = [ m, -m];\n",
        "        let unrl = [-m,  m];\n",
        "        let (first, second) = if sign[axis] < 0 { (unrl, real) } else { (real, unrl) };\n",
        "        out[2*axis + 0] = first;\n",
        "        out[2*axis + 1] = second;\n",
        "    }\n",
        "    out\n",
        "}\n",
        "\n",
        "fn permute_primaries_by_initiator(prim6: [[f32;2];6], init_axis: u8) -> [[f32;2];6] {\n",
        "    let idx_x = [0usize,1,2,3,4,5];\n",
        "    let idx_y = [2usize,3,4,5,0,1];\n",
        "    let idx_z = [4usize,5,0,1,2,3];\n",
        "    let idx = match init_axis { 0 => idx_x, 1 => idx_y, _ => idx_z };\n",
        "    let mut out = [[0.0f32;2];6];\n",
        "    for i in 0..6 { out[i] = prim6[idx[i]]; }\n",
        "    out\n",
        "}\n",
        "\n",
        "fn add_pd(a: [f32;2], b: [f32;2]) -> [f32;2] { [a[0]+b[0], a[1]+b[1]] }\n",
        "fn sub_pd(a: [f32;2], b: [f32;2]) -> [f32;2] { [a[0]-b[0], a[1]-b[1]] }\n",
        "fn mul_pd(a: [f32;2], b: [f32;2]) -> [f32;2] { [a[0]*b[0], a[1]*b[1]] }\n",
        "fn div_pd(a: [f32;2], b: [f32;2]) -> [f32;2] {\n",
        "    let mut out = [0.0f32;2];\n",
        "    for i in 0..2 { if b[i].abs() > EPS { out[i] = a[i] / b[i]; } }\n",
        "    out\n",
        "}\n",
        "\n",
        "fn build_register30_for_qubit(prim6: [[f32;2];6], swap_sum_out: &mut u8) -> [[f32;2]; SLOTS] {\n",
        "    let (p0,p1,p2,p3,p4,p5) = (prim6[0],prim6[1],prim6[2],prim6[3],prim6[4],prim6[5]);\n",
        "    let (a0,a1) = (p0,p1);\n",
        "    let (b0,b1) = (p2,p3);\n",
        "    let (c0,c1) = (p4,p5);\n",
        "\n",
        "    let spec: [([f32;2],[f32;2],u8);8] = [\n",
        "        (a0,b0,0), (b0,c0,0), (a0,c0,0), (a1,b1,0),\n",
        "        (a0,b1,1), (b0,c1,1), (a1,c0,1), (b1,c1,1),\n",
        "    ];\n",
        "\n",
        "    let mut reg = [[0.0f32;2]; SLOTS];\n",
        "    reg[0]=p0; reg[1]=p1; reg[2]=p2; reg[3]=p3; reg[4]=p4; reg[5]=p5;\n",
        "\n",
        "    let mut cursor = 6usize;\n",
        "    let mut swap_sum = 0u8;\n",
        "    for (u,v,op3) in spec {\n",
        "        let addv = add_pd(u,v);\n",
        "        let subv = sub_pd(u,v);\n",
        "        let opv  = if op3==0 { mul_pd(u,v) } else { div_pd(u,v) };\n",
        "        let (first, second, swap) = if subv[0] > addv[0] { (subv, addv, 1u8) } else { (addv, subv, 0u8) };\n",
        "        swap_sum += swap;\n",
        "        reg[cursor+0] = first;\n",
        "        reg[cursor+1] = second;\n",
        "        reg[cursor+2] = opv;\n",
        "        cursor += 3;\n",
        "    }\n",
        "    *swap_sum_out = swap_sum;\n",
        "    reg\n",
        "}\n",
        "\n",
        "fn detect_collapse_triplet_scatter(pairs: &[[f32;2]; SLOTS]) -> [u8; SLOTS] {\n",
        "    let mut individual = [0u8; SLOTS];\n",
        "    for i in 0..SLOTS {\n",
        "        let real = pairs[i][0];\n",
        "        let unreal = pairs[i][1];\n",
        "        let cond1 = (real >= TAU_HI) && (unreal <= TAU_LOW);\n",
        "        let ratio = if unreal.abs() > EPS { real / unreal } else { 0.0 };\n",
        "        let cond2 = ratio > R_FOR_RATIO;\n",
        "        individual[i] = if cond1 || cond2 { 1 } else { 0 };\n",
        "    }\n",
        "\n",
        "    let mut final_mask = individual;\n",
        "    for t in 0..TRIPLETS {\n",
        "        let idx = triplet_idx(t);\n",
        "        let a = individual[idx[0]];\n",
        "        let b = individual[idx[1]];\n",
        "        let c = individual[idx[2]];\n",
        "        let uniform = (a==b) && (b==c);\n",
        "        if uniform {\n",
        "            final_mask[idx[0]] = a;\n",
        "            final_mask[idx[1]] = a;\n",
        "            final_mask[idx[2]] = a;\n",
        "        } else {\n",
        "            final_mask[idx[0]] = a;\n",
        "            final_mask[idx[1]] = b;\n",
        "            final_mask[idx[2]] = c;\n",
        "        }\n",
        "    }\n",
        "    final_mask\n",
        "}\n",
        "\n",
        "fn apply_parity_rotation(pairs: &[[f32;2]; SLOTS], collapse: &[u8; SLOTS]) -> [[f32;2]; SLOTS] {\n",
        "    let mut rotated = [[0.0f32;2]; SLOTS];\n",
        "    for i in 0..SLOTS {\n",
        "        let affected = (PRIME_MASK_30[i] > 0) || (collapse[i] > 0);\n",
        "        let s = if affected { -1.0f32 } else { 1.0f32 };\n",
        "        rotated[i] = [pairs[i][0]*s, pairs[i][1]*s];\n",
        "    }\n",
        "    rotated\n",
        "}\n",
        "\n",
        "fn bitmap(rotated: &[[f32;2]; SLOTS]) -> [u8; SLOTS] {\n",
        "    let mut bits = [0u8; SLOTS];\n",
        "    for i in 0..SLOTS { bits[i] = if rotated[i][0] > EPS { 1 } else { 0 }; }\n",
        "    bits\n",
        "}\n",
        "\n",
        "fn pack30_to_u32(bits: &[u8; SLOTS]) -> u32 {\n",
        "    let mut x = 0u32;\n",
        "    for i in 0..30 { x |= (bits[i] as u32) << i; }\n",
        "    x\n",
        "}\n",
        "\n",
        "fn pack90(b0: u32, b1: u32, b2: u32) -> (u64,u64) {\n",
        "    let b0 = (b0 & ((1u32<<30)-1)) as u64;\n",
        "    let b1 = (b1 & ((1u32<<30)-1)) as u64;\n",
        "    let b2 = (b2 & ((1u32<<30)-1)) as u64;\n",
        "    let low = b0 | (b1<<30) | ((b2 & 0xF)<<60);\n",
        "    let high = b2 >> 4;\n",
        "    (low, high)\n",
        "}\n",
        "\n",
        "fn commit_full90(instr_counter: u32, w0: u32, w1: u32, w2: u32, initiator: u8, scx: u8, scy: u8, scz: u8) -> [u8;32] {\n",
        "    let mut h = Blake2s256::new();\n",
        "    h.update(b\"NTHISA90\");\n",
        "    h.update(&instr_counter.to_le_bytes());\n",
        "    h.update(&w0.to_le_bytes());\n",
        "    h.update(&w1.to_le_bytes());\n",
        "    h.update(&w2.to_le_bytes());\n",
        "    h.update(&[initiator, scx, scy, scz]);\n",
        "    let out = h.finalize();\n",
        "    let mut a = [0u8;32];\n",
        "    a.copy_from_slice(&out[..]);\n",
        "    a\n",
        "}\n",
        "\n",
        "fn tag_u64(commit: &[u8;32], q: usize, instr_counter: u32) -> u64 {\n",
        "    let mut h = Blake2s256::new();\n",
        "    h.update(b\"NTH_TAG0\");\n",
        "    h.update(commit);\n",
        "    h.update(&(q as u16).to_le_bytes());\n",
        "    h.update(&instr_counter.to_le_bytes());\n",
        "    let out = h.finalize();\n",
        "    u64::from_le_bytes(out[0..8].try_into().unwrap())\n",
        "}\n",
        "\n",
        "fn state_groups(commits: &[[u8;32]; Q]) -> usize {\n",
        "    let mut m: HashMap<[u8;32], u32> = HashMap::new();\n",
        "    for q in 0..Q { *m.entry(commits[q]).or_insert(0) += 1; }\n",
        "    m.len()\n",
        "}\n",
        "\n",
        "fn dedup(commits: &[[u8;32]; Q], efficiency: &[u32; Q]) -> (u32,u32,[bool;Q],[usize;Q]) {\n",
        "    let mut map: HashMap<[u8;32], Vec<usize>> = HashMap::new();\n",
        "    for q in 0..Q { map.entry(commits[q]).or_insert_with(Vec::new).push(q); }\n",
        "\n",
        "    let mut winner_of = core::array::from_fn(|i| i);\n",
        "    let mut active_mask = [true; Q];\n",
        "    let mut collision_qubits = 0u32;\n",
        "\n",
        "    for (_k, qs) in map.iter() {\n",
        "        if qs.len() > 1 { collision_qubits += (qs.len() as u32) - 1; }\n",
        "        let mut best = qs[0];\n",
        "        for &q in qs.iter() {\n",
        "            let eb = efficiency[best];\n",
        "            let eq = efficiency[q];\n",
        "            if (eq < eb) || (eq == eb && q < best) { best = q; }\n",
        "        }\n",
        "        for &q in qs.iter() {\n",
        "            winner_of[q] = best;\n",
        "            if q != best { active_mask[q] = false; }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    (map.len() as u32, collision_qubits, active_mask, winner_of)\n",
        "}\n",
        "\n",
        "fn free_alias(st: &mut ISA) {\n",
        "    if st.mode_pair_hunt {\n",
        "        for q in 0..Q {\n",
        "            if !st.active_mask[q] {\n",
        "                let w = st.winner_of[q];\n",
        "                st.mag_xyz[q] = st.mag_xyz[w];\n",
        "                st.base_sign[q] = st.base_sign[w];\n",
        "            }\n",
        "        }\n",
        "    } else {\n",
        "        for q in 0..Q {\n",
        "            if !st.active_mask[q] {\n",
        "                let mut h = Blake2s256::new();\n",
        "                h.update(b\"NTH_FREE0\");\n",
        "                h.update(&st.commits[q]);\n",
        "                h.update(&(q as u16).to_le_bytes());\n",
        "                h.update(&(st.instr_counter + 1).to_le_bytes());\n",
        "                let out = h.finalize();\n",
        "                let m0 = (out[0] as i32) & 63;\n",
        "                let m1 = (out[1] as i32) & 63;\n",
        "                let m2 = (out[2] as i32) & 63;\n",
        "                let sb = out[3];\n",
        "                let s0 = if (sb & 1) != 0 { 1 } else { -1 };\n",
        "                let s1 = if (sb & 2) != 0 { 1 } else { -1 };\n",
        "                let s2 = if (sb & 4) != 0 { 1 } else { -1 };\n",
        "                st.mag_xyz[q] = [m0,m1,m2];\n",
        "                st.base_sign[q] = [s0,s1,s2];\n",
        "            }\n",
        "        }\n",
        "        st.active_mask = [true; Q];\n",
        "        st.winner_of = core::array::from_fn(|i| i);\n",
        "        st.has_schedule = false;\n",
        "    }\n",
        "}\n",
        "\n",
        "fn stage_measure_transcode(st: &mut ISA) {\n",
        "    st.initiator = initiator_from_shared_counts(&st.mag_xyz);\n",
        "\n",
        "    let active_only = st.active_only_allowed();\n",
        "    let mut do_q = [true; Q];\n",
        "    if active_only {\n",
        "        for q in 0..Q { do_q[q] = st.active_mask[q]; }\n",
        "    }\n",
        "\n",
        "    // winners\n",
        "    for q in 0..Q {\n",
        "        if !do_q[q] { continue; }\n",
        "        let prim6 = build_primaries_from_nec_for_qubit(st.mag_xyz[q], st.base_sign[q]);\n",
        "\n",
        "        for v in 0..3 {\n",
        "            let prim_v = permute_primaries_by_initiator(prim6, v as u8);\n",
        "            let mut swap_sum = 0u8;\n",
        "            let reg30 = build_register30_for_qubit(prim_v, &mut swap_sum);\n",
        "            st.swapcount_xyz[q][v] = swap_sum;\n",
        "\n",
        "            let coll = detect_collapse_triplet_scatter(&reg30);\n",
        "            let rot = apply_parity_rotation(&reg30, &coll);\n",
        "            let bits = bitmap(&rot);\n",
        "\n",
        "            st.packed_views_u32[q][v] = pack30_to_u32(&bits);\n",
        "        }\n",
        "\n",
        "        let (lo, hi) = pack90(st.packed_views_u32[q][0], st.packed_views_u32[q][1], st.packed_views_u32[q][2]);\n",
        "        st.packed90_u64[q] = [lo, hi];\n",
        "\n",
        "        st.commits[q] = commit_full90(\n",
        "            st.instr_counter,\n",
        "            st.packed_views_u32[q][0], st.packed_views_u32[q][1], st.packed_views_u32[q][2],\n",
        "            st.initiator[q],\n",
        "            st.swapcount_xyz[q][0], st.swapcount_xyz[q][1], st.swapcount_xyz[q][2]\n",
        "        );\n",
        "        st.tags_u64[q] = tag_u64(&st.commits[q], q, st.instr_counter);\n",
        "    }\n",
        "\n",
        "    // aliases in PAIR_HUNT\n",
        "    if active_only && st.mode_pair_hunt {\n",
        "        for q in 0..Q {\n",
        "            if !st.active_mask[q] {\n",
        "                let w = st.winner_of[q];\n",
        "                st.packed_views_u32[q] = st.packed_views_u32[w];\n",
        "                st.packed90_u64[q] = st.packed90_u64[w];\n",
        "                st.swapcount_xyz[q] = st.swapcount_xyz[w];\n",
        "                st.commits[q] = st.commits[w];\n",
        "                st.tags_u64[q] = tag_u64(&st.commits[w], q, st.instr_counter);\n",
        "                st.initiator[q] = st.initiator[w];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "fn exec_one(st: &mut ISA, ins: DecodedInstr) {\n",
        "    match ins.op {\n",
        "        Opcode::NecLoad => {\n",
        "            let mut x = (st.instr_counter as u64) ^ (ins.aux32 as u64) ^ 0x9E3779B97F4A7C15u64;\n",
        "            for q in 0..Q {\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                st.mag_xyz[q][0] = (x as i32) & 63;\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                st.mag_xyz[q][1] = (x as i32) & 63;\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                st.mag_xyz[q][2] = (x as i32) & 63;\n",
        "                x ^= x << 13; x ^= x >> 7; x ^= x << 17;\n",
        "                let sb = (x as u8) & 7;\n",
        "                st.base_sign[q][0] = if (sb & 1)!=0 { 1 } else { -1 };\n",
        "                st.base_sign[q][1] = if (sb & 2)!=0 { 1 } else { -1 };\n",
        "                st.base_sign[q][2] = if (sb & 4)!=0 { 1 } else { -1 };\n",
        "            }\n",
        "            st.active_mask = [true; Q];\n",
        "            st.winner_of = core::array::from_fn(|i| i);\n",
        "            st.has_schedule = false;\n",
        "            st.barrier_dedup = false;\n",
        "            st.barrier_all = false;\n",
        "        }\n",
        "        Opcode::NecAlu => {\n",
        "            let subop = ins.imm8;\n",
        "            let dst = (ins.dst_axis as usize).min(2);\n",
        "            let src = (ins.src_axis as usize).min(2);\n",
        "            let imm = ins.imm32;\n",
        "            for q in 0..Q {\n",
        "                let a = st.mag_xyz[q][dst];\n",
        "                let b = st.mag_xyz[q][src];\n",
        "                let v = match subop {\n",
        "                    0 => (a + b) & 63,\n",
        "                    1 => (a - b) & 63,\n",
        "                    2 => (a * b) & 63,\n",
        "                    3 => if b==0 { a } else { (a / b) & 63 },\n",
        "                    4 => (a ^ b) & 63,\n",
        "                    5 => (a + imm) & 63,\n",
        "                    _ => a,\n",
        "                };\n",
        "                st.mag_xyz[q][dst] = v;\n",
        "            }\n",
        "        }\n",
        "        Opcode::PhaseFlip => {\n",
        "            let axis = (ins.dst_axis as usize).min(2);\n",
        "            for q in 0..Q { st.base_sign[q][axis] *= -1; }\n",
        "        }\n",
        "        Opcode::RotAxes => {\n",
        "            let dir = ins.imm8;\n",
        "            for q in 0..Q {\n",
        "                if dir == 0 {\n",
        "                    let m = st.mag_xyz[q];\n",
        "                    let s = st.base_sign[q];\n",
        "                    st.mag_xyz[q] = [m[2], m[0], m[1]];\n",
        "                    st.base_sign[q] = [s[2], s[0], s[1]];\n",
        "                } else {\n",
        "                    let m = st.mag_xyz[q];\n",
        "                    let s = st.base_sign[q];\n",
        "                    st.mag_xyz[q] = [m[1], m[2], m[0]];\n",
        "                    st.base_sign[q] = [s[1], s[2], s[0]];\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        Opcode::ShiftMag => {\n",
        "            let axis = (ins.dst_axis as usize).min(2);\n",
        "            let sh = ins.imm32;\n",
        "            for q in 0..Q {\n",
        "                let a = st.mag_xyz[q][axis];\n",
        "                let v = if sh >= 0 { (a << sh) & 63 } else { (a >> (-sh)) & 63 };\n",
        "                st.mag_xyz[q][axis] = v;\n",
        "            }\n",
        "        }\n",
        "        Opcode::BarrierDedup => st.barrier_dedup = true,\n",
        "        Opcode::BarrierAll => {\n",
        "            st.barrier_all = true;\n",
        "            st.active_mask = [true; Q];\n",
        "            st.winner_of = core::array::from_fn(|i| i);\n",
        "            st.has_schedule = false;\n",
        "        }\n",
        "        Opcode::Pack => stage_measure_transcode(st),\n",
        "        Opcode::Dedup => {\n",
        "            if st.barrier_all {\n",
        "                st.epoch_log.push((st.instr_counter, 2, 0, 0, 64));\n",
        "                st.active_mask = [true; Q];\n",
        "                st.winner_of = core::array::from_fn(|i| i);\n",
        "                st.has_schedule = false;\n",
        "            } else if st.barrier_dedup {\n",
        "                let active = st.active_mask.iter().filter(|&&b| b).count() as u32;\n",
        "                st.epoch_log.push((st.instr_counter, 1, 0, 0, active));\n",
        "            } else {\n",
        "                let mut eff = [0u32; Q];\n",
        "                for q in 0..Q {\n",
        "                    eff[q] = (st.swapcount_xyz[q][0] as u32)\n",
        "                           + (st.swapcount_xyz[q][1] as u32)\n",
        "                           + (st.swapcount_xyz[q][2] as u32);\n",
        "                }\n",
        "                let (groups, collisions, am, wo) = dedup(&st.commits, &eff);\n",
        "                st.active_mask = am;\n",
        "                st.winner_of = wo;\n",
        "                st.has_schedule = true;\n",
        "                let active = st.active_mask.iter().filter(|&&b| b).count() as u32;\n",
        "                st.epoch_log.push((st.instr_counter, 0, groups, collisions, active));\n",
        "            }\n",
        "        }\n",
        "        Opcode::FreeAlias => free_alias(st),\n",
        "        Opcode::Next => {\n",
        "            st.instr_counter += 1;\n",
        "            st.barrier_dedup = false;\n",
        "            st.barrier_all = false;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "fn exec_program(st: &mut ISA, bytecode: &[u8]) {\n",
        "    assert!(bytecode.len() % 16 == 0);\n",
        "    let n = bytecode.len() / 16;\n",
        "    for i in 0..n {\n",
        "        let ins = decode16(&bytecode[i*16..i*16+16]);\n",
        "        exec_one(st, ins);\n",
        "    }\n",
        "}\n",
        "\n",
        "#[pyfunction]\n",
        "fn run_uisa(bytecode: Vec<u8>, mode: &str, exec_active_only: bool) -> PyResult<PyObject> {\n",
        "    if bytecode.len() % 16 != 0 {\n",
        "        return Err(pyo3::exceptions::PyValueError::new_err(\"bytecode length must be multiple of 16\"));\n",
        "    }\n",
        "    let mode_pair_hunt = match mode {\n",
        "        \"FREE\" => false,\n",
        "        \"PAIR_HUNT\" => true,\n",
        "        _ => return Err(pyo3::exceptions::PyValueError::new_err(\"mode must be 'FREE' or 'PAIR_HUNT'\")),\n",
        "    };\n",
        "\n",
        "    let mut st = ISA::new(mode_pair_hunt, exec_active_only);\n",
        "    exec_program(&mut st, &bytecode);\n",
        "\n",
        "    let mut packed_views: Vec<u32> = Vec::with_capacity(Q*3);\n",
        "    let mut packed90: Vec<u64> = Vec::with_capacity(Q*2);\n",
        "    let mut initiator: Vec<u8> = Vec::with_capacity(Q);\n",
        "    let mut active: Vec<u8> = Vec::with_capacity(Q);\n",
        "    let mut winner: Vec<u32> = Vec::with_capacity(Q);\n",
        "    let mut tags: Vec<u64> = Vec::with_capacity(Q);\n",
        "    let mut commits: Vec<u8> = Vec::with_capacity(Q*32);\n",
        "\n",
        "    for q in 0..Q {\n",
        "        packed_views.extend_from_slice(&st.packed_views_u32[q]);\n",
        "        packed90.push(st.packed90_u64[q][0]);\n",
        "        packed90.push(st.packed90_u64[q][1]);\n",
        "        initiator.push(st.initiator[q]);\n",
        "        active.push(if st.active_mask[q] { 1 } else { 0 });\n",
        "        winner.push(st.winner_of[q] as u32);\n",
        "        tags.push(st.tags_u64[q]);\n",
        "        commits.extend_from_slice(&st.commits[q]);\n",
        "    }\n",
        "\n",
        "    let groups = state_groups(&st.commits);\n",
        "\n",
        "    Python::with_gil(|py| {\n",
        "        let dict = PyDict::new(py);\n",
        "        dict.set_item(\"instr_counter\", st.instr_counter)?;\n",
        "        dict.set_item(\"mode_pair_hunt\", st.mode_pair_hunt)?;\n",
        "        dict.set_item(\"state_groups\", groups)?;\n",
        "        dict.set_item(\"packed_views_u32_flat\", packed_views)?;\n",
        "        dict.set_item(\"packed90_u64_flat\", packed90)?;\n",
        "        dict.set_item(\"initiator\", initiator)?;\n",
        "        dict.set_item(\"active_mask\", active)?;\n",
        "        dict.set_item(\"winner_of\", winner)?;\n",
        "        dict.set_item(\"tags_u64\", tags)?;\n",
        "        dict.set_item(\"commits_bytes\", commits)?;\n",
        "        dict.set_item(\"epoch_log\", st.epoch_log)?;\n",
        "        Ok(dict.into())\n",
        "    })\n",
        "}\n",
        "\n",
        "#[pymodule]\n",
        "fn uisa_v10(_py: Python, m: &PyModule) -> PyResult<()> {\n",
        "    m.add_function(wrap_pyfunction!(run_uisa, m)?)?;\n",
        "    Ok(())\n",
        "}\n",
        "RS\n",
        "\n",
        "cd uisa_v10\n",
        "source $HOME/.cargo/env\n",
        "maturin build -q --release\n",
        "python3 -m pip -q install target/wheels/uisa_v10-*.whl\n",
        "echo \"Built and installed uisa_v10 v0.10.1.\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62Tn5jZ5P14g",
        "outputId": "bfe12b8f-e90c-4ffc-8e46-cfc8405c6b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built and installed uisa_v10 v0.10.1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "    Updating crates.io index\n",
            "     Locking 36 packages to latest compatible versions\n",
            "      Adding generic-array v0.14.7 (available: v0.14.9)\n",
            "      Adding pyo3 v0.21.2 (available: v0.27.2)\n",
            "🔗 Found pyo3 bindings\n",
            "🐍 Found CPython 3.12 at /usr/bin/python3\n",
            "warning: use of deprecated associated function `pyo3::types::PyDict::new`: `PyDict::new` will be replaced by `PyDict::new_bound` in a future PyO3 version\n",
            "   --> src/lib.rs:610:28\n",
            "    |\n",
            "610 |         let dict = PyDict::new(py);\n",
            "    |                            ^^^\n",
            "    |\n",
            "    = note: `#[warn(deprecated)]` on by default\n",
            "\n",
            "warning: use of deprecated method `pyo3::deprecations::GilRefs::<T>::function_arg`: use `&Bound<'_, T>` instead for this function argument\n",
            "   --> src/lib.rs:627:26\n",
            "    |\n",
            "627 | fn uisa_v10(_py: Python, m: &PyModule) -> PyResult<()> {\n",
            "    |                          ^\n",
            "\n",
            "📦 Built wheel for CPython 3.12 to /content/uisa_v10/target/wheels/uisa_v10-0.10.1-cp312-cp312-manylinux_2_34_x86_64.whl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2: Run"
      ],
      "metadata": {
        "id": "X-uE0xsUP2L8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import struct\n",
        "import numpy as np\n",
        "import uisa_v10\n",
        "\n",
        "def emit(op, flags=0, gpr_mask=0, dst=0, src=0, imm8=0, imm32=0, aux32=0):\n",
        "    b = bytearray(16)\n",
        "    b[0] = op\n",
        "    b[1] = flags\n",
        "    b[2] = gpr_mask\n",
        "    b[3] = dst\n",
        "    b[4] = src\n",
        "    b[5] = imm8\n",
        "    b[8:12] = struct.pack(\"<i\", imm32)\n",
        "    b[12:16] = struct.pack(\"<I\", aux32)\n",
        "    return bytes(b)\n",
        "\n",
        "# opcodes\n",
        "OP_NEC_LOAD      = 0x01\n",
        "OP_NEC_ALU       = 0x02\n",
        "OP_PHASE_FLIP    = 0x03\n",
        "OP_ROT_AXES      = 0x04\n",
        "OP_SHIFT_MAG     = 0x05\n",
        "OP_BARRIER_DEDUP = 0x06\n",
        "OP_BARRIER_ALL   = 0x07\n",
        "OP_PACK          = 0x15\n",
        "OP_DEDUP         = 0x17\n",
        "OP_FREE_ALIAS    = 0x18\n",
        "OP_NEXT          = 0x19\n",
        "\n",
        "# subops\n",
        "ALU_ADD  = 0\n",
        "ALU_SUB  = 1\n",
        "ALU_MUL  = 2\n",
        "ALU_DIV  = 3\n",
        "ALU_XOR  = 4\n",
        "ALU_ADDI = 5\n",
        "\n",
        "# Program: epoch0 does dedup; epoch1 uses dedup-skip-preserve barrier (so PAIR_HUNT keeps schedule);\n",
        "# epoch2 uses all-exec barrier (forces all active).\n",
        "bc = b\"\".join([\n",
        "    emit(OP_NEC_LOAD, aux32=11),\n",
        "\n",
        "    emit(OP_NEC_ALU, dst=0, src=1, imm8=ALU_ADD),\n",
        "    emit(OP_NEC_ALU, dst=2, src=0, imm8=ALU_XOR),\n",
        "    emit(OP_SHIFT_MAG, dst=1, imm32=1),\n",
        "    emit(OP_PHASE_FLIP, dst=0),\n",
        "    emit(OP_ROT_AXES, imm8=0),\n",
        "\n",
        "    emit(OP_PACK),\n",
        "    emit(OP_DEDUP),\n",
        "    emit(OP_FREE_ALIAS),\n",
        "    emit(OP_NEXT),\n",
        "\n",
        "    # epoch1: compute again, but prevent dedup update while preserving schedule\n",
        "    emit(OP_NEC_ALU, dst=0, src=2, imm8=ALU_MUL),\n",
        "    emit(OP_PACK),\n",
        "    emit(OP_BARRIER_DEDUP),\n",
        "    emit(OP_DEDUP),\n",
        "    emit(OP_NEXT),\n",
        "\n",
        "    # epoch2: force all active barrier\n",
        "    emit(OP_PACK),\n",
        "    emit(OP_BARRIER_ALL),\n",
        "    emit(OP_DEDUP),\n",
        "    emit(OP_NEXT),\n",
        "])\n",
        "\n",
        "def reshape(out):\n",
        "    packed_views = np.array(out[\"packed_views_u32_flat\"], dtype=np.uint32).reshape(64,3)\n",
        "    packed90 = np.array(out[\"packed90_u64_flat\"], dtype=np.uint64).reshape(64,2)\n",
        "    initiator = np.array(out[\"initiator\"], dtype=np.uint8)\n",
        "    active = np.array(out[\"active_mask\"], dtype=np.uint8)\n",
        "    winner = np.array(out[\"winner_of\"], dtype=np.uint32)\n",
        "    tags = np.array(out[\"tags_u64\"], dtype=np.uint64)\n",
        "    commits = bytes(out[\"commits_bytes\"])\n",
        "    commits = [commits[i*32:(i+1)*32] for i in range(64)]\n",
        "    return packed_views, packed90, initiator, active, winner, tags, commits\n",
        "\n",
        "for mode in [\"FREE\", \"PAIR_HUNT\"]:\n",
        "    out = uisa_v10.run_uisa(bytecode=list(bc), mode=mode, exec_active_only=True)\n",
        "    packed_views, packed90, initiator, active, winner, tags, commits = reshape(out)\n",
        "\n",
        "    print(\"\\n=== v0.10 Rust module run ===\")\n",
        "    print(\"mode:\", mode, \"instr_counter:\", out[\"instr_counter\"], \"state_groups:\", out[\"state_groups\"])\n",
        "    print(\"packed_views_u32[0]:\", packed_views[0].tolist())\n",
        "    print(\"packed90_u64[0]:\", packed90[0].tolist())\n",
        "    print(\"initiator counts:\", np.bincount(initiator, minlength=3).tolist())\n",
        "    print(\"active count:\", int(active.sum()), \"aliases:\", 64-int(active.sum()))\n",
        "    print(\"winner_of[0..7]:\", winner[:8].tolist())\n",
        "    print(\"tags_u64[0..3]:\", tags[:4].tolist())\n",
        "    print(\"commit0:\", commits[0].hex()[:32], \"...\")\n",
        "\n",
        "    # epoch log: (t, barrier_mode, groups, collisions, active)\n",
        "    # barrier_mode: 0=normal,1=dedup-skip-preserve,2=all-exec\n",
        "    print(\"epoch_log:\", out[\"epoch_log\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v33uM8_0QC8E",
        "outputId": "ae6226ac-32df-4598-9875-b26c22ed5882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== v0.10 Rust module run ===\n",
            "mode: FREE instr_counter: 3 state_groups: 50\n",
            "packed_views_u32[0]: [604514724, 538601608, 76677124]\n",
            "packed90_u64[0]: [5190005092015155620, 4792320]\n",
            "initiator counts: [27, 16, 21]\n",
            "active count: 64 aliases: 0\n",
            "winner_of[0..7]: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "tags_u64[0..3]: [14082824732673922278, 7249405683105673377, 2863212038624005551, 13821119079048824300]\n",
            "commit0: f8b7e123c69c2bdbcbe82277dbd1e593 ...\n",
            "epoch_log: [(0, 0, 47, 17, 47), (1, 1, 0, 0, 64), (2, 2, 0, 0, 64)]\n",
            "\n",
            "=== v0.10 Rust module run ===\n",
            "mode: PAIR_HUNT instr_counter: 3 state_groups: 44\n",
            "packed_views_u32[0]: [604514724, 538601608, 76677124]\n",
            "packed90_u64[0]: [5190005092015155620, 4792320]\n",
            "initiator counts: [17, 20, 27]\n",
            "active count: 64 aliases: 0\n",
            "winner_of[0..7]: [0, 1, 2, 3, 4, 5, 6, 7]\n",
            "tags_u64[0..3]: [14082824732673922278, 16799423996720699811, 9032297607405725997, 13821119079048824300]\n",
            "commit0: f8b7e123c69c2bdbcbe82277dbd1e593 ...\n",
            "epoch_log: [(0, 0, 47, 17, 47), (1, 1, 0, 0, 47), (2, 2, 0, 0, 64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v0.1.1 GPR, State Select, Active/Freed Exposed Mask"
      ],
      "metadata": {
        "id": "CZktRWTJQQ_q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1 Build"
      ],
      "metadata": {
        "id": "UPS2lf25SGLj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OAXmckdJSIKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2 Run"
      ],
      "metadata": {
        "id": "2LP50neBSJEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uucqEQgDSKYj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}